@article{LEESON2008630,
title = {Cognitive ability, personality, and academic performance in adolescence},
journal = {Personality and Individual Differences},
volume = {45},
number = {7},
pages = {630-635},
year = {2008},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2008.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0191886908002444},
author = {Peter Leeson and Joseph Ciarrochi and Patrick C.L. Heaven},
keywords = {Cognitive ability, Personality, Academic performance, Adolescents, Hope, Self-esteem, Attributional style, Psychometric },
abstract = {Does positive thinking predict variance in school grades over and above that predicted by cognitive ability? Six hundred and thirty nine high school students participated in a three-year longitudinal study that predicted grades using cognitive ability and three positive thinking variables – self-esteem, hope, and attributional style. Hope, positive attributional style and cognitive ability predicted higher grades, whilst self-esteem was a less consistent predictor of academic performance. Structural equation modelling revealed significant paths from cognitive ability, gender, and a second order positive thinking factor to grades. The results suggest that intelligence, gender, and positive thinking each play a unique role in predicting academic performance in youth. Some suggestions for further research are made.}
}
@article{CAMARENA2020122574,
title = {Artificial intelligence in the design of the transitions to sustainable food systems},
journal = {Journal of Cleaner Production},
volume = {271},
pages = {122574},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.122574},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620326214},
author = {Stéphanie Camaréna},
keywords = {Artificial intelligence, Design ethics, Transdisciplinary research, Design for sustainability, Sustainable food systems, Systems thinking},
abstract = {Food systems and our ability to secure food and nutrition for current and future generations is challenged by population growth, climate change, resource depletion and pollution. The current agricultural and supply chain systems are one of the main contributors to the issues. Transformational, not incremental change is needed to transition to sustainable food systems capable of feeding close to 10 billion people in less than 30 years. Artificial intelligence (AI) is pervading all parts of food systems in ways that indicate transformative system changes are possible. Designers, as mediators between people, technology and the environment have a responsibility to recognise and reflect on ways AI could bring the change needed to move to sustainable food systems. This literature review is situated at the intersection of Food systems, Design, Artificial Intelligence and Sustainability. The transdisciplinary approach reveals what exists across the disciplines, what can be done with AI to transition to sustainable food systems, how Design proposes to approach the change, and which ethical or philosophical considerations start to emerge. The discussion reflects on AI as a potential leverage point to bring changes in the system and on the designer's role in establishing the human-technology-environmental relationships. Further research and recommendations are provided.}
}
@article{WANG2016747,
title = {Towards felicitous decision making: An overview on challenges and trends of Big Data},
journal = {Information Sciences},
volume = {367-368},
pages = {747-765},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516304868},
author = {Hai Wang and Zeshui Xu and Hamido Fujita and Shousheng Liu},
keywords = {Big Data, Data deluge, Decision making, Data analysis, Data-intensive applications, Computational social science},
abstract = {The era of Big Data has arrived along with large volume, complex and growing data generated by many distinct sources. Nowadays, nearly every aspect of the modern society is impacted by Big Data, involving medical, health care, business, management and government. It has been receiving growing attention of researches from many disciplines including natural sciences, life sciences, engineering and even art & humanities. It also leads to new research paradigms and ways of thinking on the path of development. Lots of developed and under-developing tools improve our ability to make more felicitous decisions than what we have made ever before. This paper presents an overview on Big Data including four issues, namely: (i) concepts, characteristics and processing paradigms of Big Data; (ii) the state-of-the-art techniques for decision making in Big Data; (iii) felicitous decision making applications of Big Data in social science; and (iv) the current challenges of Big Data as well as possible future directions.}
}
@article{JACKSON201386,
title = {Airflow reversal and alternating corkscrew vortices in foredune wake zones during perpendicular and oblique offshore winds},
journal = {Geomorphology},
volume = {187},
pages = {86-93},
year = {2013},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2012.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X13000081},
author = {Derek W.T. Jackson and Meiring Beyers and Irene Delgado-Fernandez and Andreas C.W. Baas and Andrew J. Cooper and Kevin Lynch},
keywords = {Computational fluid dynamics, Aeolian, Foredunes, Transport, Airflow modelling, Lee side eddies},
abstract = {On all sandy coastlines fringed by dunes, understanding localised air flow allows us to examine the potential sand transfer between the beach and dunes by wind-blown (Aeolian) action. Traditional thinking into this phenomenon had previously included only onshore winds as effective drivers of this transfer. Recent research by the authors, however, has shown that offshore air-flow too can contribute significantly, through lee-side back eddies, to the overall windblown sediment budget to coastal dunes. Under rising sea levels and increased erosion scenarios, this is an important process in any post-storm recovery of sandy beaches. Until now though, full visualisation in 3D of this newly recognised mechanism in offshore flows has not been achieved. Here, we show for the first time, this return flow eddy system using 3D computational fluid dynamics modelling, and reveal the presence of complex corkscrew vortices and other phenomena. The work highlights the importance of relatively small surface undulations in the dune crest which act to induce the spatial patterns of airflow (and transport) found on the adjacent beach.}
}
@incollection{KALBFLEISCH2010641,
title = {2.33 - Genomics, Bioinformatics, and Computational Biology},
editor = {Charlene A. McQueen},
booktitle = {Comprehensive Toxicology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {641-661},
year = {2010},
isbn = {978-0-08-046884-6},
doi = {https://doi.org/10.1016/B978-0-08-046884-6.00236-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780080468846002360},
author = {T.S. Kalbfleisch and G.A. Rempala and K.S. Ramos},
abstract = {In this chapter, we describe how computational biology can be aided by informatics infrastructure to provide the basis for in silico studies that no longer require the generation of data, and instead facilitate the collection, organization, and analysis of existing datasets that can drive discovery. A new reality is that we are awash in data and tools to analyze these data and one of the most significant challenges is that of enabling the researcher to discover datasets relevant to their work, collect these data, assess its quality, and analyze it. The development of an adequate infrastructure within a researcher’s institution greatly facilitates progress on this front, both in terms of the development of tools and the development of local informatics expertise necessary to complement the domain-specific expertise of the researcher. As an informatics community we often ponder the heterogeneity of tools and resources on a global scale at the expense of the more immediate local problems encountered on a routine basis. Here, we suggest that getting our own houses in order by first employing interoperable solutions that support and facilitate collaboration amongst the complementary disciplines within our own institutions places the informatics community in a better position to address global informatics challenges. This approach can ensure that the solutions implemented employ an architecture and standards that support interoperability. Indeed, this is an organizational and cultural challenge rather than a technological one. Organizational structure and practices are described that provide a comprehensive base of talent capable of creating an environment that supports a sustainable informatics infrastructure, and that can quickly grow as needed to support the specific and rapidly evolving needs unique to that institution.}
}
@article{BOELSENROBINSON2021102032,
title = {Mapping factors associated with a successful shift towards healthier food retail in community-based organisations: A systems approach},
journal = {Food Policy},
volume = {101},
pages = {102032},
year = {2021},
issn = {0306-9192},
doi = {https://doi.org/10.1016/j.foodpol.2021.102032},
url = {https://www.sciencedirect.com/science/article/pii/S0306919221000105},
author = {Tara Boelsen-Robinson and Miranda R. Blake and Andrew D. Brown and Oliver Huse and Claire Palermo and Neetu A. George and Anna Peeters},
keywords = {Food retail, Systems mapping, Intervention, Community, Implementation, START map, Nutrition, Policy, Qualitative, Interviews},
abstract = {Background
Food retailers in community settings are gatekeepers to the crucial food systems changes needed to improve population nutrition. Evidence-based models of change are needed to enable shifts in these complex retail environments. Systems thinking offers unique insights by capturing potential unintended consequences and multiple pathways to success. This study sought to create a systems map for retailers, public health practitioners and other stakeholders seeking to implement healthy food retail policies. It aimed to identify (i) points of intervention through which community-based organisations can shift to healthier food provision, and (ii) key feedback loops that could drive potential unintended consequences of such policies in a complex system.
Methods
Semi-structured interviews (n = 26) were conducted, from 2015 to 2018, across four community food retail settings where healthy food retail policies had been implemented in Victoria, Australia. Interviews were coded by identifying causal relationships and their direction between factors. Vensim software was used to merge interview results and then reduce the map to the strongest and most frequent factors and relationships. Illustrative implementation stories and points of intervention were identified.
Findings
The resulting map is titled the Systems Thinking Approach for Retail Transformation (START) map. Five prominent implementation stories incorporating 17 factors highlighted that: 1) retailer resistance to change is strongest in the beginning but decreases with the demonstration of favourable initiative outcomes; 2) successive changes tend to be increasingly complex, and therefore harder for retailers to implement; 3) organisational resourcing can be influenced through multiple pathways; 4) customer acceptability of healthy changes and retailers' willingness to engage in changes influence each other; and 5) challenges in accessing healthy supply options make retailers more resistant to implementing healthy changes.
Conclusions
The application of systems thinking to the challenge of unhealthy food retail creates novel and practical insights for retailers and health promotion practitioners into what actions are most likely to promote healthy changes in complex retail environments.}
}
@article{CARNEY2004135,
title = {Denis Noble discusses his career in computational biology},
journal = {Drug Discovery Today: BIOSILICO},
volume = {2},
number = {4},
pages = {135-137},
year = {2004},
issn = {1741-8364},
doi = {https://doi.org/10.1016/S1741-8364(04)02414-X},
url = {https://www.sciencedirect.com/science/article/pii/S174183640402414X},
author = {Stephen Carney},
keywords = {Interview, computer modeling, grid computing, cardiac electrophysiology, whole organ models, arrhythmia},
abstract = {Denis Noble was born in 1936 and obtained a BSc and PhD from University College London. He is one of the pioneers of computational biology related to cardiac cell electrophysiology and its incorporation into the first detailed biophysical models of the whole organ. He has made many major contributions to this work spanning from his groundbreaking work in 1960, showing that in heart, contrary to the situation in nerve, the first effect of membrane depolarisation is to greatly reduce potassium conductance, which in turn is greatly dependent on plasma potassium levels. His work over the last forty years has culminated in a highly successful virtual model of the heart, which has allowed theoretical interpretation of cardiac arrhythmias and the development of antiarrhythmic drugs. Professor Noble was made a fellow of the Royal Society in 1979, one of the highlights of his many awards. He is in great demand as a presenter of plenary lectures at many august meetings. In addition to his abilities as a computational biologist, Professor Noble is an accomplished linguist and has given lectures in French and Italian, and has significant abilities in Japanese, Korean and even Maori.}
}
@article{LAZARO2021111384,
title = {Policy and governance dynamics in the water-energy-food-land nexus of biofuels: Proposing a qualitative analysis model},
journal = {Renewable and Sustainable Energy Reviews},
volume = {149},
pages = {111384},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111384},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121006699},
author = {Lira Luz Benites Lazaro and Leandro Luiz Giatti and Celio Bermann and Angelica Giarolla and Jean Ometto},
keywords = {Water–energy–food nexus, Nexus thinking, Governance, Policy, Biofuels, Nexus methodology, Nexus method, Innovation},
abstract = {The production of biofuels is inextricably linked with the water-energy-food-land (WEFL) nexus. Understanding these linkages is necessary to formulate effective policies that can influence positive outcomes and contribute to the realization of long-term economic, environmental, and social goals. The use of biofuels can help achieve the United Nation's Sustainable Development Goals (SDGs) and implement the Paris Agreement on climate change. However, the biofuels sector must account for its interdependencies and trade-offs with other sectors. In this study, we formulate a qualitative analytical model that goes beyond the three water-energy-food nexus components by incorporating other elements, such as policy, innovation, governance, and labor to examine their effect as influencing factors and to understand how synergies, trade-offs, and long-overlooked interlinkages between sectors and among existing policies and institutions can become visible. This qualitative model was applied to the case of ethanol in Brazil, for which a large corpus was constructed from the scientific literature, documents and sustainability reports from sugarcane ethanol companies. We used a supervised latent Dirichlet allocation (sLDA) algorithm along with co-occurrence and network analyses. The results demonstrate this approach can be used to evaluate the interfaces between science, policy, and businesses within the WEFL-biofuels nexus. This is done by identifying how best to integrate the development of policies, governance, and stakeholder actions to support cost-effective decisions for optimal resource management and regulatory processes while enabling better integration of scientific insight and policy-making. We also identified how these four influencing factors are of vital importance within the nexus and, if properly addressed, can contribute to more holistic nexus thinking management.}
}
@article{LI2024141569,
title = {Programming experiment course for innovative and sustainable education: A case study of Java for Millikan Oil-Drop experiment},
journal = {Journal of Cleaner Production},
volume = {447},
pages = {141569},
year = {2024},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2024.141569},
url = {https://www.sciencedirect.com/science/article/pii/S0959652624010175},
author = {Yizheng Li and Guandong Su and Haocheng Pan and Chengwei Tan and Gongsheng Li},
keywords = {Laboratory instruction, Java object-oriented programming, Innovative and sustainable education, Student-centered learning},
abstract = {A teaching approach of programming experiment courses with a new education process is proposed in this study to improve the sustainability of engineering education and extend the accessibility of lab experiments across experiment courses, with the goal of encouraging innovative and scientific thinking among students. The Millikan Oil-Drop experiment combined with Java object-oriented programming is demonstrated as a case study to validate the feasibility and advantages of this teaching approach. The new education process of the experiment course is designed based on Jean Piaget's cognitive development theory, which has high practical potential for popularization among tertiary institutions without additional cost. Additionally, this work discussed the relevance of the general criterion of the Accreditation Board for Engineering and Technology on student outcomes to educational accreditation, further indicating that introducing programming into experiment education can improve students' all-round ability and strengthen the triangular relationship among the three main subjects in tertiary education, namely, students, faculty, and higher educational institutions. This study may serve as an educational guide for teachers and tertiary institutions to pursue innovative and sustainable education.}
}
@article{ARUN2009S1115,
title = {P03-116 Damage to object oriented programming in the brain explains many of the psychopathological features of schizophrenia},
journal = {European Psychiatry},
volume = {24},
pages = {S1115},
year = {2009},
note = {17th EPA Congress - Lisbon, Portugal, January 2009, Abstract book},
issn = {0924-9338},
doi = {https://doi.org/10.1016/S0924-9338(09)71348-3},
url = {https://www.sciencedirect.com/science/article/pii/S0924933809713483},
author = {C.P. Arun},
abstract = {Introduction
Modern computers often use programs that incorporate a programming technique called Object Oriented Programming (OOP), allowing users to manipulate complex ‘computational objects’ such as menus, screen windows, etc with very little effort, say the click of a mouse. OOP deals with structures called objects and allows time and computational effort saving devices such as inheritance, polymorphism and encapsulation. We examine whether the brain itself may use OOP and if representation of objects suffers a breakdown in schizophrenia.
Review of literature
Previous models fail to provide a unifying explanation with a computational basis that could explain the psychopathology in schizophrenia. METHODS Using the object oriented programming language JavaTM we designed a system of self-objects named ‘hand’, ‘action monitor’ etc interacting with non-self objects ‘scissors’, ‘hammer’, ‘wall’, etc. In computational experiments, we allow the ‘action monitor’ to fail; the features of disparate objects are allowed to merge, some features of an object are allowed to be shared with other objects, etc.
Results
By transposing only a few lines of code, it is possible to duplicate various features of the psychopathology of schizophrenia.
Discussion
Our model can demonstrate overinclusion (overabstraction), concrete thinking (underabstraction), loss of ego boundaries (conjoining of disparate objects), delusions (misattribution of object function), lack of insight (poor monitoring of object activity) and passivity (loss of monitoring and misattribution of object activity).
Conclusion
The brain must use the OOP model in its computations. Failure of object representation and manipulation must lie at the core of the psychopathology of schizophrenia.}
}
@article{WEBB2008360,
title = {The role of teacher instructional practices in student collaboration},
journal = {Contemporary Educational Psychology},
volume = {33},
number = {3},
pages = {360-381},
year = {2008},
note = {Collaborative Discourse, Argumentation, and Learning},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2008.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X0800026X},
author = {Noreen M. Webb and Megan L. Franke and Marsha Ing and Angela Chan and Tondra De and Deanna Freund and Dan Battey},
keywords = {Instructional practices, Student collaboration},
abstract = {Prior research on collaborative learning identifies student behaviors that significantly predict student achievement, such as giving explanations of one’s thinking. Less often studied is the role of teachers’ instructional practices in collaboration among students. This article investigates the extent to which teachers engage in practices that support students’ explanations of their thinking, and how these teacher practices might be related to the nature of explanations that students give when asked by the teacher to collaborate with each other. The teachers observed here, all of whom received specific instruction in eliciting the details of student thinking, varied significantly in the extent to which they asked students to elaborate on their suggestions. This variation corresponded to variation across classrooms in the nature and extent of student explanations during collaborative conversations and to differences in student achievement.}
}
@article{SANTOS2023102749,
title = {Policy entrepreneurs in the global education complex: The case of Finnish education experts working in international organisations},
journal = {International Journal of Educational Development},
volume = {98},
pages = {102749},
year = {2023},
issn = {0738-0593},
doi = {https://doi.org/10.1016/j.ijedudev.2023.102749},
url = {https://www.sciencedirect.com/science/article/pii/S0738059323000263},
author = {Íris Santos and Elias Pekkola},
keywords = {Development cooperation for education, Influence, Finnish education experts, Complexity, Multiple streams approach},
abstract = {This article analyses the perceived role of Finnish education experts working in development cooperation for education. We interviewed 31 education experts working in international organisations representing Finland. A theoretically pluralist approach is utilised combining complexity thinking with a multiple streams approach. The analysis demonstrates that the context of educational development cooperation is ambiguous and complex. Influencing policymaking is a strategic, non-linear task which takes time, resources, and personal skills. Policy entrepreneurs need to understand the dynamics of development cooperation, identify actors that trust them, and recognise when policy windows are likely to open.}
}
@incollection{MAURYA2010175,
title = {Chapter 8 - Computational Challenges in Systems Biology},
editor = {Edison T. Liu and Douglas A. Lauffenburger},
booktitle = {Systems Biomedicine},
publisher = {Academic Press},
address = {San Diego},
pages = {175-223},
year = {2010},
isbn = {978-0-12-372550-9},
doi = {https://doi.org/10.1016/B978-0-12-372550-9.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123725509000080},
author = {Mano Ram Maurya and Shankar Subramaniam},
abstract = {Publisher Summary
This chapter examines the challenges and some of the recent advances in computational systems biology. Research in computational systems biology has moved beyond interaction networks based simply on clustering and correlation. There are two paradigms in computational systems biology: the iterative cycle of biochemical model—mathematical model—computational model, and integration of novel data and legacy knowledge to develop context-specific biochemical, mathematical, and computational models. Challenges in building biochemical models include the complexity of proteomic states and interactions, integration of diverse data to infer biochemical interactions, and the temporal state of biochemical models. Challenges in building mathematical models include incorporating statistical/probabilistic information into analytical models, using qualitative constraints in mathematical models, and incomplete knowledge and coarse-graining. Challenges in computational modeling include the absence of knowledge about model parameters such as rate constants, local versus global concentrations of species and multiple scales of distance and time, and variation among different cell types and subpopulation variability, or variability among biological repeats. Advanced research in coarse graining will pave the way for progress in the development of multiscale multidomain modeling that can connect fundamental research in network biology to clinical research.}
}
@article{ANDROUTSOPOULOS2024100817,
title = {Scaling as method: A three-stage, mixed-methods approach to digital discourse analysis},
journal = {Discourse, Context & Media},
volume = {62},
pages = {100817},
year = {2024},
issn = {2211-6958},
doi = {https://doi.org/10.1016/j.dcm.2024.100817},
url = {https://www.sciencedirect.com/science/article/pii/S2211695824000631},
author = {Jannis Androutsopoulos},
keywords = {Scaling, Mixed-methods, Digital discourse, Abduction, Indignation mark, Reddit},
abstract = {Drawing on research on graphic contextualization cues in punctuation and typography, this paper describes a three-stage, mixed-methods approach to digital discourse analysis. It introduces the terms ‘scale’ and ‘scaling’ as methodological metaphors for a researcher’s planned, yet contingent movement through formations of digital textual data that differ in terms of volume, method of collection, processing, and analysis. ‘Scaling-as-method’ aims to replace static binaries (such as ‘micro’ and ‘macro’, ‘small’ and ‘big’ data, ‘manual’ and ‘automated’ processing) by the vision of a researcher who shifts their degree of abstraction, or ‘distance’, towards digital data, while moving from close to distant reading and back again. The paper exemplifies this three-stage process on the example of the indignation mark, aka <!!1>, a twist on the iterated exclamation mark that is attested in digital discourse in various languages as a cue of double-voicing. The explorative examination of a small dataset (Stage 1) leads to the computational collection and distributional analysis of a much larger dataset (‘scaling up’, Stage 2), followed by the manual annotation of a selected subset of this data (‘scaling down’, Stage 3). Each stage draws on a different amount of data, which enables different techniques of processing and analysis, and relies on a specific combination of abductive, deductive, and inductive reasoning. Yet all three stages complement one another in a kaleidoscopic way towards understanding connections between punctuation practices and participatory political discourse online. Scaling as method is not a closed recipe, but an adaptable procedure that can be applied to a variety of discrete digital features. It does not aim to replace established methods of computational social media analysis, but to boost research that is predominantly based on the manual collection and annotation of social media data, and to enables a dialogue between multiple understandings of context.}
}
@article{AKTAYEVA2022285,
title = {Aesthetic education: the process of teaching mathematics with the open-source software},
journal = {Transportation Research Procedia},
volume = {63},
pages = {285-293},
year = {2022},
note = {X International Scientific Siberian Transport Forum — TransSiberia 2022},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2022.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S2352146522002708},
author = {Alena Aktayeva and Elena Zubareva and Aibek Dautov and Kymbat Saginbayeva and Rozamgul Niyazova and Sergey Khan and Aigerim Shonasheva},
keywords = {Aesthetic education, mathematical education, software, computer programs},
abstract = {In the article one of leading aims of educating mathematics is examined is aesthetic education of student facilities of mathematics. Presentation of aesthetic beauty at her decisions possibility of students is investigated, specifying them on the decision of one problem in several ways that assists the detailed consideration of idea of aesthetic education, through Open-source Software. The technical capabilities and elegant ease of use of systems Open-source Software provides a seamless, integrated and constantly expanding system that covers the breadth and depth of mathematical computing, and is available seamlessly through any web browser along with all modern systems used in the educational process. The article will describe understanding of beauty the decision of a problem; methods of decisions that are accompanied by the use make possible a uniquely flexible and convenient approach to charting and information visualization in a mathematical calculate. Such sort of activity assists aesthetic education, allowing to develop a culture and logical thinking, forming at students a different choice, grace of decision of problems.}
}
@article{HAWES201560,
title = {Effects of mental rotation training on children’s spatial and mathematics performance: A randomized controlled study},
journal = {Trends in Neuroscience and Education},
volume = {4},
number = {3},
pages = {60-68},
year = {2015},
issn = {2211-9493},
doi = {https://doi.org/10.1016/j.tine.2015.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211949315000083},
author = {Zachary Hawes and Joan Moss and Beverly Caswell and Daniel Poliszczuk},
keywords = {Spatial thinking, Mental rotation, Spatial training, Computerized cognitive training, Mathematics education, STEM},
abstract = {The purpose of the current study was to (i) investigate the malleability of children’s spatial thinking, and (ii) the extent to which training-related gains in spatial thinking generalize to mathematics performance. Sixty-one 6- to 8-year-olds were randomly assigned to either computerized mental rotation training or literacy training. Training took place on iPad devices over a 6-week period as part of regular classroom activity. Results revealed that in comparison to the control group, children who received spatial training demonstrated significant gains on two measures of mental rotation and marginally significant improvements on an untrained mental transformation task; a finding that suggests that training may have had a general effect on children’s spatial ability. However, contrary to theoretical claims and prior empirical findings, there was no evidence that spatial training transferred to mathematics performance.}
}
@article{IWASE20211,
title = {Towards a Noncompliant Pedagogy of the Image: Reading Negentropic Bifurcatory Potentials in Video Images},
journal = {Video Journal of Education and Pedagogy},
volume = {6},
number = {1},
pages = {1-27},
year = {2021},
issn = {2364-4583},
doi = {https://doi.org/10.1163/23644583-bja10020},
url = {https://www.sciencedirect.com/science/article/pii/S236445832300023X},
author = {Masayuki Iwase and Joff P. N. Bradley},
keywords = {urban film-making, critique, metamodelization, global mnemotechnical system, proletarianized knowledge, mnemonic control, artificial and living engines, machinic enslavement, negentropic bifurcation, Deleuze, Heidegger, Virilio, time-image, lectosign, spiritual automation, zooming-in/out, autistic milieus, diffractive becoming, radical pedagogy},
abstract = {The authors explore the noncompliant pedagogy of the image based on their video Autopoietic Veering: Schizo Socius of Tokyo and Vancouver (2021). It is not the kind of trendy modelized video abstract or kinetic presentation eagerly promoted by international publishers; it is a cross-cultural collaborative work intended to generate affirmative temporal ruptures of entropic habitual modes of seeing, memorizing, and thinking of human and nonhuman life in the cities of Tokyo (Japan) and Vancouver (Canada). The authors elucidate Stiegler’s (2015b) concept of a “global mnemotechnical system” that stores and produces human memories in vast digital archives and databases (tertiary retentions) through “mnemonic control” (Parisi & Goodman, 2011). The authors repurpose video images to interrupt and recontrol human perception and memories as “living engines” (Lazzarato, 2006). They foreground the philosophical work of Deleuze, Heidegger, and Virilio to rethink and revive the creative act of “critique” (Foucault, 1997) through “metamodelization” (Guattari, 1995; Manning, 2020); therefore, they plug these apparently incommensurable modes of thinking into their readings of the video’s images. They read the images as “time-images” and focus on their five dimensions that possibly activate “spiritual automation” (Deleuze, 1989), which they assess as “negentropic bifurcatory” potentials (Bradley & Kennedy, 2019).}
}
@article{LOPEZORTEGA20133459,
title = {Computer-assisted creativity: Emulation of cognitive processes on a multi-agent system},
journal = {Expert Systems with Applications},
volume = {40},
number = {9},
pages = {3459-3470},
year = {2013},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2012.12.054},
url = {https://www.sciencedirect.com/science/article/pii/S095741741201295X},
author = {Omar López-Ortega},
keywords = {Computer-assisted creativity, Cognitive processes, Agent-oriented programming, Recursive systems},
abstract = {For creativity to be computed, it is paramount to understand the cognitive processes involved, which have been elucidated by either surveying creative people or discovering regions of the human brain that activate during creative endeavors. From this scattering, the author proposes a holistic framework to describe them and their interaction. Hence, creativity can be regarded as a meta process which coordinates autonomous cognitive processes such as planning or divergent thinking. To represent the interplay of cognitive processes around creativity, models are developed in the Agent Unified Modeling Language (AUML). Then, the execution of each process is delegated to autonomous agents and a global coordination protocol is devised. The implementation of the MAS is done on the JADE platform. Two modules of the resultant system are exemplified: opus planning and divergent exploration. The coordination protocol is also presented. The domain in which the software system is tested is the creation of musical pieces.}
}
@article{ZHENG2025192,
title = {The unbearable slowness of being: Why do we live at 10 bits/s?},
journal = {Neuron},
volume = {113},
number = {2},
pages = {192-204},
year = {2025},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2024.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0896627324008080},
author = {Jieyu Zheng and Markus Meister},
keywords = {human behavior, speed of cognition, neural computation, bottleneck, attention, neural efficiency, information rate, memory sports},
abstract = {Summary
This article is about the neural conundrum behind the slowness of human behavior. The information throughput of a human being is about 10 bits/s. In comparison, our sensory systems gather data at ∼109 bits/s. The stark contrast between these numbers remains unexplained and touches on fundamental aspects of brain function: what neural substrate sets this speed limit on the pace of our existence? Why does the brain need billions of neurons to process 10 bits/s? Why can we only think about one thing at a time? The brain seems to operate in two distinct modes: the “outer” brain handles fast high-dimensional sensory and motor signals, whereas the “inner” brain processes the reduced few bits needed to control behavior. Plausible explanations exist for the large neuron numbers in the outer brain, but not for the inner brain, and we propose new research directions to remedy this.}
}
@article{MUST20167,
title = {Predicting the Flynn Effect through word abstractness : Results from the National Intelligence Tests support Flynn's explanation},
journal = {Intelligence},
volume = {57},
pages = {7-14},
year = {2016},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0160289616300253},
author = {Olev Must and Aasa Must and Jaan Mikk},
keywords = {Flynn Effect, National Intelligence Tests, Abstract thinking, Guessing, Tork, Estonia},
abstract = {The current study investigates the Flynn Effect (FE) and its relation to abstract thinking ability. We compare two cohorts of Estonian students (1933/36, n=888; 2006, n=912) using the Concepts (Logical Selection) subtest of the Estonian adaptation of the National Intelligence Tests (NIT). The item presentation order of the subtest correlates with the abstractness of the words used in the items (r=.609) of the subtest. The different test results (right, wrong and missing answers) were analysed in order to make an estimate of the FE magnitude. The FE for abstract thinking ability of those samples was 1.06 Hedges' g (adjusted for guessing). The magnitude of the FE is dependent upon the degree of difficulty of the items (an item's difficulty is estimated by determining its abstractness and its familiarity to students). The more difficult part of the subtest (the second half) showed a FE=1.80 whereas the easier part (the first half) of the subtest showed a FE=.72. Word abstractness was a strong predictor of all the testing results in both cohorts (Beta=.700). The familiarity of words used in the test items has no correlation with the test results if word abstractness is controlled in both cohorts. Our findings support Flynn's explanation that the FE is primarily an indicator of the rise in abstract thinking ability.}
}
@article{CHATURVEDI2005694,
title = {Agent-based simulation for computational experimentation: Developing an artificial labor market},
journal = {European Journal of Operational Research},
volume = {166},
number = {3},
pages = {694-716},
year = {2005},
note = {Advances in Complex Systems Modeling},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2004.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S0377221704004102},
author = {Alok Chaturvedi and Shailendra Mehta and Daniel Dolk and Rick Ayer},
keywords = {Artificial intelligence, Decision support systems, Simulation, Modelling systems and languages, Economics},
abstract = {This paper discusses the creation of an artificial labor market (ALM) as an agent-based simulation model. We trace the development of the ALM by adapting the traditional simulation life cycle into two main parts: the model phase and the simulation phase. In the modeling phase of the life cycle, we focus upon agent representation and specification within the virtual world. In the simulation phase, we discuss the use of scenario planning as the experimentation vehicle. Throughout, we use military recruit market as an example to illustrate the methodology. The benefits of the ALM are (1) it provides a virtual world for continuous computational experimentation, (2) it supports market segmentation by allowing “drilldowns” to finer and finer levels of granularity, and (3) when connected via a common OLAP interface to a “real world” counterpart, it facilitates a tightly integrated, persistent, “sense and respond” decision support functionality.}
}
@article{DUAN2024100234,
title = {Making waves: Knowledge and data fusion in urban water modelling},
journal = {Water Research X},
volume = {24},
pages = {100234},
year = {2024},
issn = {2589-9147},
doi = {https://doi.org/10.1016/j.wroa.2024.100234},
url = {https://www.sciencedirect.com/science/article/pii/S2589914724000240},
author = {Haoran Duan and Jiuling Li and Zhiguo Yuan},
keywords = {Modelling, Data-driven, Machine learning, Hybrid model, Urban water systems},
abstract = {Mathematical modeling plays a crucial role in understanding and managing urban water systems (UWS), with mechanistic models often serving as the foundation for their design and operations. Despite the wide adoptions, mechanistic models are challenged by the complexity of dynamic processes and high computational demands. Data-driven models bring opportunities to capture system complexities and reduce computational cost, by leveraging the abundant data made available by recent advance in sensor technologies. However, the interpretability and data availability hinder their wider adoption. This paper advocates for a paradigm shift in the application of data-driven models within the context of UWS. Integrating existing mechanistic knowledge into data-driven modeling offers a unique solution that reduces data requirements and enhances model interpretability. The knowledge-informed approach balances model complexity with dataset size, enabling more efficient and interpretable modeling in UWS. Furthermore, the integration of mechanistic and data-driven models offers a more accurate representation of UWS dynamics, addressing lingering uncertainties and advancing modelling capabilities. This paper presents perspectives and conceptual framework on developing and implementing knowledge-informed data-driven modeling, highlighting their potential to improve UWS management in the digital era.}
}
@article{SVOZIL2005845,
title = {Computational universes},
journal = {Chaos, Solitons & Fractals},
volume = {25},
number = {4},
pages = {845-859},
year = {2005},
note = {TRANSFINITE PHYSICS Treading the Path of Cantor and Einstein A collection of papers in honour of the Egyptian Engineering Scientist},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2004.11.055},
url = {https://www.sciencedirect.com/science/article/pii/S0960077904007830},
author = {Karl Svozil},
abstract = {Suspicions that the world might be some sort of a machine or algorithm existing “in the mind” of some symbolic number cruncher have lingered from antiquity. Although popular at times, the most radical forms of this idea never reached mainstream. Modern developments in physics and computer science have lent support to the thesis, but empirical evidence is needed before it can begin to replace our contemporary world view.}
}
@incollection{KENDRICK2008685,
title = {Chapter 17 The Supporting Role of Molecular Modelling and Computational Chemistry in Polymer Analysis},
editor = {John M. Chalmers and Robert J. Meier},
series = {Comprehensive Analytical Chemistry},
publisher = {Elsevier},
volume = {53},
pages = {685-734},
year = {2008},
booktitle = {Molecular Characterization and Analysis of Polymers},
issn = {0166-526X},
doi = {https://doi.org/10.1016/S0166-526X(08)00417-0},
url = {https://www.sciencedirect.com/science/article/pii/S0166526X08004170},
author = {John Kendrick},
abstract = {Publisher Summary
Molecular modeling covers a wide range of techniques and the calculation of an even wider range of properties. Although for polymers, the possibility of treating a polymer chain quantum mechanically is formidable, it is clear that the modeling approach allows calculations on monomers, dimmers, and oligomers to guide the interpretation of many spectroscopic observations with great success. For those systems, where longer times scales and larger size scales are important, molecular mechanics and molecular dynamics methods are available, but the issue of the force field and the approximations that it introduces remain significant. The key to the change in attitude to modeling and its role have to lie in the availability of mature algorithms with well-known and well-understood properties. The density functional theory method in quantum mechanics has introduced a new era in applications of quantum mechanical methods.}
}
@article{CHENG2024104948,
title = {Exploring differences in self-regulated learning strategy use between high- and low-performing students in introductory programming: An analysis of eye-tracking and retrospective think-aloud data from program comprehension},
journal = {Computers & Education},
volume = {208},
pages = {104948},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104948},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002257},
author = {Gary Cheng and Di Zou and Haoran Xie and Fu Lee Wang},
keywords = {Introductory programming, Self-regulated learning strategies, Eye tracking, Retrospective think aloud, Higher education},
abstract = {Previous studies have reported mixed results regarding the relationship between students’ use of self-regulated learning (SRL) strategies and their performance in introductory programming courses. These studies were constrained by their reliance on self-report questionnaires as a means of collecting and analysing data. To address this limitation, this study aimed to employ eye-tracking and retrospective think-aloud techniques to identify differences in SRL strategy use for program comprehension tasks between high-performing students (N = 31) and low-performing students (N = 31) in an undergraduate programming course. All participants attended individual eye-tracking sessions to comprehend two Python program codes with different constructs. Their eye-tracking data and video-recalled retrospective think-aloud data were captured and recorded for analysis. The findings reveal that higher-order cognitive skills, such as elaboration and critical thinking, were mostly adopted by high-performing students, while basic cognitive and resource management strategy, such as rehearsal and help-seeking, were mostly employed by low-performing students when comprehending the program codes. This study not only demonstrates the design of combining eye-tracking and retrospective think-aloud data to explore students’ use of SRL strategies but also provides evidence to support the notion that program comprehension is a complex process that cannot be effectively addressed by employing merely rudimentary strategies, such as repetitively reading the same code segment. In the future, researchers could explore the possibility of using a webcam to monitor and assess students’ online programming processes and provide feedback based on their eye movements. They could also examine the effects of SRL strategies training on students’ motivation, engagement, and performance in various types of programming activities.}
}
@article{CRILLY2021309,
title = {The Evolution of “Co-evolution” (Part I): Problem Solving, Problem Finding, and Their Interaction in Design and Other Creative Practices},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {7},
number = {3},
pages = {309-332},
year = {2021},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2021.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2405872621000915},
author = {Nathan Crilly},
keywords = {Design process, Design thinking, Creativity, Design history, Interdisciplinarity},
abstract = {One of the most influential descriptions of design activity emphasizes how problems and solutions “co-evolve.” This concept has somehow escaped critical review and cross-disciplinary comparison, resulting in a fragmented approach to the subject. Reviewing the published literature on design co-evolution reveals that the term is used to refer to a range of distinct concepts, and the study of co-evolution has generated a number of elaborations and alternatives. Reviewing the broader literature in design and other disciplines further reveals that discussions of design co-evolution are disconnected from the history of relevant concepts in design research, and disconnected from a range of relevant concepts in other disciplines that describe creative work. Here I examine what the different concepts of design co-evolution are, how they have been modified and what they are related to. This leads to questioning the distinction between problems and solutions, defining them in relative terms, and drawing a connection between design co-evolution and design fixation.}
}
@article{CHISCI1995487,
title = {Fast Computation of Stabilizing Predictive Control Laws},
journal = {IFAC Proceedings Volumes},
volume = {28},
number = {5},
pages = {487-493},
year = {1995},
note = {3rd IFAC/IFIP Workshop on Algorithms and Architectures for Real-Time Control 1995 (AARTC'95), Ostend, Belgium, 31 May-2 June 1995},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)47270-3},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017472703},
author = {L. Chisci and A. Garulli and G. Zappa},
keywords = {Predictive control, linear quadratic regulators, control algorithms, fast parallel algorithms, fast Kalman algorithms, computational methods, adaptive control},
abstract = {A fast algorithm for Linear Quadratic(LQ) control with linear equality constraints is derived and exploited for stabilizing predictive control synthesis. The algorithm requires only O(Nn) computations for an nth order plant and N-steps prediction horizon, and possesses a remarkable numerical accuracy.}
}
@article{PIAW20114019,
title = {Establishing a Brain Styles Test: The YBRAINS Test},
journal = {Procedia - Social and Behavioral Sciences},
volume = {15},
pages = {4019-4027},
year = {2011},
note = {3rd World Conference on Educational Sciences - 2011},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2011.04.407},
url = {https://www.sciencedirect.com/science/article/pii/S1877042811009530},
author = {Chua Yan Piaw},
keywords = {Brain style, thinking and learning, YBRAINS, validity and reliability},
abstract = {Teaching with knowledge of students’ thinking and learning styles increases its effectiveness. The YBRAINS test is developed to help school teachers to understand the thinking and learning readiness levels of their students in the process of providing effective teaching and learning activities. The test was established based on theories and brain experiment research evidences. This article reports the rationale of establishing the test and its validity and reliability.}
}
@article{LEE2021100737,
title = {Turbulent boundary layer trailing-edge noise: Theory, computation, experiment, and application},
journal = {Progress in Aerospace Sciences},
volume = {126},
pages = {100737},
year = {2021},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2021.100737},
url = {https://www.sciencedirect.com/science/article/pii/S0376042121000427},
author = {Seongkyu Lee and Lorna Ayton and Franck Bertagnolio and Stephane Moreau and Tze Pei Chong and Phillip Joseph},
keywords = {Trailing-edge noise, Aeroacoustics, Turbulent boundary layer},
abstract = {When the pressure fluctuations caused by turbulence vorticity in the boundary layer are scattered by a sharp trailing edge, acoustic energy is generated and propagated to the far field. This trailing edge noise is emitted from aircraft wings, turbomachinery blades, wind turbine blades, helicopter blades, etc. Being dominant at high frequencies, this trailing-edge noise is a key element that annoys human hearing. This article covers virtually the entire landscape of modern research into trailing-edge noise including theoretical developments, numerical simulations, wind tunnel experiments, and applications of trailing-edge noise. The theoretical approach includes Green’s function formulations, Wiener–Hopf methods that solve the mixed boundary-value problem, Howe’s and Amiet’s models that relate the wall pressure spectrum to acoustic radiation. Recent analytical developments for poroelasticity and serrations are also included. We discuss a hierarchy of numerical approaches that range from semi-empirical schemes that estimate the wall pressure spectrum using mean-flow and turbulence statistics to high-fidelity unsteady flow simulations such as Large Eddy Simulation (LES) or Direct Numerical Simulation (DNS) that resolve the sound generation and scattering process based on the first-principles flow physics. Wind tunnel experimental research that provided benchmark data for numerical simulations and unravel flow physics is reviewed. In each theoretical, numerical, and experimental approach, noise control methods for mitigating trailing-edge noise are discussed. Finally, highlights of practical applications of trailing-edge noise prediction and reduction to wind turbine noise, fan noise, and rotorcraft noise are given. The current challenges in each approach are summarized with a look toward the future developments. The review could be useful as a primer for new researchers or as a reference point to the state of the art for experienced professionals.}
}
@article{MILLER1993205,
title = {Educational tools for computational modelling},
journal = {Computers & Education},
volume = {21},
number = {3},
pages = {205-261},
year = {1993},
issn = {0360-1315},
doi = {https://doi.org/10.1016/0360-1315(93)90019-F},
url = {https://www.sciencedirect.com/science/article/pii/036013159390019F},
author = {Rob Miller and Jon Ogborn and Jonathan Briggs and Derek Brough and Joan Bliss and Richard Boohan and Tim Brosnan and Harvey Mellar and Babis Sakonidis},
abstract = {The paper reports both a theoretical analysis and a comparison of educational tools for computational modelling, and describes three prototype tools developed in the Programme for use in empirical studies of children reasoning with the aid of computational tools, together with an outline of the result obtained by using the tools with children.}
}
@article{CHU20181,
title = {Supporting scientific modeling through curriculum-based making in elementary school science classes},
journal = {International Journal of Child-Computer Interaction},
volume = {16},
pages = {1-8},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2017.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300545},
author = {Sharon Lynn Chu and Elizabeth Deuermeyer and Francis Quek},
keywords = {Making, Maker movement, Children, Science, Science models, Scientific modeling, Model thinking, Electronics, Programming},
abstract = {Our work investigates how Making may be used in the context of scientific modeling in formal elementary school science classes. This paper presents an investigation of fourth- and fifth-grade students engaging in Making activities to create simulation, concept-process, and illustrative models in the science classroom. Based on video analyses of the Making-based class sessions, a generalized process model was developed for each type of science model. In addition, cross-cutting themes were found in Making-based science modeling: first, there are two loops that intersect and interact with each other (modeling for Making and modeling for Science content), and they interrelate in various ways depending on science model type; and second, showcasing Making products (sharing with peers, teachers, or helpers) is a primary factor that determines students’ overall engagement with science in the activity. We suggest that Making-based science kit and lesson design needs to support students to showcase their Making output, on top of science-related reflections, and to consider the balance between Making and science activity. We conclude that Making has the potential to support the development of scientific model thinking in the elementary science classroom, but much further research is needed in this area.}
}
@article{ZILLES20101072,
title = {The computational complexity of avoiding spurious states in state space abstraction},
journal = {Artificial Intelligence},
volume = {174},
number = {14},
pages = {1072-1092},
year = {2010},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2010.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0004370210000950},
author = {Sandra Zilles and Robert C. Holte},
keywords = {Abstraction, Heuristic search, Planning},
abstract = {Abstraction is a powerful technique for speeding up planning and search. A problem that can arise in using abstraction is the generation of abstract states, called spurious states, from which the goal state is reachable in the abstract space but for which there is no corresponding state in the original space from which the goal state can be reached. Spurious states can be harmful, in practice, because they can create artificial shortcuts in the abstract space that slow down planning and search, and they can greatly increase the memory needed to store heuristic information derived from the abstract space (e.g., pattern databases). This paper analyzes the computational complexity of creating abstractions that do not contain spurious states. We define a property—the downward path preserving property (DPP)—that formally captures the notion that an abstraction does not result in spurious states. We then analyze the computational complexity of (i) testing the downward path preserving property for a given state space and abstraction and of (ii) determining whether this property is achievable at all for a given state space. The strong hardness results shown carry over to typical description languages for planning problems, including sas+ and propositional strips. On the positive side, we identify and illustrate formal conditions under which finding downward path preserving abstractions is provably tractable.}
}
@article{SELBY20001491,
title = {Computational Aspects of Complex Securities},
journal = {Journal of Economic Dynamics and Control},
volume = {24},
number = {11},
pages = {1491-1497},
year = {2000},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(99)00084-6},
url = {https://www.sciencedirect.com/science/article/pii/S0165188999000846},
author = {Michaël J.P Selby}
}
@article{ATALLAH2022B2,
title = {Society for Maternal-Fetal Medicine Special Statement: Cognitive bias and medical error in obstetrics—challenges and opportunities},
journal = {American Journal of Obstetrics and Gynecology},
volume = {227},
number = {2},
pages = {B2-B10},
year = {2022},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2022.04.033},
url = {https://www.sciencedirect.com/science/article/pii/S0002937822003143},
author = {Fouad Atallah and Rebecca F. Hamm and Christina M. Davidson and C. Andrew Combs},
keywords = {decision-making, diagnostic error, disparities, implicit bias, inequity, medical error, racism},
abstract = {The processes of diagnosis and management involve clinical decision-making. However, decision-making is often affected by cognitive biases that can lead to medical errors. This statement presents a framework of clinical thinking and decision-making and shows how these processes can be bias-prone. We review examples of cognitive bias in obstetrics and introduce debiasing tools and strategies. When an adverse event or near miss is reviewed, the concept of a cognitive autopsy—a root cause analysis of medical decision-making and the potential influence of cognitive biases—is promoted as part of the review process. Finally, areas for future research on cognitive bias in obstetrics are suggested.}
}
@incollection{VALLERO2024613,
title = {Chapter 20 - Future},
editor = {Daniel A. Vallero and Trevor M. Letcher},
booktitle = {Unraveling Environmental Disasters (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {613-634},
year = {2024},
isbn = {978-0-443-18651-6},
doi = {https://doi.org/10.1016/B978-0-443-18651-6.00004-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443186516000044},
author = {Daniel A. Vallero and Trevor M. Letcher},
keywords = {Deconstructing disasters, Failure, Integrated pest management (IPM), Land use, Maslow's hierarchy of needs, Information technology, Interoperability, Systems thinking, Spills, Life-cycle analysis, Design for the environment (DfE), Design for disassembly (DfD), Aesop's fables, Tragedy of the Commons, Triple bottom line, Categorical imperative},
abstract = {This chapter revisits the concept of disasters as failures introduced in Chapter 2. This entails approaches to consider the many factors and causes. System thinking is introduced as a means of preventing or reducing the damage of disasters. Systematic approaches must make use of various tools, including regulatory measures; economic incentives; property rights; infrastructure installment; public education; for international projects, international inspections; and cooperation. Disaster prevention and mitigation must integrate planning and engineering approaches, especially thoughtful land use. This also requires an understanding of how people expect to meet basic and advanced needs, as exemplified by Maslow's hierarchy. Other tools include optimizing information technologies and interoperability. The good news is that with education and consideration of past disasters, the implementation of rules and regulations there can be a reduction of number and severity of disasters; e.g., decrease in oil tanker spills over the past half century.}
}
@article{ZHANG2024,
title = {Crowdsourcing Adverse Events Associated With Monoclonal Antibodies Targeting Calcitonin Gene–Related Peptide Signaling for Migraine Prevention: Natural Language Processing Analysis of Social Media},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/58176},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24006255},
author = {Pengfei Zhang and Brad K Kamitaki and Thien Phu Do},
keywords = {internet, patient reported outcome, headache, health information, Reddit, registry, monoclonal antibody, crowdsourcing, postmarketing, safety, surveillance, migraine, preventives, prevention, self-reported, calcitonin gene–related peptide, calcitonin, therapeutics, social media, medication-related, posts, propranolol, topiramate, erenumab, fremanezumab, cross-sectional, surveys},
abstract = {Background
Clinical trials demonstrate the efficacy and tolerability of medications targeting calcitonin gene–related peptide (CGRP) signaling for migraine prevention. However, these trials may not accurately reflect the real-world experiences of more diverse and heterogeneous patient populations, who often have higher disease burden and more comorbidities. Therefore, postmarketing safety surveillance is warranted. Regulatory organizations encourage marketing authorization holders to screen digital media for suspected adverse reactions, applying the same requirements as for spontaneous reports. Real-world data from social media platforms constitute a potential venue to capture diverse patient experiences and help detect treatment-related adverse events. However, while social media holds promise for this purpose, its use in pharmacovigilance is still in its early stages. Computational linguistics, which involves the automatic manipulation and quantitative analysis of oral or written language, offers a potential method for exploring this content.
Objective
This study aims to characterize adverse events related to monoclonal antibodies targeting CGRP signaling on Reddit, a large online social media forum, by using computational linguistics.
Methods
We examined differences in word frequencies from medication-related posts on the Reddit subforum r/Migraine over a 10-year period (2010-2020) using computational linguistics. The study had 2 phases: a validation phase and an application phase. In the validation phase, we compared posts about propranolol and topiramate, as well as posts about each medication against randomly selected posts, to identify known and expected adverse events. In the application phase, we analyzed posts discussing 2 monoclonal antibodies targeting CGRP signaling—erenumab and fremanezumab—to identify potential adverse events for these medications.
Results
From 22,467 Reddit r/Migraine posts, we extracted 402 (2%) propranolol posts, 1423 (6.33%) topiramate posts, 468 (2.08%) erenumab posts, and 73 (0.32%) fremanezumab posts. Comparing topiramate against propranolol identified several expected adverse events, for example, “appetite,” “weight,” “taste,” “foggy,” “forgetful,” and “dizziness.” Comparing erenumab against a random selection of terms identified “constipation” as a recurring keyword. Comparing erenumab against fremanezumab identified “constipation,” “depression,” “vomiting,” and “muscle” as keywords. No adverse events were identified for fremanezumab.
Conclusions
The validation phase of our study accurately identified common adverse events for oral migraine preventive medications. For example, typical adverse events such as “appetite” and “dizziness” were mentioned in posts about topiramate. When we applied this methodology to monoclonal antibodies targeting CGRP or its receptor—fremanezumab and erenumab, respectively—we found no definite adverse events for fremanezumab. However, notable flagged words for erenumab included “constipation,” “depression,” and “vomiting.” In conclusion, computational linguistics applied to social media may help identify potential adverse events for novel therapeutics. While social media data show promise for pharmacovigilance, further work is needed to improve its reliability and usability.}
}
@article{KUMAR20101805,
title = {A generalized computational approach to stability of static equilibria of nonlinearly elastic rods in the presence of constraints},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {199},
number = {25},
pages = {1805-1815},
year = {2010},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2010.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0045782510000654},
author = {Ajeet Kumar and Timothy J. Healey},
keywords = {Stability, Elasticity, Rods, Constraints},
abstract = {We present a generalized approach to stability of static equilibria of nonlinearly elastic rods, subjected to general loading, boundary conditions and constraints (of both point-wise and integral type), based upon the linearized dynamics stability criterion. Discretization of the governing equations leads to a non-standard (singular) generalized eigenvalue problem. A new efficient sparse-matrix-friendly algorithm is presented to determine its few left-most eigenvalues, which, in turn, yield stability/instability information. For conservative problems, the eigenvalue problem arising from the linearized dynamics stability criterion is also shown to be equivalent to that arising in the determination of constrained local minima of the potential energy. We illustrate the method with several examples. A novel variational formulation for extensible and unshearable rods is also proposed within the context of one of the example problems.}
}
@article{BENSASSI20233123,
title = {Fuzzy knowledge based assessment system for K-12 Scientific Reasoning Competencies},
journal = {Procedia Computer Science},
volume = {225},
pages = {3123-3132},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.306},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014643},
author = {Manel BenSassi and Henda Ben Ghezala},
keywords = {Learning analytics, educational recommendations, fuzzy competencies assessment, knowledge representation, fuzzy ontology, Scientific Reasoning competencies},
abstract = {Developing Scientific Reasoning (SR) competencies at an early age, are challenging to meet expectation of the 4th sustainable development goal. Hence, educators and educational decision-makers try to embed these competencies into such subjects as the arts, language, technology, economics, mathematics and science, using an inter-disciplinary approach. In this context, this paper proposes a fuzzy knowledge-based solution to build practical pupils, educators, and decision-makers recommender system to support the development of SR competencies in a data driver manner. Our system consists of:(1) inferring and computational module that calculates in a fuzzy manner the global appreciation to each SR-competencies. (2) recommendation module that aims to help learners, educators and decision makers to assess the degree of development of SR competencies and to get alternative suggestion of remediation. The proposed solution has been tested on the last two levels of science education in four Tunisian elementary schools in different regions. A preliminary analysis showed that the learning process should be more focused on Tunisian pupil's profile, and that investigation and collaborative based learning should be applied further in Tunisian classroom.}
}
@article{NOROOZI2019295,
title = {Multidisciplinary innovations and technologies for facilitation of self-regulated learning},
journal = {Computers in Human Behavior},
volume = {100},
pages = {295-297},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219302638},
author = {Omid Noroozi and Sanna Järvelä and Paul A. Kirschner},
abstract = {Technology-enhanced learning environments provide ample opportunities for learners to self-regulate their learning processes and activities for achieving the intended learning outcomes in various disciplines from soft to hard sciences and from humanities to the natural and social sciences. This special issue discusses the emerging technological advancements and cutting-edge research on self-regulated learning dealing with different cognitive, motivational, emotional, and social processes of learning both at the individual and group levels. Specifically, it discusses how to optimally use advanced technologies to facilitate learners’ self-regulated learning for achieving their own individual learning needs and goals. In this special issue, seven researchers/research teams from the fields of collaborative learning, computational thinking, educational psychology, and learning analytics presented contributions to self-regulated learning with the goal of stimulating cross-border discussion in the field.}
}
@article{GALLISTEL201266,
title = {Extinction from a rationalist perspective},
journal = {Behavioural Processes},
volume = {90},
number = {1},
pages = {66-80},
year = {2012},
note = {Society for the Quantitative Analyses of Behavior: Extinction},
issn = {0376-6357},
doi = {https://doi.org/10.1016/j.beproc.2012.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0376635712000447},
author = {C.R. Gallistel},
keywords = {Acquisition, Extinction, Partial reinforcement, Spontaneous recovery, Renewal, Reinstatement, Resurgence, Information theory, Bayesian inference},
abstract = {The merging of the computational theory of mind and evolutionary thinking leads to a kind of rationalism, in which enduring truths about the world have become implicit in the computations that enable the brain to cope with the experienced world. The dead reckoning computation, for example, is implemented within the brains of animals as one of the mechanisms that enables them to learn where they are (Gallistel, 1990, Gallistel, 1995). It integrates a velocity signal with respect to a time signal. Thus, the manner in which position and velocity relate to one another in the world is reflected in the manner in which signals representing those variables are processed in the brain. I use principles of information theory and Bayesian inference to derive from other simple principles explanations for: (1) the failure of partial reinforcement to increase reinforcements to acquisition; (2) the partial reinforcement extinction effect; (3) spontaneous recovery; (4) renewal; (5) reinstatement; (6) resurgence (aka facilitated reacquisition). Like the principle underlying dead-reckoning, these principles are grounded in analytic considerations. They are the kind of enduring truths about the world that are likely to have shaped the brain's computations.}
}
@article{BAKEEVA2022676,
title = {Increasing the student talking time parameter under the digitalization in transport engineering learning},
journal = {Transportation Research Procedia},
volume = {63},
pages = {676-685},
year = {2022},
note = {X International Scientific Siberian Transport Forum — TransSiberia 2022},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2022.06.062},
url = {https://www.sciencedirect.com/science/article/pii/S2352146522003179},
author = {L Bakeeva and L Brylevskaya and L Gonchar and E Pastukhova and Y Romanova and O Skepko},
keywords = {Digitalization of education, transport engineering, student talking time, study-train-explain methodology},
abstract = {The most recent information technologies have become an integral part of modern life. As the study shows, along with the obvious benefits, their use can lead to negative consequences, namely the loss of communication and soft skills, changes in the ability to absorb information, decreased motivation to acquire new knowledge among the younger age group. The authors propose a new methodology for organizing the educational process Study-Train-Explain. The aim of the method is to increase the Student Talking Time parameter to develop the skills of mathematical data analysis, systematic and analytical thinking to master the methods of description and construction of mathematical model of the phenomenon or process. These competencies are extremely in demand in the professional field related to the organization of transportation and operation of transport-technological machines and complexes under the conditions of digitalization of global processes. The article presents an algorithm and the results of the experimental training process carried out by the authors according to the specified methodology.}
}
@article{AGRE19951,
title = {Computational research on interaction and agency},
journal = {Artificial Intelligence},
volume = {72},
number = {1},
pages = {1-52},
year = {1995},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(94)00054-5},
url = {https://www.sciencedirect.com/science/article/pii/0004370294000545},
author = {Philip E. Agre},
abstract = {Recent research in artificial intelligence has developed computational theories of agents' involvements in their environments. Although inspired by a great diversity of formalisms and architectures, these research projects are unified by a common concern: using principled characterizations of agents' interactions with their environments to guide analysis of living agents and design of artificial ones. This article offers a conceptual framework for such theories, surveys several other fields of research that hold the potential for dialogue with these new computational projects, and summarizes the principal contributions of the articles in this special double volume. It also briefly describes a case study in these ideas—a computer program called Toast that acts as a short-order breakfast cook. Because its designers have discovered useful structures in the world it inhabits, Toast can employ an extremely simple mechanism to decide what to do next.}
}
@article{NAJJAR19991907,
title = {Advances in the dataflow computational model},
journal = {Parallel Computing},
volume = {25},
number = {13},
pages = {1907-1929},
year = {1999},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(99)00070-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167819199000708},
author = {Walid A Najjar and Edward A Lee and Guang R Gao},
keywords = {Computational models, Dataflow, Multithreaded computer architecture, von Neumann computer, Dataflow history, Memory models},
abstract = {The dataflow program graph execution model, or dataflow for short, is an alternative to the stored-program (von Neumann) execution model. Because it relies on a graph representation of programs, the strengths of the dataflow model are very much the complements of those of the stored-program one. In the last thirty or so years since it was proposed, the dataflow model of computation has been used and developed in very many areas of computing research: from programming languages to processor design, and from signal processing to reconfigurable computing. This paper is a review of the current state-of-the-art in the applications of the dataflow model of computation. It focuses on three areas: multithreaded computing, signal processing and reconfigurable computing.}
}
@article{GREGOR19981481,
title = {A computational study of the focus-of-attention EM-ML algorithm for PET reconstruction1Research supported in part by the National Science Foundation under grant CDA-95-29459.1},
journal = {Parallel Computing},
volume = {24},
number = {9},
pages = {1481-1497},
year = {1998},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(98)00067-2},
url = {https://www.sciencedirect.com/science/article/pii/S0167819198000672},
author = {Jens Gregor and Dean A. Huff},
keywords = {Distributed computing, Expectation-maximization, Image reconstruction, Positron emission tomography},
abstract = {The expectation-maximization maximum-likelihood (EM-ML) algorithm for image reconstruction in positron emission tomography (PET) essentially solves a large linear system of equations. In this paper, we study computational aspects of a recently developed preprocessing scheme for focusing the attention, and thus the computational resources, on a subset of the equations and unknowns in order to reduce the storage, computation, and communication requirements of the EM-ML algorithm. The approach is completely data-driven and uses no prior anatomic knowledge. The experimental results are obtained from runs on a small network of workstations using simulated phantom data as well as data obtained from a clinical ECAT 921 PET scanner.}
}
@incollection{CHORAFAS2004141,
title = {7 - Five models by the Basel Committee for computation of operational risk},
editor = {Dimitris N. Chorafas},
booktitle = {Operational Risk Control with Basel II},
publisher = {Butterworth-Heinemann},
address = {Oxford},
pages = {141-162},
year = {2004},
isbn = {978-0-7506-5909-3},
doi = {https://doi.org/10.1016/B978-075065909-3.50009-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780750659093500098},
author = {Dimitris N. Chorafas},
abstract = {Publisher Summary
This chapter analyzes the four methods of capital allocation for operational risk by the Basel Committee on Banking Supervision: (1) the basic indicator approach, (2) standard approach, (3) internal measurement approach, and (4) loss distribution approach. The chapter also explains why the internal measurement approach and loss distribution approach require leadership in databasing and datamining. The chapter depicts these four methods for computation of operational risk charges on a double scale: expected amount of capital allocation and complexity. Valid solutions take account of different perspectives and definitions of operational risk. The way operational risk is managed is affected by the manner in it is viewed, added with how the board and CEO come to grips with operational risk, the skills and tools at the regulators' disposal, and the resolve to put the risk under lock and key. This is the reason why Basel II wants banks to put aside capital for operational risk control.}
}
@article{ZORARPACI2024108162,
title = {A fast intrusion detection system based on swift wrapper feature selection and speedy ensemble classifier},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108162},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108162},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624003208},
author = {Ezgi Zorarpaci},
keywords = {Data mining, Ensemble classifier, Feature selection, Intrusion detection system},
abstract = {Due to the widespread use of the internet, computer network systems may be exposed to different types of attacks. For this reason, the intrusion detection systems (IDSs) are often used to protect the network systems. Network traffic data (i.e., network packets) includes many features. However, most of them are irrelevant and can lead to a decrease in the runtime and/or the detection performance of the IDS. Although various data mining methods have been applied to improve the effectiveness of IDS, research regarding IDSs having high detection rates and better runtime performance (i.e., lower computational cost) is ongoing. On the other hand, the dimensionality reduction techniques help to eliminate unnecessary features and reduce the computation time of a classification algorithm. In the literature, the feature selection methods (i.e., filter and wrapper) have been widely used for the dimensionality reduction in IDSs. Although the wrapper feature selection techniques outperform the filters, they are time-consuming. Again, the ensemble classifiers can achieve higher detection rates for IDSs compared to the stand-alone classifiers, but they require more computation time to build the model. In order to improve the runtime performance and the detection rate of IDS, a swift wrapper feature selection and a speedy ensemble classifier are proposed in this study. For the dimensionality reduction, the swift wrapper feature selection (i.e., DBDE-QDA) is used, which consists of dichotomous binary differential evolution (DBDE) and quadratic discriminant analysis (QDA). For attack detection, the speedy ensemble classifier is used, which combines Holte's 1R, random tree, and reduced error pruning tree. In the experiments, the NSL-KDD, UNSW-NB15, and CICDDoS2019 datasets are used. According to the experimental results, the proposed IDS reaches 95%–97.4%, 82.7%, and 99.5%–99.9% detection rates for the NSL-KDD, UNSW-NB15, and CICDDoS2019 datasets. In this way, the proposed IDS competes with the state-of-the-art methods in terms of detection rate and false alarm rate. In addition, the proposed IDS has a lower computational cost than the state-of-the-art methods. Moreover, DBDE-QDA reduces the dimension by 60.97%–82.92%, 73.46%, and 96.55%–98.85% for the NSL-KDD, UNSW-NB15, and CICDoS2019 datasets.}
}
@article{WATKINS200867,
title = {Specifying Properties of Concurrent Computations in CLF},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {199},
pages = {67-87},
year = {2008},
note = {Proceedings of the Fourth International Workshop on Logical Frameworks and Meta-Languages (LFM 2004)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2007.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108000790},
author = {Kevin Watkins and Iliano Cervesato and Frank Pfenning and David Walker},
keywords = {logical frameworks, type theory, linear logic, concurrency},
abstract = {CLF (the Concurrent Logical Framework) is a language for specifying and reasoning about concurrent systems. Its most significant feature is the first-class representation of concurrent executions as monadic expressions. We illustrate the representation techniques available within CLF by applying them to an asynchronous pi-calculus with correspondence assertions, including its dynamic semantics, safety criterion, and a type system with latent effects due to Gordon and Jeffrey.}
}
@article{INAL2024101338,
title = {Current clinical status of IC/BPS and what the future holds in basic & translational science},
journal = {Continence},
volume = {11},
pages = {101338},
year = {2024},
issn = {2772-9737},
doi = {https://doi.org/10.1016/j.cont.2024.101338},
url = {https://www.sciencedirect.com/science/article/pii/S2772973724002716},
author = {Guldal Inal and Dick Janssen and Naside Mangir and Francisco Cruz and Ana Charrua},
keywords = {IC/BPS, Biomarkers, Bioinformatics, Artificial intelligence, Animal models},
abstract = {The present review summarizes the scientific content in the workshop “Current clinical status of IC/BPS and what the future holds in basic & translational science” at the International Continence Society (ICS) 2023, Toronto. In the workshop, clinicians and scientists from different disciplines and nationalities discussed the current clinical status of IC/BPS diagnostic and treatment. They defined the available trends in biomarker search and translational medicine. The recent contribution of computational science and bioinformatics, together with artificial intelligence and the recent improvements in the use of animal models were also explored. The search for diagnostic and predictive biomarkers for IC/BPS patients is important. The use of well-refined and characterized animal models and the use of bioinformatics and artificial intelligence will be useful in this search.}
}
@article{LIM2025103550,
title = {Exploring trends and topics in hybrid intelligence using keyword co-occurrence networks and topic modelling},
journal = {Futures},
volume = {167},
pages = {103550},
year = {2025},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2025.103550},
url = {https://www.sciencedirect.com/science/article/pii/S0016328725000138},
author = {Jihye Lim and Junseok Hwang},
keywords = {Hybrid Intelligence, Artificial Intelligence, Human Intelligence, Keywords Co-occurrence Network, Topic Modeling, Knowledge classification},
abstract = {Hybrid Intelligence (HI) represents the ability to solve problems by using human and artificial intelligence (AI) together, pursuing the strengths of both the former (e.g., ethical, creative, and common-sense thinking) and the latter (e.g., the fast and efficient ability). This study conducted a keyword network analysis and topic modelling to extract topics, examine research trends, and explore future development directions. HI-related research has increased rapidly since 2017, and the applied research fields have increased in diversity. The most active research fields are computer science, engineering, and mathematics. Based on the topic and keyword analysis, we found four trending topics (decision making, medical science, social factors, and automation) and three emerging topics (crowdsourcing, data science, and teamwork). Among the four types of knowledge (factual, conceptual, expectational, and methodological), previous papers have been lacking focus on methodological research in terms of basic research. Since HI can include both human and artificial intelligences, it offers endless possibilities for methodological knowledge in terms of the research process. We therefore propose the development of research methodologies leveraging HI as a promising future research topic.}
}
@article{CASTRO2006811,
title = {Patient-Specific Computational Modeling of Cerebral Aneurysms With Multiple Avenues of Flow From 3D Rotational Angiography Images},
journal = {Academic Radiology},
volume = {13},
number = {7},
pages = {811-821},
year = {2006},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2006.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S1076633206001826},
author = {Marcelo A. Castro and Christopher M. Putman and Juan R. Cebral},
abstract = {Rationale and Objectives
Previous studies of aneurysm flow dynamics based on three-dimensional (3D) rotational angiography (RA) images were limited to aneurysms with a single route of blood inflow. However, aneurysms of the circle of Willis frequently involve locations with more than one source of inflow, such as aneurysms of the anterior communicating artery. The highest resolution images of cerebral vessels are from RA images, but this technique is limited to visualizing only one route of inflow at a time, leaving a significant limitation in the application of 3DRA image sets for clinical studies of patient-specific computational fluid dynamics (CFD) simulations. In this report, subject-specific models of cerebral aneurysms with multiple avenues of flow are constructed from RA images by using a novel combination of image coregistration and surface merging techniques.
Materials and Methods
RA images are obtained by means of contrast injection in each vessel that provides inflow to the aneurysm. Anatomic models are constructed independently of each of these vascular trees and fused together into a single model. The model is used to construct a finite element grid for CFD simulations of hemodynamics.
Results
Three examples of patient-specific models are presented: an anterior communicating artery aneurysm, a basilar tip aneurysm, and a model of an entire circle of Willis with five coincident aneurysms. The method is evaluated with a numeric phantom of an aneurysm in the anterior communicating artery.
Conclusion
These examples show that this new technique can be used to create merged network numeric models for CFD modeling. Furthermore, intra-aneurysmal flow patterns are influenced strongly by merging of the two inflow streams. This effect decreases as distance from the merging streams increases.}
}
@article{BERGER2016337,
title = {Cognitive hierarchies in the minimizer game},
journal = {Journal of Economic Behavior & Organization},
volume = {130},
pages = {337-348},
year = {2016},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2016.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167268116301639},
author = {Ulrich Berger and Hannelore {De Silva} and Gerlinde Fellner-Röhling},
keywords = {Behavioral game theory, Experimental games, Poisson cognitive hierarchy, Level- model, Minimizer game},
abstract = {Experimental tests of choice predictions in one-shot games show only little support for Nash equilibrium (NE). Poisson Cognitive Hierarchy (PCH) and level-k (LK) are behavioral models of the thinking-steps variety where subjects differ in the number of levels of iterated reasoning they perform. Camerer et al. (2004) claim that substituting the Poisson parameter τ=1.5 yields a parameter-free PCH model (pfPCH) which predicts experimental data considerably better than NE. We design a new multi-person game, the Minimizer Game, as a testbed to compare initial choice predictions of NE, pfPCH and LK. Data obtained from two large-scale online experiments strongly reject NE and LK, but are well in line with the point-prediction of pfPCH.}
}
@incollection{GARDNER202477,
title = {Chapter 4 - Smart design for urban activation and placemaking},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {77-102},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000082},
author = {Nicole Gardner},
keywords = {Cyber-physical systems, Design, Digital placemaking, Interaction, Placemaking, Smart design, Urban activation, Urban amenitization},
abstract = {This chapter charts out the distinction between the concepts of digital placemaking and smart placemaking. It examines existing and speculative urban technology projects that combine spatial design thinking and physical computing to address placemaking design goals such as urban activation, amenitization, and safety and security. In ways different from conventional smart city initiatives that surveil urban dynamics en masse to imperceptibly calibrate large-scale urban services and infrastructural systems, the projects discussed in this chapter engage sensor-based technologies to create localized, responsive, and interactive urban environments to address the social, cultural, and aesthetic dimensions of urban livability.}
}
@article{COURTNEY2025168819,
title = {memerna: Sparse RNA folding including coaxial stacking},
journal = {Journal of Molecular Biology},
volume = {437},
number = {3},
pages = {168819},
year = {2025},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2024.168819},
url = {https://www.sciencedirect.com/science/article/pii/S0022283624004418},
author = {Eliot Courtney and Amitava Datta and David H. Mathews and Max Ward},
keywords = {RNA secondary structure, sparsification, dynamic programming, nearest neighbor, energy model},
abstract = {Determining RNA secondary structure is a core problem in computational biology. Fast algorithms for predicting secondary structure are fundamental to this task. We describe a modified formulation of the Zuker-Stiegler algorithm with coaxial stacking, a stabilising interaction in which the ends of helices in multi-loops are stacked. In particular, optimal coaxial stacking is computed as part of the dynamic programming state, rather than in an inner loop. We introduce a new notion of sparsity, which we call replaceability. Replaceability is a more general condition and applicable in more places than the triangle inequality that is used by previous sparse folding methods. We also introduce non-monotonic candidate lists as an additional sparsification tool. Existing usages of the triangle inequality for sparsification can be thought of as an application of both replaceability and monotonicity together. The modified recurrences along with replaceability allows sparsification to be applied to coaxial stacking as well, which increases the speed of the algorithm. We implemented this algorithm in software we call memerna, which we show to have the fastest exact (non–heuristic) implementation of RNA folding under the complete Turner 2004 model with coaxial stacking, out of several popular RNA folding tools supporting coaxial stacking. We also introduce a new notation for secondary structure which includes coaxial stacking, terminal mismatches, and dangles (CTDs) information. The memerna package 0.1 release is available at https://github.com/Edgeworth/memerna/tree/release/0.1.}
}
@article{KUHN202428,
title = {A landscape of consciousness: Toward a taxonomy of explanations and implications},
journal = {Progress in Biophysics and Molecular Biology},
volume = {190},
pages = {28-169},
year = {2024},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2023.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0079610723001128},
author = {Robert Lawrence Kuhn},
keywords = {Consciousness, Mind-body problem, Materialism, Monism, Dualism, Idealism},
abstract = {Diverse explanations or theories of consciousness are arrayed on a roughly physicalist-to-nonphysicalist landscape of essences and mechanisms. Categories: Materialism Theories (philosophical, neurobiological, electromagnetic field, computational and informational, homeostatic and affective, embodied and enactive, relational, representational, language, phylogenetic evolution); Non-Reductive Physicalism; Quantum Theories; Integrated Information Theory; Panpsychisms; Monisms; Dualisms; Idealisms; Anomalous and Altered States Theories; Challenge Theories. There are many subcategories, especially for Materialism Theories. Each explanation is self-described by its adherents, critique is minimal and only for clarification, and there is no attempt to adjudicate among theories. The implications of consciousness explanations or theories are assessed with respect to four questions: meaning/purpose/value (if any); AI consciousness; virtual immortality; and survival beyond death. A Landscape of Consciousness, I suggest, offers perspective.}
}
@article{YANG20242009,
title = {Maximum Power Point Tracking Technology for PV Systems: Current Status and Perspectives},
journal = {Energy Engineering},
volume = {121},
number = {8},
pages = {2009-2022},
year = {2024},
issn = {0199-8595},
doi = {https://doi.org/10.32604/ee.2024.049423},
url = {https://www.sciencedirect.com/science/article/pii/S0199859524000708},
author = {Bo Yang and Rui Xie and Zhengxun Guo},
keywords = {PV systems, MPPT, partial shading condition, DC-DC converter},
abstract = {Maximum power point tracking (MPPT) technology plays a key role in improving the energy conversion efficiency of photovoltaic (PV) systems, especially when multiple local maximum power points (LMPPs) occur under partial shading conditions (PSC). It is necessary to modify the operating point efficiently and accurately with the help of MPPT technology to maximize the collected power. Even though a lot of research has been carried out and impressive progress achieved for MPPT technology, it still faces some challenges and dilemmas. Firstly, the mathematical model established for PV cells is not precise enough. Second, the existing algorithms are often optimized for specific conditions and lack comprehensive adaptability to the actual operating environment. Besides, a single algorithm may not be able to give full play to its advantages. In the end, the selection criteria for choosing the suitable MPPT algorithm/converter combination to achieve better performance in a given scenario is very limited. Therefore, this paper systematically discusses the current research status and challenges faced by PV MPPT technology around the three aspects of MPPT models, algorithms, and hardware implementation. Through in-depth thinking and discussion, it also puts forward positive perspectives on future development, and five forward-looking solutions to improve the performance of PV systems MPPT are suggested.}
}
@article{ALIABADI2000243,
title = {Stabilized-finite-element/interface-capturing technique for parallel computation of unsteady flows with interfaces},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {3},
pages = {243-261},
year = {2000},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(00)00200-0},
url = {https://www.sciencedirect.com/science/article/pii/S0045782500002000},
author = {Shahrouz Aliabadi and Tayfun E. Tezduyar},
abstract = {We present the stabilized-finite-element/interface-capturing (SFE/IC) method developed for parallel computation of unsteady flow problems with two-fluid interfaces and free surfaces. The SFE/IC method involves stabilized formulations, an interface-sharpening technique, and the enforcement of global mass conservation for each fluid. The SFE/IC method has been efficiently implemented on the CRAY T3E parallel supercomputer. A number of 2D test problems are presented to demonstrate how the SFE/IC method works and the accuracy it attains. We also show how the SFE/IC method can be very effectively applied to 3D simulation of challenging flow problems, such as two-fluid interfaces in a centrifuge tube and operational stability of a partially filled tanker truck driving over a bump.}
}
@article{MENGOV2022101944,
title = {Virtual social networking increases the individual's economic predictability},
journal = {Journal of Behavioral and Experimental Economics},
volume = {101},
pages = {101944},
year = {2022},
issn = {2214-8043},
doi = {https://doi.org/10.1016/j.socec.2022.101944},
url = {https://www.sciencedirect.com/science/article/pii/S221480432200115X},
author = {George Mengov and Nikolay Georgiev and Irina Zinovieva and Anton Gerunov},
keywords = {Decision making, Virtual social network, Emotional economic choice, Neural model},
abstract = {Forecasting economic choice is hard because today we still do not know enough about human motivation. A fundamental problem is the lack of knowledge about how the neural networks in the brain give rise to thinking and decision making. One way to address the issue has been to develop simplified economic experiments, in which participants need skills of little complexity and their minds employ cognitive mechanisms, already well understood by mathematical psychology and neuroscience. Here we take a neural model for rudimentary emotion generation and memorizing and use it as a guiding theory to understand decision making in an experimental oligopoly market. For the first time in that line of research, participants are put in a lab virtual social network serving to exchange opinions about deals with companies. On average, choices become significantly more predictable when people participate in the network, in contrast to working alone with expert information. Calibrating the model for each person, we find that some people are predicted with startling precision.}
}
@article{WANG2016357,
title = {Research on Application of Abduction to Fire Investigation},
journal = {Procedia Engineering},
volume = {135},
pages = {357-362},
year = {2016},
note = {2015 International Conference on Performance-based Fire and Fire Protection Engineering (ICPFFPE 2015)},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2016.01.142},
url = {https://www.sciencedirect.com/science/article/pii/S1877705816001466},
author = {Shi Wang and Zhong-jun Shu},
keywords = {Fire investigation, Abduction, Logical thinking},
abstract = {To solve the problem of fire investigation caused by lack of exacting logical reasoning, it is of significance in helping that abduction, an important logical thinking should be introduced to the field of fire investigation. This paper first analyzes the fundamental reasoning forms of abduction as well as its general situation of application. Combined with practical work experience, the mode of application of abduction to fire investigation is put forward. The author shows it in detail by analyzing a real fire case. It is north noting that some matters needing attention in application are presented in the end. This paper will be conductive to constructing the right logical reasoning model in fire investigation.}
}
@incollection{YANG20151,
title = {Chapter 1 - Bio-Inspired Computation and Optimization: An Overview},
editor = {Xin-She Yang and Su Fong Chien and Tiew On Ting},
booktitle = {Bio-Inspired Computation in Telecommunications},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {1-21},
year = {2015},
isbn = {978-0-12-801538-4},
doi = {https://doi.org/10.1016/B978-0-12-801538-4.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012801538400001X},
author = {Xin-She Yang and Su Fong Chien and Tiew On Ting},
keywords = {Algorithm, Ant algorithm, Bee algorithm, Bat algorithm, Bio-inspired computation, Cuckoo search, Firefly algorithm, Harmony search, Particle swarm optimization, Metaheuristics, Swarm intelligence, Telecommunications},
abstract = {All design problems in telecommunications can be formulated as optimization problems, and thus may be tackled by some optimization techniques. However, these problems can be extremely challenging due to the stringent time requirements, complex constraints, and a high number of design parameters. Solution methods tend to use conventional methods such as Lagrangian duality and fractional programming in combination with numerical solvers, while new trends tend to use evolutionary algorithms and swarm intelligence. This chapter provides a summary review of the bio-inspired optimization algorithms and their applications in telecommunications. We also discuss key issues in optimization and some active topics for further research.}
}
@article{FARRELL20175597,
title = {N‐Aryl‐9,10‐phenanthreneimines as Scaffolds for Exploring Noncovalent Interactions: A Structural and Computational Study},
journal = {European Journal of Organic Chemistry},
volume = {2017},
number = {37},
pages = {5597-5609},
year = {2017},
issn = {1434-193X},
doi = {https://doi.org/10.1002/ejoc.201700884},
url = {https://www.sciencedirect.com/science/article/pii/S1434193X22035940},
author = {David Farrell and Samuel J. Kingston and Dmitry Tungulin and Stefano Nuzzo and Brendan Twamley and James A. Platts and Robert J. Baker},
keywords = {Stacking interactions, Noncovalent interactions, Density functional calculations},
abstract = {A series of 10‐[(4‐halo‐2,6‐diisopropylphenyl)imino]phenanthren‐9‐ones and derivatives of the phenanthrene‐9,10‐dione ligand have been synthesised and structurally characterised to explore two types of noncovalent interactions, namely the influence of the steric bulk upon the resulting C–H···π and π‐stacking interactions and halogen bonding. Selected noncovalent interactions have additionally been analysed by DFT and AIM techniques. No halogen bonding has been observed in these systems, but X lone pair···π, C–H···O=C and C–H···π interactions are the prevalent ones in the halogenated systems. Removal of the steric bulk in N‐(2,4,6‐trimethylphenyl)‐9,10‐iminophenanthrenequinone affords different noncovalent interactions, but the C–H···O=C hydrogen bonds are observed. Surprisingly, in N‐(2,6‐dimethylphenyl)‐9,10‐iminophenanthrenequinone and N‐(phenyl)‐9,10‐iminophenanthrenequinone these C–H···O=C hydrogen bonds are not observed. However, they are observed in the related 2,6‐di‐tert‐butylphenanthrene‐9,10‐dione. The π‐interactions in dimers extracted from the crystal structures have been analysed by DFT and AIM. Spectroscopic investigations are also presented and these show only small perturbations to the O=C–C=N fragment.}
}
@article{NORTON2006600,
title = {Computational fluid dynamics (CFD) – an effective and efficient design and analysis tool for the food industry: A review},
journal = {Trends in Food Science & Technology},
volume = {17},
number = {11},
pages = {600-620},
year = {2006},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2006.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0924224406001981},
author = {Tomás Norton and Da-Wen Sun},
abstract = {Computational fluid dynamics (CFD) is a powerful numerical tool that is becoming widely used to simulate many processes in the food industry. Recent progression in computing efficacy coupled with reduced costs of CFD software packages has advanced CFD as a viable technique to provide effective and efficient design solutions. This paper discusses the fundamentals involved in developing a CFD solution. It also provides a state-of-the-art review on various CFD applications in the food industry such as ventilation, drying, sterilisation, refrigeration, cold display and storage, and mixing and elucidates the physical models most commonly used in these applications. The challenges faced by modellers using CFD in the food industry are also discussed.}
}
@article{ZHANG2024101587,
title = {Effects of a problem posing instructional interventions on student learning outcomes: A three-level meta-analysis},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101587},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101587},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001251},
author = {Cheng Zhang and Ying Zhou and Tommy Tanu Wijaya and Jihe Chen and Yimin Ning},
keywords = {Problem posing, Learning outcomes, Three-level meta-analysis, Instructional interventions},
abstract = {Problem posing is increasingly being considered in the field of education, with many experts exploring its positive effects on student learning outcomes. In this case, different perspectives have emerged regarding the impact of the intervention, claiming the overall effect remains uncertain. Therefore, this study aims to explore the effects of a problem posing instructional intervention on student learning outcomes at the cognitive and non-cognitive levels from 2000 to 2023, using a three-level meta-analysis. 32 studies and 4,068 participants were included to compare the classrooms with and without problem posing instructional interventions in elementary to higher education. The results showed a moderate-positive and small positive effect on students cognitive (Hedges' g = 0.681, 95 % CI [0.552, 0.810], p < 0.001) and non-cognitive (Hedges' g = 0.367, 95 % CI [0.113, 0.620], p = 0.003) levels, respectively. Based on the moderator analysis, there were differences in the learning outcomes among students across various task formats. Notably, tasks that included specific information and involved problem posing in context demonstrated significantly better performance. In conclusion, these results indicate the importance of problem posing instructional interventions in promoting student's development and their impact on cognitive and non-cognitive dimensions.}
}
@article{ARTHUR2023638,
title = {Economics in nouns and verbs},
journal = {Journal of Economic Behavior & Organization},
volume = {205},
pages = {638-647},
year = {2023},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2022.10.036},
url = {https://www.sciencedirect.com/science/article/pii/S0167268122003936},
author = {W. Brian Arthur},
keywords = {Economic theory, Mathematics in economics, Algorithms, Complexity economics, Computational economics},
abstract = {Standard economic theory uses mathematics as its main means of understanding, and this brings clarity of reasoning and logical power. But there is a drawback: algebraic mathematics restricts economic modeling to what can be expressed only in quantitative nouns, and this forces theory to leave out matters to do with process, formation, adjustment, and creation—matters to do with nonequilibrium. For these we need a different means of understanding, one that allows verbs as well as nouns. Algorithmic expression is such a means. It allows verbs—processes—as well as nouns—objects and quantities. It allows fuller description in economics, and can include heterogeneity of agents, actions as well as objects, and realistic models of behavior in ill-defined situations. The world that algorithms reveal is action-based as well as object-based, organic, possibly ever-changing, and not fully knowable. But it is strangely and wonderfully alive.}
}
@article{JAUK2012219,
title = {Tackling creativity at its roots: Evidence for different patterns of EEG alpha activity related to convergent and divergent modes of task processing},
journal = {International Journal of Psychophysiology},
volume = {84},
number = {2},
pages = {219-225},
year = {2012},
issn = {0167-8760},
doi = {https://doi.org/10.1016/j.ijpsycho.2012.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0167876012000748},
author = {Emanuel Jauk and Mathias Benedek and Aljoscha C. Neubauer},
keywords = {EEG, Creativity, Alpha synchronization, Divergent thinking, Convergent thinking},
abstract = {The distinction between convergent and divergent cognitive processes given by Guilford (1956) had a strong influence on the empirical research on creative thinking. Neuroscientific studies typically find higher event-related synchronization in the EEG alpha rhythm for individuals engaged in creative ideation tasks compared to intelligence-related tasks. This study examined, whether these neurophysiological effects can also be found when both cognitive processing modes (convergent vs. divergent) are assessed by means of the same task employing a simple variation of instruction. A sample of 55 participants performed the alternate uses task as well as a more basic word association task while EEG was recorded. On a trial-by-trial basis, participants were either instructed to find a most common solution (convergent condition) or a most uncommon solution (divergent condition). The answers given in the divergent condition were in both tasks significantly more original than those in the convergent condition. Moreover, divergent processing was found to involve higher task-related EEG alpha power than convergent processing in both the alternate uses task and the word association task. EEG alpha synchronization can hence explicitly be associated with divergent cognitive processing rather than with general task characteristics of creative ideation tasks. Further results point to a differential involvement of frontal and parietal cortical areas by individuals of lower versus higher trait creativity.}
}
@article{MOORE2021,
title = {Age-Related Differences in Experiences With Social Distancing at the Onset of the COVID-19 Pandemic: A Computational and Content Analytic Investigation of Natural Language From a Social Media Survey},
journal = {JMIR Human Factors},
volume = {8},
number = {2},
year = {2021},
issn = {2292-9495},
doi = {https://doi.org/10.2196/26043},
url = {https://www.sciencedirect.com/science/article/pii/S2292949521000274},
author = {Ryan C Moore and Angela Y Lee and Jeffrey T Hancock and Meghan C Halley and Eleni Linos},
keywords = {COVID-19, natural language processing, public health messaging, social distancing compliance, age differences, older adults, younger adults, age, NLP, public health, elderly, youth, adult, emotion, compliance, guideline},
abstract = {Background
As COVID-19 poses different levels of threat to people of different ages, health communication regarding prevention measures such as social distancing and isolation may be strengthened by understanding the unique experiences of various age groups.
Objective
The aim of this study was to examine how people of different ages (1) experienced the impact of the COVID-19 pandemic and (2) their respective rates and reasons for compliance or noncompliance with social distancing and isolation health guidance.
Methods
We fielded a survey on social media early in the pandemic to examine the emotional impact of COVID-19 and individuals’ rates and reasons for noncompliance with public health guidance, using computational and content analytic methods of linguistic analysis.
Results
A total of 17,287 participants were surveyed. The majority (n=13,183, 76.3%) were from the United States. Younger (18-31 years), middle-aged (32-44 years and 45-64 years), and older (≥65 years) individuals significantly varied in how they described the impact of COVID-19 on their lives, including their emotional experience, self-focused attention, and topical concerns. Younger individuals were more emotionally negative and self-focused, while middle-aged people were other-focused and concerned with family. The oldest and most at-risk group was most concerned with health-related terms but were lower in anxiety (use of fewer anxiety-related terms) and higher in the use of emotionally positive terms than the other less at-risk age groups. While all groups discussed topics such as acquiring essential supplies, they differentially experienced the impact of school closures and limited social interactions. We also found relatively high rates of noncompliance with COVID-19 prevention measures, such as social distancing and self-isolation, with younger people being more likely to be noncompliant than older people (P<.001). Among the 43.1% (n=7456) of respondents who did not fully comply with health orders, people differed substantially in the reasons they gave for noncompliance. The most common reason for noncompliance was not being able to afford to miss work (n=4273, 57.3%). While work obligations proved challenging for participants across ages, younger people struggled more to find adequate space to self-isolate and manage their mental and physical health; middle-aged people had more concerns regarding childcare; and older people perceived themselves as being able to take sufficient precautions.
Conclusions
Analysis of natural language can provide insight into rapidly developing public health challenges like the COVID-19 pandemic, uncovering individual differences in emotional experiences and health-related behaviors. In this case, our analyses revealed significant differences between different age groups in feelings about and responses to public health orders aimed to mitigate the spread of COVID-19. To improve public compliance with health orders as the pandemic continues, health communication strategies could be made more effective by being tailored to these age-related differences.}
}
@article{KONOPKA1994V,
title = {Computational experiments in molecular biology: Searching for the ‘big picture’},
journal = {Computers & Chemistry},
volume = {18},
number = {3},
pages = {V-VIII},
year = {1994},
issn = {0097-8485},
doi = {https://doi.org/10.1016/0097-8485(94)85013-5},
url = {https://www.sciencedirect.com/science/article/pii/0097848594850135},
author = {AndrzejK. Konopka}
}
@article{BULLEN2022101933,
title = {Patterns of math and reading achievement in children and adolescents with autism spectrum disorder},
journal = {Research in Autism Spectrum Disorders},
volume = {92},
pages = {101933},
year = {2022},
issn = {1750-9467},
doi = {https://doi.org/10.1016/j.rasd.2022.101933},
url = {https://www.sciencedirect.com/science/article/pii/S1750946722000204},
author = {Jennifer C. Bullen and Matthew C. Zajic and Nancy McIntyre and Emily Solari and Peter Mundy},
keywords = {Autism spectrum disorder, Academic achievement, Hierarchical cluster analysis, Math achievement, Reading fluency},
abstract = {Background
There has been an increase of autistic students without intellectual disabilities (autisticWoID) placed in general education settings (Hussar et al., 2020), but there is a lack of understanding of how to best support classroom learning for these children. Previous research has pointed to subgroups of autisticWoID children who display difficulty with mathematics and reading achievement (Chen et al., 2018; Estes et al., 2011; Jones et al., 2009; Wei et al., 2015). Research has primarily focused on symptomatology and communication factors related to learning in subgroups of autistic children. The current study sought to expand upon this research by assessing the validity of these previous studies and by investigating the specific contribution of domain-general cognitive abilities to differences in these subgroups.
Method
Seventy-eight autisticWoID individuals (M = 11.34 years, SD = 2.14) completed measures of mathematics and reading achievement, IQ, working memory, inferential thinking, and Theory of Mind (ToM). A hierarchical cluster analysis was performed on the math and reading measures.
Results
The analysis revealed two unique achievement groups: one group that performed lower than expected on math and reading achievement and a second group that performed higher than expected. Groups differed significantly on IQ and working memory and were distinguished by performance on reading fluency. Groups did not differ on ToM, inferential thinking, or symptomatology.
Conclusion
These findings describe a group of autisticWoID individuals that may be more likely to experience difficulty learning, which should be accounted for in general education settings.}
}
@article{WESTRA2023645,
title = {Accounting for systemic complexity in the assessment of climate risk},
journal = {One Earth},
volume = {6},
number = {6},
pages = {645-655},
year = {2023},
issn = {2590-3322},
doi = {https://doi.org/10.1016/j.oneear.2023.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2590332223002063},
author = {Seth Westra and Jakob Zscheischler},
abstract = {Summary
Widespread changes to climate-sensitive systems are placing increased demands on risk assessments as a foundation for managing risk. Recent attention to compounding and cascading risks, deep uncertainty, and “bottom-up” risk assessment frameworks have foregrounded the need to account for systemic complexity in risk assessment methodology. We describe the sources of systemic complexity and highlight the role of risk assessments as a formal sense-making device that enables learning and organizing knowledge of the dynamic interplay between the climate-sensitive system and its (climatological) environment. We highlight boundary judgments as a core concern of risk assessments, helping to create islands of analytical and cognitive tractability in a complex, uncertain, and ambiguous world. We then point to three key concepts—boundary critique, multi-methodology, and second-order learning—as critical elements of contemporary risk assessment practice, and we weave these into an overarching framework to better account for systemic complexity in the assessment of climate risk.}
}
@article{BECKER2003164,
title = {A computational model of the role of dopamine and psychotropic drugs in modulating motivated action},
journal = {Schizophrenia Research},
volume = {60},
number = {1, Supplement },
pages = {164},
year = {2003},
note = {Abstracts of the IXth International Congress on Schizophrenia Research},
issn = {0920-9964},
doi = {https://doi.org/10.1016/S0920-9964(03)81019-8},
url = {https://www.sciencedirect.com/science/article/pii/S0920996403810198},
author = {S. Becker and A. Chan and P. Fletcher and A. Smith and S. Kapur}
}
@article{BRIMKOV20071631,
title = {Digital hyperplane recognition in arbitrary fixed dimension within an algebraic computation model},
journal = {Image and Vision Computing},
volume = {25},
number = {10},
pages = {1631-1643},
year = {2007},
note = {Discrete Geometry for Computer Imagery 2005},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2006.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0262885606002988},
author = {Valentin E. Brimkov and Stefan Dantchev},
keywords = {Digital hyperplane, Digital plane recognition, Integer programming, Euclidean algorithm},
abstract = {In this paper we present an algorithm for the integer linear programming (ILP) problem within an algebraic model of computation and use it to solve the following digital plane segment recognition problem: Given a set of points M={p1,p2,…,pm}⊆Rn, decide whether M is a portion of a digital hyperplane and, if so, determine its analytical representation. In our setting p1, p2, …,pm may be arbitrary points (possibly, with rational and/or irrational coefficients) and the dimension n may be any arbitrary fixed integer. We reduce this last problem to an ILP to which our general integer programming algorithm applies. It performs O(mlogD) arithmetic operations, where D is a bound on the norm of the domain elements. For the special case of problem dimension two, we propose an elementary algorithm that takes advantage of the specific geometry of the problem and appears to be optimal. It implies an efficient algorithm for digital line segment recognition.}
}
@article{REDKO2016105,
title = {Epistemological foundations of investigation of cognitive evolution},
journal = {Biologically Inspired Cognitive Architectures},
volume = {18},
pages = {105-115},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2016.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X16300597},
author = {Vladimir G. Red’ko},
keywords = {Modeling of cognitive evolution, Cognitive agents, Animal cognitive features, Epistemological foundations},
abstract = {Epistemological foundations for modeling of cognitive evolution are characterized. Cognitive evolution is the evolution of cognitive abilities of biological organisms. The important result of this evolution is the human thinking, which is used at scientific cognition of nature. The related epistemological viewpoints of David Hume, Immanuel Kant, Konrad Lorenz, and Eugene Wigner are outlined. The sketch program for future investigations of cognitive evolution is proposed; initial models of these studies are outlined. According to the presented analysis, it is possible to believe the following. Investigations of cognitive evolution are directed to analyze the fundamental problems: “Why is human thinking applicable to cognition of nature?”, “How did human thinking origin in the process of biological evolution?” There are powerful backgrounds for considered investigations: (1) models of autonomous cognitive agents, (2) biological investigations of animal cognitive features. Studies of cognitive evolution would have broad interdisciplinary relations. These studies should contribute significantly to the development of the scientific point of view.}
}
@incollection{KRAAK2020141,
title = {Geovisualization},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {141-151},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10552-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955105529},
author = {Menno-Jan Kraak},
keywords = {Alternative visualization, Cartography, Cognition, Coordinated multiple views, Geocomputation, Geovisualization, Information visualization, Interfaces, Maps, Representation, Spatiotemporal data, Usability, Visual analytics, Visual exploration, Visual representation, Visual thinking},
abstract = {Due to technological developments and societal needs cartography, scientific visualization, image analysis and remote sensing, information visualization, exploratory data analysis, visual analytics, and GIScience have undergone fundamental changes in recent years. Interactivity and dynamics allow not only maps and diagrams to present known facts but also to analyze and explore unknown data. The environment in which the maps and diagrams are used has also changed and often includes coordinated multiple views display via the Internet. Such environments allow for simultaneous alternative views of the data and stimulate visual thinking, resulting in geovisualization.}
}
@article{RUSSWINKEL2011336,
title = {Predicting temporal errors in complex task environments: A computational and experimental approach},
journal = {Cognitive Systems Research},
volume = {12},
number = {3},
pages = {336-354},
year = {2011},
note = {Special Issue on Complex Cognition},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000143},
author = {Nele Russwinkel and Leon Urbas and Manfred Thüring},
keywords = {Cognitive modelling, Time perception, Working memory, Expectations, Surprise, ACT-R},
abstract = {Management in complex environments requires knowledge about temporal contingencies. Expectations about durations enable us to prepare for important events in good time, but also to detect irregularities. Unfortunately, time perception is not invariant. Situational aspects as well as features of the task at hand may dramatically change our sense of time. Particularly under varying workload conditions, temporal distortions may lead to performance errors. A valid and reliable model of time perception must account for these characteristics. Based on the cognitive architecture ACT-R (Anderson et al., 2004), we developed a computational model in line with this requirement. Specific emphasis was placed on mechanisms of coordinative working memory which seem to influence time encoding and perception. The model’s assumptions were tested in three steps. First, the model was applied to account for time distortions ‘a posteriori’. Effects of varying working memory demands reported by Dutke (2005) were replicated and explained by simulations of the model. Second, the model was used for predicting effects ‘a priori’. Augmenting Dutke’s (2005) approach by switching between different degrees of memory demands, predictions of time distortions were derived from the model. These predictions were compared with experimental data. Central assumptions of the model were supported, but there were also some deviations that the model had not captured. Based on the conclusions from the results of the experiment, a second a priori testing addressed temporal expectations in a complex task using a micro-world scenario. The results support the interpretation of the previous experiment and provide new insights for modelling time perception. In summary, our results indicate that coordinative working memory – in contrast to general attention – causes differences in timing performance. This characteristic is captured by our approach. The model we propose heavily relies on mechanisms of working memory and can be applied to explain effects for different time intervals, under a variety of experimental conditions and in different task environments.}
}
@article{FLANIGAN2017179,
title = {Implicit intelligence beliefs of computer science students: Exploring change across the semester},
journal = {Contemporary Educational Psychology},
volume = {48},
pages = {179-196},
year = {2017},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2016.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X16300479},
author = {Abraham E. Flanigan and Markeya S. Peteranetz and Duane F. Shell and Leen-Kiat Soh},
keywords = {Motivation, Implicit intelligence beliefs, Computer science, Self-regulation, Engagement},
abstract = {This study investigated introductory computer science (CS1) students’ implicit beliefs of intelligence. Referencing Dweck and Leggett’s (1988) framework for implicit beliefs of intelligence, we examined how (1) students’ implicit beliefs changed over the course of a semester, (2) these changes differed as a function of course enrollment and students’ motivated self-regulated engagement profile, and (3) implicit beliefs predicted student learning based on standardized course grades and performance on a computational thinking knowledge test. For all students, there were significant increases in entity beliefs and significant decreases in incremental beliefs across the semester. However, examination of effect sizes suggests that significant findings for change across time were driven by changes in specific subpopulations of students. Moreover, results showed that students endorsed incremental belief more strongly than entity belief at both the beginning and end of the semester. Furthermore, the magnitude of changes differed based on students’ motivated self-regulated engagement profiles. Additionally, students’ achievement outcomes were weakly predicted by their implicit beliefs of intelligence. Finally, results showed that the relationship between changes in implicit intelligence beliefs and student achievement varied across different CS1 courses. Theoretical implications for implicit intelligence beliefs and recommendations for STEM educators are discussed.}
}
@article{SWARUP2006273,
title = {A new evolutionary computation technique for economic dispatch with security constraints},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {28},
number = {4},
pages = {273-283},
year = {2006},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2006.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142061506000020},
author = {K.S. Swarup and P. Rohit Kumar},
keywords = {Power system optimization, Economic load dispatch, Particle swarm optimization, Line-flow, Voltage constraints},
abstract = {This paper presents an efficient and reliable evolutionary based approach to solve the economic load dispatch (ELD) with security constraints. A new approach is proposed which employs attractive and repulsive particle swarm optimization (ARPSO) algorithm for ELD. Incorporation of ARPSO as a derivative-free optimization technique in solving ELD with security (voltages and line-flows) constraints significantly relieves the assumptions imposed on the optimized objective function. The proposed approach has been implemented on three representative systems, i.e. IEEE 14 bus, IEEE 30 bus and IEEE 57 bus systems, respectively. The feasibility of the proposed method is demonstrated and the results are compared with linear programming, quadratic programming and genetic algorithm, respectively. The premature convergence problem, that is common in all evolutionary computation techniques, is solved in ARPSO by including the diversity factor in the Type 1 PSO algorithm. The developed algorithms are computationally faster (in terms of the number of load flows carried out) than the other methods because only one run is required.}
}
@article{OLCAYSOYOKTEN2022111606,
title = {When knowledge is blinding: The dangers of being certain about the future during uncertain societal events},
journal = {Personality and Individual Differences},
volume = {195},
pages = {111606},
year = {2022},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2022.111606},
url = {https://www.sciencedirect.com/science/article/pii/S0191886922001106},
author = {Irmak {Olcaysoy Okten} and Anton Gollwitzer and Gabriele Oettingen},
keywords = {Subjective certainty, Future thinking, COVID-19, Elections, Information seeking, Uncertainty},
abstract = {Past research has independently examined the concepts of certainty and future thought. Here we combine these concepts by examining the cognitive and behavioral outcomes of certainty about the future during periods of societal uncertainty. Three studies (N = 1218) examined future certainty, defined as feeling certain about some future event or outcome, during two major societal events of uncertainty—the COVID-19 pandemic and the 2020 U.S. Presidential Election. In Study 1, certainty about positive or negative futures of COVID-19 (e.g., the pandemic will end soon; the pandemic will never end) predicted poorer information seeking—ignorance of medical experts, adherence to conspiratorial thinking, and lower objective knowledgeability about COVID-19. Building on these findings, in Study 2, future certainty predicted antisocial health behaviors, including failing to social distance. Study 3 extended these findings to the political domain—the 2020 Presidential Election. Future certainty that one's preferred candidate would win the election predicted poor information seeking and antisocial behaviors in terms of claiming that the election was rigged, endorsing violence if one's candidate lost, and, among Trump supporters, identifying with Capitol insurrectionists. These findings suggest that future certainty is linked to intellectual blindness and antisocial behaviors during important periods of societal uncertainty.}
}
@article{PAZBARUCH2023101294,
title = {Cognitive abilities and creativity: The role of working memory and visual processing},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101294},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101294},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000640},
author = {Nurit Paz-Baruch and Rotem Maor},
keywords = {Cognitive abilities, Creativity, Working memory, Visual processing},
abstract = {Recent studies have revealed the importance of cognitive abilities in creative thinking. However, most research addressed adults and only a few studies have examined the ways these correlations are manifested among young children. The present study explores the role of various cognitive abilities in creativity among school children. Measures of creativity, visual-spatial working memory (VSWM), verbal short-term memory (STM), working memory (WM), and visual processing (VP) were administered to 331 students in Grades 4 and 5. Cluster analysis was used to group students' creativity levels. A multivariate analysis of variance (MANOVA) was conducted to test differences in cognitive abilities across the three clusters. Group differences between high and moderate level creativity students and low creativity students were found regarding VP abilities in the following tests: VSWM, visual discrimination (VD), and Raven's Colored Progressive Matrices (RCPM). Group differences between high creativity students and low creativity students were also found on verbal STM and WM. Additionally, structural equation modeling (SEM) analysis revealed that VP can significantly account for unique variances associated with creativity, while verbal STM and WM are not significantly related to creativity. These findings enlighten the cognitive processes underlying creativity in young children.}
}
@article{MORRIS2015,
title = {Efficacy of a Web-Based, Crowdsourced Peer-To-Peer Cognitive Reappraisal Platform for Depression: Randomized Controlled Trial},
journal = {Journal of Medical Internet Research},
volume = {17},
number = {3},
year = {2015},
issn = {1438-8871},
doi = {https://doi.org/10.2196/jmir.4167},
url = {https://www.sciencedirect.com/science/article/pii/S1438887115000783},
author = {Robert R Morris and Stephen M Schueller and Rosalind W Picard},
keywords = {Web-based intervention, crowdsourcing, randomized controlled trial, depression, cognitive behavioral therapy, mental health, social networks},
abstract = {Background
Self-guided, Web-based interventions for depression show promising results but suffer from high attrition and low user engagement. Online peer support networks can be highly engaging, but they show mixed results and lack evidence-based content.
Objective
Our aim was to introduce and evaluate a novel Web-based, peer-to-peer cognitive reappraisal platform designed to promote evidence-based techniques, with the hypotheses that (1) repeated use of the platform increases reappraisal and reduces depression and (2) that the social, crowdsourced interactions enhance engagement.
Methods
Participants aged 18-35 were recruited online and were randomly assigned to the treatment group, “Panoply” (n=84), or an active control group, online expressive writing (n=82). Both are fully automated Web-based platforms. Participants were asked to use their assigned platform for a minimum of 25 minutes per week for 3 weeks. Both platforms involved posting descriptions of stressful thoughts and situations. Participants on the Panoply platform additionally received crowdsourced reappraisal support immediately after submitting a post (median response time=9 minutes). Panoply participants could also practice reappraising stressful situations submitted by other users. Online questionnaires administered at baseline and 3 weeks assessed depression symptoms, reappraisal, and perseverative thinking. Engagement was assessed through self-report measures, session data, and activity levels.
Results
The Panoply platform produced significant improvements from pre to post for depression (P=.001), reappraisal (P<.001), and perseverative thinking (P<.001). The expressive writing platform yielded significant pre to post improvements for depression (P=.02) and perseverative thinking (P<.001), but not reappraisal (P=.45). The two groups did not diverge significantly at post-test on measures of depression or perseverative thinking, though Panoply users had significantly higher reappraisal scores (P=.02) than expressive writing. We also found significant group by treatment interactions. Individuals with elevated depression symptoms showed greater comparative benefit from Panoply for depression (P=.02) and perseverative thinking (P=.008). Individuals with baseline reappraisal deficits showed greater comparative benefit from Panoply for depression (P=.002) and perseverative thinking (P=.002). Changes in reappraisal mediated the effects of Panoply, but not the expressive writing platform, for both outcomes of depression (ab=-1.04, SE 0.58, 95% CI -2.67 to -.12) and perseverative thinking (ab=-1.02, SE 0.61, 95% CI -2.88 to -.20). Dropout rates were similar for the two platforms; however, Panoply yielded significantly more usage activity (P<.001) and significantly greater user experience scores (P<.001).
Conclusions
Panoply engaged its users and was especially helpful for depressed individuals and for those who might ordinarily underutilize reappraisal techniques. Further investigation is needed to examine the long-term effects of such a platform and whether the benefits generalize to a more diverse population of users.
Trial Registration
ClinicalTrials.gov NCT02302248; https://clinicaltrials.gov/ct2/show/NCT02302248 (Archived by WebCite at http://www.webcitation.org/6Wtkj6CXU).}
}
@incollection{ESFELD2015131,
title = {Atomism and Holism: Philosophical Aspects},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {131-135},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.63003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868630039},
author = {Michael Esfeld},
keywords = {Atomism, Collectivism, Confirmation, Externalism, Holism, Human nature, Individualism, Internalism, Meaning, Ontological dependence, Rationality, Rule-following, Thought},
abstract = {In the philosophy of the social sciences, atomism is the view that human beings can be thinking, rational beings independently of social relations. Holism, by contrast, is the view that social relations are essential to human beings insofar as they are thinking, rational beings. This article first provides an overview of different sorts of atomism and holism (see Section Types of Atomism and Holism). It then briefly sketches the historical background of these notions in modern philosophy (Section The Historical Background of Atomism and Holism). The main part is a systematic characterization of atomism and holism (see Section A Characterization of Atomism and Holism) and a summary of the most important arguments for both these positions (see Section Arguments for Atomism and Holism).}
}
@article{RAPAKA2025100809,
title = {Revolutionizing learning − A journey into educational games with immersive and AI technologies},
journal = {Entertainment Computing},
volume = {52},
pages = {100809},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100809},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124001770},
author = {Anuj Rapaka and S.C. Dharmadhikari and Kishori Kasat and Chinnem Rama Mohan and Kuldeep Chouhan and Manu Gupta},
keywords = {Artificial intelligence (AI), Educational games, Learning styles, Stochastic swing golf optimization (SSGOA)},
abstract = {Educational games rapidly integrate entertainment technology and learning, engaging individuals in dynamic educational experiences. These games incorporate multimedia content to encourage critical thinking, problem-solving and information retention. Educational games employ immersive technology such as virtual and augmented reality to transfer individuals to simulated worlds, hence improving learning. Furthermore, artificial intelligence (AI) technologies optimize educational experiences by adjusting information to individual learning styles, providing focused feedback as well as encouraging a more effective and entertaining learning technology. The integration of educational games with immersive and AI technology provides great potential for transforming how individuals acquire and apply information sharing. This research determined the creation of significant educational applications that are personalized and adaptive through the use of image, emotional recognition and speech, intelligent agents that replicate the effects of an individual opponent and control over the complexities of game levels along with information. The study evaluated the different tools that educators and learners could utilize to develop immersive and artificial intelligence-based instructional games without a requirement for programming knowledge. The study demonstrates that immersive technology and AI technology could represent beneficial resources for creating educational video games and entertainment technology. The research highlights the novel possibilities of stochastic swing golf optimization (SSGOA) immersive and AI technologies providing an innovative approach to developing effective as well as attractive learning environments.}
}
@incollection{ZIMMERMAN2005255,
title = {VIII - Development of Theory with Computation},
editor = {M. Olivucci},
series = {Theoretical and Computational Chemistry},
publisher = {Elsevier},
volume = {16},
pages = {255-278},
year = {2005},
booktitle = {Computational Photochemistry},
issn = {1380-7323},
doi = {https://doi.org/10.1016/S1380-7323(05)80025-1},
url = {https://www.sciencedirect.com/science/article/pii/S1380732305800251},
author = {Howard E. Zimmerman}
}
@article{SAHA2024,
title = {Predicting depression level based on human activities and feelings: A fuzzy logic-based analysis},
journal = {Data Science and Management},
year = {2024},
issn = {2666-7649},
doi = {https://doi.org/10.1016/j.dsm.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S266676492400064X},
author = {Urmi Saha and Syed Mohammod {Minhaz Hossain} and Iqbal H. Sarker},
keywords = {Depression Level Prediction, Human Activities, Human Feelings, Pearson Correlation Method, R-Squared Method, Uncertainty, Fuzzy Rules},
abstract = {Millions of individuals die by suicide each year, and many more suffer from severe depression. Furthermore, these deaths harm education, the economy, and healthcare worldwide. An individual’s persistent feelings and activities, which include sleep disorders such as insomnia, sleeping overtime, or spending the majority of time lying down; pessimistic thinking about the future; and thoughts of committing suicide, help uncover the cause of depression. Several attempts have been made to prevent these losses and deaths. Our study proposes a simple fuzzy inference model that accurately predicts depression levels based on emotions and activities—even with incomplete data and uncertainties—and enhances mental health prediction, bridging theory and practice effectively. Psychologists and professors collaborated to create a survey to collect data for this study. The experiment was conducted using a Google survey form. This method effectively captures the ambiguity and imprecision in depression evaluation by combining linguistic elements of psychological traits. Using the Pearson correlation and R-squared methods, 15 features were chosen from 30 features, followed by five membership functions (poor, mediocre, average, decent, and good) and fuzzy rules to evaluate and create accurate forecasts of depression severity. Our proposed architecture can correctly classify depression levels based on human activities and feelings with 94% accuracy using a less sophisticated rules dictionary than previous pre-trained or hybrid models. Fuzzy logic performs better here by accurately categorizing ambiguous human emotional inputs into distinct degrees.}
}
@article{MASON2020103898,
title = {Development and analysis of the Elementary Student Coding Attitudes Survey},
journal = {Computers & Education},
volume = {153},
pages = {103898},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103898},
url = {https://www.sciencedirect.com/science/article/pii/S036013152030097X},
author = {Stacie L. Mason and Peter J. Rich},
keywords = {Elementary education, Computational thinking, Coding, Attitude scale, Instrument validation},
abstract = {There is an increasing emphasis on teaching young learners to code; yet, there are few tools designed to measure the effect of learning to code on children. The purpose of this study was to develop and validate a tool to assess changes in young learners' attitudes toward coding: the Elementary Student Coding Attitudes Survey (ESCAS). We validated the scale using Confirmatory Factory Analysis and Structural Equation Modeling with responses from over 6000 4th-6th grade students (aged 9–12 years). Survey validation revealed a scale consisting of five constructs that comprise young learners' attitudes toward coding: social value, coding confidence, coding interest, perception of coders, and coding utility. In our analysis, students' grade level, ethnicity, gender, coding frequency, coding experience, and math interest influenced social value, which in turn influenced coding interest, perception of coders, and coding utility. Students' math confidence, coding frequency, coding experience, ethnicity, and coding interest predicted their coding confidence. Among observable variables, coding frequency and math interest had the greatest influence on social value, which substantially influenced all other factors. We discuss how this tool can help those who teach coding to young children to better measure and understand the variables that may influence young learners’ attitudes toward coding over time.}
}
@article{HICKOK2011407,
title = {Sensorimotor Integration in Speech Processing: Computational Basis and Neural Organization},
journal = {Neuron},
volume = {69},
number = {3},
pages = {407-422},
year = {2011},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2011.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0896627311000675},
author = {Gregory Hickok and John Houde and Feng Rong},
abstract = {Sensorimotor integration is an active domain of speech research and is characterized by two main ideas, that the auditory system is critically involved in speech production and that the motor system is critically involved in speech perception. Despite the complementarity of these ideas, there is little crosstalk between these literatures. We propose an integrative model of the speech-related “dorsal stream” in which sensorimotor interaction primarily supports speech production, in the form of a state feedback control architecture. A critical component of this control system is forward sensory prediction, which affords a natural mechanism for limited motor influence on perception, as recent perceptual research has suggested. Evidence shows that this influence is modulatory but not necessary for speech perception. The neuroanatomy of the proposed circuit is discussed as well as some probable clinical correlates including conduction aphasia, stuttering, and aspects of schizophrenia.}
}
@article{CROOKS2014344,
title = {Defining and measuring conceptual knowledge in mathematics},
journal = {Developmental Review},
volume = {34},
number = {4},
pages = {344-377},
year = {2014},
issn = {0273-2297},
doi = {https://doi.org/10.1016/j.dr.2014.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0273229714000380},
author = {Noelle M. Crooks and Martha W. Alibali},
keywords = {Mathematical thinking, Conceptual knowledge, Equivalence, Cardinality, Inversion},
abstract = {A long tradition of research on mathematical thinking has focused on procedural knowledge, or knowledge of how to solve problems and enact procedures. In recent years, however, there has been a shift toward focusing, not only on solving problems, but also on conceptual knowledge. In the current work, we reviewed (1) how conceptual knowledge is defined in the mathematical thinking literature, and (2) how conceptual knowledge is defined, operationalized, and measured in three mathematical domains: equivalence, cardinality, and inversion. We uncovered three general issues. First, few investigators provide explicit definitions of conceptual knowledge. Second, the definitions that are provided are often vague or poorly operationalized. Finally, the tasks used to measure conceptual knowledge do not always align with theoretical claims about mathematical understanding. Together, these three issues make it challenging to understand the development of conceptual knowledge, its relationship to procedural knowledge, and how it can best be taught to students. In light of these issues, we propose a general framework that divides conceptual knowledge into two facets: knowledge of general principles and knowledge of the principles underlying procedures.}
}
@article{HEYN2023111604,
title = {A compositional approach to creating architecture frameworks with an application to distributed AI systems},
journal = {Journal of Systems and Software},
volume = {198},
pages = {111604},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2022.111604},
url = {https://www.sciencedirect.com/science/article/pii/S0164121222002801},
author = {Hans-Martin Heyn and Eric Knauss and Patrizio Pelliccione},
keywords = {AI systems, Architectural frameworks, Compositional thinking, Requirements engineering, Systems engineering},
abstract = {Artificial intelligence (AI) in its various forms finds more and more its way into complex distributed systems. For instance, it is used locally, as part of a sensor system, on the edge for low-latency high-performance inference, or in the cloud, e.g. for data mining. Modern complex systems, such as connected vehicles, are often part of an Internet of Things (IoT). This poses additional architectural challenges. To manage complexity, architectures are described with architecture frameworks, which are composed of a number of architectural views connected through correspondence rules. Despite some attempts, the definition of a mathematical foundation for architecture frameworks that are suitable for the development of distributed AI systems still requires investigation and study. In this paper, we propose to extend the state of the art on architecture framework by providing a mathematical model for system architectures, which is scalable and supports co-evolution of different aspects for example of an AI system. Based on Design Science Research, this study starts by identifying the challenges with architectural frameworks in a use case of distributed AI systems. Then, we derive from the identified challenges four rules, and we formulate them by exploiting concepts from category theory. We show how compositional thinking can provide rules for the creation and management of architectural frameworks for complex systems, for example distributed systems with AI. The aim of the paper is not to provide viewpoints or architecture models specific to AI systems, but instead to provide guidelines based on a mathematical formulation on how a consistent framework can be built up with existing, or newly created, viewpoints. To put in practice and test the approach, the identified and formulated rules are applied to derive an architectural framework for the EU Horizon 2020 project “Very efficient deep learning in the IoT” (VEDLIoT) in the form of a case study.}
}
@article{BARBER200798,
title = {Interplay between computational models and cognitive electrophysiology in visual word recognition},
journal = {Brain Research Reviews},
volume = {53},
number = {1},
pages = {98-123},
year = {2007},
issn = {0165-0173},
doi = {https://doi.org/10.1016/j.brainresrev.2006.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165017306000853},
author = {Horacio A. Barber and Marta Kutas},
keywords = {Language, Reading, Visual word recognition, Computational model, Event-related potential (ERP), EEG, MEG, Cognitive electrophysiology},
abstract = {In this article, we discuss the relevance of electrophysiological data to the enterprise of analyzing and understanding the reading process. Specifically, we detail how the event-related brain potential (ERP) technique (and its magnetic counterpart) can aid in development of models of visual word recognition. Any viable and accurate account of reading must take into account the temporal and anatomical constraints imposed by the fact that reading is a human brain function. We believe that neurophysiological (especially, although not limited to electrophysiological) data can serve an essential reference in the development of biologically realistic models of reading. We assess just how well extant electrophysiological data comport with specific predictions of existing computational models and offer some suggestions for the kinds of research that can address some of the remaining open questions.}
}
@article{WOLFE197853,
title = {The rise of network thinking in anthropology},
journal = {Social Networks},
volume = {1},
number = {1},
pages = {53-64},
year = {1978},
issn = {0378-8733},
doi = {https://doi.org/10.1016/0378-8733(78)90012-6},
url = {https://www.sciencedirect.com/science/article/pii/0378873378900126},
author = {Alvin W. Wolfe},
abstract = {The encyclopedic inventory of the first half of the twentieth century, “Anthropology Today”, published in 1953, gave little inkling that within a few decades developing trends in social theory, in field experience, in electronic data processing, and in mathematics would combine to bring to prominence a distinctive theoretical approach using a quite formal network model for social systems. Now, sophisticated mathematics and computer programming permit sophisticated network models — networks seen as sets of links, networks seen as generated structures, and networks seen as flow processes. Although network thinking has shown a dramatic rise from the “Anthropology Today” of 1953 to the current anthropology of 1978, it is predicted to soar in the next quarter century, much of the weighty burden of network analysis having been lifted from us by ever more rapid electronic data processing.}
}
@article{MATTHEWS2021100278,
title = {Reconceptualising feedback: Designing educational tangible technologies to be a creative material},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100278},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100278},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000210},
author = {Sarah Matthews and Ben Matthews},
keywords = {Tangible technologies, Feedback, Educational technologies, Creative material, Interaction design, Empirical studies},
abstract = {This paper investigates how children who are engaged in a creative project with tangible technology kits make sense of the system feedback the technology provides. A micro-analytic video study was conducted of primary school children designing their own technologies using existing educational microcontrollers. Our investigation reveals that the roles feedback plays in children’s interactions cannot easily be assimilated within the existing approaches to understand feedback that have been articulated in HCI literature. Our qualitative analysis shows how children do not make sense of feedback as semantic communication from the system, but make sense of it with respect to its embeddedness in a sequence of activities they are performing with the system and each other. The principal contribution to emerge from our study is a conception of feedback as a process, rather than as a semantic communicative event, nor a direct coupling of action and system response. Our discussion identifies how feedback participates in the institutional agendas of classrooms (e.g. discovery, computational thinking), and draws out initial implications for the design of feedback in educational tangible technologies, identifying possibilities for how feedback might be redesigned to better promote children’s diagnostic practices with open-ended technology kits.}
}
@article{ZOMAYA2004551,
title = {Parallel and nature-inspired computational paradigms and applications},
journal = {Parallel Computing},
volume = {30},
number = {5},
pages = {551-552},
year = {2004},
note = {Parallel and nature-inspired computational paradigms and applications},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2004.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167819104000304},
author = {Albert Y Zomaya and Fikret Ercal and El-ghazali Talbi}
}
@article{HUNTER2025100118,
title = {Is LIWC reliable, efficient, and effective for the analysis of large online datasets in forensic and security contexts?},
journal = {Applied Corpus Linguistics},
volume = {5},
number = {1},
pages = {100118},
year = {2025},
issn = {2666-7991},
doi = {https://doi.org/10.1016/j.acorp.2025.100118},
url = {https://www.sciencedirect.com/science/article/pii/S2666799125000012},
author = {Madison Hunter and Tim Grant},
keywords = {LIWC, Reliability, Computerized text analysis, Forensic linguistics, Discourse analysis},
abstract = {This article evaluates the reliability, efficiency, and effectiveness of Linguistic Inquiry and Word Count (LIWC; Boyd et al., 2022) for the analysis of a white nationalist forum. This is important because LIWC has been the computational tool of choice for scores of studies generally and many examining extremist content in a forensic or security context. Our purpose, therefore, is to understand whether LIWC can be depended upon for large-scale analyses; we initially examine this here using a small sample of posts from a set of just eight users and manually checking the program's automated codings of a subset of categories. Our results show that the LIWC coding cannot be relied upon – precision falls to as low as 49.6 % and recall as low as 41.7 % for some categories. It would be possible to engage in considerable manual correction of these results, but this undermines its purported efficiency for large datasets.}
}
@incollection{HALL2006338,
title = {Computational Approaches to Fibril Structure and Formation},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {412},
pages = {338-365},
year = {2006},
booktitle = {Amyloid, Prions, and Other Protein Aggregates, Part B},
issn = {0076-6879},
doi = {https://doi.org/10.1016/S0076-6879(06)12020-0},
url = {https://www.sciencedirect.com/science/article/pii/S0076687906120200},
author = {Carol K. Hall and Victoria A. Wagoner},
abstract = {Assembly of normally soluble proteins into amyloid fibrils is a cause or associated symptom of numerous human disorders. Although some progress toward understanding the molecular‐level details of fibril structure has been made through in vitro experiments, the insoluble nature of fibrils make them difficult to study experimentally. We describe two computational approaches used to investigate fibril formation and structure: intermediate‐resolution discontinuous molecular dynamics simulations and atomistic molecular dynamics simulations. Each method has its strengths and weaknesses, but taken together the two approaches provide a useful molecular‐level picture of fibril structure and formation.}
}
@article{TUZUN202085,
title = {Introduction to systems engineering and sustainability PART I: Student-centred learning for chemical and biological engineers},
journal = {Education for Chemical Engineers},
volume = {31},
pages = {85-93},
year = {2020},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2020.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1749772820300269},
author = {U. Tuzun},
keywords = {Systems engineering & sustainability, Active learning, Formative assessment},
abstract = {Student-Centred Active Learning of Systems Engineering and Sustainability requires challenging metacognitive integration of high-level evaluation skills combined with discipline-based core knowledge. This two-part series aims to demonstrate the basic principles, methodology and specific examples of active learning with formative assessment implemented to achieve improved student academic performance. In this part I of the two-part series, firstly, a detailed description is introduced of the cognitive learning methodology which makes use of student-centered recognition, analysis and synthesis for decision-making when there is no entirely right or wrong decision. The concept of “decision situation” is described which combines several surrounding and contingency elements to arrive at a demonstration of the holistic decision-making through systems analysis. A Holistic thinking approach is further developed using a systems learning methodology that combines normative with descriptive analyses to arrive at a cognitive mode model of judgement and choice. Sustainability modelling using the three-gateway systems approach is introduced and compared with the multi-layered view of chemical and biochemical engineering education and research; see Gani et al. (2020). Holistic thinking strategy is applied most recently to integrating, backcasting and eco-design for the circular economy (CE); see Mendoza et al. (2017). A student-centred learning approach is advocated that makes use of these principles and enables the systematic embedding of sustainability modeling in industrial and economic activities whose success rely substantively on decision-making. Finally, the relative importance is evaluated using classroom data available with specific engineering topics of the didactic “rule-based” methods of knowledge transfer in contrast with the experiential accumulation of practical information amassed through social interactions in a co-operative learning environment that relies on sustained improvement through active communication and feedback between the teacher/instructor and the student/learner; see Stephan et al. (2017) and Shallcross and Alpay (2018).}
}
@article{BOKHOVE2023100497,
title = {Using Social Network Analysis to gain insight into social creativity while designing digital mathematics books},
journal = {Social Sciences & Humanities Open},
volume = {8},
number = {1},
pages = {100497},
year = {2023},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2023.100497},
url = {https://www.sciencedirect.com/science/article/pii/S259029112300102X},
author = {Christian Bokhove and Marios Xenos and Manolis Mavrikis},
keywords = {Technological environment, Co-creation, Social creativity, Social network analysis},
abstract = {Analysing the processes and products of creativity to better understand and support individuals and teams, is a difficult and elusive challenge despite years of research in creativity. In this article, we are particularly interested in social creativity in communities of interest. Building on Guilford's classic model of Divergent Thinking of fluency, flexibility, originality and elaboration, we employ Social Network Analysis to model the creative design process. The creative process in the current study takes place in a technological environment called the ‘MC-squared platform’, in which members of a community of interest collaborate in a social, co-creative process for designing digital, mathematical textbooks. Both the technological environment and the methodology are exemplified through two case examples, one on the design process of a digital book about a bioclimatic amusement park and one on the design process of a digital book about fractions. We conclude that, for these examples, both the technological tool and the data analysis approach provide insight into the social creativity process of the community of interest.}
}
@article{SAVARD2025109184,
title = {Toward cognitive models of misophonia},
journal = {Hearing Research},
volume = {458},
pages = {109184},
year = {2025},
issn = {0378-5955},
doi = {https://doi.org/10.1016/j.heares.2025.109184},
url = {https://www.sciencedirect.com/science/article/pii/S0378595525000036},
author = {Marie-Anick Savard and Emily B.J. Coffey},
keywords = {Misophonia, Cognitive science, Cognitive neuroscience, Sound sensitivity, Models},
abstract = {Misophonia is a disorder in which specific common sounds such as another person breathing or chewing, or the ticking of a clock, cause an atypical negative emotional response. Affected individuals may experience anger, irritability, annoyance, disgust, and anxiety, as well as physiological autonomic responses, and may find everyday environments and contexts to be unbearable in which their ‘misophonic stimuli’ (often called ‘trigger sounds’) are present. Misophonia is gradually being recognized as a genuine problem that causes significant distress and has negative consequences for individuals and their families. It has only recently come under scientific scrutiny, as researchers and clinicians are establishing its prevalence, distinguishing it from other disorders of sensory sensitivity such as hyperacusis, establishing its neurobiological bases, and evaluating the effectiveness of potential treatments. While ideas abound as to the mechanisms involved in misophonia, few have coalesced into models. The aim of the present work is to summarize and extend recent thinking on the mechanistic basis of misophonia, with a focus on moving towards neurologically-informed cognitive models that can (a) account for extant findings, and (b) generate testable predictions. We hope this work will facilitate future refinements in our understanding of misophonia, and ultimately inform treatments.}
}
@article{ZHOU2025110885,
title = {Developing a deep reinforcement learning model for safety risk prediction at subway construction sites},
journal = {Reliability Engineering & System Safety},
volume = {257},
pages = {110885},
year = {2025},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2025.110885},
url = {https://www.sciencedirect.com/science/article/pii/S0951832025000894},
author = {Zhipeng Zhou and Wen Zhuo and Jianqiang Cui and Haiying Luan and Yudi Chen and Dong Lin},
keywords = {Subway construction safety, Grounded theory, Deep reinforcement learning, Double deep Q-network, Permutation importance},
abstract = {Underground construction work is heavily affected by surrounding hydrogeology, adjacent pipelines, and existing subway lines, which can lead to a high degree of uncertainty and generate safety risk on site. In order to overcome rigid thinking of causal factors within a structured framework and incorporate features of different accidents, this study adopted grounded theory for the investigation on factors contributing to workplace accidents in subway construction. The deep reinforcement learning model of double deep Q-network (DDQN) was developed for predicting subway construction safety risk, which integrated the advantage of reinforcement learning in decision making with the advantage of deep learning in objection perception. The findings denoted that DDQN performed better than other machine learning models inclusive of random forest, extreme gradient boosting, k-nearest neighbor, and support vector machine. Contributing factors relevant to subway construction accidents were quantitatively analyzed using permutation importance of attributes. It was beneficial for determining how the 37 contributing factors had negative effects on subway construction safety risk. Safety measures for risk reduction and controlling could be optimized according to permutation importance of individual contributing factor, which paved a new way for the promotion of safety management performance at subway construction sites.}
}
@article{BROSSEAU2003373,
title = {Computational electromagnetics and the rational design of new dielectric heterostructures},
journal = {Progress in Materials Science},
volume = {48},
number = {5},
pages = {373-456},
year = {2003},
issn = {0079-6425},
doi = {https://doi.org/10.1016/S0079-6425(02)00013-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079642502000130},
author = {C. Brosseau and A. Beroual},
abstract = {Dielectric properties of heterogeneous materials for various condensed-matter systems have been gaining world-wide attention over the past 50 or so years in the design (or engineering) of materials structures for desired properties and functional purposes. These applications range from cable and current limiters to sensors. These multiscale systems lead to challenging problems of connecting micro- or meso-structural features to macroscopic materials response, i.e. permittivity, conductivity. This article first reviews progress made at that time of the underlying physics of dielectric heterostructures and points out the missing elements that have led to a resurgence of interest in these and related materials. Recent advances in computational electromagnetics provide unparalleled control over morphology in this class of materials to produce a seemingly unlimited number of exquisitely structured materials endowed with tailored electromagnetic, and other physical properties. In the text to follow, we illustrate how an ab initio computational technique can be used to accurately characterize structure–dielectric property relationships of periodic heterostructures in the quasistatic limit. More specifically, we have carried out two-dimensional (2D) and three-dimensional (3D) numerical studies of two-component materials in which equal-sized inclusions, with shape and orientation and possibly fused together, are fixed in a periodic square (2D) or cubic (3D) array. Boundary-integral equations (BIE) are derived from Green's theorem and are solved for the local field with appropriate periodicity conditions on a unit cell of the structures using the field calculation package PHI3D. A number of illustrative examples shows how this computational technique can provide very accurate predictions for the complex effective permittivity of translationally-invariant heterostructures. The performance of the method is also compared with those of other computational and analytical techniques. We comment on how this computational method helps identify some important characteristics for rationalizing and predicting the structure of composite materials in terms of the nature, size, shape and orientation of their constituents.}
}
@incollection{CAMERON200789,
title = {Designing Computational Clusters for Performance and Power},
editor = {Marvin V. Zelkowitz},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {69},
pages = {89-153},
year = {2007},
booktitle = {Architectural Issues},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(06)69002-5},
url = {https://www.sciencedirect.com/science/article/pii/S0065245806690025},
author = {Kirk W. Cameron and Rong Ge and Xizhou Feng},
abstract = {Power consumption in computational clusters has reached critical levels. High-end cluster performance improves exponentially while the power consumed and heat dissipated increase operational costs and failure rates. Yet, the demand for more powerful machines continues to grow. In this chapter, we motivate the need to reconsider the traditional performance-at-any-cost cluster design approach. We propose designs where power and performance are considered critical constraints. We describe power-aware and low power techniques to reduce the power profiles of parallel applications and mitigate the impact on performance.}
}
@article{DRAGGIOTIS1998157,
title = {On the computation of multigluon amplitudes},
journal = {Physics Letters B},
volume = {439},
number = {1},
pages = {157-164},
year = {1998},
issn = {0370-2693},
doi = {https://doi.org/10.1016/S0370-2693(98)01015-6},
url = {https://www.sciencedirect.com/science/article/pii/S0370269398010156},
author = {Petros Draggiotis and Ronald H.P. Kleiss and Costas G. Papadopoulos},
abstract = {A computational algorithm based on recursive equations is developed in order to estimate multigluon production processes at high energy hadron colliders. The partonic reactions gg→(n−2)g with n≤9 are studied and comparisons with known approximations are presented.}
}
@incollection{YANG20133,
title = {1 - Swarm Intelligence and Bio-Inspired Computation: An Overview},
editor = {Xin-She Yang and Zhihua Cui and Renbin Xiao and Amir Hossein Gandomi and Mehmet Karamanoglu},
booktitle = {Swarm Intelligence and Bio-Inspired Computation},
publisher = {Elsevier},
address = {Oxford},
pages = {3-23},
year = {2013},
isbn = {978-0-12-405163-8},
doi = {https://doi.org/10.1016/B978-0-12-405163-8.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124051638000016},
author = {Xin-She Yang and Mehmet Karamanoglu},
keywords = {Algorithm, ant algorithm, bee algorithm, bat algorithm, bio-inspired, cuckoo search, firefly algorithm, harmony search, particle swarm optimization, swarm intelligence, metaheuristics},
abstract = {Swarm intelligence (SI) and bio-inspired computing in general have attracted great interest in almost every area of science, engineering, and industry over the last two decades. In this chapter, we provide an overview of some of the most widely used bio-inspired algorithms, especially those based on SI such as cuckoo search, firefly algorithm, and particle swarm optimization. We also analyze the essence of algorithms and their connections to self-organization. Furthermore, we highlight the main challenging issues associated with these metaheuristic algorithms with in-depth discussions. Finally, we provide some key, open problems that need to be addressed in the next decade.}
}