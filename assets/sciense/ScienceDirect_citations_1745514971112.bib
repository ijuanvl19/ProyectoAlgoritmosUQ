@article{JOKONYA20141533,
title = {Towards a Big Data Framework for the Prevention and Control of HIV/AIDS, TB and Silicosis in the Mining Industry},
journal = {Procedia Technology},
volume = {16},
pages = {1533-1541},
year = {2014},
note = {CENTERIS 2014 - Conference on ENTERprise Information Systems / ProjMAN 2014 - International Conference on Project MANagement / HCIST 2014 - International Conference on Health and Social Care Information Systems and Technologies},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2014.10.175},
url = {https://www.sciencedirect.com/science/article/pii/S2212017314004022},
author = {Osden Jokonya},
keywords = {Tuberculosis, Big Data, HIV/AIDS, Silicosis, Systems Approach, Viable Systems Model, Organizational Cybernetics, Hard Systems Thinking, Soft Systems Thinking, Emancipatory Systems Thinking, Critical Systems Thinking, Epidemiology},
abstract = {This paper proposes a big data integrated framework to assist with prevention and control of HIV/AIDS, TB and silicosis (HATS) in the mining industry. The linkage between HATS presents a major challenge to the mining industry globally. When the immune system is compromised by HIV/AIDS and silicosis, it makes it easier for tuberculosis to infect the body. In addition, the silica dust which affects the lungs may also cause silicosis and tuberculosis. The objective of this paper is to posit a big data integrated framework to assist in the prevention and control of HATS in the mining industry. Literature was reviewed in order to build a conceptual framework. Although this study is not the first to apply big data in healthcare, to the researcher's knowledge, it is the first to apply big data in understanding the linkage between HATS in the mining industry. The literature review indicates only a few studies using big data in healthcare with no research found on big data and HATS. It therefore makes a contribution to existing body of literature on the control of HATS. The proposed big data framework has the potential of addressing the needs of predictive epidemiology which is important in forecasting and disease control in the mining industry. The paper therefore lays a foundation for the use of viable systems model and big data to address the challenges of HATS in the mining industry. As part of future work, the framework will be validated using sequential explanatory mixed methods case study approach in mining organizations.}
}
@article{MARTINEZMINGO2023101154,
title = {Quantum projections on conceptual subspaces},
journal = {Cognitive Systems Research},
volume = {82},
pages = {101154},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101154},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723000827},
author = {Alejandro Martínez-Mingo and Guillermo Jorge-Botana and José Ángel Martinez-Huertas and Ricardo {Olmos Albacete}},
keywords = {Quantum similarity model, Semantic-vector space models, Computational linguistics, Similarity},
abstract = {One of the main challenges of cognitive science is to explain the representation of conceptual knowledge and the mechanisms involved in evaluating the similarities between these representations. Theories that attempt to explain this phenomenon should account for the fact that conceptual knowledge is not static. In line with this thinking, many studies suggest that the representation of a concept changes depending on context. Traditionally, concepts have been studied as vectors within a geometric space, sometimes called Semantic-Vector Space Models (S-VSMs). However, S-VSMs have certain limitations in emulating human biases or context effects when the similarity of concepts is judged. Such limitations are related to the use of a classical geometric approach that represents a concept as a point in space. Recently, some theories have proposed the use of sequential projections of subspaces based on Quantum Probability Theory (Busemeyer and Bruza, 2012; Pothos et al., 2013). They argue that this theoretical approach may facilitate accounting for human similarity biases and context effects in a more natural way. More specifically, Pothos and Busemeyer (2011) proposed the Quantum Similarity Model (QSM) to determine expectation in conceptual spaces in a non-monotonic logic frame. To the best of our knowledge, previous data-driven studies have used the QSM subspaces in a unidimensional way. In this paper, we present a data-driven method to generate these conceptual subspaces in a multidimensional manner using a traditional S-VSM. We present an illustration of the method taking Tversky’s classical examples to explain the effects of Asymmetry, Triangular Inequality, and the Diagnosticity by means of sequential projections of those conceptual subspaces.}
}
@article{LIBEROS2019319,
title = {Phase singularity point tracking for the identification of typical and atypical flutter patients: A clinical-computational study},
journal = {Computers in Biology and Medicine},
volume = {104},
pages = {319-328},
year = {2019},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2018.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0010482518303901},
author = {A. Liberos and M. Rodrigo and I. Hernandez-Romero and A. Quesada and F. Fernandez-Aviles and F. Atienza and A.M. Climent and M.S. Guillem},
keywords = {Atrial flutter, Phase map, Cardiac model, Body surface potential mapping},
abstract = {Atrial Flutter (AFL) termination by ablating the path responsible for the arrhythmia maintenance is an extended practice. However, the difficulty associated with the identification of the circuit in the case of atypical AFL motivates the development of diagnostic techniques. We propose body surface phase map analysis as a noninvasive tool to identify AFL circuits. Sixty seven lead body surface recordings were acquired in 9 patients during AFL (i.e. 3 typical, 6 atypical). Computed body surface phase maps from simulations of 5 reentrant behaviors in a realistic atrial structure were also used. Surface representation of the macro-reentrant activity was analyzed by tracking the singularity points (SPs) in surface phase maps obtained from band-pass filtered body surface potential maps. Spatial distribution of SPs showed significant differences between typical and atypical AFL. Whereas for typical AFL patients 70.78 ± 16.17% of the maps presented two SPs simultaneously in the areas defined around the midaxialliary lines, this condition was only satisfied in 5.15 ± 10.99% (p < 0.05) maps corresponding to atypical AFL patients. Simulations confirmed these results. Surface phase maps highlights the reentrant mechanism maintaining the arrhythmia and appear as a promising tool for the noninvasive characterization of the circuit maintaining AFL. The potential of the technique as a diagnosis tool needs to be evaluated in larger populations and, if it is confirmed, may help in planning ablation procedures.}
}
@article{HUANG2022209,
title = {A Framework for Collaborative Artificial Intelligence in Marketing},
journal = {Journal of Retailing},
volume = {98},
number = {2},
pages = {209-223},
year = {2022},
issn = {0022-4359},
doi = {https://doi.org/10.1016/j.jretai.2021.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0022435921000142},
author = {Ming-Hui Huang and Roland T. Rust},
keywords = {Artificial intelligence, Collaborative AI, Collaborative intelligence, Augmentation, Replacement},
abstract = {We develop a conceptual framework for collaborative artificial intelligence (AI) in marketing, providing systematic guidance for how human marketers and consumers can team up with AI, which has profound implications for retailing, which is the interface between marketers and consumers. Drawing from the multiple intelligences view that AI advances from mechanical, to thinking, to feeling intelligence (based on how difficult for AI to mimic human intelligences), the framework posits that collaboration between AI and HI (human marketers and consumers) can be achieved by 1) recognizing the respective strengths of AI and HI, 2) having lower-level AI augmenting higher-level HI, and 3) moving HI to a higher intelligence level when AI automates the lower level. Implications for marketers, consumers, and researchers are derived. Marketers should optimize the mix and timing of AI-HI marketing team, consumers should understand the complementarity between AI and HI strengths for informed consumption decisions, and researchers can investigate innovative approaches to and boundary conditions of collaborative intelligence.}
}
@article{JOHNSON20013201,
title = {Methods for 3D computation of fluid–object interactions in spatially periodic flows},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {24},
pages = {3201-3221},
year = {2001},
note = {Advances in Computational Methods for Fluid-Structure Interaction},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(00)00389-3},
url = {https://www.sciencedirect.com/science/article/pii/S0045782500003893},
author = {Andrew Johnson and Tayfun Tezduyar},
abstract = {We present computational methods for 3D simulation of fluid–object interactions in spatially periodic flows. These methods include a stabilized space-time finite element formulation for incompressible flows with spatial periodicity, automatic mesh generation and update techniques for fluid–object mixtures with spatial periodicity, and parallel implementations. The methods can be applied to uni-periodic (i.e., periodic in one direction), bi-periodic, or tri-periodic flows. The methods are described here in the context of tri-periodic flows with fluid–object interactions, and are applied to the simulation of sedimentation of particles in a fluid. We present several case studies where the results obtained provide notable insight into the behavior of fluid–particle mixtures during sedimentation.}
}
@incollection{ALIPPI2019245,
title = {Chapter 12 - Computational Intelligence in the Time of Cyber-Physical Systems and the Internet of Things},
editor = {Robert Kozma and Cesare Alippi and Yoonsuck Choe and Francesco Carlo Morabito},
booktitle = {Artificial Intelligence in the Age of Neural Networks and Brain Computing},
publisher = {Academic Press},
pages = {245-263},
year = {2019},
isbn = {978-0-12-815480-9},
doi = {https://doi.org/10.1016/B978-0-12-815480-9.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128154809000128},
author = {Cesare Alippi and Seiichi Ozawa},
keywords = {Brain computing, Cyber-physical systems, Cybersecurity, Embedded systems, Neurodynamics, IoT, Machine learning, Neural networks},
abstract = {The emergence of nontrivial embedded sensor units and cyber-physical systems and the Internet of Things has made possible the design and implementation of sophisticated applications where large amounts of real-time data are collected, possibly to constitute a big data picture as time passes. Within this framework, intelligence mechanisms based on machine learning, neural networks, and brain computing approaches play a key role to provide systems with advanced functionalities. Intelligent mechanisms are needed to guarantee appropriate performances within an evolving, time-variant environment, optimally harvest the available energy and manage the residual energy, reduce the energy consumption of the whole system, identify and mitigate occurrence of faults, and provide shields against cyberattacks. The chapter introduces the above aspects of intelligence, whose functionalities are needed to boost the next generation of cyber-physical and Internet of Things applications, and the smart world generation whose footprint is already around us.}
}
@article{LIU2025101211,
title = {RePower: An LLM-driven autonomous platform for power system data-guided research},
journal = {Patterns},
volume = {6},
number = {4},
pages = {101211},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101211},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925000595},
author = {Yu-Xiao Liu and Mengshuo Jia and Yong-Xin Zhang and Jianxiao Wang and Guannan He and Shao-Long Zhong and Zhi-Min Dang},
keywords = {algorithm evolution, autonomous research, data-driven tasks, large language models, power systems, research assistant},
abstract = {Summary
Large language models (LLMs) have shown strong capabilities across disciplines such as chemistry, mathematics, and medicine, yet their application in power system research remains limited, and most studies still focus on supporting specific tasks under human supervision. Here, we introduce Revive Power Systems (RePower), an autonomous LLM-driven research platform that uses a reflection-evolution strategy to independently conduct complex research in power systems. RePower assists researchers by controlling devices, acquiring data, designing methods, and evolving algorithms to address problems that are difficult to solve but easy to evaluate. Validated on three critical data-driven tasks in power systems—parameter prediction, power optimization, and state estimation—RePower outperformed traditional methods. Consistent performance improvements were observed across multiple tasks, with an average error reduction of 29.07%. For example, in the power optimization task, the error decreased from 0.00137 to 0.000825, a reduction of 39.78%. This framework facilitates autonomous discoveries, promoting innovation in power systems research.}
}
@article{LIN2021103499,
title = {Informational cues or content? Examining project funding decisions by crowdfunders},
journal = {Information & Management},
volume = {58},
number = {7},
pages = {103499},
year = {2021},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2021.103499},
url = {https://www.sciencedirect.com/science/article/pii/S0378720621000732},
author = {Yan Lin and Wai Fong Boh},
keywords = {Experience, Elaboration Likelihood Model, Information Asymmetry, Crowdfunding},
abstract = {We examine how crowdfunder experience affects their reliance on information available on projects. Drawing on elaboration likelihood model and using data from Kickstarter, we apply machine learning techniques and choice modeling to examine the information provided by creators, investigating not only the descriptions, but also the pictures and the videos. We found that more experienced crowdfunders react positively to descriptions exhibiting higher analytical thinking, while less experienced crowdfunders rely more on cues that arouse attention (e.g., number of pictures and positive emotions in videos). We highlight the importance of considering how experience influences crowdfunders’ interpretation of different types of information.}
}
@article{WANG202428,
title = {Exploring the interplay between core and mood symptoms in schizophrenia: A network analysis},
journal = {Schizophrenia Research},
volume = {269},
pages = {28-35},
year = {2024},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2024.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0920996424001695},
author = {Yucheng Wang and Yixiao Xu and Peiyi Wu and Yang Zhou and Huanrui Zhang and Zijia Li and Yanqing Tang},
keywords = {Schizophrenia, Core symptoms, Mood symptoms, Network analysis, Symptom interactions},
abstract = {Background
Schizophrenia is a complex neuropsychiatric disorder characterized by positive symptoms, negative symptoms, cognitive deficits, and co-occurring mood symptoms. Network analysis offers a novel approach to investigate the intricate relationships between these symptom dimensions, potentially informing personalized treatment strategies.
Methods
A cross-sectional study was conducted from November 2019 to October 2021, involving 1285 inpatients with schizophrenia in Liaoning Province, China. Symptom severity was assessed using the Positive and Negative Syndrome Scale (PANSS), Hamilton Depression Rating Scale (HAMD-17), Hamilton Anxiety Rating Scale (HAMA-14), and Montreal Cognitive Assessment (MoCA). Network analysis was conducted to investigate the network structure, central symptoms, and bridge symptoms.
Results
The network analysis uncovered profound interconnectivity between core symptoms and the anxiety-depression community. Central symptoms, such as psychic anxiety, poor rapport, delusions, and attention, were identified as potential therapeutic targets. Bridge symptoms, including insomnia, depressed mood, anxiety-somatic, conceptual disorganization, and stereotyped thinking, emerged as key nodes facilitating interactions between symptom communities. The stability and reliability of the networks were confirmed through bootstrapping procedures.
Discussion
The findings highlight the complex interplay between schizophrenia symptoms, emphasizing the importance of targeting affective symptoms and cognitive impairment in treatment. The identification of central and bridge symptoms suggests potential pathways for personalized interventions aimed at disrupting self-reinforcing symptom cycles. The study underscores the need for a transdiagnostic, personalized approach to schizophrenia treatment.}
}
@article{KENDON2008187,
title = {Optimal computation with non-unitary quantum walks},
journal = {Theoretical Computer Science},
volume = {394},
number = {3},
pages = {187-196},
year = {2008},
note = {From Gödel to Einstein: Computability between Logic and Physics},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2007.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0304397507008791},
author = {Viv Kendon and Olivier Maloyer},
keywords = {Quantum computing, Quantum walks, Quantum algorithms},
abstract = {Quantum versions of random walks on the line and the cycle show a quadratic improvement over classical random walks in their spreading rates and mixing times, respectively. Non-unitary quantum walks can provide a useful optimisation of these properties, producing a more uniform distribution on the line, and faster mixing times on the cycle. We investigate the interplay between quantum and random dynamics by comparing the resources required, and examining numerically how the level of quantum correlations varies during the walk. We show numerically that the optimal non-unitary quantum walk proceeds such that the quantum correlations are nearly all removed at the point of the final measurement. This requires only O(logT) random bits for a quantum walk of T steps.}
}
@article{ALBUS20101519,
title = {A model of computation and representation in the brain},
journal = {Information Sciences},
volume = {180},
number = {9},
pages = {1519-1554},
year = {2010},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2009.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0020025510000095},
author = {James S. Albus},
keywords = {Brain modeling, Cognitive modeling, Human neocortex, Image processing, Knowledge representation, Perception, Reverse engineering the brain, Segmentation, Signals to symbols},
abstract = {The brain is first and foremost a control system that is capable of building an internal representation of the external world, and using this representation to make decisions, set goals and priorities, formulate plans, and control behavior with intent to achieve its goals. The internal representation is distributed throughout the brain in two forms: (1) firmware embedded in synaptic connections and axon-dendrite circuitry, and (2) dynamic state-variables encoded in the firing rates of neurons in computational loops in the spinal cord, midbrain, subcortical nuclei, and arrays of cortical columns. It assumes that clusters and arrays of neurons are capable of computing logical predicates, smooth arithmetic functions, and matrix transformations over a space defined by large input vectors and arrays. Feedback from output to input of these neural computational units enable them to function as finite-state-automata (fsa), Markov decision processes (MDP), or delay lines in processing signals and generating strings and grammars. Thus, clusters of neurons are capable of parsing and generating language, decomposing tasks, generating plans, and executing scripts. In the cortex, neurons are arranged in arrays of cortical columns that interact in tight loops with their underlying subcortical nuclei. It is hypothesized that these circuits compute sophisticated mathematical and logical functions that maintain and use complex abstract data structures. It is proposed that cortical hypercolumns together with their underlying thalamic nuclei can be modeled as a cortical computational unit (CCU) consisting of a frame-like data structure (containing attributes and pointers) plus the computational processes and mechanisms required to maintain it and use it for perception cognition, and sensory-motor behavior. In sensory processing areas of the brain, CCU processes enable focus of attention, segmentation, grouping, and classification. Pointers stored in CCU frames define relationships that link pixels and signals to objects and events in situations and episodes. CCU frame pointers also link objects and events to class prototypes and overlay them with meaning and emotional values. In behavior generating areas of the brain, CCU processes make decisions, set goals and priorities, generate plans, and control behavior. In general, CCU pointers are used to define rules, grammars, procedures, plans, and behaviors. CCU pointers also define abstract data structures analogous to lists, frames, objects, classes, rules, plans, and semantic nets. It is suggested that it may be possible to reverse engineer the human brain at the CCU level of fidelity using next-generation massively parallel computer hardware and software.}
}
@incollection{PRATT198497,
title = {A Theoretical Framework for Thinking About Depiction},
editor = {W. Ray Crozier and Antlony J. Chapman},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {19},
pages = {97-109},
year = {1984},
booktitle = {Cognitive Processes in the Perception of Art},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(08)62347-X},
url = {https://www.sciencedirect.com/science/article/pii/S016641150862347X},
author = {Francis Pratt},
abstract = {Publisher Summary
This chapter provides a chronological account of the steps which describes the present theoretical framework for thinking about depiction. The experimental results provides good evidence for the following assertions: (1) knowledge is a necessary part of all acts of depiction done by people of all ages and of all levels of skill, (2) knowledge is a main determinant of looking strategies, (3) the role of knowledge in the organization of looking strategies is one of determining the level of description to be used as the basis of analytic processes, and (4) "good" copying performance (i.e., "accurate" in terms of scene-specific and view-specific relations) can be equated with level of description accessed. The chapter emphasizes on: (1) each descending level of description implies an increasing disintegration of the analytic task. (2) Analysis for depiction is concerned with variance. It is concerned with relations that change according to viewing circumstances. In effect, they can be considered as novel relations. There is much evidence that people's ability to maintain "novel" relations in memory is severely limited. (3) The model consisting of a group of straight lines is only capable of being analyzed at the lowest levels of description.}
}
@article{GENT202336,
title = {Computing comes to life},
journal = {New Scientist},
volume = {258},
number = {3442},
pages = {36-39},
year = {2023},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(23)01054-0},
url = {https://www.sciencedirect.com/science/article/pii/S0262407923010540},
author = {Edd Gent},
abstract = {Nature is capable of astonishing feats of computation. Now, we are re-engineering molecules, cells and even whole organisms into living processors, says Edd Gent}
}
@article{CIMIER2025100092,
title = {Multisensory objects’ role on creativity},
journal = {Journal of Creativity},
volume = {35},
number = {1},
pages = {100092},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100092},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000189},
author = {Amandine Cimier and Beatrice Biancardi and Jérome Guegan and Frédéric Segonds and Fabrice Mantelet and Camille Jean and Claude Gazo and Stéphanie Buisine},
keywords = {Engineering, Manipulation, Embodied cognition, Kinesthesia, Creativity},
abstract = {In this research, we investigated the role of multisensorial manipulation on creativity, and the influence of inspirational objects on creative outcomes. Object manipulation may support embodied cognition during a generative creative phase (emergence of motor, spatial, emotional ideas, etc.) then exploratory phase (creative fixation, development of a functional creation, etc.). Our protocol involved 136 engineering students divided into 34 groups which were provided with inspirational cubes illustrating manufacturing inventive principles or basic volumes from the Creative Mental Synthesis Task. They could manipulate these objects either in a visuo-haptic condition, or in a visuo-imaginative condition. Our results highlighted a main effect of manipulation, showing that visual-haptic condition led to higher creativity than visual-imaginative condition. We also observed several effects in favor of inspirational cubes with regard to basic volumes: significantly higher creativity, more subjective and inter-subjective facilitation behaviors, more cognitive and emotional operations. Participants also showed at an individual level a better mobilization of the multisensorial senses. Creative thinking may be stimulated when an active manipulation phase is set up before the creative production. This could contribute to improving practice for engineers, particularly for using additive manufacturing and/or during their training at school.}
}
@article{CUNHA2024,
title = {Converging extended reality and Machine Learning to improve the lecturing of geometry in basic education},
journal = {Journal of Engineering Research},
year = {2024},
issn = {2307-1877},
doi = {https://doi.org/10.1016/j.jer.2024.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S2307187724002736},
author = {Carlos R. Cunha and André Moreira and Sílvia Coelho and Vítor Mendonça and João Pedro Gomes},
keywords = {Geometry, Teaching, Learning, Education, Extended reality, Mixed reality, Machine learning},
abstract = {Technology is constantly supporting in the innovation of the teaching-learning process. Today’s students are more demanding actors when it comes to the environment they have at their disposal to learn, experiment and develop their critical thinking. The area of Mathematics has successively suffered from students’ learning difficulties, whether due to lack of motivation, low abstraction ability or lack of new tools for teachers to bring innovation into the classroom and outside it. While being true that digitalization has entered schools, it often follows a basic and simple process of digital replication of approaches and materials that were previously only available on physical media. This work focuses on the use of Extended Realities, more precisely, Mixed Reality, for teaching Mathematics, and very particularly in the teaching of Geometry, through the proposition of a conceptual model that combines the use of Extended Reality and Machine Learning. The proposed model was subject to prototyping, which is presented as a form of laboratory validation as a contribution to innovate the way of how the geometry teaching-learning process is developed and to promote the integration of Extended Reality technologies into the Education Sector as practical tools, as well due to its potential use to obtain useful insights for teachers, and students, throughout the process.}
}
@article{MCDERMOTT20071183,
title = {Level-headed},
journal = {Artificial Intelligence},
volume = {171},
number = {18},
pages = {1183-1186},
year = {2007},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2007.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0004370207001488},
author = {Drew McDermott},
keywords = {Speculation, Methodology, Natural language},
abstract = {I don't believe that human-level intelligence is a well defined goal. As the cognitive-science community learns more about thinking and computation, the mileposts will keep changing in ways that we can't predict, as will the esteem we assign to past accomplishments. It would be fun to have a computer that could solve brain teasers as well as the average scientist, but focusing on such things, besides being parochial, overlooks the crucial role language plays in everything humans do, a role we understand hardly at all on a computational level. I am optimistic that we will eventually figure language out, but not without new ideas. Plus, when we can talk to machines, will we understand each other?}
}
@article{MIRA2009793,
title = {Sensory representation spaces in neuroscience and computation},
journal = {Neurocomputing},
volume = {72},
number = {4},
pages = {793-805},
year = {2009},
note = {Brain Inspired Cognitive Systems (BICS 2006) / Interplay Between Natural and Artificial Computation (IWINAC 2007)},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2008.04.054},
url = {https://www.sciencedirect.com/science/article/pii/S0925231208004682},
author = {J. Mira and A.E. Delgado},
keywords = {Representation space, Perception, Cortical maps, Semantic gap},
abstract = {Physics, Neuroscience and Computation are concerned with finding the most appropriate representation spaces to describe the interaction of a dynamic system with its environment. In this work first we review the two basic conceptual approaches to the problem of representing an environment, Marr's ascending “constructivism” and Gibson's “direct perception” hypothesis. Later we review the basic neural mechanisms associated with creating meaning in both approaches: lateral inhibition and the creation of cortical maps by resonance to patterns of stimuli of families of spatially ordered neurons. We end by considering the usefulness in artificial intelligence of knowledge about the way in which biological systems construct their representation spaces. We stress the idea regarding events as representation entities and, consequently, using an event time, different from physical time. Semantics emerges from the mechanisms that detect these relevant events in each organisational level and their composition rules to specify the constitutive entities of the next level. This semantic is distributed in the cortical maps of the neuron groups that resound to the corresponding events.}
}
@article{PEREZLOPEZ2024105162,
title = {Cartographic analysis as spatial determinant for climate change adaptation in the Hunter River Estuary, Australia},
journal = {Cities},
volume = {152},
pages = {105162},
year = {2024},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2024.105162},
url = {https://www.sciencedirect.com/science/article/pii/S0264275124003767},
author = {Irene {Perez Lopez} and Sandra Carrasco and Cesar {Mariscal Madrigal}},
keywords = {Ecological design, Estuary urbanism, Climate adaptation, Living infrastructures, Hunter River Australia},
abstract = {This paper explores the hydrological history of the Hunter River and Estuary (Newcastle, Australia), to identify pathways for incorporating climate-sensitive adaptation approaches into urban development and planning. The research method utilises mapping as a methodological discovery tools to visually articulate the correlation of pre-colonial hydrological landscapes, the transformation of the estuary over two centuries, the areas identified as at risk, and the opportunities for developing a climate-resilient estuary. This research aims to contribute to the redefinition of the discourse on the role of estuary planning for changing climate, focusing on four critical aspects: identify the impacts of urbanisation and industrialisation on ecosystems and its correlation with climate hazard at the estuary; visualise such transformations over time and space to identify critical spatial and climate factors threatening inhabitation; propose strategic spatial practices towards adaptation and resilience; and synthesising the options to foster reflective thinking and establish a correlation with novel policies, governance and practices. The study highlights that adopting new urbanism aligned with cultural and ecological principles can mitigate future climate impacts through re-naturalisation and urban adaptation to sea-level rise by focusing on proactive approaches to building resilient communities. This paper also acknowledges the need for site-specific adaptive design and planning strategies at multiple scales and governance levels.}
}
@article{GANO201556,
title = {Starting with Universe: Buckminster Fuller's Design Science Now},
journal = {Futures},
volume = {70},
pages = {56-64},
year = {2015},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2014.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0016328714002055},
author = {Gretchen Gano},
keywords = {Comprehensiveness, Big data, Design science, Buckminster Fuller, Worldviews Network},
abstract = {Increasingly, decision makers seek to harness “big data” to guide choices in management and policy settings as well as in professions that manufacture, build, and innovate. Scholars examining this trend tend to diagnose it at once as techno positivist in its insistence on design yoked to quantifiable variables and computational modeling and, alternatively, as an imperative integral to realizing ecologically sustainable innovation. This article investigates this tension. It reflects on the role of futurists, designers, architects, urban planners, social scientists, and artists in interpreting and utilizing comprehensiveness as a design frame. Among nine experimental foresight workshops at the inaugural Emerge conference at Arizona State University, many focused on producing physical objects or media, one modeled and expanded upon a method pioneered by architect and polymath R. Buckminster Fuller. At a time when many of the capabilities to realize Fuller's specifications for big data have matured, I investigate whether comprehensive design as framed by Fuller's method shows promise as a trend enabling ecologically sustainable innovations. A historical look at Fuller's Design Science and the reflection on it in the Emerge workshop marks an opportunity to highlight and interpret the resurgence of comprehensive thinking in design while navigating the contradictions this orientation engenders.}
}
@article{MACHKROL2023259,
title = {An ML-extended conceptual framework for implementing temporal big data analytics in organizations to support their agility},
journal = {Procedia Computer Science},
volume = {225},
pages = {259-268},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923011687},
author = {Maria Mach-Król and Bartłomiej Hadasik},
keywords = {temporal big data analytics, temporal knowledge, machine learning, organizational agility, feedback loop},
abstract = {The main aim of this paper is to present the machine learning (ML) extension to the authors’ original conceptual framework for implementing temporal big data analytics (TBDA) in organizations. The framework has been also supplemented with a ML-supported feedback loop aimed at ongoing verification of the organization's maturity for TBDA in light of changing needs, requirements, and the company's environment. Such extension is needed to make the TBDA more flexible and adaptable to market environment, thus augmenting organizational agility. The research has been carried following the Design Science Research in Information Systems (DSRIS) methodological approach with the addition of creative thinking. As a result, the extended framework is elaborated, and further improvements and research directions are identified.}
}
@article{WAUTELET2025125664,
title = {Circulise, a model-driven framework to build and align socio-technical systems for the twin transition: Fanyatu’s case of sustainability in reforestation},
journal = {Expert Systems with Applications},
volume = {262},
pages = {125664},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125664},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424025314},
author = {Yves Wautelet and Xavier Rouget},
keywords = {Circulise, Circular economy development, Cryptocurrency, Reforestation, Sustainability, Sustainability engineering, Twin transition},
abstract = {Building circular economic systems is crucial to address ecological challenges like climate change. The twin transition suggests that, to maximize the impact of sustainable solutions, humans and (disruptive) technologies need to be effectively integrated. Methods to conceptually build such (eco)systems integrating these and assess their ecological impact before implementation are lacking. This paper addresses this gap by proposing the Circulise framework, a model-driven method designed to build circular systems and evaluate their environmental performance. The approach promotes design-thinking to create socio-technical ecosystems that can be evaluated at the light of their alignment with circular economy and/or sustainability principles and be used to generate operational software behavior. The Circulise framework was developed following the methodological guidance of design science research. It is applied in this paper to the case of Fanyatu, a non-profit organization focused on reforestation in the Congo Basin, showing its ability to create a circular ecosystem not only supporting the creation of regenerative CO2-absorbing forests but also empowering and improving the quality of life of the local communities involved in the planting of trees. In Fanyatu’s case, Circulise’s strategic planning and technology integration lead to virtuous cycles, enabling a snowball effect in forest creation and the promotion of sustainable projects. The framework’s scalability and versatility allow it to be applied across various contexts, enabling the creation of customized circular ecosystems for sustainability tailored to specific human and technological needs.}
}
@article{BOWMAN201834,
title = {Big questions, informative data, excellent science},
journal = {Statistics & Probability Letters},
volume = {136},
pages = {34-36},
year = {2018},
note = {The role of Statistics in the era of big data},
issn = {0167-7152},
doi = {https://doi.org/10.1016/j.spl.2018.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167715218300622},
author = {Adrian W. Bowman},
keywords = {Big data, Statistical models},
abstract = {The expression big data is often used in a manner which implies that immediate insight is readily available. Unfortunately, this raises unrealistic expectations. A model which encapsulates the powerful concepts of statistical thinking remains an invaluable component of good analysis.}
}
@article{BILLINGE20243714,
title = {Do materials have a genome, and if they do, what can be done with it?},
journal = {Matter},
volume = {7},
number = {11},
pages = {3714-3727},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400345X},
author = {Simon J.L. Billinge},
abstract = {Summary
Materials do not have a genome, yet for the past decade, and into the next decade, in the USA, there has been a presidential and inter-agency funding initiative called the “Materials Genome Initiative (MGI).” This initiative has nothing to do with real genomes, materials, or otherwise. However, in this paper, we, somewhat whimsically, explore some ideas about what a material’s gene could be and how it could be used to further our understanding of materials structure and properties. The result is a slightly non-conventional, less crystal-centric, view of materials structure that we believe can, will, and is resulting in novel materials insights.}
}
@article{HASKOVA2025102515,
title = {Fuzzy calculator – A tool for management needs},
journal = {Journal of Computational Science},
volume = {85},
pages = {102515},
year = {2025},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102515},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324003089},
author = {Simona Hašková and Petr Šuleř and Martin Smrt},
keywords = {Fuzzy calculator, Computer program, Multi-criteria evaluation, Fuzzy logic},
abstract = {Fuzzy logic and fuzzy system models have become popular tools in the field of management as they enable efficient handling of uncertainty. We present a tool based on the authors´ original approach focused on solving complex managerial problems affected by the vagueness or uncertainty caused by the human factor. For this purpose, we show the connection between the functioning principle of the tool and processes occurring in the human mind including a description of its structure as perceived by an external observer. This is followed by an overview of selected fragments of fuzzy propositional logic, the theory of fuzzy sets, and the conclusions derived from it. The main part consists of formulating an algebraic description of the computational process of multi-criteria evaluation of the considered alternative performed by a fuzzy system, which serves as the executive unit of a Fuzzy calculator. This is supplemented by a flowchart diagram illustrating the algorithm of its functioning. The Fuzzy calculator distinguishes itself from other fuzzy systems by standardizing all linguistic variables, regardless of the number of linguistic values, into a unified framework comprising three terms L, M, and H, which are represented using trapezoidal fuzzy numbers, ensuring precise mathematical characterization. During the transformation, the original linguistic terms are preserved by incorporating the positions of their support intervals, thereby maintaining the specificity of the input information. This approach establishes the Fuzzy calculator as a universal and highly adaptable tool, capable of addressing a wide range of practical managerial problems with improved consistency and control.}
}
@article{TEZDUYAR199997,
title = {CFD methods for three-dimensional computation of complex flow problems},
journal = {Journal of Wind Engineering and Industrial Aerodynamics},
volume = {81},
number = {1},
pages = {97-116},
year = {1999},
issn = {0167-6105},
doi = {https://doi.org/10.1016/S0167-6105(99)00011-2},
url = {https://www.sciencedirect.com/science/article/pii/S0167610599000112},
author = {Tayfun E. Tezduyar},
keywords = {CFD methods, T*AFSM, Three-dimensional flow simulations},
abstract = {This paper provides an overview of some of the CFD methods developed by the Team for Advanced Flow Simulation and Modeling (T*AFSM) [http://www.mems.rice.edu/TAFSM/]. The paper also provides many examples of three-dimensional flow simulations carried out with these CFD methods and advanced parallel supercomputers. The methods and tools described in this paper include: stabilized finite element formulations; formulations for flows with moving boundaries and interfaces; mesh update methods; iterative solution techniques for large nonlinear equation systems; and parallel implementation of these methods. Our target is to be able to address effectively certain classes of flow simulation problems. These include: unsteady flows with interfaces; fluid–object interactions; fluid–structure interactions; airdrop systems; aerodynamics of complex shapes; and contaminant dispersion.}
}
@article{SUPPES201295,
title = {Phase-oscillator computations as neural models of stimulus–response conditioning and response selection},
journal = {Journal of Mathematical Psychology},
volume = {56},
number = {2},
pages = {95-117},
year = {2012},
issn = {0022-2496},
doi = {https://doi.org/10.1016/j.jmp.2012.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S002224961200003X},
author = {P. Suppes and J. Acacio {de Barros} and G. Oas},
keywords = {Learning, Neural oscillators, Three-oscillator Kuramoto model, Stability points of the Kuramoto model, Stimulus–response theory, Phase representation, Continuum of responses},
abstract = {The activity of collections of synchronizing neurons can be represented by weakly coupled nonlinear phase oscillators satisfying Kuramoto’s equations. In this article, we build such neural-oscillator models, partly based on neurophysiological evidence, to represent approximately the learning behavior predicted and confirmed in three experiments by well-known stochastic learning models of behavioral stimulus–response theory. We use three Kuramoto oscillators to model a continuum of responses, and we provide detailed numerical simulations and analysis of the three-oscillator Kuramoto problem, including an analysis of the stability points for different coupling conditions. We show that the oscillator simulation data are well-matched to the behavioral data of the three experiments.}
}
@incollection{KATZ2016123,
title = {Chapter 6 - Development of Counting Ability: An Evolutionary Computation Point of View},
editor = {Avishai Henik},
booktitle = {Continuous Issues in Numerical Cognition},
publisher = {Academic Press},
address = {San Diego},
pages = {123-145},
year = {2016},
isbn = {978-0-12-801637-4},
doi = {https://doi.org/10.1016/B978-0-12-801637-4.00006-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128016374000068},
author = {Gali Barabash Katz and Amit Benbassat and Moshe Sipper},
keywords = {numerical cognition, size perception, counting, evolutionary algorithms, genetic algorithms, artificial neural networks},
abstract = {Examination of numerical cognition encompasses multiple facets (eg, discrete vs. continuous properties, subitizing, estimation, counting, etc.). Many models have been suggested to explain these features. By looking into the basic ability to perceive size, against the complex one of counting, we hypothesize that counting system evolved on the basis of a primitive size perception system rather than the two systems evolved separately. In this chapter, we present a novel way of using evolutionary computation techniques to evolve artificial neural networks (ANNs) first to perceive size and then to count, and compare their counting skills to a different group of ANNs who evolved to count from scratch. The results revealed better counting skills when evolving first to perceive size (or other classification task) and then to count over those who evolved just to count. In addition, ANNs who evolved with continuous stimuli presented better counting skills than those evolved with discrete stimuli.}
}
@article{WOOD199740,
title = {Thinking about Networks in the Control of Male Hamster Sexual Behavior},
journal = {Hormones and Behavior},
volume = {32},
number = {1},
pages = {40-45},
year = {1997},
issn = {0018-506X},
doi = {https://doi.org/10.1006/hbeh.1997.1403},
url = {https://www.sciencedirect.com/science/article/pii/S0018506X97914033},
author = {Ruth I. Wood},
abstract = {Motivated social behaviors such as mating are controlled by a complex network of limbic nuclei. Concepts of network organization derived from computational neuroscience may aid our understanding of the links between the neuroanatomical circuitry and what is represented by the anatomy. Research in my laboratory uses mating behavior in the male Syrian hamster as a model to elucidate how chemosensory and steroid cues are integrated in the brain. An interaction of odors and hormones is required for mating in this species. These two essential stimuli are transmitted through separate parallel pathways in the limbic system. The functional organization of the hamster mating behavior circuit is characterized by distributed representation, divergent and convergent neural pathways, and recurrent feedback. Odors and hormones have different modes of action on this neural network. While chemosensory cues stimulate the input units of the network, steroids facilitate behavior through the hidden units. In this manner, steroids appear to create a permissive environment for subsequent activation by odor cues.}
}
@article{HONG201611,
title = {Ontology-based conceptual design for ultra-precision hydrostatic guideways with human–machine interaction},
journal = {Journal of Industrial Information Integration},
volume = {2},
pages = {11-18},
year = {2016},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2016.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X16300188},
author = {Haibo Hong and Yuehong Yin},
keywords = {Human machine integrated conceptual design, Information integration, High dimensional information integration, Ontology},
abstract = {This paper proposed a human–machine integrated conceptual design method based on ontology, aiming at eliminating the uncertainties and blindness during the design process of ultra-precision grinding machine, especially for its key component–the ultra-precision hydrostatic guideways. Both the required knowledge and the database of hydrostatic guideways are modelled using ontologies to provide a consensual understanding among collaborators. Moreover, a formalized knowledge searching interface is developed to obtain similar instances as references according to the design principles and rules. Based on the imaginal thinking theory, the search process and the results are attempted to be presented in the form of image in order to fit human's customary intuitive thinking frame, facilitating the decision making process. Finally, our design of hydrostatic guideways for an ultra-precision grinding machine is used to validate the effectiveness of the method.}
}
@article{ZHOU2024108310,
title = {The neuroanatomical correlates of daily habitual tendencies and mediating effect on the association between daily habitual tendencies and symptoms of behavioral addictions},
journal = {Computers in Human Behavior},
volume = {158},
pages = {108310},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108310},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400178X},
author = {Xinqi Zhou and Qi Liu and Lan Wang and Xianyang Gan and Ran Zhang and Xiqin Liu and Guojuan Jiao and Christian Montag and Weihua Zhao and Benjamin Becker},
keywords = {Habit, Gray matter, vmPFC, Precuneus, Internet gaming disorder, Smartphone use},
abstract = {Habitual behaviors significantly shape our daily actions. Furthermore, habit formation is proposed as a key mechanism contributing to the development and maintenance of addiction. However, the neural substrates underlying daily habitual tendencies and their contribution to behavioral addiction symptoms in everyday life remain poorly understood. To explore these questions, we conducted a comprehensive analysis of data from 219 individuals who underwent neuroimaging (structural MRI) assessments alongside evaluations of their daily habitual tendencies and symptoms of Internet Gaming Disorder (IGD) and Problematic Smartphone Use (PSU). Using voxel-based morphometry, meta-analytic decoding, and mediation analysis, we found that daily habitual tendencies were positively correlated with larger gray matter volumes in the ventromedial prefrontal cortex (vmPFC), precuneus, superior frontal gyrus (SFG), inferior temporal gyrus (ITG), and supplementary motor area (SMA). Notably, the midline regions, including the vmPFC and precuneus, play a crucial role in value-based computation, emotional regulation, social cognition, and self-referential thinking. Individual variations in gray matter volumes within these regions served as mediators, influencing the bidirectional relationship between daily habitual tendencies and IGD symptoms. However, vmPFC variations were specifically found to mediate the pathway from PSU to daily habitual tendencies. Our findings suggest that the morphological architecture of the vmPFC and precuneus is associated with habitual tendencies in daily life and may mediate the development of addictive behaviors. This study contributes to a more nuanced understanding of the neuroanatomical basis of daily habitual tendencies and their role in addictive behaviors.}
}
@article{ZHANG2024117045,
title = {A bidirectional collaborative method based on an improved artificial fish swarm algorithm for ship pipe and equipment layout design},
journal = {Ocean Engineering},
volume = {296},
pages = {117045},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117045},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824003822},
author = {Hongshuo Zhang and Yanyun Yu and Qiaoyu Zhang and Yuansong Yang and Haiyang Liu and Yan Lin},
keywords = {Collaborative optimization, Ship engine room layout design, Multi-strategy heuristic algorithm, Hybrid-objective optimization, Coding technique, Automation design},
abstract = {Ship engine room layout design (SERLD) significantly impacts a ship's transportation efficiency and safety by focusing on the layouts of equipment and piping. However, owing to complex constraints, previous research has mainly focused on single-dimensional layout designs and has failed to provide comprehensive references for designers. To address this research gap, this study proposes a collaborative layout method based on a multistrategy hybrid-objective artificial fish swarm algorithm (HMSAFSA). In terms of the underlying mathematical representation, a more stable Manhattan trajectory-based coding method suitable for a collaborative layout is proposed. Building on this coding method, multiple strategies are incorporated into the heuristic AFSA to enhance its optimization and collaborative performance. Collaborative evaluation functions and methods are designed and refined to ensure effective layout results for multiple objectives. Furthermore, a layout procedure incorporating bidirectional guidance strategies and hierarchical thinking is proposed. This method achieves collaborative layouts through the mutual guidance of optimal objectives. Finally, the effectiveness of the proposed method is verified through representative cases of various types of ship engine rooms in practical engineering. The method demonstrates its capability to offer multiple optimal layout schemes, thus presenting substantial value for practical engineering designs.}
}
@article{EGUCHI2016692,
title = {RoboCupJunior for promoting STEM education, 21st century skills, and technological advancement through robotics competition},
journal = {Robotics and Autonomous Systems},
volume = {75},
pages = {692-699},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015001281},
author = {Amy Eguchi},
keywords = {Educational robotics, Robotics competitions, STEM education, Computational thinking, Engineering skills, 21st century skills},
abstract = {RoboCupJunior is an international educational robotics initiative, aiming to promote STEM content and skill learning among participating youth through educational robotics competition inaugurated in 2000. What makes RoboCupJunior quite unique is its relationship with RoboCup which aims to promote robotics and AI research, by offering a publicly appealing, but formidable challenge including development of soccer robots, search and rescue robots, and robots functions at home and at work. This paper introduces a case of RoboCupJunior and the effectiveness of its practice for enhancing learning of STEM contents and skills for innovation and creativity among participating students. It presents the survey results from one of the World Championships held in 2012, the anecdotal and personal account of participating US students on their learning experience from their participation in 2013 World Championship, and participating students’ technological and innovative contributions to highlight the impacts RoboCupJunior has had through over a decade of its practice.}
}
@article{MANIKANTAN2009639,
title = {Challenges for the future modifications of the TNM staging system for head and neck cancer: Case for a new computational model?},
journal = {Cancer Treatment Reviews},
volume = {35},
number = {7},
pages = {639-644},
year = {2009},
issn = {0305-7372},
doi = {https://doi.org/10.1016/j.ctrv.2009.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0305737209000632},
author = {Kapila Manikantan and Suhail I. Sayed and Konstantinos N. Syrigos and Peter Rhys-Evans and Chris M. Nutting and Kevin J. Harrington and Rehan Kazi},
keywords = {TNM stage, Head and neck cancer, Co-morbidity},
abstract = {Summary
The TNM system of staging cancers is a simple and effective method to map the extent of tumours. It had traditionally strived to maintain a balance between being simple and user-friendly on one hand and comprehensive on the other. A number of revisions have taken place over the years with the goal of improving utility. However, numerous controversies surround the TNM system. There is a school of thought that contends that patient co-morbidity and specific tumour-related factors should be incorporated to add further prognostic capabilities in the TNM system, but this raises concerns that such an approach may unnecessarily complicate the system. This review highlights some controversies that surround the TNM system and suggests prognostic indicators that may be added to make it more useful in guiding treatment decisions and predicting outcomes.}
}
@article{HARVEY2025,
title = {Using Natural Language Processing Methods to Build the Hypersexuality in Bipolar Reddit Corpus: Infodemiology Study of Reddit},
journal = {JMIR Infodemiology},
volume = {5},
year = {2025},
issn = {2564-1891},
doi = {https://doi.org/10.2196/65632},
url = {https://www.sciencedirect.com/science/article/pii/S2564189125000118},
author = {Daisy Harvey and Paul Rayson and Fiona Lobban and Jasper Palmier-Claus and Clare Dolman and Anne Chataigné and Steven Jones},
keywords = {bipolar, hypersexuality, natural language processing, Linguistic Inquiry and Word Count, LIWC, BERTopic, topic modeling, computational linguistics},
abstract = {Background
Bipolar is a severe mental health condition affecting at least 2% of the global population, with clinical observations suggesting that individuals experiencing elevated mood states, such as mania or hypomania, may have an increased propensity for engaging in risk-taking behaviors, including hypersexuality. Hypersexuality has historically been stigmatized in society and in health care provision, which makes it more difficult for service users to talk about their behaviors. There is a need for greater understanding of hypersexuality to develop better evidence-based treatment, support, and training for health professionals.
Objective
This study aimed to develop and assess effective methodologies for identifying posts on Reddit related to hypersexuality posted by people with a self-reported bipolar diagnosis. Using natural language processing techniques, this research presents a specialized dataset, the Talking About Bipolar on Reddit Corpus (TABoRC). We used various computational tools to filter and categorize posts that mentioned hypersexuality, forming the Hypersexuality in Bipolar Reddit Corpus (HiB-RC). This paper introduces a novel methodology for detecting hypersexuality-related conversations on Reddit and offers both methodological insights and preliminary findings, laying the groundwork for further research in this emerging field.
Methods
A toolbox of computational linguistic methods was used to create the corpora and infer demographic variables for the Redditors in the dataset. The key psychological domains in the corpus were measured using Linguistic Inquiry and Word Count, and a topic model was built using BERTopic to identify salient language clusters. This paper also discusses ethical considerations associated with this type of analysis.
Results
The TABoRC is a corpus of 6,679,485 posts from 5177 Redditors, and the HiB-RC is a corpus totaling 2146 posts from 816 Redditors. The results demonstrate that, between 2012 and 2021, there was a 91.65% average yearly increase in posts in the HiB-RC (SD 119.6%) compared to 48.14% in the TABoRC (SD 51.2%) and an 86.97% average yearly increase in users (SD 93.8%) compared to 27.17% in the TABoRC (SD 38.7%). These statistics suggest that there was an increase in posting activity related to hypersexuality that exceeded the increase in general Reddit use over the same period. Several key psychological domains were identified as significant in the HiB-RC (P<.001), including more negative tone, more discussion of sex, and less discussion of wellness compared to the TABoRC. Finally, BERTopic was used to identify 9 key topics from the dataset.
Conclusions
Hypersexuality is an important symptom that is discussed by people with bipolar on Reddit and needs to be systematically recognized as a symptom of this illness. This research demonstrates the utility of a computational linguistic framework and offers a high-level overview of hypersexuality in bipolar, providing empirical evidence that paves the way for a deeper understanding of hypersexuality from a lived experience perspective.}
}
@incollection{NUNES2010457,
title = {Learning Outside of School},
editor = {Penelope Peterson and Eva Baker and Barry McGaw},
booktitle = {International Encyclopedia of Education (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {457-463},
year = {2010},
isbn = {978-0-08-044894-7},
doi = {https://doi.org/10.1016/B978-0-08-044894-7.00525-X},
url = {https://www.sciencedirect.com/science/article/pii/B978008044894700525X},
author = {T. Nunes},
keywords = {Guided participation, Informal learning, Informal mathematics, Learning outside school, Nonformal learning, Oral arithmetic, Situated learning, Street mathematics, Thinking in action, Work-based learning},
abstract = {Learning can take place everywhere: in the home, the community, or at work. Learning outside school is often invisible because it is taken for granted, as common sense or cultural knowledge. It happens in the course of activities not designed for learning, so it can be described as thinking in action. The representational tools (number systems, graphs) and objects (crates, coins, bills) used outside school become part of our thinking as we act and think with them. A major process in learning outside school is guided participation, where learners take responsibility for accomplishing tasks guided by a more experienced person.}
}
@incollection{PROCHAZKOVA2020121,
title = {Chapter 6 - Altered states of consciousness and creativity},
editor = {David D. Preiss and Diego Cosmelli and James C. Kaufman},
booktitle = {Creativity and the Wandering Mind},
publisher = {Academic Press},
pages = {121-158},
year = {2020},
series = {Explorations in Creativity Research},
isbn = {978-0-12-816400-6},
doi = {https://doi.org/10.1016/B978-0-12-816400-6.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128164006000067},
author = {Luisa Prochazkova and Bernhard Hommel},
keywords = {Altered states of consciousness (ASC), Cannabis, Convergent thinking, Creativity, Divergent thinking, Hallucinations, Meditation, Metactontrol, Psychedelics},
abstract = {Increasing evidence suggests that altered states of consciousness (ASC) are associated with both positive and negative effects on components of creative performance, and convergent and divergent thinking in particular. We provide a metacontrol framework that allows characterizing factors that induce ASC in terms of their general impact on the information processing style of problem solvers. We discuss behavioral and neuronal findings from three areas that reflect strong connections between ASC and the underlying effects on metacontrol on the one hand and components of creativity on the other hand: drug-induced ASC, meditation-induced ASC, and hallucinations. While more, and especially more systematic research is needed, we identify a general trend, suggesting that factors that induce ASC are likely to alter the metacontrol state by biasing it toward either persistence, which is beneficial for convergent thinking and other persistence-heavy operations, or flexibility, which is beneficial for divergent thinking and other flexibility-heavy operations.}
}
@article{ONTIVEROSARAIZA2025105361,
title = {The Neurobehavioral State hypothesis},
journal = {BioSystems},
volume = {247},
pages = {105361},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105361},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002466},
author = {Luis Fernando Ontiveros-Araiza},
keywords = {Brain networks, Neuronal dynamics, Neural code, Neurotransmitter, Electrophysiology, Neuronal computation, Behavior},
abstract = {Since the early attempts to understand the brain made by Greek philosophers more than 2000 years ago, one of the main questions in neuroscience has been how the brain perceives all the stimuli in the environment and uses this information to implement a response. Recent hypotheses of the neural code rely on the existence of an ideal observer, whether on specific areas of the cerebral cortex or distributed network composed of cortical and subcortical elements. The Neurobehavioral State hypothesis stipulates that neurons are in a quasi-stable state due to the dynamic interaction of their molecular components. This increases their computational capabilities and electrophysiological behavior further than a binary active/inactive state. Together, neuronal populations across the brain learn to identify and associate internal and external stimuli with actions and emotions. Furthermore, such associations can be stored through the regulation of neuronal components as new quasi-stable states. Using this framework, behavior arises as the result of the dynamic interaction between internal and external stimuli together with previously established quasi-stable states that delineate the behavioral response. Finally, the Neurobehavioral State hypothesis is firmly grounded on present evidence of the complex dynamics within the brain, from the molecular to the network level, and avoids the need for a central observer by proposing the brain configures itself through experience-driven associations.}
}
@article{LEVYGARBOUA2024102438,
title = {Creative cognition as a bandit problem},
journal = {Learning and Individual Differences},
volume = {111},
pages = {102438},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102438},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024000311},
author = {Louis Lévy-Garboua and Marco Gazel and Noémi Berlin and Jan Dul and Todd Lubart},
keywords = {Creative cognition, Multi-armed bandit problem, Education and creativity, Individual differences in creative potential, Adolescents' behavior},
abstract = {This paper draws a parallel between creative cognition and a multi-armed bandit problem involving learning from experience in an uncertain environment. Special emphasis is put on the optimal sequencing of divergent and convergent behavior by showing that divergence must be inhibited at one point to converge toward creative behavior so that excessive divergence is counterproductive. We test this hypothesis with a behavioral experiment, using measures of individual divergence and convergence components of creative potential in high school students. Results confirmed that a mix of divergence and convergence predicted high performance in a bandit task but not in a purely random task or in a simple repetitive task. These predictions are maintained after controlling for sex, personality, incentives, and other factors. As hypothesized, creative cognition was necessary for high performance under the appropriate conditions. However, it was not necessary to get high grades in a traditional school system.
Educational relevance statement
Relating to the goal of educators and public policies in the 21st century to make children and adolescents more creative, and schools more receptive to creative thinking, this research focuses on the creative potential and behavior of high school students. It provides an evidence-based policy argument in support of the screening and development by the educational sector of the creative potential of students.}
}
@article{GARDNER201854,
title = {SMLXL: Scaling the smart city, from metropolis to individual},
journal = {City, Culture and Society},
volume = {12},
pages = {54-61},
year = {2018},
note = {Innovation and identity in next generation smart cities},
issn = {1877-9166},
doi = {https://doi.org/10.1016/j.ccs.2017.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S1877916617301315},
author = {Nicole Gardner and Luke Hespanhol},
keywords = {Smart cities, Architecture, Design, Physical computing, Proxemics, Computational design},
abstract = {The ‘smart city’ is an oft-cited techno-urban imaginary promoted by businesses and governments alike. It thinks big, and is chiefly imagined in terms of large-scale information communications systems that hinge on the collection of real-time and so-called ‘big data’. Less talked about are the human-scale implications and user-experience of the smart city. Much of the current academic scholarship on smart cities offers synoptic and technical perspectives, leaving the users of smart systems curiously unaccounted for. While they purport to empower citizens, smart cities initiatives are rarely focused at the citizen-scale, nor do they necessarily attend to the ways initiatives can be user-led or co-designed. Drawing on the outcomes of a university studio, this article rethinks the smart city as a series of urban scales—metropolis, community, individual, and personal—and proposes an analytical model for classifying smart city initiatives in terms of engagement. Informed by the theory of proxemics, the model proposed analyses smart city initiatives in terms of the scope of their features and audience size; the actors accountable for their deployment and maintenance; their spatial reach; and the ability of design solutions to re-shape and adapt to different urban scenarios and precincts. We argue that the significance of this model lies in its potential to facilitate modes of thinking across and between scales in ways that can gauge the levels of involvement in the design of digitally mediated urban environments, and productively re-situate citizens as central to the design of smart city initiatives.}
}
@article{LAING2011306,
title = {Computational approaches to RNA structure prediction, analysis, and design},
journal = {Current Opinion in Structural Biology},
volume = {21},
number = {3},
pages = {306-318},
year = {2011},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2011.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X11000674},
author = {Christian Laing and Tamar Schlick},
abstract = {RNA molecules are important cellular components involved in many fundamental biological processes. Understanding the mechanisms behind their functions requires RNA tertiary structure knowledge. Although modeling approaches for the study of RNA structures and dynamics lag behind efforts in protein folding, much progress has been achieved in the past two years. Here, we review recent advances in RNA folding algorithms, RNA tertiary motif discovery, applications of graph theory approaches to RNA structure and function, and in silico generation of RNA sequence pools for aptamer design. Advances within each area can be combined to impact many problems in RNA structure and function.}
}
@article{SHARIF2022104090,
title = {Robotic sheet metal folding: Tool vs. material programming},
journal = {Automation in Construction},
volume = {134},
pages = {104090},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104090},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005410},
author = {Shani Sharif and Russell Gentry},
keywords = {Robotic fabrication, Mass-customization, Dieless sheet metal folding},
abstract = {This research explores how deductive engineering thinking, as opposed to an abductive design rationale, can influence how robotic methods of fabricating building components are developed. The goal of this research is to demonstrate how creative thinking can introduce alternative robotic fabrication techniques targeted for the architectural mass-customization process. For this purpose, we chose robotic dieless sheet metal folding as the main fabrication technique, due to its wide range of applications in both the architectural construction and manufacturing industries. Two robotic sheet metal folding projects were developed. The first, an example of tool programming, took advantage of an engineering approach and was focused on the affordances of the tool (an industrial robotic arm). The second project, one of material programming, employed a design methodology and was directed towards the affordances of the material (i.e., stainless steel sheet metal). By discussing the advantages and disadvantages of each approach, this research argues that both engineering and design should be considered required and complementary processes in the development of new creative fabrication solutions, allowing them to and make the overall production process more efficient.}
}
@incollection{GLENBERG199977,
title = {4 Why mental models must be embodied},
editor = {Gert Rickheit and Christopher Habel},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {128},
pages = {77-90},
year = {1999},
booktitle = {Mental Models in Discourse Processing and Reasoning},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(99)80048-X},
url = {https://www.sciencedirect.com/science/article/pii/S016641159980048X},
author = {Arthur Glenberg},
abstract = {Publisher Summary
Mental models are related to the concept of meaning and language comprehension; in other words, comprehending a linguistic message means that an appropriate mental model has been formed. The manipulation of mental models corresponds to thinking, and it is the manipulation that generates emergent ideas. The chapter discusses the importance of considering the ways ideas combine and presents the data from two experiments that illustrate the combination of ideas. The chapter illustrates the major implications for the theories of mental models. The first implication is that the computational theories cannot account for the data. The second implication is that something like embodiment is needed, and the chapter outlines one account of embodied mental models. The third implication is the most important and most controversial. It is that the human cognition is not a computational phenomenon.}
}
@article{TSENG2025106570,
title = {Exploring artificial intelligence literacy and the use of ChatGPT and copilot in instruction on nursing academic report writing},
journal = {Nurse Education Today},
volume = {147},
pages = {106570},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106570},
url = {https://www.sciencedirect.com/science/article/pii/S026069172500005X},
author = {Li-Ping Tseng and Li-Ping Huang and Wei-Ru Chen},
keywords = {Artificial intelligence literacy, Nursing education, ChatGPT, Copilot, Academic report writing, Scaffolding teaching, Artificial intelligence},
abstract = {Background
Nursing education increasingly emphasizes academic writing and communication, critical for delivering quality patient care and professional advancement. Rapidly emerging artificial intelligence (AI) tools such as ChatGPT and Copilot are transforming educational methodologies, and a focus is being placed on embedding AI literacy to effectively bridge the gap between theoretical knowledge and clinical practice. These technologies have the potential to reshape nursing education in a technology-driven health-care landscape.
Aim
This study investigated the effectiveness of AI literacy and the application of ChatGPT and Copilot in academic nursing report writing. It assessed the level of AI literacy of nursing students, examined the integration of basic AI concepts into a curriculum, and analyzed the impact of these tools compared with traditional teaching methods.
Methods
The study adopted a sample of 203 senior nursing students from Southern Taiwan to compare an AI-enhanced teaching approach using ChatGPT and Copilot with conventional methods. The curriculum, centered on the “Writing Case Reports and Seminars” course, employed the Analyze, Design, Develop, Implement, Evaluate model and incorporated scaffolding techniques to synergistically integrate clinical skills with academic learning. AI literacy was measured using the Meta AI Literacy Scale (MAILS). Summative assessments, adhering to the Taiwan Nursing Association standards, focused on individual and group case report evaluations.
Findings
Following an 18-week AI intervention, the experimental group demonstrated significant improvements in all dimensions of the MAILS. A ChatGPT usage of 100 % was found, with a notable enhancement discovered in the “Nursing Plan” section of case reports. Although the experimental group outperformed the control group in overall case report evaluations, the connections between identified problems and proposed plans were weaker and nursing interventions tended to be less individualized for the experimental group.
Conclusions
The incorporation of AI tools such as ChatGPT and Copilot into a scaffolding teaching framework significantly boosted students' AI literacy and performance in summative assessments. Effective AI training for students, supervised use of these tools, and continuous professional development for educators are paramount to successful implementation. Addressing the current limitations of AI has the potential to further improve academic writing, foster critical thinking, and ensure responsible application in patient care, ultimately leading to higher-quality and more effective nursing education.}
}
@article{SCHMITT2025111332,
title = {Relationships and representations of brain structures, connectivity, dynamics and functions},
journal = {Progress in Neuro-Psychopharmacology and Biological Psychiatry},
volume = {138},
pages = {111332},
year = {2025},
issn = {0278-5846},
doi = {https://doi.org/10.1016/j.pnpbp.2025.111332},
url = {https://www.sciencedirect.com/science/article/pii/S0278584625000867},
author = {Oliver Schmitt},
keywords = {Brain theory, Functions, Hierarchies, Ontologies, Connectomics, Imaging, Modeling, Simulation, Computational neuroscience, Neuronal dynamics, Behavior},
abstract = {The review explores the complex interplay between brain structures and their associated functions, presenting a diversity of hierarchical models that enhances our understanding of these relationships. Central to this approach are structure-function flow diagrams, which offer a visual representation of how specific neuroanatomical structures are linked to their functional roles. These diagrams are instrumental in mapping the intricate connections between different brain regions, providing a clearer understanding of how functions emerge from the underlying neural architecture. The study details innovative attempts to develop new functional hierarchies that integrate structural and functional data. These efforts leverage recent advancements in neuroimaging techniques such as fMRI, EEG, MEG, and PET, as well as computational models that simulate neural dynamics. By combining these approaches, the study seeks to create a more refined and dynamic hierarchy that can accommodate the brain’s complexity, including its capacity for plasticity and adaptation. A significant focus is placed on the overlap of structures and functions within the brain. The manuscript acknowledges that many brain regions are multifunctional, contributing to different cognitive and behavioral processes depending on the context. This overlap highlights the need for a flexible, non-linear hierarchy that can capture the brain’s intricate functional landscape. Moreover, the study examines the interdependence of these functions, emphasizing how the loss or impairment of one function can impact others. Another crucial aspect discussed is the brain’s ability to compensate for functional deficits following neurological diseases or injuries. The investigation explores how the brain reorganizes itself, often through the recruitment of alternative neural pathways or the enhancement of existing ones, to maintain functionality despite structural damage. This compensatory mechanism underscores the brain’s remarkable plasticity, demonstrating its ability to adapt and reconfigure itself in response to injury, thereby ensuring the continuation of essential functions. In conclusion, the study presents a system of brain functions that integrates structural, functional, and dynamic perspectives. It offers a robust framework for understanding how the brain’s complex network of structures supports a wide range of cognitive and behavioral functions, with significant implications for both basic neuroscience and clinical applications.}
}
@incollection{VARGAS201945,
title = {Cell Adhesion: Basic Principles and Computational Modeling},
editor = {Roger Narayan},
booktitle = {Encyclopedia of Biomedical Engineering},
publisher = {Elsevier},
address = {Oxford},
pages = {45-58},
year = {2019},
isbn = {978-0-12-805144-3},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.99930-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383999306},
author = {Diego A. Vargas and Hans {Van Oosterwyck}},
keywords = {Adherens junction, Adhesion dynamics, Bond lifetime, Cell adhesion, Cellularized material, Focal adhesion, Force spectroscopy, Mathematical modeling, Mechanotransduction, Multiscale modeling, Rate constant, Vertex model},
abstract = {A cell interacts with its environment through adhesion complexes. These are protein complexes that form through noncovalent interactions between adhesion receptors in the cell membrane and similar receptors in neighboring cells or ligand molecules in the surrounding extracellular matrix. Cell adhesions are crucial to maintain tissue integrity and cellular communication. Communication and sensing occur through the transmittal of forces through adhesions. This relevant role motivated researchers to develop theoretical models of adhesion. Initial models were based on studies of association kinetics of proteins, which later were expanded to explicitly include the role of force in determining bond strength. The introduction of techniques that allowed measurements of force in the range of a single adhesion produced models that describe the inner workings of the adhesion molecules themselves. Despite the relative simplicity of these models, they are still relevant. Not only were these studies novel and creative, they have been integrated into models describing larger cellular aggregates, unraveling the role of mechanics in biology. These models have been used in the study of cell migration, developmental biology, and cancer biology.}
}
@article{DUCH1996136,
title = {Computational physics of the mind},
journal = {Computer Physics Communications},
volume = {97},
number = {1},
pages = {136-153},
year = {1996},
note = {High-Performance Computing in Science},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(96)00027-6},
url = {https://www.sciencedirect.com/science/article/pii/0010465596000276},
author = {Włodzisław Duch},
abstract = {In the XIX century and earlier physicists such as Newton, Mayer, Hooke, Helmholtz and Mach were actively engaged in the research on psychophysics, trying to relate psychological sensations to intensities of physical stimuli. Computational physics allows to simulate complex neural processes giving a chance to answer not only the original psychophysical questions but also to create models of the mind. In this paper several approaches relevant to modeling of the mind are outlined. Since direct modeling of the brain functions is rather limited due to the complexity of such models a number of approximations is introduced. The path from the brain, or computational neurosciences, to the mind, or cognitive sciences, is sketched, with emphasis on higher cognitive functions such as memory and consciousness. No fundamental problems in understanding of the mind seem to arise. From a computational point of view realistic models require massively parallel architectures.}
}
@article{CAMERON2019102,
title = {Education in Process Systems Engineering: Why it matters more than ever and how it can be structured},
journal = {Computers & Chemical Engineering},
volume = {126},
pages = {102-112},
year = {2019},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2019.03.036},
url = {https://www.sciencedirect.com/science/article/pii/S0098135418311773},
author = {Ian T. Cameron and Sebastian Engell and Christos Georgakis and Norbert Asprion and Dominique Bonvin and Furong Gao and Dimitrios I. Gerogiorgis and Ignacio E. Grossmann and Sandro Macchietto and Heinz A. Preisig and Brent R. Young},
abstract = {This position paper is an outcome of discussions that took place at the third FIPSE Symposium in Rhodes, Greece, between June 20–22, 2016 (http://fi-in-pse.org). The FIPSE objective is to discuss open research challenges in topics of Process Systems Engineering (PSE). Here, we discuss the societal and industrial context in which systems thinking and Process Systems Engineering provide indispensable skills and tools for generating innovative solutions to complex problems. We further highlight the present and future challenges that require systems approaches and tools to address not only ‘grand’ challenges but any complex socio-technical challenge. The current state of Process Systems Engineering (PSE) education in the area of chemical and biochemical engineering is considered. We discuss approaches and content at both the unit learning level and at the curriculum level that will enhance the graduates’ capabilities to meet the future challenges they will be facing. PSE principles are important in their own right, but importantly they provide significant opportunities to aid the integration of learning in the basic and engineering sciences across the whole curriculum. This fact is crucial in curriculum design and implementation, such that our graduates benefit to the maximum extent from their learning.}
}
@article{MATTHEWS201973,
title = {Introducing a computational method to estimate and prioritize systemic body exposure of organic chemicals in humans using their physicochemical properties},
journal = {Computational Toxicology},
volume = {9},
pages = {73-99},
year = {2019},
issn = {2468-1113},
doi = {https://doi.org/10.1016/j.comtox.2018.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2468111318300276},
author = {Edwin John Matthews},
keywords = {Absorption, Bioavailability, Chemical disposition, Data-gaps, Distribution, Food ingredient, GRAS, Hazard identification, , OCS (optimal chemical space), Pharmacokinetics, Physicochemical property, Preservative, Prioritization, QSAR, QSPR, Read-across, Risk-ranking, Sequestration, Signal-detection, Toxicokinetics},
abstract = {This report describes a computational method developed to predict systemic exposure (s-exposure), chemical disposition {(CD) intestinal absorption, transport, membrane permeability, distribution, sequestration, phospholipidosis and toxicokinetics} of organic chemicals in humans. The method qualitatively and quantitatively estimates a chemical's CD activity profile based upon computed molecular descriptor properties (descriptors), and it facilitates in silico signal-detection of data-gaps, prioritization, risk-ranking, read-across, and re-assessments (if mandated) of large sets of chemicals in a safety evaluation setting. The investigation used a reference set of 2372 marketed human pharmaceuticals to define decision rules for an optimal chemical space (OCS) in which chemicals have high s-exposure, good CD, and a potential for chemical toxicity (CT); conversely, chemicals outside the OCS have low s-exposure, poor CD into the body, and low potential for CT. The method requires computation of 29 descriptors, identification of OCS molecular descriptor property violations (descriptor_violations), and alignment of descriptor_violations with specific decision rules for individual CD endpoint activities. The investigation predicted the CD activities of food and cosmetic preservatives, ingredients in GRAS (generally recognized as safe). Notices submitted to the FDA, reference pharmaceuticals, and it provides prioritization metrics and indices that facilitate prioritization of chemical in silico computed CD activities.}
}
@article{RIVEST19931,
title = {On Choosing between Experimenting and Thinking when Learning},
journal = {Information and Computation},
volume = {106},
number = {1},
pages = {1-25},
year = {1993},
issn = {0890-5401},
doi = {https://doi.org/10.1006/inco.1993.1047},
url = {https://www.sciencedirect.com/science/article/pii/S0890540183710473},
author = {R.L. Rivest and R.H. Sloan},
abstract = {We introduce a model of inductive inference, or learning, that extends the conventional Bayesian approach by explicitly considering the computational cost of formulating predictions to be tested. We view the learner as a scientist who must divide her time between doing experiments and deducing predictions from promising theories, and we wish to know how she can do so most effectively. We explore several approaches based on the cost of making a prediction relative to the cost of performing an experiment. The resulting strategies share many qualitative characteristics with "real" science. This model is significant for the following reasons: •It allows us to study how a scientist might go about acquiring knowledge in a world where (as in real life) both performing experiments and making predictions from theories require time and effort.•It lays the foundation for a rigorous machine-implementable notion of "subjective probability." Good (1959, , 443-447) argues persuasively that subjective probability is at the heart of probability theory. Previous treatments of subjective probability do not handle the complication that the learner′s subjective probabilities may change as the result of pure thinking; our model captures this and other effects in a realistic manner. In addition, we begin to answer the question of how to trade off versus -a question that is fundamental for computers that must exist in the world and learn from their experience.}
}
@article{OSINGA2022103298,
title = {Big data in agriculture: Between opportunity and solution},
journal = {Agricultural Systems},
volume = {195},
pages = {103298},
year = {2022},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2021.103298},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X21002511},
author = {Sjoukje A. Osinga and Dilli Paudel and Spiros A. Mouzakitis and Ioannis N. Athanasiadis},
keywords = {Big data solutions, Precision Agriculture, Case study, Stakeholders, Technological maturity level, Mixed-method approach},
abstract = {CONTEXT
Big data applications in agriculture evolve fast, as more experience, applications, good practices and computational power become available. Actual solutions to real-life problems are scarce. What characterizes the adoption of big data problems to solutions and to what extent is there a match between them?
OBJECTIVE
We aim to assess the conditions of the adoption of big data technologies in agricultural applications, based on the investigation of twelve real-life practical use cases in the precision agriculture and livestock domain.
METHODS
We use a mixed method approach: a case study research around the twelve use cases of Horizon 2020 project CYBELE, varying from precision arable and livestock farming to fishing and food security, and a stakeholder survey (n = 56). Our analysis focuses on four perspectives: (1) the drivers of change that initiated the use cases; (2) the big data characteristics of the problem; (3) the technological maturity level of the solution both at start and end of the project; (4) the stakeholder perspective.
RESULTS AND CONCLUSIONS
Results show that the use cases’ drivers of change are a combination of data-, technology, research- and commercial interests; most have at least a research drive. The big data characteristics (volume, velocity, variety, veracity) are well-represented, with most emphasis on velocity and variety. Technology readiness levels show that the majority of use cases started at experimental or lab environment stage and aims at a technical maturity of real-world small-scale deployment. Stakeholders’ main concern is cost, user friendliness and to embed the solution within their current work practice. The adoption of better-matching big data solutions is modest. Big data solutions do not work out-of-the-box when changing application domains. Additional technology development is needed for addressing the idiosyncrasies of agricultural applications.
SIGNIFICANCE
We add a practical, empirical assessment of the current status of big data problems and solutions to the existing body of mainly theoretical knowledge. We considered the CYBELE research project as our laboratory for this. Our strength is that we interviewed the use case representatives in person, and that we included the stakeholders’ perspective in our results. Large-scale deployments need effective interdisciplinary approaches and long-term project horizons to address issues emerging from big data characteristics, and to avoid compartmentalization of agricultural sciences. We need both an engineering perspective – to make things work in practice – and a systems thinking perspective – to offer holistic, integrated solutions.}
}
@article{CHENG2013267,
title = {Shape-anisotropic particles at curved fluid interfaces and role of Laplace pressure: A computational study},
journal = {Journal of Colloid and Interface Science},
volume = {402},
pages = {267-278},
year = {2013},
issn = {0021-9797},
doi = {https://doi.org/10.1016/j.jcis.2013.03.047},
url = {https://www.sciencedirect.com/science/article/pii/S0021979713003056},
author = {Tian-Le Cheng and Yu U. Wang},
keywords = {Capillary forces, Surface tension, Laplace pressure, Diffuse interface field approach, Gibbs–Duhem relation, Shape anisotropy, Pickering emulsions},
abstract = {The self-assembly behavior of shape-anisotropic particles at curved fluid interfaces is computationally investigated by diffuse interface field approach (DIFA). A Gibbs–Duhem-type thermodynamic formalism is introduced to treat heterogeneous pressure within the phenomenological model, in agreement with Young–Laplace equation. Computer simulations are performed to study the effects of capillary forces (interfacial tension and Laplace pressure) on particle self-assembly at fluid interfaces in various two-dimensional cases. For isolated particles, it is found that the equilibrium liquid interface remains circular and particles of different shapes do not disturb the homogeneous curvature of liquid interface, while the equilibrium position, orientation and stability of a particle at the liquid interface depend on its shape and initial location with respect to the liquid interface. For interacting particles, the curvature of local liquid interfaces is different from the apparent curvature of the particle shell; nevertheless, irrespective of the particle shapes, a particle-coated droplet always tends to deform into a circular morphology under positive Laplace pressure, loses mechanical stability and collapses under negative Laplace pressure, while adapts to any morphology and stays in neutral equilibrium under zero Laplace pressure. Finally, the collective behaviors of particles and Laplace pressure evolution in bicontinuous interfacially jammed emulsion gels (bijels) are investigated.}
}
@article{VAHLDICK2020100037,
title = {A blocks-based serious game to support introductory computer programming in undergraduate education},
journal = {Computers in Human Behavior Reports},
volume = {2},
pages = {100037},
year = {2020},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2020.100037},
url = {https://www.sciencedirect.com/science/article/pii/S2451958820300373},
author = {Adilson Vahldick and Paulo Roberto Farah and Maria José Marcelino and António José Mendes},
keywords = {Computer programming learning, Blocks-based approach, Serious games},
abstract = {Blocks-based environments have been used to promote computational thinking (CT) and programming learning mostly in elementary and middle schools. In many countries, like Brazil and Portugal, isolated initiatives have been launched to promote CT learning, but until now there is no evidence of a widespread use of this type of environments. Consequently, it is not common that students that reach higher education nowadays are familiar with CT and programming. This paper presents the development of a serious game to support the learning of basic computer programming. It is a blocks-based environment including also resources that allow the teacher to follow the student’s progress and customize in-game tasks. Four cycles of experiments were conducted, improving both the game and how it was used. Based on the results of these experiences, the key contribution of this paper is a set of fourteen findings and recommendations to the creation and use of a game-based approach to support introductory computer programming learning for novices.}
}
@article{VAHDANJOO2025101287,
title = {Digital transformation of the agri-food system},
journal = {Current Opinion in Food Science},
volume = {63},
pages = {101287},
year = {2025},
issn = {2214-7993},
doi = {https://doi.org/10.1016/j.cofs.2025.101287},
url = {https://www.sciencedirect.com/science/article/pii/S2214799325000177},
author = {Mahdi Vahdanjoo and Claus Grøn Sørensen and Michael Nørremark},
abstract = {The purpose of this paper is to examine the role of digital transformation in the agri-food sector. The study emphasizes digitalization as both an enabler of production efficiency and a radical innovator, redesigning business models and agricultural practices. The study explores the development of applications and products that connect consumers, supply chain actors, and producers, leading to customized food products. It highlights the notion of circular agri-food systems for feedback loops in the value chain, minimizing waste and integrating environmental and social values. Also, the paper explores the challenges in digital adoption, including technical barriers, privacy, and security concerns. To overcome these challenges, an interdisciplinary approach is proposed, merging technological, ecological, economic, and governance insights. Key needs identified for successful digital transformation include enhanced data processing, technological convergence, sustainability awareness, interoperability, and user adoption. The conclusion stresses the importance of invoking systemic thinking, user-friendly designs, and interdisciplinary collaboration in making sure that digital innovations enable a sustainable and resilient food production system.}
}
@article{AIZENBERG199987,
title = {One computational approach in support of the Riemann hypothesis},
journal = {Computers & Mathematics with Applications},
volume = {37},
number = {1},
pages = {87-94},
year = {1999},
issn = {0898-1221},
doi = {https://doi.org/10.1016/S0898-1221(98)00244-2},
url = {https://www.sciencedirect.com/science/article/pii/S0898122198002442},
author = {L. Aizenberg and V. Adamchik and V.E. Levit},
keywords = {ς-function, Riemann Hypothesis, Analytic continuation of a function given on a part of its boundary, Holomorphic functions, Conformal mappings, Unit disk, Computational experiments},
abstract = {Some of the results on the criteria for the existence of an analytic continuation into a domain of a function given on a part of its boundary obtained by one of the authors are applied to the Riemann Hypothesis on the zeta-function zeroes. We include all of the basic structural information needed on the previous results on analytic continuation. Some comprehensive numerical experiments have been performed. We have found two important trends in the associated numerical results. The first one is that these findings favor the view that the Riemann Hypothesis is valid. The second one corresponds to a new conjecture on monotonic behavior of some sequences of integrals. The computational experiments have been performed with the Mathematica V3.0.}
}
@article{CRUJEIRAS2013208,
title = {Challenges in the implementation of a competency-based curriculum in Spain},
journal = {Thinking Skills and Creativity},
volume = {10},
pages = {208-220},
year = {2013},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2013.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S187118711300045X},
author = {Beatriz Crujeiras and María Pilar Jiménez-Aleixandre},
keywords = {Scientific competency, Epistemic practices, Higher-order thinking, Policy},
abstract = {This paper addresses some of the challenges involved in implementing the new approach established in the Spanish National Curriculum in 2006, which brought as a major change a focus on the development of key competencies. The paper focuses on scientific competency and the challenges involved in the itinerary from policy documents to classrooms are addressed in three sections: (i) an analysis is made of the changes in the science curriculum as a consequence of the emphasis on scientific competency, comparing the assessment criteria in the previous and current steering documents; (ii) trends in teacher education are discussed; (iii) the findings of the diagnostic evaluation are analyzed. The paper is framed in a theoretical approach, viewing students’ participation in scientific practices, and the development of higher-order thinking as necessary goals of science education. We argue that the focus on competencies, characterized as the ability to apply knowledge and skills in new contexts, involves a major change towards knowledge transfer and higher-order thinking skills. Some issues emerging from the analysis relate to the implications of assessment criteria and the challenges involved in its implementation, to the trends in teacher professional development and the difficulties related to the current economic crisis and to the results of the diagnostic evaluation and time frame needed for reforms to have an impact. It is argued that the development of both competencies and higher-order thinking requires students’ prolonged engagement.}
}
@article{NIKIFORIDOU20124830,
title = {Risk Literacy in Early Childhood Education Under a Lifelong Perspective},
journal = {Procedia - Social and Behavioral Sciences},
volume = {46},
pages = {4830-4833},
year = {2012},
note = {4th WORLD CONFERENCE ON EDUCATIONAL SCIENCES (WCES-2012) 02-05 February 2012 Barcelona, Spain},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.06.343},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812020794},
author = {Zoi Nikiforidou and Jenny Pange and Theodore Chadjipadelis},
keywords = {First keywords, second keywords, third keywords, forth keywords},
abstract = {Risk entails every action, every level and every perspective of our lives. The ability to make advantageous decisions, to deal with uncertainties, to infer and estimate more or less probable outcomes, to manage risky or riskless situations compose the wider notion of risk literacy and may be inserted from formal preschool education. The current paper aims to enlighten the notion of risk literacy and safety education as a necessity in establishing pupils ready to accept failure, to achieve success, to take initiatives, to become self-competent, to develop probabilistic and statistical thinking, to confront uncertainty and in turn to face the challenges of modern risk society. It is argued that within the formal settings of preschool education, through developmentally appropriate activities, opportunities may be implemented in order to encourage children as future citizens to construct risk literate personalities. It is concluded that risk perception and management imply awareness, assessment, avoidance and adaptation and are connected with growth, maturity, practice, experiences, intuitions and computations.}
}
@article{MEDINAOLIVA201338,
title = {PRM-based patterns for knowledge formalisation of industrial systems to support maintenance strategies assessment},
journal = {Reliability Engineering & System Safety},
volume = {116},
pages = {38-56},
year = {2013},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2013.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S0951832013000616},
author = {G. Medina-Oliva and P. Weber and B. Iung},
keywords = {Maintenance strategies, Performances analysis, Decision-making, Bayesian Networks (BN), Probabilistic Relational Model (PRM)},
abstract = {The production system and its maintenance system must be now developed on “system thinking” paradigm in order to guarantee that Key Performance Indicators (KPI) will be optimized all along the production system (operation) life. In a recursive way, maintenance system engineering has to integrate also KPI considerations with regards to its own enabling systems. Thus this paper develops a system-based methodology wherein a set of KPIs is computed in order to verify if the objectives of the production and maintenance systems are satisfied. In order to help the decision-making process for maintenance managers, a “unified” generic model have been developed. This model integrates (a) the interactions of the maintenance system with its enabling systems, (b) the impact of the maintenance strategies through the computation of some key performance indicators, and (c) different kinds of knowledge regarding the maintenance system and the system of interest, including quantitative and qualitative knowledge. This methodology is based on an executable unified model built with Probabilistic Relational Model (PRM). PRM allows a modular representation and inferences computation of large size models. The methodology added-value is shown on a test-bench.}
}
@article{TETEWSKY1986202,
title = {Conceptual and lexical determinants of nonentrenched thinking},
journal = {Journal of Memory and Language},
volume = {25},
number = {2},
pages = {202-225},
year = {1986},
issn = {0749-596X},
doi = {https://doi.org/10.1016/0749-596X(86)90030-6},
url = {https://www.sciencedirect.com/science/article/pii/0749596X86900306},
author = {Sheldon J Tetewsky and Robert J Sternberg},
abstract = {Two experiments investigating information-processing consequences of entrenched and nonentrenched concepts are reported. An attempt is made to distinguish between these two kinds of concepts by using two variables—the naturalness of the occurrence described by a concept and the familiarity of the name used to refer to that occurrence. In each experiment a given conceptual system was expressed in four alternative forms by crossing concept familiarity (naturalness) with lexical familiarity. The experiments used a concept-selection task in which subjects were required to characterize an event based on a preliminary piece of information and a final, confirmatory piece of information. The results indicated that the locus of nonentrenchment lies in using a familiar name to identify an unfamiliar occurrence or in using an unfamiliar name to identify a familiar occurrence. An information-processing model of task performance provided a very good account of the latency data and scores from the concept-selection task correlated with scores from a set of psychometric reasoning tests. The distinction between entrenched and nonentrenched concepts can be interpreted in terms of interference theory, and it also has implications for the way we think about induction and human intelligence.}
}
@article{SHI2024e35268,
title = {3D dynamic landscape simulation of artificial intelligence in environmental landscape design},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e35268},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35268},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024112996},
author = {Binbin Shi},
keywords = {Artificial intelligence, Environmental landscape design, Fuzzy analytical hierarchical process, Geographical information system, 3D dynamic landscape, Interactive design system},
abstract = {Three-dimensional (3D) simulations and precise landscape visualizations are crucial for various applications, like landscape management and planning, computer and connection of the landscape, evaluation, and tracking of land use. The consequences of several plans and a large scene cannot be communicated using older methods of comprehensive environmental planning and development in a timely, rational, and coordinated manner. Architects have trouble incorporating ideas into other comprehensive planning implementation processes. Architects did not thoroughly investigate the neighbourhood's demographics and matching behavioural needs and lacked critical thinking. The 3D dynamic landscape simulation is a detailed computerized three-dimensional simulation of the environment that can be dynamically presented. With the aid of Artificial Intelligence (AI) technology, the system possesses a strong sense of reality, a user-friendly interface, and interactive features that can be tailored to the requirements of the contemporary urban environmental landscape. Regarding exterior publicity, domestic assistance, environmental land use planning, and information systems. The novelty of the proposed Interactive Design System based on AI (IDS-AI) is to create a 3D dynamic landscape model based on a real-life environmental scene, utilizing a Geographic Information System (GIS) to optimize landscape vision. Secondly, 3D environmental landscape design simulation was implemented using GIS spatial analysis in conjunction with the Fuzzy Analytical Hierarchical Process (FAHP) to reduce the data overlap rate and help make an accurate decision. Finally, the design incorporates the development of the interactive interface system application of landscape design and environmental resources for viewing the landscape, the factors that affect them, and the area coverage ratio of various land cover types. The experimental outcomes show that the suggested IDS model increases the gradient sensitivity level of 98.3 % and area coverage ratio of 93.4 % compared to other existing models.}
}
@article{MA2024103893,
title = {Secure outsourced decryption for FHE-based privacy-preserving cloud computing},
journal = {Journal of Information Security and Applications},
volume = {86},
pages = {103893},
year = {2024},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103893},
url = {https://www.sciencedirect.com/science/article/pii/S2214212624001959},
author = {Xirong Ma and Chuan Li and Yuchang Hu and Yunting Tao and Yali Jiang and Yanbin Li and Fanyu Kong and Chunpeng Ge},
keywords = {Privacy-preserving computation, Outsourced computing, Homomorphic encryption},
abstract = {The demand for processing vast volumes of data has surged dramatically due to the advancement of machine learning technology. Large-scale data processing necessitates substantial computational resources, prompting individuals and enterprises to turn to cloud services. Accompanying this trend is a growing concern regarding data leakage and misuse. Homomorphic encryption (HE) is one solution for safeguarding data privacy, enabling encrypted data to be processed securely in the cloud. However, the encryption and decryption routines of some HE schemes require considerable computational resources, presenting non-trivial work for clients. In this paper, we propose an outsourced decryption protocol for the prevailing RLWE-based fully homomorphic encryption schemes. The protocol splits the original decryption into two routines, with the computationally intensive part executed remotely by the cloud. Its security relies on an invariant of the NTRU-search problem with a newly designed blinding key distribution. Cryptographic analyses are conducted to configure protocol parameters across varying security levels. Our experiments demonstrate that the proposed protocol achieves up to a 67% acceleration in the client-side computation, accompanied by a 50% reduction in space usage.}
}
@article{MUNSON2019100736,
title = {After eliciting: Variation in elementary mathematics teachers’ discursive pathways during collaborative problem solving},
journal = {The Journal of Mathematical Behavior},
volume = {56},
pages = {100736},
year = {2019},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2019.100736},
url = {https://www.sciencedirect.com/science/article/pii/S073231231930046X},
author = {Jen Munson},
keywords = {Classroom discourse, Eliciting, Responsiveness, Student understanding},
abstract = {Mathematics teachers are called on to craft instruction that centers students’ mathematical ideas and creates consistent, pervasive opportunities for meaning-making through discourse. In the context of collaborative problem solving, teachers can use eliciting and probing to uncover student thinking while students work together to develop mathematical ideas and strategies. After eliciting and probing, teachers can further respond to the student thinking that has been revealed. This study explored the discursive pathways two fourth grade mathematics teachers used after eliciting student thinking, when their aim was to be responsive to and advance student thinking. Drawing on interactions (n = 97) from nine lessons, qualitative analysis identified five distinct discursive pathways after eliciting, two of which, praise and funneling, were associated with the nature of student understanding uncovered during eliciting. Implications for future research and professional development on teacher-student discourse are discussed.}
}
@article{PANANGADEN201410,
title = {Causality in physics and computation},
journal = {Theoretical Computer Science},
volume = {546},
pages = {10-16},
year = {2014},
note = {Models of Interaction: Essays in Honour of Glynn Winskel},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2014.02.041},
url = {https://www.sciencedirect.com/science/article/pii/S0304397514001674},
author = {Prakash Panangaden},
keywords = {Causal structure, Event structure, Spacetime, Petri nets},
abstract = {Glynn Winskel has had enormous influence on the study of causal structure in computer science. In this brief note, I discuss analogous concepts in relativity where also causality plays a fundamental role. I discuss spacetime structure in a series of layers and emphasize the role of causal structure. I close with some comparisons between causality in relativity and in distributed computing systems.}
}
@article{SUTHAR202431,
title = {Practical exercises of computer-aided process synthesis for chemical engineering undergraduates},
journal = {Education for Chemical Engineers},
volume = {48},
pages = {31-43},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000071},
author = {Krunal J. Suthar and Aesha Mehta and Swapna Rekha Panda and Hitesh Panchal and Rakesh Sinha},
keywords = {computational tools, lifelong learning, laboratory learning, process synthesis},
abstract = {The study presents ten different exercises covering various computational tools. These exercises are practical applications presented to improve the understanding and skills of students in important concepts of chemical-aided process synthesis. A few exercises aim to build a foundation in computational techniques for chemical engineering undergraduates. The exercises are based on a spreadsheet that covers the design of regression analysis to find the optimum Antoine constants, array calculation for multicomponent distillation material balance, and the generation of a Gantt chart to plan and study the activities of batch processes. The other exercises included an introduction to process simulation, simulation, and reactor rating, and a simulation of multicomponent shortcut distillation. These exercises provide students with hands-on experience in utilizing process simulation software essential for analysing and optimizing chemical processes in real-world scenarios. The exercises also included the design of a heat exchanger network and solving a linear programming problem. An anonymous survey was collected from the cohort that had undergone the exercises, and the practical grades were compared with the batch that did not study the proposed exercises. Additionally, student feedback on practical exercises was collected. Based on the experience of the course coordinator and the collected feedback from participants, it was clear that the exercises helped students to inculcate critical thinking and self-learning abilities. An article essentially sheds light on the computer-aided practical exercises that enable chemical engineering graduates to engage in lifelong learning.}
}
@article{KUDARIYAWAR2016193,
title = {Computational study of instabilities in a rectangular natural circulation loop using 3D CFD simulation},
journal = {International Journal of Thermal Sciences},
volume = {101},
pages = {193-206},
year = {2016},
issn = {1290-0729},
doi = {https://doi.org/10.1016/j.ijthermalsci.2015.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1290072915003440},
author = {Jayaraj Yallappa Kudariyawar and Abhijeet Mohan Vaidya and Naresh Kumar Maheshwari and Polepalle Satyamurthy},
keywords = {Natural circulation loop, 3D CFD simulation, Instability},
abstract = {Steady state and transient characteristics of a natural circulation loop working with water are obtained. For this purpose, 3D steady state and transient CFD simulations are performed. The CFD model includes pipe thickness as well as secondary side coolant passage apart from primary side. Steady state and transient characteristics are computed for various configurations i.e. Vertical Heater Vertical Cooler (VHVC), Horizontal Heater Horizontal Cooler (HHHC), etc. Steady state data was compared with available correlations. Flow initiation transients were compared with experimental data. Both the steady state and transient results are found to be in good agreement with previously published data. The reason for formation of unidirectional and bi-directional pulsing in HHHC configuration at different powers is explained with the help of temperature fields at different instants of time. Effect of sudden power rise/power step back on instability in HHHC configuration is estimated using CFD simulations.}
}
@article{SANCHEZTORRUBIA201212177,
title = {An approach to automatic learning assessment based on the computational theory of perceptions},
journal = {Expert Systems with Applications},
volume = {39},
number = {15},
pages = {12177-12191},
year = {2012},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2012.04.069},
url = {https://www.sciencedirect.com/science/article/pii/S0957417412006665},
author = {M. Gloria Sánchez-Torrubia and Carmen Torres-Blanc and Gracian Trivino},
keywords = {Automatic learning assessment, Computing with words and perceptions, Granular linguistic model of a phenomenon},
abstract = {E-learning systems output a huge quantity of data on a learning process. However, it takes a lot of specialist human resources to manually process these data and generate an assessment report. Additionally, for formative assessment, the report should state the attainment level of the learning goals defined by the instructor. This paper describes the use of the granular linguistic model of a phenomenon (GLMP) to model the assessment of the learning process and implement the automated generation of an assessment report. GLMP is based on fuzzy logic and the computational theory of perceptions. This technique is useful for implementing complex assessment criteria using inference systems based on linguistic rules. Apart from the grade, the model also generates a detailed natural language progress report on the achieved proficiency level, based exclusively on the objective data gathered from correct and incorrect responses. This is illustrated by applying the model to the assessment of Dijkstra’s algorithm learning using a visual simulation-based graph algorithm learning environment, called GRAPHs.}
}
@article{NIKNAM20112805,
title = {Non-smooth economic dispatch computation by fuzzy and self adaptive particle swarm optimization},
journal = {Applied Soft Computing},
volume = {11},
number = {2},
pages = {2805-2817},
year = {2011},
note = {The Impact of Soft Computing for the Progress of Artificial Intelligence},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2010.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S1568494610002875},
author = {Taher Niknam and Hasan Doagou Mojarrad and Hamed Zeinoddini Meymand},
keywords = {Economic dispatch, New adaptive particle swarm optimization (NAPSO), Mutation operator, Multi-fuel effects, Self-adaptive parameter control},
abstract = {Economic dispatch (ED) problem is a nonlinear and non-smooth optimization problem when valve-point effects, multi-fuel effects and prohibited operating zones (POZs) have been considered. This paper presents an efficient evolutionary method for a constrained ED problem using the new adaptive particle swarm optimization (NAPSO) algorithm. The original PSO has difficulties in premature convergence, performance and the diversity loss in optimization process as well as appropriate tuning of its parameters. In the proposed algorithm, to improve the global searching capability and prevent the convergence to local minima, a new mutation is integrated with adaptive particle swarm optimization (APSO). In APSO, the inertia weight is tuned by using fuzzy IF/THEN rules and the cognitive and the social parameters are self-adaptively adjusted. The proposed NAPSO algorithm is validated on test systems consisting of 6, 10, 15, 40 and 80 generators with the objective functions possessing prohibited zones, multi-fuel effects and valve-point loading effects. The research results reveal the effectiveness and applicability of the proposed algorithm to the practical ED problem.}
}
@article{RAJAN2024R1221,
title = {Cellular cognition: How single cells learn using non-neural networks},
journal = {Current Biology},
volume = {34},
number = {24},
pages = {R1221-R1223},
year = {2024},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2024.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0960982224015239},
author = {Deepa H. Rajan and Wallace F. Marshall},
abstract = {Summary
Single cells can perform surprisingly complex behaviors and computations, including primitive forms of learning like habituation. New work highlighted here uses mathematical modeling to show that relatively simple biochemical networks can recapitulate many features of habituation in animals.}
}
@article{JONES2000571,
title = {Unstructured mesh computations on CCMs},
journal = {Advances in Engineering Software},
volume = {31},
number = {8},
pages = {571-580},
year = {2000},
issn = {0965-9978},
doi = {https://doi.org/10.1016/S0965-9978(00)00012-0},
url = {https://www.sciencedirect.com/science/article/pii/S0965997800000120},
author = {M.T Jones and K Ramachandran},
keywords = {Configurable computing, Floating point, Finite element},
abstract = {Configurable Computing Machines (CCMs) have been able to provide orders of magnitude increases in execution rates for applications such as image processing, signal processing, and automatic target recognition. This paper describes the use of CCMs to accelerate complex, large-scale scientific computations. These applications present a challenge for CCMs because of their large size, hundreds of thousands of lines of code, and the unstructured nature of the computations. This paper describes strategies for accelerating scientific computations on CCMs and demonstrates the effectiveness of one such strategy on the Annapolis Micro Systems WildForce board. Results from this implementation are analyzed.}
}
@article{CRONIN2022100987,
title = {Analysis of tutors’ responses to students’ queries in a second linear algebra course at a mathematics support center},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100987},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100987},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000554},
author = {Anthony Cronin and Sepideh Stewart},
keywords = {Mathematics tutors, Second courses in linear algebra, Mathematics support center, Feedback, Tutors’ tactics, Advanced mathematical thinking},
abstract = {This paper analyses six years of tutor feedback produced after inquiries made by students in a second linear algebra course at a university mathematics support center (MSC). We utilized Mason’s (2002) pedagogical tactics to build a model to analyze MSC tutors' feedback responding to these students’ queries. The aim of this research was to investigate the nature of students’ difficulties with concepts in a second linear algebra course that emphasizes theories and proof, in addition to examining the tactics employed by tutors to resolve student difficulties. We analyzed 227 feedback comments from 44 tutors based on their interactions with 82 students over six years. Our findings indicated that the most common areas of difficulty were basis, vector space, subspace, span, and proof. Tutor tactics deployed included ‘being mathematical’, ‘simplifying and complexifying’, and ‘worked examples’. We also discuss some implications for linear algebra tutor training.}
}
@incollection{BARBAROSSA2018419,
title = {Chapter 16 - The Edge Cloud: A Holistic View of Communication, Computation, and Caching},
editor = {Petar M. Djurić and Cédric Richard},
booktitle = {Cooperative and Graph Signal Processing},
publisher = {Academic Press},
pages = {419-444},
year = {2018},
isbn = {978-0-12-813677-5},
doi = {https://doi.org/10.1016/B978-0-12-813677-5.00016-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012813677500016X},
author = {Sergio Barbarossa and Stefania Sardellitti and Elena Ceci and Mattia Merluzzi},
keywords = {5G networks, Wireless communications, Graph-based learning},
abstract = {The evolution of communication networks shows a clear shift of focus from just improving the communications aspects to enabling new important services, from Industry 4.0 to automated driving, virtual/augmented reality, the Internet of Things (IoT), and so on. This trend is evident in the roadmap planned for the deployment of the fifth-generation (5G) communication networks. This ambitious goal requires a paradigm shift toward a vision that looks at communication, computation, and caching (3C) resources as three components of a single holistic system. The further step is to bring these 3C resources closer to the mobile user, at the edge of the network, to enable very low latency and high reliability services. The scope of this chapter is to show that signal processing techniques can play a key role in this new vision. In particular, we motivate the joint optimization of 3C resources. Then we show how graph-based representations can play a key role in building effective learning methods and devising innovative resource allocation techniques.}
}
@article{CASTRO20242377,
title = {Product Customization based on Digital Twin and Cloud Manufacturing within a Decentralized Production System},
journal = {Procedia Computer Science},
volume = {239},
pages = {2377-2384},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.431},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924016752},
author = {Hélio Castro and Fernando Câmara and Paulo Ávila and Luís Ferreira and Manuela Cruz-Cunha},
keywords = {Industry 4.0, Digital Twin, Cyber-Physical System, Smart Factory, Product Customization, Cloud Manufacturing},
abstract = {Industry 4.0 represents a turning point in the thinking of the production model since it is based on digitalized production systems with the aim of improving productivity, product quality, and delivery time to the customer. The digitalization and evolution of information technology allowed the emulation of production system virtual models, namely in the concept of Digital Twin (DT), with the ability to simulate different scenarios providing support for better decision making. This concept not only represents a virtual copy of the physical world that obtains information about the state of the value chain but also illustrates a system capable of changing the development of the production activity according to the fulfillment of the intended business goals. In literature, the concept of the Digital Twin is exhaustively treated as a stand-alone factory (one digital factory represents one physical factory) and underestimates the possibility of a DT oriented to a customized product (a project) that requires decentralized production systems. This paper brings to discussion the relevance of product customized applying DT to smart customization, and the inclusion of decentralized production systems supported by Cloud Manufacturing.}
}
@article{CIRAOLO201378,
title = {A computational method for the Helmholtz equation in unbounded domains based on the minimization of an integral functional},
journal = {Journal of Computational Physics},
volume = {246},
pages = {78-95},
year = {2013},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2013.03.047},
url = {https://www.sciencedirect.com/science/article/pii/S0021999113002258},
author = {Giulio Ciraolo and Francesco Gargano and Vincenzo Sciacca},
keywords = {Helmholtz equation, Transparent boundary conditions, Minimization of integral functionals},
abstract = {We study a new approach to the problem of transparent boundary conditions for the Helmholtz equation in unbounded domains. Our approach is based on the minimization of an integral functional arising from a volume integral formulation of the radiation condition. The index of refraction does not need to be constant at infinity and may have some angular dependency as well as perturbations. We prove analytical results on the convergence of the approximate solution. Numerical examples for different shapes of the artificial boundary and for non-constant indexes of refraction will be presented.}
}
@article{TEZDUYAR19992039,
title = {Methods for parallel computation of complex flow problems},
journal = {Parallel Computing},
volume = {25},
number = {13},
pages = {2039-2066},
year = {1999},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(99)00080-0},
url = {https://www.sciencedirect.com/science/article/pii/S0167819199000800},
author = {Tayfun Tezduyar and Yasuo Osawa},
keywords = {Computational fluid dynamics, Flow simulation, Stabilization methods, Compressible flow, Incompressible flow, Multidomain computational methods},
abstract = {This paper is an overview of some of the methods developed by the Team for Advanced Flow Simulation and Modeling (T★AFSM) [http://www.mems.rice.edu/TAFSM/] to support flow simulation and modeling in a number of “Targeted Challenges”. The “Targeted Challenges” include unsteady flows with interfaces, fluid–object and fluid–structure interactions, airdrop systems, and air circulation and contaminant dispersion. The methods developed include special numerical stabilization methods for compressible and incompressible flows, methods for moving boundaries and interfaces, advanced mesh management methods, and multi-domain computational methods. We include in this paper a number of numerical examples from the simulation of complex flow problems.}
}
@article{GOMEZCARRILLO2023296,
title = {Integrating neuroscience in psychiatry: a cultural–ecosocial systemic approach},
journal = {The Lancet Psychiatry},
volume = {10},
number = {4},
pages = {296-304},
year = {2023},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(23)00006-8},
url = {https://www.sciencedirect.com/science/article/pii/S2215036623000068},
author = {Ana Gómez-Carrillo and Laurence J Kirmayer and Neil Krishan Aggarwal and Kamaldeep S Bhui and Kenneth Po-Lun Fung and Brandon A Kohrt and Mitchell G Weiss and Roberto Lewis-Fernández},
abstract = {Summary
Psychiatry has increasingly adopted explanations for psychopathology that are based on neurobiological reductionism. With the recognition of health disparities and the realisation that someone's postcode can be a better predictor of health outcomes than their genetic code, there are increasing efforts to ensure cultural and social–structural competence in psychiatric practice. Although neuroscientific and social–cultural approaches in psychiatry remain largely separate, they can be brought together in a multilevel explanatory framework to advance psychiatric theory, research, and practice. In this Personal View, we outline how a cultural–ecosocial systems approach to integrating neuroscience in psychiatry can promote social–contextual and systemic thinking for more clinically useful formulations and person-centred care.}
}
@article{GUERRAMACIAS2025e41099,
title = {Development of transversal skills in higher education programs in conjunction with online learning: relationship between learning strategies, project-based pedagogical practices, e-learning platforms, and academic performance},
journal = {Heliyon},
volume = {11},
number = {2},
pages = {e41099},
year = {2025},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e41099},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024171307},
author = {Yolanda Guerra-Macías and Sergio Tobón},
keywords = {Generic competencies, 21st-century skills, Virtual education, Higher education, Socioformation, Generic skills, Socioformative rubrics},
abstract = {This study investigates the development of transversal skills and their association with academic performance in university students enrolled in on-campus programs with online activities. A cross-sectional, descriptive, and quantitative research was conducted with 252 students from a public university in Mexico. Transversal skills, socioformative project-based practices, learning strategies, and the relevance of online activities were assessed using validated rubrics. The results indicated a low level of development in three transversal skills: research, entrepreneurship, and English, with the latter being the poorest rated. Critical and creative thinking exhibited the highest level of development. In the didactic component, socioformative project-based pedagogical practices and learning strategies showed acceptable levels. Students expressed satisfaction with complementary online activities, showing a preference for interactive videos and short videos under 4 min. Regression analysis and structural equations were used to examine the relationships between various factors. Results demonstrated that socioformative project-based pedagogical practices, learning strategies, and online education positively correlated with the development of transversal skills. Furthermore, a higher level of transversal skills was associated with better academic averages among students. Socioformative project-based pedagogical practices also correlated with academic performance through transversal skills. The study concludes that integrating online activities into on-campus programs, based on the socioformative pedagogical model, can enhance the development of transversal skills and improve academic performance. Further research into the implementation of this educational model and its long-term impact on university education and professional success is recommended.}
}
@article{FIORE2006S248,
title = {Multi-scale computational analysis of fluid dynamics in the Toraymyxin adsorption cartridge},
journal = {Journal of Biomechanics},
volume = {39},
pages = {S248},
year = {2006},
note = {Abstracts of the 5th World Congress of Biomechanics},
issn = {0021-9290},
doi = {https://doi.org/10.1016/S0021-9290(06)83940-0},
url = {https://www.sciencedirect.com/science/article/pii/S0021929006839400},
author = {G.B. Fiore and G. Guadagni and M. Soncini and S. Vesentini and A. Redaelli}
}
@article{HOWARD2006464,
title = {Cumulative semantic inhibition in picture naming: experimental and computational studies},
journal = {Cognition},
volume = {100},
number = {3},
pages = {464-482},
year = {2006},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2005.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010027705001393},
author = {David Howard and Lyndsey Nickels and Max Coltheart and Jennifer Cole-Virtue},
keywords = {Semantic inhibition, Spoken word production, Picture naming, Competition, Word retrieval, Computational modelling, Priming},
abstract = {We report an experiment in which subjects named 120 pictures, consisting of series of five pictures drawn from each of 24 semantic categories (and intermixed with 45 fillers). The number of intervening trials (lag) between successive presentations of members of the same category varied from two to eight. Subjects' naming latencies were slowed by 30ms for each preceding member of the category. This effect was both cumulative and linear, and unrelated to the lag elapsing since the previous presentation of a category member. These results definitively demonstrate the occurrence of cumulative interference for word retrieval by prior retrieval of other exemplars of the same semantic category—cumulative semantic inhibition. We claim that this inhibition effect could only occur if the spoken word production system possesses three specific properties (competition, priming, and sharing of semantic activation). We provide computational-modelling evidence in support of this claim. We show that no current theory of spoken word production has all of these properties. In their current form, all these theories are falsified by these results. We briefly discuss the obstacles that may be encountered by current models were they modified to account for our findings.}
}
@article{HSU2011380,
title = {The probabilistic analysis of language acquisition: Theoretical, computational, and experimental analysis},
journal = {Cognition},
volume = {120},
number = {3},
pages = {380-390},
year = {2011},
note = {Probabilistic models of cognitive development},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2011.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010027711000734},
author = {Anne S. Hsu and Nick Chater and Paul M.B. Vitányi},
keywords = {Child language acquisition, Poverty of the stimulus, No negative evidence, Bayesian models, Minimum description length, Simplicity principle, Natural language, Probabilistic models, Identification in the limit},
abstract = {There is much debate over the degree to which language learning is governed by innate language-specific biases, or acquired through cognition-general principles. Here we examine the probabilistic language acquisition hypothesis on three levels: We outline a novel theoretical result showing that it is possible to learn the exact generative model underlying a wide class of languages, purely from observing samples of the language. We then describe a recently proposed practical framework, which quantifies natural language learnability, allowing specific learnability predictions to be made for the first time. In previous work, this framework was used to make learnability predictions for a wide variety of linguistic constructions, for which learnability has been much debated. Here, we present a new experiment which tests these learnability predictions. We find that our experimental results support the possibility that these linguistic constructions are acquired probabilistically from cognition-general principles.}
}
@article{CRAWFORD202180,
title = {Efficient mechanisms for level-k bilateral trading},
journal = {Games and Economic Behavior},
volume = {127},
pages = {80-101},
year = {2021},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2021.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0899825621000282},
author = {Vincent P. Crawford},
keywords = {Mechanism design, Bilateral trading, Level- thinking, Behavioral game theory},
abstract = {This paper revisits Myerson and Satterthwaite's (1983) classic analysis of mechanism design for bilateral trading, replacing equilibrium with a level-k model of strategic thinking and focusing on direct mechanisms. The revelation principle fails for level-k models, so restricting attention to direct mechanisms and imposing incentive-compatibility are not without loss of generality. If, however, only direct, level-k-incentive-compatible mechanisms are feasible and traders' levels are observable, Myerson and Satterthwaite's characterization of mechanisms that maximize traders' total surplus subject to incentive constraints generalizes qualitatively to level-k models. If only direct, level-k-incentive-compatible mechanisms are feasible but traders' levels are not observable, generically a particular posted-price mechanism maximizes traders' total expected surplus subject to incentive constraints. If direct, non-level-k-incentive-compatible mechanisms are feasible and traders best respond to them, total expected surplus-maximizing mechanisms may take completely different forms.}
}
@article{CUMMINGS2003369,
title = {Computational challenges in high angle of attack flow prediction},
journal = {Progress in Aerospace Sciences},
volume = {39},
number = {5},
pages = {369-384},
year = {2003},
issn = {0376-0421},
doi = {https://doi.org/10.1016/S0376-0421(03)00041-1},
url = {https://www.sciencedirect.com/science/article/pii/S0376042103000411},
author = {Russell M. Cummings and James R. Forsythe and Scott A. Morton and Kyle D. Squires},
abstract = {Aircraft aerodynamics have been predicted using computational fluid dynamics for a number of years. While viscous flow computations for cruise conditions have become commonplace, the non-linear effects that take place at high angles of attack are much more difficult to predict. A variety of difficulties arise when performing these computations, including challenges in properly modeling turbulence and transition for vortical and massively separated flows, the need to use appropriate numerical algorithms if flow asymmetry is possible, and the difficulties in creating grids that allow for accurate simulation of the flowfield. These issues are addressed and recommendations are made for further improvements in high angle of attack flow prediction. Current predictive capabilities for high angle of attack flows are reviewed, and solutions based on hybrid turbulence models are presented.}
}
@incollection{1991344,
title = {Appendix A - Scientific chaos: a new way of thinking about dynamics},
editor = {Ralph D. Stacey},
booktitle = {The Chaos Frontier},
publisher = {Butterworth-Heinemann},
pages = {344-365},
year = {1991},
isbn = {978-0-7506-0139-9},
doi = {https://doi.org/10.1016/B978-0-7506-0139-9.50021-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780750601399500212}
}
@article{ARKOUDAS2008461,
title = {Computation, hypercomputation, and physical science},
journal = {Journal of Applied Logic},
volume = {6},
number = {4},
pages = {461-475},
year = {2008},
note = {The Philosophy of Computer Science},
issn = {1570-8683},
doi = {https://doi.org/10.1016/j.jal.2008.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S1570868308000414},
author = {Konstantine Arkoudas},
keywords = {Hypercomputation, Church–Turing thesis, Gandy's thesis, Mechanical computability, Algorithms, Turing limit, Physical science, Physical computability},
abstract = {Copeland and others have argued that the Church–Turing thesis (CTT) has been widely misunderstood by philosophers and cognitive scientists. In particular, they have claimed that CTT is in principle compatible with the existence of machines that compute functions above the “Turing limit,” and that empirical investigation is needed to determine the “exact membership” of the set of functions that are physically computable. I argue for the following points: (a) It is highly doubtful that philosophers and cognitive scientists have widely misunderstood CTT as alleged.1 In fact, by and large, computability theorists and mathematical logicians understand CTT in the exact same way. (b) That understanding most likely coincides with what Turing and Church had in mind. Even if it does not, an accurate exegesis of Turing and Church need not dictate how today's working scientists understand the thesis. (c) Even if we grant Copeland's reading of CTT, an orthodox stronger version of it which he rejects (Gandy's thesis) follows readily if we only accept a highly plausible necessary condition for what constitutes a deterministic digital computer. Finally, (d) regardless of whether we accept this condition, the prospects for a scientific theory of hypercomputation are exceedingly poor because physical science does not have the wherewithal to investigate computability or to discover its ultimate “limit.”}
}
@article{KARAGIANNIS2022103631,
title = {The OMiLAB Digital Innovation environment: Agile conceptual models to bridge business value with Digital and Physical Twins for Product-Service Systems development},
journal = {Computers in Industry},
volume = {138},
pages = {103631},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103631},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522000264},
author = {Dimitris Karagiannis and Robert Andrei Buchmann and Wilfrid Utz},
keywords = {Digital twin, Physical twin, Smart Product-service Systems, Agile modeling method engineering, OMiLAB, Domain-specific conceptual modeling},
abstract = {OMiLAB is a community of practice which offers a digital ecosystem bringing together open technologies to investigate and apply conceptual modeling methods for varying purposes and domains. One of the core value propositions is a dedicated Digital Innovation environment comprising several toolkits and workspaces, designed to support Product-Service Systems (PSS) prototyping – a key ingredient for PSS lifecycle management. At the core of this environment is a notion of Agile Digital Twin – a conceptual representation that can be tailored with knowledge engineering means to bridge the semantic and functional gap between a business perspective (focusing on value creation) and an engineering perspective (focusing on cyber-physical proofs-of-concept). To facilitate this bridging, the hereby proposed environment orchestrates, across three abstraction layers, methods such as Design Thinking, Agile Modeling Method Engineering and Model-driven Engineering to turn Ideation into smart Product-Service Systems experiments, in a laboratory setting. The proposed environment was built following Design Science principles. It addresses the problem of historically-disconnected skills required for Digital Innovation projects and it provides a testbed for feasibility experimentation. For design-oriented, artifact building research, a higher Technology Readiness Level can thus be achieved (compared to the level that idea development methods typically attain).}
}
@article{BYTYQIDAMONI2024137516,
title = {Synthesis, characterization, and computational study of novel carvacrol-based 2-aminothiol and sulfonic acid derivatives as metabolic enzyme inhibitors},
journal = {Journal of Molecular Structure},
volume = {1303},
pages = {137516},
year = {2024},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2024.137516},
url = {https://www.sciencedirect.com/science/article/pii/S0022286024000395},
author = {Arlinda Bytyqi-Damoni and Eda Mehtap Uc and Rıfat Emin Bora and Hayriye Genc Bilgicli and Mehmet Abdullah Alagöz and Mustafa Zengin and İlhami Gülçin},
keywords = {Carvacrol, Carbonic anhydrase, α-glucosidase, Acetylcholinesterase, Butyrylcholinesterase},
abstract = {Eight new 2-aminothiols (69–96%) and three new sulfonic acids (51–76%) were synthesized and characterized by NMR and HRMS spectra. This study presents the inhibitory effects of a series of novel carvacrol-based 2-aminothiol and sulfonic acid derivatives (3a-f,4a-c) against human carbonic anhydrase I and II isozymes (hCA I and II) acetylcholinesterase (AChE), butyrylcholinesterase (BChE) and α-glycosidase. Ki values were calculated as 12.52±3.61–335.65±60.56 nM for hCA I, 12.20±3.59–389.69±119.41 nM for hCA II, 1.79±0.56–84.86±23.34 nM for AChE, 6.57±2.54–88.05±21.05 nM for BChE and 14.63±4.76–116.39±33.70 nM α-glucosidase enzymes. Also, the inhibition effects of novel carvacrol-based 2-aminothiol (3a-h) and sulfonic acid derivatives (4a-c) were compared to standard and clinically used inhibitors of acetazolamide, Tacrine and acarbose, respectively. Molecular modeling studies of novel compounds, docking scores, and free binding energies were calculated. The activity results of the compounds were found to be compatible with the docking scores. Molecular dynamics studies were conducted with the best activity against CA I and CA II compounds, 4b (IC50: 4.76 nM) and 4a (IC50: 4.36 nM), respectively. In Dynamic Simulation studies, it was observed that the compounds remained stable at the active sites of the proteins.}
}
@article{GOLDBACH2016249,
title = {Computational Cutting Pattern Generation Using Isogeometric B-Rep Analysis},
journal = {Procedia Engineering},
volume = {155},
pages = {249-255},
year = {2016},
note = {TENSINET – COST TU1303 International Symposium 2016 "Novel structural skins - Improving sustainability and efficiency through new structural textile materials and designs"},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2016.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S1877705816321671},
author = {Ann-Kathrin Goldbach and Michael Breitenberger and Armin Widhammer and Kai-Uwe Bletzinger},
keywords = {Cutting pattern generation, Variation of Reference Strategy, Isogeometric Analysis, Isogeometric B-Rep Analysis, Design cycle of structural membranes},
abstract = {The cutting pattern plays a major role for the design of structural membranes, since it influences both their aesthetical appearance and structural behavior. A novel approach towards cutting pattern generation is the so-called Variation of Reference Strategy (VaReS) [1], which minimizes the total potential energy arising from the motion of a planar cutting pattern to its corresponding three-dimensional shape. With non-uniform rational B-Splines (NURBS) being the standard tool for geometry description in CAD, it is only consequent to use these for analysis as well. Isogeometric B-Rep Analysis (IBRA) [2] follows up on this idea and enriches the original Isogeometric Analysis (IGA), which was introduced by Hughes et al. [3], by the possibility of analysing trimmed NURBS geometries. This paper presents cutting pattern generation with the Variation of Reference Strategy in the context of IGA/IBRA. With this approach, the whole design of a membrane structure can be represented by NURBS geometries – including blueprint plans. To use the benefits of IBRA for cutting pattern generation, a NURBS-based membrane-element was developed for the VaReS routine. A developable surface serves as a benchmark example, since its analytical cutting pattern is known. Examples of double-curved geometries show the applicability and benefits of the proposed procedure for real structures.}
}
@article{KADUWELA2024105337,
title = {Application of a human-centered design for embedded machine learning model to develop data labeling software with nurses: Human-to-Artificial Intelligence (H2AI)},
journal = {International Journal of Medical Informatics},
volume = {183},
pages = {105337},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105337},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623003556},
author = {Naomi A. Kaduwela and Susan Horner and Priyansh Dadar and Renee C.B. Manworren},
keywords = {Clinical decision support software, Data labeling, Human-centered Design for Embedded Machine Learning Solutions Machine Learning, Machine learning models},
abstract = {Background
Nurses are essential for assessing and managing acute pain in hospitalized patients, especially those who are unable to self-report pain. Given their role and subject matter expertise (SME), nurses are also essential for the design and development of a supervised machine learning (ML) model for pain detection and clinical decision support software (CDSS) in a pain recognition automated monitoring system (PRAMS). Our first step for developing PRAMS with nurses was to create SME-friendly data labeling software.
Purpose
To develop an intuitive and efficient data labeling software solution, Human-to-Artificial Intelligence (H2AI).
Method
The Human-centered Design for Embedded Machine Learning Solutions (HCDe-MLS) model was used to engage nurses. In this paper, HCDe-MLS will be explained using H2AI and PRAMS as illustrative cases.
Findings
Using HCDe-MLS, H2AI was developed and facilitated labeling of 139 videos (mean = 29.83 min) with 3189 images labeled (mean = 75 s) by 6 nurses. OpenCV was used for video-to-image pre-processing; and MobileFaceNet was used for default landmark placement on images. H2AI randomly assigned videos to nurses for data labeling, tracked labelers’ inter-rater reliability, and stored labeled data to train ML models.
Conclusions
Nurses’ engagement in CDSS development was critical for ensuring the end-product addressed nurses’ priorities, reflected nurses’ cognitive and decision-making processes, and garnered nurses’ trust for technology adoption.}
}
@article{SILVEIRA1980165,
title = {Generic masculine words and thinking},
journal = {Women's Studies International Quarterly},
volume = {3},
number = {2},
pages = {165-178},
year = {1980},
note = {The voices and words of women and men},
issn = {0148-0685},
doi = {https://doi.org/10.1016/S0148-0685(80)92113-2},
url = {https://www.sciencedirect.com/science/article/pii/S0148068580921132},
author = {Jeanette Silveira},
abstract = {Synopsis
It has been alleged that, in appropriate verbal contexts, man and he are generic, i.e. that the words include women as well as men, as for example in, Man is mortal, or One must watch his language. Many feminists argue for the elimination of this generic use of man and he and the substitution of such non-male words as people and they. Others argue on various grounds that these changes are unnecessary. This paper isolates the issues involved in such arguments and provisionally concludes that a reduction in the generic use of man and he would result in a long term reduction in sexist thinking. Recent feminist research on man and he is carefully reviewed. In its final section, the paper develops the implication that women experience more alienation than men in the presence of the generic man and he.}
}
@article{DEBARROS2012171,
title = {Quantum-like model of behavioral response computation using neural oscillators},
journal = {Biosystems},
volume = {110},
number = {3},
pages = {171-182},
year = {2012},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2012.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0303264712001736},
author = {J. Acacio {de Barros}},
keywords = {Disjunction effect, Quantum cognition, Quantum-like model, Neural oscillators, Stimulus-response theory},
abstract = {In this paper we propose the use of neural interference as the origin of quantum-like effects in the brain. We do so by using a neural oscillator model consistent with neurophysiological data. The model used was shown elsewhere to reproduce well the predictions of behavioral stimulus-response theory. The quantum-like effects are brought about by the spreading activation of incompatible oscillators, leading to an interference-like effect mediated by inhibitory and excitatory synapses.}
}
@article{EMILYESTHERRANI2025107032,
title = {Alzheimer disease classification using optimal clustering based pre-trained SqueezeNet model},
journal = {Biomedical Signal Processing and Control},
volume = {100},
pages = {107032},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.107032},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424010905},
author = {K. {Emily Esther Rani} and S. Baulkani},
keywords = {Alzheimer disease, Optimal center, Clustering, Adaptive reptile search algorithm, Pre-trained squeezenet},
abstract = {Alzheimer’s disease (AD) is an irreversible neurological illness identified by deficits in thinking, behavior, and memory. Early detection and prevention of AD is a crucial and difficult task. DL (Deep Learning) has gained significant attention recently as a potential tool for early AD detection. However, traditional diagnostic methods such as cognitive tests and manual analysis of brain imaging are time consuming and prone to error. Hence, there is a need for an automated model which shows better classification performance. To tackle these issues, this study presents a system to improve AD recognition performance. Initially, the pre-processing and skull stripping processes are performed. Then, for segmenting the grey, whiter matters and Cerebrospinal Fluid (CSF), the optimal clustering process is carried out. Here, the optimal center of clusters is selected by the metaheuristic optimization Adaptive Reptile Search Algorithm-Clustering Approach (ARSA-CA) is utilized. The proposed ARSA is the integration of the optimization RSA and simulated annealing (SA). Finally, for classifying the different classes of AD, the DL approach pre-trained SqueezeNet is utilized. The experimentation is carried out on the ADNI and OASIS datasets and achieved better accuracies of 98.3% and 98.2% respectively. Thus, it is proved that the proposed model is suitable for identifying AD.}
}
@incollection{MYUNG20012453,
title = {Computational Approaches to Model Evaluation},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2453-2457},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/00589-1},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767005891},
author = {I.J. Myung},
abstract = {The induction problem of inferring a predictive function (i.e., model) from finite data is a central component of the scientific enterprise in cognitive science, computer science and statistics, and yet the problem is fundamentally ill posed. Many models can often provide equally good fits to a given observed data set but they may differ considerably in their ability to generalize to new, as yet unseen, data sets generated from the same underlying process. To make this inductive inference problem well posed one needs to define a justifiable measure of generalizability and then use the measure to choose among a set of competing models. Many such measures have been proposed in the past, notably by scientists in the fields of machine learning and algorithmic coding theory. A representative list of such approaches includes the structural risk minimization method and Vapnik-Chervonenkis dimension, the regularization theory, and the minimum description length principle. This article presents a review of these computational approaches to model evaluation. Also discussed are the interesting connections between the computational approaches and some of the statistical approaches to model evaluation such as the Akaike information criterion, the Bayesian information criterion and Bayesian model selection.}
}
@incollection{DEAN2014157,
title = {Chapter 7 - Decorrelation Learning in the Cerebellum: Computational Analysis and Experimental Questions},
editor = {Narender Ramnani},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {210},
pages = {157-192},
year = {2014},
booktitle = {Cerebellar Learning},
issn = {0079-6123},
doi = {https://doi.org/10.1016/B978-0-444-63356-9.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444633569000078},
author = {Paul Dean and John Porrill},
keywords = {Cerebellum, eye blink conditioning, vestibulo-ocular reflex, spike-timing dependent plasticity, avoidance learning, long-term depression, long-term potentiation, supervised learning, reafference, least mean squares},
abstract = {Many cerebellar models use a form of synaptic plasticity that implements decorrelation learning. Parallel fibers carrying signals positively correlated with climbing-fiber input have their synapses weakened (long-term depression), whereas those carrying signals negatively correlated with climbing input have their synapses strengthened (long-term potentiation). Learning therefore ceases when all parallel-fiber signals have been decorrelated from climbing-fiber input. This is a computationally powerful rule for supervised learning and can be cast in a spike-timing dependent plasticity form for comparison with experimental evidence. Decorrelation learning is particularly well suited to sensory prediction, for example, in the reafference problem where external sensory signals are interfered with by reafferent signals from the organism’s own movements, and the required circuit appears similar to the one found to mediate classical eye blink conditioning. However, for certain stimuli, avoidance is a much better option than simple prediction, and decorrelation learning can also be used to acquire appropriate avoidance movements. One example of a stimulus to be avoided is retinal slip that degrades visual processing, and decorrelation learning appears to play a role in the vestibulo-ocular reflex that stabilizes gaze in the face of unpredicted head movements. Decorrelation learning is thus suitable for both sensory prediction and motor control. It may also be well suited for generic spatial and temporal coordination, because of its ability to remove the unwanted side effects of movement. Finally, because it can be used with any kind of time-varying signal, the cerebellum could play a role in cognitive processing.}
}
@article{JONES20171,
title = {Diversity not quantity in caregiver speech: Using computational modeling to isolate the effects of the quantity and the diversity of the input on vocabulary growth},
journal = {Cognitive Psychology},
volume = {98},
pages = {1-21},
year = {2017},
issn = {0010-0285},
doi = {https://doi.org/10.1016/j.cogpsych.2017.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0010028516302274},
author = {Gary Jones and Caroline F. Rowland},
keywords = {Input quantity, Lexical diversity, Vocabulary acquisition, CLASSIC, Language acquisition},
abstract = {Children who hear large amounts of diverse speech learn language more quickly than children who do not. However, high correlations between the amount and the diversity of the input in speech samples makes it difficult to isolate the influence of each. We overcame this problem by controlling the input to a computational model so that amount of exposure to linguistic input (quantity) and the quality of that input (lexical diversity) were independently manipulated. Sublexical, lexical, and multi-word knowledge were charted across development (Study 1), showing that while input quantity may be important early in learning, lexical diversity is ultimately more crucial, a prediction confirmed against children’s data (Study 2). The model trained on a lexically diverse input also performed better on nonword repetition and sentence recall tests (Study 3) and was quicker to learn new words over time (Study 4). A language input that is rich in lexical diversity outperforms equivalent richness in quantity for learned sublexical and lexical knowledge, for well-established language tests, and for acquiring words that have never been encountered before.}
}
@article{HEYLIGHEN2014113,
title = {Designing in the absence of sight: Design cognition re-articulated},
journal = {Design Studies},
volume = {35},
number = {2},
pages = {113-132},
year = {2014},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2013.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X13000926},
author = {Ann Heylighen and Greg Nijs},
keywords = {design cognition, design research, epistemology},
abstract = {Starting from the study of an architect who designs in the absence of sight, we question to what extent prevailing notions of design may be complemented with alternative articulations. In doing so, we point to the cognitivist understanding of human cognition underlying design researchers' strong attention to ‘visual thinking’, and contrast this with more situated understandings of human cognition. The ontological and epistemological differences between both raise questions about how design research is produced, and consequently what design can also be. By accounting for how a blind architect re-articulates prevailing notions of design, we invite researchers to keep the discussion open and call for an ontological and epistemological re-articulation in design research.}
}
@article{GOMEZTALAL2024108109,
title = {Understanding the disparities in Mathematics performance: An interpretability-based examination},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108109},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108109},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624002677},
author = {Ismael Gómez-Talal and Luis Bote-Curiel and José Luis Rojo-Álvarez},
keywords = {Programme for International Student Assessment, Interpretable machine learning, Shapley additive explanations, Explainable black-box models},
abstract = {Problem:
Educational disparities in Mathematics performance are a persistent challenge. This study aims to unravel the complex factors contributing to these disparities among students internationally, with a focus on the interpretability of the contributing factors.
Methodology:
Utilizing data from the Programme for International Student Assessment (PISA), we conducted rigorous preprocessing and variable selection to prepare for applying binary classification interpretability models. These models were trained using the Stratified K-Fold technique to ensure balanced representation and assessed using six key metrics.
Solution:
By applying interpretability models such as Shapley Additive Explanations (SHAP) analysis, we identified critical factors impacting student performance, including reading accessibility, critical thinking skills, gender, and geographical location.
Results:
Our findings reveal significant disparities linked to resource availability, with students from lower socioeconomic backgrounds possessing fewer books and demonstrating lower performance in Mathematics. The geographical analysis highlighted regional educational disparities, with certain areas consistently underperforming in PISA assessments. Gender also emerged as a determinant, with females contributing differently to performance levels across the spectrum.
Conclusion:
The study provides insights into the multifaceted determinants of student Mathematics performance and suggests potential avenues for future research to explore global interpretability models and further investigate the socioeconomic, cultural, and educational factors at play.}
}
@article{TRINDADE2025101104,
title = {Teaching mathematical concepts in management with generative artificial intelligence: The power of human oversight in AI-driven learning},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101104},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101104},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001757},
author = {Maria A.M. Trindade and Gihan S. Edirisinghe and Lan Luo},
keywords = {Generative artificial intelligence in education, Generative AI-Driven learning, Mathematics in management education, Operations management, Economic order quantity, Generative AI in management education},
abstract = {This study demonstrates a successful use of Generative Artificial Intelligence (AI) in teaching mathematical material to management students. We herein introduce the EOQ World Tour game, which substantially improves understanding of inventory-related concepts and long-term knowledge retention compared with traditional methods. Generative AI is revolutionizing management education, by offering innovative methods for teaching and learning. The integration of AI into quantitative business disciplines through novel learning mechanisms provides significant benefits, including enhanced data analysis, improved decision-making models, and sophisticated simulations for hands-on experience. This study introduces the EOQ World Tour game, specifically designed to teach the Economic Order Quantity concept in Operations Management. The game addresses challenges in integrating Generative AI into mathematics in management education by combining human oversight and instructor control through three innovative features: (1) a Generative AI-based simulation, (2) a macropowered Excel worksheet for validating the calculations of an AI chatbot, and (3) a Google Sheets dashboard for centralizing team-generated AI data for postgame analysis. Our study included 41 students divided into experimental and control groups. Pretest results indicated no significant differences in baseline knowledge. However, the post-test results showed that the experimental group achieved a better understanding of inventory-related concepts and practical applications, along with higher engagement, excitement, confidence, and long-term knowledge retention.}
}
@article{GISIGER2000250,
title = {Computational models of association cortex},
journal = {Current Opinion in Neurobiology},
volume = {10},
number = {2},
pages = {250-259},
year = {2000},
issn = {0959-4388},
doi = {https://doi.org/10.1016/S0959-4388(00)00075-1},
url = {https://www.sciencedirect.com/science/article/pii/S0959438800000751},
author = {Thomas Gisiger and Stanislas Dehaene and Jean-Pierre Changeux},
abstract = {Recent computational models, or mathematical realizations of neurobiological theories, are providing insights into the organization and workings of the association cortex. Such models concern the construction of cortical maps, the neural basis of cognitive functions such as visual perception, reward-motivated learning and some aspects of consciousness.}
}
@incollection{2016295,
title = {10 - Computational fluid dynamics in aerospace field and CFD-based multidisciplinary simulations},
editor = {Qun Zhang and Song Cen},
booktitle = {Multiphysics Modeling},
publisher = {Academic Press},
address = {Oxford},
pages = {295-328},
year = {2016},
series = {Elsevier and Tsinghua University Press Computational Mechanics Series},
isbn = {978-0-12-407709-6},
doi = {https://doi.org/10.1016/B978-0-12-407709-6.00010-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780124077096000109},
keywords = {aerospace engineering, finite volume method, ALE formulation, discrete geometric conservation law, mesh deformation, remeshing, flapping wing, store separation, wing flutter},
abstract = {In this chapter, the ALE formulation of the finite volume method is proposed for the simulation of compressible fluid flow. Two major topics of the discrete geometric conservation lawgeometric conservation law and mesh deformationmesh deformation algorithm in this chapter are to handle the moving boundary problem accurately and efficiently. Three examples are given to verify the effectiveness of the presented methods in multiphysics simulation for aerospace engineering problems.}
}
@article{CORREABAENA20181410,
title = {Accelerating Materials Development via Automation, Machine Learning, and High-Performance Computing},
journal = {Joule},
volume = {2},
number = {8},
pages = {1410-1420},
year = {2018},
issn = {2542-4351},
doi = {https://doi.org/10.1016/j.joule.2018.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S2542435118302289},
author = {Juan-Pablo Correa-Baena and Kedar Hippalgaonkar and Jeroen {van Duren} and Shaffiq Jaffer and Vijay R. Chandrasekhar and Vladan Stevanovic and Cyrus Wadia and Supratik Guha and Tonio Buonassisi},
keywords = {accelerated materials development, machine learning, artificial intelligence, energy materials},
abstract = {Successful materials innovations can transform society. However, materials research often involves long timelines and low success probabilities, dissuading investors who have expectations of shorter times from bench to business. A combination of emergent technologies could accelerate the pace of novel materials development by ten times or more, aligning the timelines of stakeholders (investors and researchers), markets, and the environment, while increasing return on investment. First, tool automation enables rapid experimental testing of candidate materials. Second, high-performance computing concentrates experimental bandwidth on promising compounds by predicting and inferring bulk, interface, and defect-related properties. Third, machine learning connects the former two, where experimental outputs automatically refine theory and help define next experiments. We describe state-of-the-art attempts to realize this vision and identify resource gaps. We posit that over the coming decade, this combination of tools will transform the way we perform materials research, with considerable first-mover advantages at stake.}
}
@article{PEZZULO2011275,
title = {Computational explorations of perceptual symbol systems theory},
journal = {New Ideas in Psychology},
volume = {29},
number = {3},
pages = {275-297},
year = {2011},
note = {Special Issue: Cognitive Robotics and Reevaluation of Piaget Concept of Egocentrism},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2009.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X09000336},
author = {Giovanni Pezzulo and Gianguglielmo Calvi},
keywords = {Perceptual symbol systems, Schemas, Embodiment, Anticipation, Simulation},
abstract = {The aim of this paper is twofold. First, we provide a methodological pathway from theories of situated, embodied cognition to simulations with an eye to empirical evidence, and suggest a possible cross-fertilization between cognitive robotics and psychology. Psychological theories, in particular those formulated at an abstract level, include models which are often severely underspecified at the level of mechanisms. This is true in the synchronic, constructive perspective (how can the effects observed in experiments be concretely generated by the model's mechanisms?) and in the diachronic, developmental perspective (how can such mechanisms be learned and developed?). The synthetic method of artificial cognitive systems research, and in particular of cognitive robotics, can complement research in psychology (and neurosciences) by exploring the constructive and developmental aspects of theories. Our second aim is to provide an example of such a methodology by describing simulations aiming at developing a perceptual symbol system (PSS) (Barsalou, 1999). We then describe the two main theoretical constructs of the PSS, perceptual symbols and simulators, illustrate their development in an artificial system, and test the system in prediction, categorization, and abstraction tasks.}
}
@article{AMADORHIDALGO2021103694,
title = {Cognitive abilities and risk-taking: Errors, not preferences},
journal = {European Economic Review},
volume = {134},
pages = {103694},
year = {2021},
issn = {0014-2921},
doi = {https://doi.org/10.1016/j.euroecorev.2021.103694},
url = {https://www.sciencedirect.com/science/article/pii/S0014292121000477},
author = {Luis Amador-Hidalgo and Pablo Brañas-Garza and Antonio M. Espín and Teresa García-Muñoz and Ana Hernández-Román},
keywords = {Decision making under uncertainty, Cognitive abilities, Online experiment, Risk and loss aversion, Factor analysis},
abstract = {There is an intense debate whether risk-taking behavior is partially driven by cognitive abilities. The critical issue is whether choices arising from subjects with lower cognitive abilities are more likely driven by errors or lack of understanding than pure preferences for risk. The latter implies that the often-argued link between risk preferences and cognitive abilities (a common finding is that abilities relate negatively to risk aversion and positively to loss aversion) might be a spurious correlation. This experiment reports evidence from a sample of 556 participants who made choices in two risk-related tasks and completed three cognitive tasks, all with real monetary incentives: number-additions (including incentive-compatible expected number of correct additions), the Cognitive Reflection Test (to measure analytical/reflective thinking) and the Remote Associates Test (for convergent thinking). Results are unambiguous: none of our cognition measures plays any systematic role on risky decision making. Using structural equation modeling and factor analysis, we show that cognitive abilities are negatively associated with noisy, inconsistent choices and this effect may make higher ability individuals appear to be less risk averse and more loss averse. Yet we show that errors are more likely to appear when the two payoffs in a given decision exhibit similar probability. Therefore, our results suggest that failing to account for noisy decision making might have led to erroneously inferring a correlation between cognitive abilities and risk preferences in previous studies.}
}