@article{FUCHS2023103688,
title = {A post-Cartesian economic and Buddhist view on tourism},
journal = {Annals of Tourism Research},
volume = {103},
pages = {103688},
year = {2023},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2023.103688},
url = {https://www.sciencedirect.com/science/article/pii/S0160738323001615},
author = {Matthias Fuchs},
keywords = {Economic growth ideology, Post-Cartesian ontology, Post-mechanistic economic theory, Buddhist philosophy, Transformative tourism},
abstract = {Insuperable socio-economic and ecological crises demonstrate the need to challenge economic growth ideology that is often embedded in contemporary tourism science. By borrowing from Buddhist philosophy this essay describes inconsistencies in economic theorizing due to its adoption of the Cartesian ontology implying a mechanistic thinking form. Following philosopher Brodbeck (2014), economic science is neither an empirically exact science nor value-free but represents an implicit ethics. To build on this, the elements of a post-mechanistic economic theory are sketched (Brodbeck, 2001). The applicability of this concept is corroborated by instances of current tourism research. After reinterpreting the homo economicus and the nature of money an agenda for a transformative tourism science building upon post-Cartesian economic thinking and Buddhist philosophy is elaborated.}
}
@incollection{DELLANGELO2022299,
title = {13 - Computational chemistry and the study and design of catalysts},
editor = {Liliana Mammino},
booktitle = {Green Chemistry and Computational Chemistry},
publisher = {Elsevier},
pages = {299-332},
year = {2022},
series = {Advances in Green and Sustainable Chemistry},
isbn = {978-0-12-819879-7},
doi = {https://doi.org/10.1016/B978-0-12-819879-7.00010-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128198797000106},
author = {David Dell’Angelo},
keywords = {CO capture, conversion and utilization, Energy storage, Free energy techniques, Metal-organic frameworks (MOFs), Nanohazard simulations, Photocatalysis technologies, Roles of catalysis in green chemistry, Simulation methods in molecular modelling, Solvent effects on chemical reactivity, Zeolites and catalysis},
abstract = {Several theoretical and computational chemistry works may yield results that prove useful for a better understanding of phenomena relevant to green chemistry, or may specifically focus on addressing green chemistry issues. This chapter presents an overview of results of this type, considering their various application areas. At the same time, it devotes particular attention to the roles that computationally obtained information may play for an efficient design of catalysts and for a better understanding of catalytic processes. This particular attention is motivated by the fundamental roles of catalysis in the design of ‘greener’ processes, where ‘greener’ may refer to a variety of aspects, such as the use of safer reactants and products, the use of benign solvents, the increase in energy efficiency and other features that make a process more environmentally friendly.}
}
@article{YERION20151967,
title = {An Introductory Course in the Computational Modeling of Nature},
journal = {Procedia Computer Science},
volume = {51},
pages = {1967-1976},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.461},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915012697},
author = {Kathie A. Yerion},
keywords = {Modeling, Agent-based, System-dynamics},
abstract = {This introductory course in computational modeling of nature contains the development of three kinds of models of phenomena in nature -- agent-based models and simple finite difference models using the environment of the NetLogo language and complex finite difference models using the language of C++. No prior programming experience is assumed. The natural phenomena modeled include some standard ones (e.g. ants following pheromone trails, the interaction of sheep and wolves) and some non-standard ones (the creation of the world, 3 dogs playing games, and formation of stripes and spots in the skins of animals). The emphasis of the course is on the modeling process. A distinguishing feature is that students are able to compare and critique these models.}
}
@article{GISSEL201661,
title = {A case of fixed asset accounting: Initial and subsequent measurement},
journal = {Journal of Accounting Education},
volume = {37},
pages = {61-66},
year = {2016},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2016.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575116300422},
author = {Jodi L. Gissel},
keywords = {Fixed asset acquisition, Depreciation, Interest capitalization, Nonmonetary exchange, Impairment, IFRS},
abstract = {This instructional case integrates multiple accounting concepts relating to fixed asset acquisition and subsequent measurement. You must apply accounting knowledge, professional judgment, and critical thinking skills to evaluate fixed assets and make recommendations. You must also analyze differences between fixed asset accounting under US generally accepted accounting principles and IFRS. As a student, you generally understand basic application of asset cost computation that simply recognizes the amount of cash paid for acquiring the asset. However, determining asset cost becomes challenging when you encounter more complex situations. You must consider initial measurement issues relating to a land purchase (demolition of existing building and a special assessment expenditure), interest capitalization for a self-constructed building, a nonmonetary asset exchange, and an asset retirement obligation. The case also considers subsequent measurement issues in terms of depreciation (straight-line and accelerated methods), replacement of an asset component, and impairment. The case structure is flexible and the teaching notes include alternatives for using scaled-down versions.}
}
@article{LIU20111907,
title = {The effect of simulation games on the learning of computational problem solving},
journal = {Computers & Education},
volume = {57},
number = {3},
pages = {1907-1918},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511000832},
author = {Chen-Chung Liu and Yuan-Bang Cheng and Chia-Wen Huang},
keywords = {Game-based learning, Problem solving, Simulation, Flow experience},
abstract = {Simulation games are now increasingly applied to many subject domains as they allow students to engage in discovery processes, and may facilitate a flow learning experience. However, the relationship between learning experiences and problem solving strategies in simulation games still remains unclear in the literature. This study, thus, analyzed the feedback and problem solving behaviors of 117 students in a simulation game, designed to assist them to learn computational problem solving. It was found that students when learning computational problem solving with the game were more likely to perceive a flow learning experience than in traditional lectures. The students’ intrinsic motivation was also enhanced when they learned with the simulation game. In particular, the results of the study found a close association between the students’ learning experience states and their problem solving strategies. The students who perceived a flow experience state frequently applied trial-and-error, learning-by-example, and analytical reasoning strategies to learn the computational problem solving skills. However, a certain portion of students who experienced states of boredom and anxiety did not demonstrate in-depth problem solving strategies. For instance, the students who felt anxious in the simulation game did not apply the learning-by-example strategy as frequently as those in the flow state. In addition, the students who felt bored in the simulation game only learned to solve the problem at a superficial level.}
}
@incollection{PHIPPEN2025125,
title = {Digital Literacy},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {125-132},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00097-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895000973},
author = {Andy Phippen},
keywords = {AI literacy, Critical thinking, Data literacy, Digital literacy, Digital wellbeing, DQ standard, Education for a connected world, Information literacy, Media literacy, Online safety, Social media literacy, Stakeholders},
abstract = {Digital literacy is a crucial skill set in the contemporary era, encompassing technical proficiency, information and media literacy, data literacy, and more. There are further disciplines that are incorporated into the broad concept of digital literacy, including cybersecurity, online safety, and responsible communication. The importance of critical thinking in digital contexts and the emerging field of digital wellbeing are addressed. There are challenges in achieving digital literacy including the lack of common frameworks and diverse barriers such as access to technology, affordability, and cultural differences. Ultimately digital literacy is something that requires the input of various stakeholders, including educators, governments, technology providers, and community organizations. There is a clear need for a collaborative, multi-pronged approach to address these challenges and the need for common agreement on what digital literacy is.}
}
@article{HAWTHORNE2022100931,
title = {Reconceptualizing a mathematical domain on the basis of student reasoning: Considering teachers’ perspectives about integers},
journal = {The Journal of Mathematical Behavior},
volume = {65},
pages = {100931},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100931},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000924},
author = {Casey Hawthorne and Randolph A. Philipp and Lisa L. Lamb and Jessica P. Bishop and Ian Whitacre and Bonnie P. Schappelle},
keywords = {Integers, Student thinking, Mathematical knowledge for teaching},
abstract = {Integers have historically been approached as a system of rules. However, to teach any mathematical domain for understanding, teachers must conceptualize it as comprised of more than procedures. Using as a lens the four types of integer reasoning identified by Bishop et al. (2014a, 2014b), we interviewed 7th-grade teachers to investigate their own integer reasoning and how this corresponds to their approaches to teaching integers and to their interpretations of students’ reasoning. The teachers not only correctly solved integer tasks but also most reasoned using more than rules, demonstrating a flexibility of strategies. Additionally, although they attempted to introduce integers in meaningful ways, most teachers viewed teaching integers as helping their students apply procedures, an orientation that constrained their understanding of students’ integer reasoning. Results indicate that teachers possess productive conceptual resources but need a structure to leverage their understandings to teach integers as more than a set of rules.}
}
@article{LETONSAARI2017131,
title = {Modeling computational algorithms using nonlinear storytelling methods of computer game design},
journal = {Procedia Computer Science},
volume = {119},
pages = {131-138},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.169},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323797},
author = {Mika Letonsaari and Jukka Selin},
keywords = {Twine, visual programming, rapid prototyping, algorithm design, digital storytelling},
abstract = {Computational algorithms can be described in many methods and implemented in many languages. Here we present an approach using storytelling methods of computer game design in modeling some finite-state machine algorithms and applications requiring user interaction. An open source software Twine is used for the task. Interactive nonlinear stories created with Twine are applications that can be executed in a web browser. Storytelling approach provides an easy-to-understand view on computational algorithms allowing communication with people with no computer science education. It also allows rapid prototyping and testing in mixed background work teams.}
}
@incollection{IACOBONI2000523,
title = {17 - Mapping Human Cognition: Thinking, Numerical Abilities, Theory of Mind, Consciousness},
editor = {Arthur W. Toga and John C. Mazziotta},
booktitle = {Brain Mapping: The Systems},
publisher = {Academic Press},
address = {San Diego},
pages = {523-534},
year = {2000},
isbn = {978-0-12-692545-6},
doi = {https://doi.org/10.1016/B978-012692545-6/50019-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780126925456500192},
author = {Marco Iacoboni},
abstract = {Publisher Summary
This chapter discusses the mapping the brain activity associated with complex cognitive functions—problem solving, reasoning, numerical processing, and consciousness. One of the most widely used tasks in brain mapping studies of problem solving is the Raven's progressive matrices. The role of frontoparietal circuits in numerical cognition has been confirmed by a positron emission tomography (PET) investigation of number multiplication and number comparison, in which bilateral frontoparietal networks are activated during both tasks. Various other regions are also found activated in this investigation, in which an exploratory, hypotheses-generating approach determined relatively “liberal” statistical thresholds. The consciousness of action is an important component of consciousness. However, the most common approach to the study of consciousness and its neural counterpart in cognitive neuroscience is via perception and visual awareness. A variety of brain mapping techniques, from PET and functional magnetic resonance imaging to electrical scalp recording, have been already used in investigations directly addressing visual awareness in normal subjects and patients with neurological disorders. A paradigm that is extremely suitable for the examination of conscious perception is binocular rivalry. A different mapping approach to the study of conscious perception is the mapping of temporal neural events.}
}
@article{SHENGLAI20124318,
title = {Study on Simulation Modeling and Approximate Synchronous Computation Technology for the Active Structural Stiffness Design},
journal = {Procedia Engineering},
volume = {29},
pages = {4318-4324},
year = {2012},
note = {2012 International Workshop on Information and Electronics Engineering},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2012.01.664},
url = {https://www.sciencedirect.com/science/article/pii/S1877705812006741},
author = {Xia Shenglai and He Jingwu and Chu Hongyu and Yang Xuan},
keywords = {active structural stiffness design (ASSD), stiffness criterion, simulation modeling, computation analysis, section stiffness},
abstract = {In the past, structure design mainly adopted strength criterion. At the same time, many problems occurred due to structural stiffness deficiency. In order to resolve many practical problems resulted from structural stiffness in aircraft structure, and draw out structural potential better, the design idea of active structural stiffness, namely, the method of active structural stiffness design (ASSD) is put forward at the beginning of the structure design. For ASSD, there are three key factors should be considered, that is, stiffness criterion, simulation modeling and computation analysis. In this paper, stiffness criterion, which is important at the preliminary stage of structural design, will be researched; Simulation modeling adopts parametric modeling technology; computation analysis is based on engineering beam theory, which is compiled and embedded into CATIA to compute structural stiffness. Using simulation modeling and computation analysis technologies, ASSD can be achieved quickly and conveniently.}
}
@article{EDELMAN201791,
title = {Language and other complex behaviors: Unifying characteristics, computational models, neural mechanisms},
journal = {Language Sciences},
volume = {62},
pages = {91-123},
year = {2017},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2017.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0388000117300128},
author = {Shimon Edelman},
abstract = {Similar to other complex behaviors, language is dynamic, social, multimodal, patterned, and purposive, its purpose being to promote desirable actions or thoughts in others and self (Edelman, 2017b). An analysis of the functional characteristics shared by complex sequential behaviors suggests that they all present a common overarching computational problem: dynamically controlled constrained navigation in concrete or abstract situation spaces. With this conceptual framework in mind, I compare and contrast computational models of language and evaluate their potential for explaining linguistic behavior and for elucidating the brain mechanisms that support it.}
}
@article{FIGLIOLIA2020102968,
title = {An FPGA multiprocessor architecture for Bayesian online change point detection using stochastic computation},
journal = {Microprocessors and Microsystems},
volume = {74},
pages = {102968},
year = {2020},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2019.102968},
url = {https://www.sciencedirect.com/science/article/pii/S0141933119304727},
author = {Tomas Figliolia and Andreas G. Andreou},
keywords = {Changepoint analysis, Changepoint detection, Image segmentation, Bayesian inference, On-line algorithm, Stochastic processing, Precision on demand, ASIC, VHDL, Probabilistic event representation},
abstract = {In this paper we report on an event-based stochastic architecture for the Adams/McKay Bayesian Online Change Point Detection algorithm (BOCPD) [1]. In the stochastic computational structures, probabilities are represented natively as stochastic events and computation is carried out directly with these probabilities and not probability density functions. A fully programmable BOCPD processor is synthesized in VHDL. The BOCPD algorithm with on-line learning, to perform foreground/background image segmentation with online learning. Running on a single Kintex 7 FPGA (Opal Kelly XEM7350-K410T) the architecture is capable of real-time processing a 160 × 120 pixels image, at 10 frames per second.}
}
@article{GRIGORIADIS2022618,
title = {Computational and conceptual blends: Material considerations and agency in a multi-material design workflow},
journal = {Frontiers of Architectural Research},
volume = {11},
number = {4},
pages = {618-629},
year = {2022},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2022.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S2095263522000449},
author = {Kostas Grigoriadis},
keywords = {Digital design, Multi-materials, Computer simulation, Material agency, Materially anchored conceptual blends},
abstract = {The assimilation of functionally graded (or multi-) materials into architecture is deemed to enable the rethinking of current architectural design practice and bring back material considerations at the heart of the early design process. In response, the paper outlines a functionally graded material (FGM) design workflow that departs from standard early-stage CAD, which is typically performed via computer elements devoid of materiality. It then analyses this workflow from a theoretical perspective, namely through Edwin Hutchins' materially anchored conceptual blending, Lambros Malafouris' Material Engagement Theory (MET) and John Searle's concepts of intentionality. The aim is to demonstrate that due to the superimposition of material considerations that precede and succeed the CAD operation, working with material-less entities during early-stage FGM design is not logically sustainable. Additionally, multi-materiality allows for the questioning of authorship in the design process and leads to a repositioning of agency from the subject to the locus of engagement with digital materials and their affordances.}
}
@article{FEHER201498,
title = {Computational approaches to mapping allosteric pathways},
journal = {Current Opinion in Structural Biology},
volume = {25},
pages = {98-103},
year = {2014},
note = {Theory and simulation / Macromolecular machines},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2014.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X14000190},
author = {Victoria A Feher and Jacob D Durrant and Adam T {Van Wart} and Rommie E Amaro},
abstract = {Allosteric signaling occurs when chemical and/or physical changes at an allosteric site alter the activity of a primary orthosteric site often many Ångströms distant. A number of recently developed computational techniques, including dynamical network analysis, novel topological and molecular dynamics methods, and hybrids of these methods, are useful for elucidating allosteric signaling pathways at the atomistic level. No single method prevails as best to identify allosteric signal propagation path(s), rather each has particular strengths in characterizing signals that occur over specific timescale ranges and magnitudes of conformational fluctuation. With continued improvement in accuracy and predictive power, these computational techniques aim to become useful drug discovery tools that will allow researchers to identify allostery critical residues for subsequent pharmacological targeting.}
}
@article{LI2024108089,
title = {Population characteristic exploitation-based multi-orientation multi-objective gene selection for microarray data classification},
journal = {Computers in Biology and Medicine},
volume = {170},
pages = {108089},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108089},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524001732},
author = {Min Li and Rutun Cao and Yangfan Zhao and Yulong Li and Shaobo Deng},
keywords = {Gene selection, Microarray data, Multi-orientation, Multi-objective, Reverse thinking},
abstract = {Gene selection is a process of selecting discriminative genes from microarray data that helps to diagnose and classify cancer samples effectively. Swarm intelligence evolution-based gene selection algorithms can never circumvent the problem that the population is prone to local optima in the process of gene selection. To tackle this challenge, previous research has focused primarily on two aspects: mitigating premature convergence to local optima and escaping from local optima. In contrast to these strategies, this paper introduces a novel perspective by adopting reverse thinking, where the issue of local optima is seen as an opportunity rather than an obstacle. Building on this foundation, we propose MOMOGS-PCE, a novel gene selection approach that effectively exploits the advantageous characteristics of populations trapped in local optima to uncover global optimal solutions. Specifically, MOMOGS-PCE employs a novel population initialization strategy, which involves the initialization of multiple populations that explore diverse orientations to foster distinct population characteristics. The subsequent step involved the utilization of an enhanced NSGA-II algorithm to amplify the advantageous characteristics exhibited by the population. Finally, a novel exchange strategy is proposed to facilitate the transfer of characteristics between populations that have reached near maturity in evolution, thereby promoting further population evolution and enhancing the search for more optimal gene subsets. The experimental results demonstrated that MOMOGS-PCE exhibited significant advantages in comprehensive indicators compared with six competitive multi-objective gene selection algorithms. It is confirmed that the “reverse-thinking" approach not only avoids local optima but also leverages it to uncover superior gene subsets for cancer diagnosis.}
}
@article{THABTAH2018112,
title = {A new computational intelligence approach to detect autistic features for autism screening},
journal = {International Journal of Medical Informatics},
volume = {117},
pages = {112-124},
year = {2018},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2018.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1386505618300546},
author = {Fadi Thabtah and Firuz Kamalov and Khairan Rajab},
keywords = {Accuracy, Autism Spectrum Disorder, Behaviour science, Classifiers, Computational intelligence, Data mining, Feature analysis, Machine learning, Sensitivity, Specificity},
abstract = {Autism Spectrum Disorder (ASD) is one of the fastest growing developmental disability diagnosis. General practitioners (GPs) and family physicians are typically the first point of contact for patients or family members concerned with ASD traits observed in themselves or their family member. Unfortunately, some families and adult patients are unaware of ASD traits that may be exhibited and as a result do not seek out necessary diagnostic services or contact their GP. Therefore, providing a quick, accessible, and simple tool utilizing items related to ASD to these families may increase the likelihood they will seek professional assessment and is vital to the early detection and treatment of ASD. This study aims at identifying fewer, albeit influential, features in common ASD screening methods in order to achieve efficient screening as demands on evaluating the items’ influences on ASD within existing tools is urgent. To achieve this aim, a computational intelligence method called Variable Analysis (Va) is proposed that considers feature-to-class correlations and reduces feature-to-feature correlations. The results of the Va have been verified using two machine learning algorithms by deriving automated classification systems with respect to specificity, sensitivity, positive predictive values (PPVs), negative predictive values (NPVs), and predictive accuracy. Experimental results using cases and controls related to items in three common screening methods, along with features related to individuals, have been analysed and compared with results obtained from other common filtering methods. The results exhibited that Va was able to derive fewer numbers of features from adult, adolescent, and child screening methods yet maintained competitive predictive accuracy, sensitivity, and specificity rates.}
}
@article{MARTIN2000195,
title = {What do animals do all day?: The division of labor, class bodies, and totemic thinking in the popular imagination},
journal = {Poetics},
volume = {27},
number = {2},
pages = {195-231},
year = {2000},
issn = {0304-422X},
doi = {https://doi.org/10.1016/S0304-422X(99)00025-X},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X9900025X},
author = {John Levi Martin},
keywords = {Animals, Totemism, Class body, Busytown, Symbolic domination, Division of labor},
abstract = {This article uses relatively new methods of the analysis of qualitative data to investigate the socio-logical relation between animal species and occupation in the popular imagination, specifically in the world of children's literature, in order to test a claim that the class habitus that naturalizes the division of labor, erasing the contingent nature of class domination, does not simply arise via the internalization of objective social divisions into a subjective social vision, but rather begins with the application of a totemic logic which maps differences between people onto differences between animals, thereby exaggerating and naturalizing them. Children are evidently instructed in the reality of class bodies and the logic of social structure before they have any first-hand acquaintance with these social processes; indeed, by working the embodied relations of class domination into the role play and role learning of the pre-school years, we make it difficult for them to have any unmediated first-hand experience that would militate against these habitual distinctions.}
}
@article{SADEGHIPOUR2012213,
title = {Gesture processing as grounded motor cognition: Towards a computational model},
journal = {Procedia - Social and Behavioral Sciences},
volume = {32},
pages = {213-223},
year = {2012},
note = {The 4th International Conference of Cognitive Science},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S187704281200033X},
author = {Amir Sadeghipour and Stefan Kopp},
keywords = {Motor Cognition, embodiment, grounded cognition, gestures, social interaction, computational model, embodied conversational agents},
abstract = {In this paper, we present an approach to treat and model the processing (i.e. recognition and production) of communicative gestures as grounded motor cognition. We first review cognitive theories and neuropsychological studies on human motor cognition. On this basis, we propose a computational framework that connects the sensorimotor processing of hand gestures in representational structures of meaning (visuospatial imagery), other modalities (language), and communicative intentions. We present an implementation that enables an embodied virtual agent to engage in gesture-based interaction with a human user.}
}
@article{LIU20121773,
title = {ACE - A Model Centered REU Program Standing on the Three Legs of CSE: Analysis, Computation and Experiment},
journal = {Procedia Computer Science},
volume = {9},
pages = {1773-1782},
year = {2012},
note = {Proceedings of the International Conference on Computational Science, ICCS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.04.195},
url = {https://www.sciencedirect.com/science/article/pii/S187705091200316X},
author = {Hong P. Liu and Andrei Ludu},
keywords = {CSE Education, REU, Project-Oriented Pedagogy},
abstract = {Enhancing REU (research experience for undergraduates) has become a popular strategy for many selective universities to enhance quality of undergraduate education and recruit gifted new students. The university that the authors are affiliated has set REU as one of the major outcomes for our QEP (quality enhancement program) for next 5 years. This paper presents a model centered REU program entitled as ACE standing for Analysis, Computation and Experiment. As a work in progress, the program is planned to run for the next 5 years and to serve for 20-30 undergraduate students who are gifted in mathematics and computing annually. ACE is to use interdisciplinary research projects, the guided exploration based on sound pedagogical practice and the top niche analogical and virtual dual lab facility bring measurable impacts to over a hundred of gifted undergraduates.}
}
@article{NITYANANDA2020R159,
title = {Insect Neurobiology: Divergent Neural Computations in Predatory Insects},
journal = {Current Biology},
volume = {30},
number = {4},
pages = {R159-R161},
year = {2020},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2019.12.035},
url = {https://www.sciencedirect.com/science/article/pii/S0960982219316689},
author = {Vivek Nityananda},
abstract = {Summary
A comparative approach to neuroscience can greatly increase our understanding of how mechanisms map onto behaviour. A new study comparing two predatory insects demonstrates how neurons that are homologous can nonetheless mediate different computations and behaviour.}
}
@article{KOKOLAKIS2023110732,
title = {Bounded rational Dubins vehicle coordination for target tracking using reinforcement learning},
journal = {Automatica},
volume = {149},
pages = {110732},
year = {2023},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2022.110732},
url = {https://www.sciencedirect.com/science/article/pii/S0005109822005982},
author = {Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis},
keywords = {Game theory, Target tracking, Bounded rationality, Reinforcement learning, Switched systems, Target allocation},
abstract = {In this paper, we address the problem of cooperative tracking of multiple heterogeneous targets by deploying multiple and heterogeneous pursuers exhibiting different decision-making capabilities. Initially, under infinite resources, we formulate a game between the evader and the pursuing team, with an evader being the maximizing player and the pursuing team being the minimizing one. Subsequently, we relax the perfect rationality assumption via the use of a level-k thinking framework that allows the evaders to not exhibit the same levels of rationality. Such rationality policies are computed by using a reinforcement learning-based architecture and are proven to form Nash policies as the thinking levels increase. Finally, in the case of multiple pursuers against multiple targets, we develop a switched learning scheme with multiple convergence sets by assigning the most intelligent pursuers to the most intelligent evaders.}
}
@incollection{2009339,
title = {Appendix A - Thinking in MATLAB},
editor = {Pascal Wallisch and Michael Lusignan and Marc Benayoun and Tanya I. Baker and Adam S. Dickey and Nicholas G. Hatsopoulos},
booktitle = {Matlab for Neuroscientists},
publisher = {Academic Press},
address = {London},
pages = {339-344},
year = {2009},
isbn = {978-0-12-374551-4},
doi = {https://doi.org/10.1016/B978-0-12-374551-4.00034-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123745514000348}
}
@article{KNIGHT20151,
title = {Computational making},
journal = {Design Studies},
volume = {41},
pages = {1-7},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000721},
author = {Terry Knight and Theodora Vardouli}
}
@article{CHI20111937,
title = {Teaching Computing to STEM Students via Visualization Tools},
journal = {Procedia Computer Science},
volume = {4},
pages = {1937-1943},
year = {2011},
note = {Proceedings of the International Conference on Computational Science, ICCS 2011},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.04.211},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911002699},
author = {Hongmei Chi and Harsh Jain},
keywords = {Visualization, ChemSketch, ParaView, Computation ;STEM education},
abstract = {Information technology is evolving fast and steady over the years providing more and more tools for society to use. There is an increasing need and implementation of computation in the conduct of modern scientific research and experimentation. Computational thinking has been scarcely understood by STEM undergraduates if their majors are not computer sciences. We explore computation projects into existing courses via visualization computational tools to increase the number of STEM students who graduate with discipline specific computational skills. The goal of this paper was to report our efforts for increasing the number of students with experience using computation in science. Discipline specific tools were chosen and implemented in the respective courses, for example Chemsketch in chemistry. Hands-on labs were designed to familiarize instructors and students so it can be helpful to smooth the learning curve in STEM undergraduate students}
}
@article{SAID2015396,
title = {Exploiting Computational Intelligence Paradigms in e-Technologies and Activities},
journal = {Procedia Computer Science},
volume = {65},
pages = {396-405},
year = {2015},
note = {International Conference on Communications, management, and Information technology (ICCMIT'2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.09.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915029312},
author = {Hanaa M. Said and Abdel-Badeeh M. Salem},
keywords = {Machine Learning, Intelligent Data Analysis, E- Technologies government, Neural Networks, Fuzzy Logic, Genetic algorithm, Case based reasoning, SVM, Swarm intelligence, computational intelligence;},
abstract = {Computational intelligence (CI) has emerged as a powerful paradigm in e-Science, providing the researchers an immense volume of intelligent computing techniques and algorithms. CI provides knowledge engineers to develop a robust techniques and intelligent tools for e-government applications and tasks. This paper presents a comparative analysis of some techniques used in e-activities and e-government systems. The study includes the following paradigms; artificial neural networks, fuzzy logic, genetic algorithms, case-based reasoning, support vector machines, and swarm intelligence. Additionally, this study found that such paradigms offer many business benefits and advantages; e.g. (a) the ability to acquire, represent, manage and structure the knowledge in the domain under study, (b) the ability to optimize resources, (c) the ability to perform efficient performance, and (d) the ability to conduct planning, budgeting, and forecasting.}
}
@article{ZENDEHROUH2015112,
title = {A new computational account of cognitive control over reinforcement-based decision-making: Modeling of a probabilistic learning task},
journal = {Neural Networks},
volume = {71},
pages = {112-123},
year = {2015},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2015.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608015001604},
author = {Sareh Zendehrouh},
keywords = {Cognitive control, Reinforcement learning, Goal-directed behavior, Dual system theory, Cost function, Probabilistic learning task},
abstract = {Recent work on decision-making field offers an account of dual-system theory for decision-making process. This theory holds that this process is conducted by two main controllers: a goal-directed system and a habitual system. In the reinforcement learning (RL) domain, the habitual behaviors are connected with model-free methods, in which appropriate actions are learned through trial-and-error experiences. However, goal-directed behaviors are associated with model-based methods of RL, in which actions are selected using a model of the environment. Studies on cognitive control also suggest that during processes like decision-making, some cortical and subcortical structures work in concert to monitor the consequences of decisions and to adjust control according to current task demands. Here a computational model is presented based on dual system theory and cognitive control perspective of decision-making. The proposed model is used to simulate human performance on a variant of probabilistic learning task. The basic proposal is that the brain implements a dual controller, while an accompanying monitoring system detects some kinds of conflict including a hypothetical cost-conflict one. The simulation results address existing theories about two event-related potentials, namely error related negativity (ERN) and feedback related negativity (FRN), and explore the best account of them. Based on the results, some testable predictions are also presented.}
}
@article{GJORGJIEVA2021iii,
title = {Editorial overview: Theoretical and computational approaches to decipher brain function from molecules to behavior},
journal = {Current Opinion in Neurobiology},
volume = {70},
pages = {iii-vii},
year = {2021},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2021.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0959438821001379},
author = {Julijana Gjorgjieva and Ila Fiete}
}
@article{DOLAN2023,
title = {Using Shopping Data to Improve the Diagnosis of Ovarian Cancer: Computational Analysis of a Web-Based Survey},
journal = {JMIR Cancer},
volume = {9},
year = {2023},
issn = {2369-1999},
doi = {https://doi.org/10.2196/37141},
url = {https://www.sciencedirect.com/science/article/pii/S2369199923000174},
author = {Elizabeth H Dolan and James Goulding and Laila J Tata and Alexandra R Lang},
keywords = {carcinoma, ovarian epithelial, ovarian neoplasms, self-medication, diagnostic errors, symptom assessment, machine learning, nonprescription drugs, over-the-counter, pharmaceutical, symptom, ovary, ovarian cancer, oncology, cancer},
abstract = {Background
Shopping data can be analyzed using machine learning techniques to study population health. It is unknown if the use of such methods can successfully investigate prediagnosis purchases linked to self-medication of symptoms of ovarian cancer.
Objective
The aims of this study were to gain new domain knowledge from women’s experiences, understand how women’s shopping behavior relates to their pathway to the diagnosis of ovarian cancer, and inform research on computational analysis of shopping data for population health.
Methods
A web-based survey on individuals’ shopping patterns prior to an ovarian cancer diagnosis was analyzed to identify key knowledge about health care purchases. Logistic regression and random forest models were employed to statistically examine how products linked to potential symptoms related to presentation to health care and timing of diagnosis.
Results
Of the 101 women surveyed with ovarian cancer, 58.4% (59/101) bought nonprescription health care products for up to more than a year prior to diagnosis, including pain relief and abdominal products. General practitioner advice was the primary reason for the purchases (23/59, 39%), with 51% (30/59) occurring due to a participant’s doctor believing their health problems were due to a condition other than ovarian cancer. Associations were shown between purchases made because a participant’s doctor believing their health problems were due to a condition other than ovarian cancer and the following variables: health problems for longer than a year prior to diagnosis (odds ratio [OR] 7.33, 95% CI 1.58-33.97), buying health care products for more than 6 months to a year (OR 3.82, 95% CI 1.04-13.98) or for more than a year (OR 7.64, 95% CI 1.38-42.33), and the number of health care product types purchased (OR 1.54, 95% CI 1.13-2.11). Purchasing patterns are shown to be potentially predictive of a participant’s doctor thinking their health problems were due to some condition other than ovarian cancer, with nested cross-validation of random forest classification models achieving an overall in-sample accuracy score of 89.1% and an out-of-sample score of 70.1%.
Conclusions
Women in the survey were 7 times more likely to have had a duration of more than a year of health problems prior to a diagnosis of ovarian cancer if they were self-medicating based on advice from a doctor rather than having made the decision to self-medicate independently. Predictive modelling indicates that women in such situations, who are self-medicating because their doctor believes their health problems may be due to a condition other than ovarian cancer, exhibit distinct shopping behaviors that may be identifiable within purchasing data. Through exploratory research combining women sharing their behaviors prior to diagnosis and computational analysis of these data, this study demonstrates that women’s shopping data could potentially be useful for early ovarian cancer detection.}
}
@article{VARNER2017170,
title = {Computational models of airway branching morphogenesis},
journal = {Seminars in Cell & Developmental Biology},
volume = {67},
pages = {170-176},
year = {2017},
note = {Extracellular Vesicles Cellular Mechanisms of Morphogenesis},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2016.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1084952116301653},
author = {Victor D. Varner and Celeste M. Nelson},
keywords = {Quantitative models, Morphodynamics, Mechanobiology, Turing patterns},
abstract = {The bronchial network of the mammalian lung consists of millions of dichotomous branches arranged in a highly complex, space-filling tree. Recent computational models of branching morphogenesis in the lung have helped uncover the biological mechanisms that construct this ramified architecture. In this review, we focus on three different theoretical approaches – geometric modeling, reaction-diffusion modeling, and continuum mechanical modeling – and discuss how, taken together, these models have identified the geometric principles necessary to build an efficient bronchial network, as well as the patterning mechanisms that specify airway geometry in the developing embryo. We emphasize models that are integrated with biological experiments and suggest how recent progress in computational modeling has advanced our understanding of airway branching morphogenesis.}
}
@article{WANG2003457,
title = {Thinking as saying: shuo (‘say’) in Taiwan Mandarin conversation and BBS talk},
journal = {Language Sciences},
volume = {25},
number = {5},
pages = {457-488},
year = {2003},
issn = {0388-0001},
doi = {https://doi.org/10.1016/S0388-0001(03)00020-2},
url = {https://www.sciencedirect.com/science/article/pii/S0388000103000202},
author = {Yu-Fang Wang and Aya Katz and Chih-Hua Chen},
keywords = {Grammaticalization, Metaphor, Propositional, Textual, Expressive},
abstract = {The research reported here is an attempt to explore the functions of shuo ‘say’ in informal Chinese speech and writing. We further probe into the grammaticalization of shuo, discussing how the various lexical, grammatical and discourse functions have come into being, with reference to the general tendencies of semantic change proposed by Traugott [(1982). In: Lehmann and Malkiel (Eds.) Perspectives on Historical Linguistics. Benjamins, Amsterdam. pp. 245–272; (1989) Language 65(1), 31–55] and Traugott and König [In: Traugott and Heine (Eds.), Approaches to Grammaticalization, Vol. I. John Benjamins, Philadelphia. pp. 189–218], and the metaphor MIND-AS-BODY proposed by Sweetser [(1990). From Etymology to Pragmatics. Cambridge University Press, Cambridge]. The corpus used in this study contains two sets of data: non-face-to-face talk on BBS (the Electronic Bulletin Board System) and face-to-face daily conversation, mainly produced by young people in Taiwan. Our data indicate that shuo, in addition to acting as a complementizer as discussed by S. Huang [On the (almost perfect) identify of speech and thought: Evidence from Chinese dialects. (1982). Paper presented at Fourteenth International Conference on Sino-Tibetan Languages and Linguistics] and Cheng [(1997). In: Cheng (Ed.), Taiwanese and Mandarin Structures and Their Developmental Trends in Taiwan II: Contacts between Taiwanese and Mandarin and Restructuring of their Synonyms. Yuan-Liou Publishing Co. Taipei. pp. 105–131], can also occur in an utterance-initial position, functioning as a marker of hearsay, and in an utterance-final position, as a marker of counterexpectation or as an intensifier. On the whole, the data suggest that the initial and final shuo's are innovations serving an expressive function. In particular, the lexeme shuo is moving from the propositional level to the expressive level; i.e., it is evolving from a verb meaning ‘say’ that prefaces an utterance conveying information into a discourse marker that encodes the attitude of the speaker toward the proposition.}
}
@article{KONG2023100126,
title = {Complementary role of large language models in educating undergraduate design of distillation column: Methodology development},
journal = {Digital Chemical Engineering},
volume = {9},
pages = {100126},
year = {2023},
issn = {2772-5081},
doi = {https://doi.org/10.1016/j.dche.2023.100126},
url = {https://www.sciencedirect.com/science/article/pii/S2772508123000443},
author = {Zong Yang Kong and Vincentius Surya Kurnia Adi and Juan Gabriel Segovia-Hernández and Jaka Sunarso},
keywords = {ChatGPT, Chemical engineering education, Large language models, Distillation, Industry 4.0, Mass transfer},
abstract = {This paper explores the integration of large language models (LLMs), such as ChatGPT, in chemical engineering education, departing from conventional practices that may not be universally accepted. While there is ongoing debate surrounding the acceptance of LLMs, driven by concerns over computational instability and potential inconsistencies, their inevitability in shaping our communication and interaction with technology cannot be ignored. As educators, we are positioned to play a vital role in guiding students toward the responsible, effective, and synergetic use of LLMs. Focusing specifically on distillation column design in undergraduate mass-transfer courses, this study demonstrates how ChatGPT can be utilized as an auxiliary tool to create interactive learning environments and simulate real-world engineering thinking processes. It emphasizes the need for students to develop critical thinking skills and a thorough understanding of LLM principles, taking responsibility for their use and creations. While ChatGPT should not be solely relied upon, its integration with fundamental principles of chemical engineering is crucial. The effectiveness and limitations of ChatGPT are exemplified through two case studies, showcasing the importance of manual calculations and established simulation software as primary tools for guiding and validating engineering results and analyses. This paper also addresses the pedagogical implications of integrating LLMs into mass transfer courses, encompassing curriculum integration, facilitation, guidance, and ethical considerations. Recommendations are provided for incorporating LLMs effectively into the curriculum. Overall, this study contributes to the advancement of chemical engineering education by examining the benefits and limitations of LLMs as educational aids in the design process.}
}
@article{FIELDS2025256,
title = {Thoughts and thinkers: On the complementarity between objects and processes},
journal = {Physics of Life Reviews},
volume = {52},
pages = {256-273},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000089},
author = {Chris Fields and Michael Levin},
keywords = {Active inference, Cognitive light cone, Emergence, Evo/devo/eco, Multiscale competency architecture, Niche construction, Semantics},
abstract = {We argue that “processes versus objects” is not a useful dichotomy. There is, instead, substantial theoretical utility in viewing “objects” and “processes” as complementary ways of describing persistence through time, and hence the possibility of observation and manipulation. This way of thinking highlights the role of memory as an essential resource for observation, and makes it clear that “memory” and “time” are also mutually inter-defined, complementary concepts. We formulate our approach in terms of the Free Energy Principle (FEP) of Friston and colleagues and the fundamental idea from quantum theory that physical interactions can be represented by linear operators. Following Levin (2024) [30], we emphasize that memory is, first and foremost, an interpretative function, from which the idea of memory as a record, at some level of accuracy, of past events is derivative. We conclude that the distinction between objects and processes is always contrived, and always misleading, and that science would be better served by abandoning it entirely.}
}
@article{SAW2025111884,
title = {Current status and future directions of explainable artificial intelligence in medical imaging},
journal = {European Journal of Radiology},
volume = {183},
pages = {111884},
year = {2025},
issn = {0720-048X},
doi = {https://doi.org/10.1016/j.ejrad.2024.111884},
url = {https://www.sciencedirect.com/science/article/pii/S0720048X24006004},
author = {Shier Nee Saw and Yet Yen Yan and Kwan Hoong Ng},
keywords = {Artificial intelligence, Interpretability, Explainability, Medical imaging, Medical information systems},
abstract = {The inherent “black box” nature of AI algorithms presents a substantial barrier to the widespread adoption of the technology in clinical settings, leading to a lack of trust among users. This review begins by examining the foundational stages involved in the interpretation of medical images by radiologists and clinicians, encompassing both type 1 (fast thinking − ability of the brain to think and act intuitively) and type 2 (slow analytical − slow analytical, laborious approach to decision-making) decision-making processes. The discussion then delves into current Explainable AI (XAI) approaches, exploring both inherent and post-hoc explainability for medical imaging applications and highlighting the milestones achieved. XAI in medicine refers to AI system designed to provide transparent, interpretable, and understandable reasoning behind AI predictions or decisions. Additionally, the paper showcases some commercial AI medical systems that offer explanations through features such as heatmaps. Opportunities, challenges and potential avenues for advancing the field are also addressed. In conclusion, the review observes that state-of-the-art XAI methods are not mature enough for implementation, as the explanations they provide are challenging for medical experts to comprehend. Deeper understanding of the cognitive mechanisms by medical professionals is important in aiming to develop more interpretable XAI methods.}
}
@article{GAMAL20241319,
title = {A computational sustainable approach for energy storage systems performance evaluation based on spherical-fuzzy MCDM with considering uncertainty},
journal = {Energy Reports},
volume = {11},
pages = {1319-1341},
year = {2024},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2023.12.058},
url = {https://www.sciencedirect.com/science/article/pii/S2352484723016529},
author = {Abduallah Gamal and Mohamed Abdel-Basset and Ibrahim M. Hezam and Karam M. Sallam and Ahmad M. Alshamrani and Ibrahim A. Hameed},
keywords = {Energy storage systems, Sustainable, Uncertainty, MCDM, SF-AHP, SF-MACONT, Sensitivity analysis},
abstract = {Incorporating energy storage systems (ESSs) can mitigate the intermittency of renewable energy sources. There are a variety of ESSs for renewable energy with vastly different characteristics. The problem of diversity of characteristics in selecting the most appropriate ESS can be approached as a multi-criteria decision-making (MCDM) problem. This research evaluates sustainable ESSs through a case study in Egypt. A sustainable computational approach is presented through which experts can use verbal expressions to express their opinions in determining the priorities of the dimensions that affect the selection of ESSs. Determining the appropriate energy storage system requires consideration of several main dimensions such as the technology dimension, environmental dimension, economic dimension, and social-political dimension and, in addition to the sub-indicators. Hence, this research applies a hybrid MCDM approach that deals with different indicators and characteristics. Also, uncertainty in applying the proposed approach was dealt with by a spherical fuzzy (SF) environment and by using the spherical fuzzy numbers (SFNs). At first, the SF analytical hierarchy process (SF-AHP) method was used to assess the priorities of the four main dimensions and their sub-indicators. Then, the SF mixed aggregation by comprehensive normalization technique (SF-MACONT) was applied to evaluate and rank the ESSs selected for analysis through research. An illustrative case study was presented that included seven ESSs out of the eighteen systems listed in the research to confirm the feasibility of the developed approach. Sensitivity analysis was carried out by changing some parameters like λ, μ, δ, and ϑ based on the SF-MACONT method and changing the weights of some main dimensions. A comparative analysis with some MCDM approaches was conducted to show the advantages of the developed approach through its flexibility and built-in parameters. The findings show that the technology dimension is the most influential in choosing a sustainable ESS, while the economic dimension is the least influential. Also, the results of the evaluation and ranking of the seven selected ESSs indicate that the "Pumped Hydro" system is the most suitable system for energy storage in Egypt.}
}
@article{DALLACHIARA201669,
title = {A first-order epistemic quantum computational semantics with relativistic-like epistemic effects},
journal = {Fuzzy Sets and Systems},
volume = {298},
pages = {69-90},
year = {2016},
note = {Special Issue on Graded Logical Approaches and Their Applications},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165011415004145},
author = {Maria Luisa {Dalla Chiara} and Roberto Giuntini and Roberto Leporini and Giuseppe Sergioli},
keywords = {Quantum computation, Quantum computational logics, Epistemic operators},
abstract = {Quantum computation has suggested new forms of quantum logic, called quantum computational logics. In these logics well-formed formulas are supposed to denote pieces of quantum information: possible pure states of quantum systems that can store the information in question. At the same time, the logical connectives are interpreted as quantum logical gates: unitary operators that process quantum information in a reversible way, giving rise to quantum circuits. Quantum computational logics have been mainly studied as sentential logics (whose alphabet consists of atomic sentences and of logical connectives). In this article we propose a semantic characterization for a first-order epistemic quantum computational logic, whose language can express sentences like “Alice knows that everybody knows that she is pretty”. One can prove that (unlike the case of logical connectives) both quantifiers and epistemic operators cannot be generally represented as (reversible) quantum logical gates. The “act of knowing” and the use of universal (or existential) assertions seem to involve some irreversible “theoretic jumps”, which are similar to quantum measurements. Since all epistemic agents are characterized by specific epistemic domains (which contain all pieces of information accessible to them), the unrealistic phenomenon of logical omniscience is here avoided: knowing a given sentence does not imply knowing all its logical consequences.}
}
@incollection{SHARMA202353,
title = {Chapter 2 - Computational approaches in drug discovery and design},
editor = {Rupesh Kumar Gautam and Mohammad Amjad Kamal and Pooja Mittal},
booktitle = {Computational Approaches in Drug Discovery, Development and Systems Pharmacology},
publisher = {Academic Press},
pages = {53-93},
year = {2023},
isbn = {978-0-323-99137-7},
doi = {https://doi.org/10.1016/B978-0-323-99137-7.00009-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323991377000095},
author = {Priyanka Sharma and Kalicharan Sharma and Mukesh Nandave},
keywords = {Molecular modeling, Molecular docking, Molecular dynamics simulation, QSAR, Bioinformatics},
abstract = {Drug development is a costly and time-consuming procedure. The medicine must meet certain characteristics such as nontoxicity, bioavailability, and potency. Establishing a better drug-like compound has now become a difficult and error-prone endeavor in light of ever-increasing expectations for effectiveness, intensity, and stability. The emergence of conformations of chemical therapeutic targets, as well as developments in computational techniques and bioinformatics, have accelerated the use of molecular modeling in pharmaceutical research. Numerous molecular modeling methodologies used in recent pharmacological studies are reviewed in this chapter. Structure- and ligand-based drug design, protein modeling and visualization molecular docking, virtual screening, molecular dynamics simulation, pharmacophore modeling, and QSAR techniques have all been discussed. In addition, we make key database resources and tools available to the researchers and scientists for future prospects.}
}
@article{YOUSEF2024137753,
title = {Biological and computational assessment of new synthesized nicotinamides as potential immunomodulatory VEGFR-2 inhibitors},
journal = {Journal of Molecular Structure},
volume = {1305},
pages = {137753},
year = {2024},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2024.137753},
url = {https://www.sciencedirect.com/science/article/pii/S002228602400276X},
author = {Reda G. Yousef and Alaa Elwan and Abdallah E. Abdallah and Hazem Elkady and Ahmed B.M. Mehany and Mariam Ali Abo-Saif and Mohamed M. Radwan and Mahmoud A. ElSohly and Ibrahim M. Ibrahim and Mohamed A. Elkady and Mohamed Ayman El-Zahabi and Ibrahim H. Eissa},
keywords = {Nicotinamides, Anticancer, VEGFR-2, Apoptosis, Immunomodulatory, Computational studies},
abstract = {As an extension to our preceding studies on nicotinamide derivatives as anticancer agents, new nicotinamide-based candidates were designed and synthesized as VEGFR-2 inhibitors. The in vitro cytotoxic activity of the synthesized compounds was evaluated against three human cancer cell lines (MCF-7, HepG-2 and HCT-116). The IC50 values for compound 17 were 2.61± 0.01, 3.20 ± 0.02, and 2.46 ± 0.01 µM, respectively, compared to sorafenib (4.21±0.03, 3.40 ± 0.02, and 5.30 ± 0.04 µM) against MCF-7, HePG-2, and HCT-116. This indicated that compound 17 possess double strength relative to sorafenib against both MCF-7 and HCT-116. Compound 17 was the most promising VEGFR-2 inhibitor with IC50 value of 0.34 μM that was slightly better than that of sorafenib (0.38 μM). Further studies displayed the ability of compound 17 to arrest the growth of HCT-116 cells at the Pre-G1 and S phases. Additionally, compound 17 induced a significant increase in the total apoptosis rate of HCT-116 cells from 1.82 % to 26.69 %. Moreover, it showed high selectivity indices against HCT-116, HepG2, and MCF-7 cancer cells. Furthermore, compound 17 showed potent inhibitory activities on TNF-α and IL-6 and showed a notable rise in caspase-3 level. In addition, the potentiality of the designed derivatives to bind with and inhibit the VEGFR-2 enzyme was indicated by molecular docking assessments. MD simulation studies revealed the stability of compound 17 in the active site of VEGFR-2 for 100 ns. Based on the previous findings, compound 17 appears to be a promising apoptotic VEGFR-2 inhibitor and could potentially direct future efforts towards the development of novel anticancer medications.}
}
@article{HEINZLE201621,
title = {Computational models of eye movements and their application to schizophrenia},
journal = {Current Opinion in Behavioral Sciences},
volume = {11},
pages = {21-29},
year = {2016},
note = {Computational modeling},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2016.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352154616300754},
author = {Jakob Heinzle and Eduardo A Aponte and Klaas Enno Stephan},
abstract = {Patients with neuropsychiatric disorders, in particular schizophrenia, show a variety of eye movement abnormalities that putatively reflect alterations of perceptual inference, learning and cognitive control. While these abnormalities are consistently found at the group level, a particularly difficult and important challenge is to translate these findings into clinically useful tests for single patients. In this paper, we argue that generative models of eye movement data, which allow for inferring individual computational and physiological mechanisms, could contribute to filling this gap. We present a selective overview of eye movement paradigms with clinical relevance for schizophrenia and review existing computational approaches that rest on (or could be turned into) generative models. We conclude by outlining desirable clinical applications at the individual subject level and discuss the necessary validation studies.}
}
@article{MURANO2020577,
title = {Model-checking graded computation-tree logic with finite path semantics},
journal = {Theoretical Computer Science},
volume = {806},
pages = {577-586},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519305651},
author = {Aniello Murano and Mimmo Parente and Sasha Rubin and Loredana Sorrentino},
keywords = {Computation tree logic, Model checking, Finite paths},
abstract = {This paper introduces Graded Computation Tree Logic with finite path semantics (GCTLf⁎, for short), a variant of Computation Tree Logic CTL⁎, in which path quantifiers are interpreted over finite paths and can count the number of such paths. State formulas of GCTLf⁎ are interpreted over Kripke structures. The syntax of GCTLf⁎ has path quantifiers of the form E≥gψ which express that there are at least g many distinct finite paths that satisfy ψ. After defining and justifying the logic GCTLf⁎, we solve its model checking problem and establish that its computational complexity is PSPACE-complete. Moreover, we investigate GCTLf⁎ under the imperfect information setting. Precisely, we introduce GCTLKf⁎, an epistemic extension of GCTLf⁎ and prove that the model checking problem also in this case is PSPACE-complete.}
}
@article{HAN20241,
title = {Ground threat prediction-based path planning of unmanned autonomous helicopter using hybrid enhanced artificial bee colony algorithm},
journal = {Defence Technology},
volume = {32},
pages = {1-22},
year = {2024},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2023.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S2214914723001071},
author = {Zengliang Han and Mou Chen and Haojie Zhu and Qingxian Wu},
keywords = {UAH, Path planning, Ground threat prediction, Hybrid enhanced, Collaborative thinking},
abstract = {Unmanned autonomous helicopter (UAH) path planning problem is an important component of the UAH mission planning system. Aiming to reduce the influence of non-complete ground threat information on UAH path planning, a ground threat prediction-based path planning method is proposed based on artificial bee colony (ABC) algorithm by collaborative thinking strategy. Firstly, a dynamic threat distribution probability model is developed based on the characteristics of typical ground threats. The dynamic no-fly zone of the UAH is simulated and established by calculating the distribution probability of ground threats in real time. Then, a dynamic path planning method for UAH is designed in complex environment based on the real-time prediction of ground threats. By adding the collision warning mechanism to the path planning model, the flight path could be dynamically adjusted according to changing no-fly zones. Furthermore, a hybrid enhanced ABC algorithm is proposed based on collaborative thinking strategy. The proposed algorithm applies the leader-member thinking mechanism to guide the direction of population evolution, and reduces the negative impact of local optimal solutions caused by collaborative learning update strategy, which makes the optimization performance of ABC algorithm more controllable and efficient. Finally, simulation results verify the feasibility and effectiveness of the proposed ground threat prediction path planning method.}
}
@article{BOTANA2016115,
title = {Some issues on the automatic computation of plane envelopes in interactive environments},
journal = {Mathematics and Computers in Simulation},
volume = {125},
pages = {115-125},
year = {2016},
note = {8th Workshop STRUCTURAL DYNAMICAL SYSTEMS: Computational Aspects; Edited by Nicoletta Del Buono, Roberto Garrappa and Giulia Spaletta and Nonstandard Applications of Computer Algebra (ACA’2013); Edited by Francisco Botana, Antonio Hernando, Eugenio Roanes-Lozano and Michael J. Wester},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2014.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0378475414001529},
author = {Francisco Botana and Tomas Recio},
keywords = {Envelope, Dynamic Geometry, Automatic computation, GröbnerCover algorithm},
abstract = {This paper addresses some concerns, and describes some proposals, on the ellusive concept of envelope of an algebraic family of varieties, and on its automatic computation. We describe how to use the recently developed Gröbner Cover algorithm to study envelopes of families of algebraic curves, and we give a protocol towards its implementation in dynamic geometry environments. The proposal is illustrated through some examples. A beta version of GeoGebra is used to highlight new envelope abilities in interactive environments, and limitations of our approach are discussed, since the computations are performed in an algebraically closed field.}
}
@article{WANG2024,
title = {News Coverage of the COVID-19 Pandemic on Social Media and the Public’s Negative Emotions: Computational Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48491},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400308X},
author = {Hanjing Wang and Yupeng Li and Xuan Ning},
keywords = {web news coverage, emotions, social media, Facebook, COVID-19},
abstract = {Background
Social media has become an increasingly popular and critical tool for users to digest diverse information and express their perceptions and attitudes. While most studies endeavor to delineate the emotional responses of social media users, there is limited research exploring the factors associated with the emergence of emotions, particularly negative ones, during news consumption.
Objective
We aim to first depict the web coverage by news organizations on social media and then explore the crucial elements of news coverage that trigger the public’s negative emotions. Our findings can act as a reference for responsible parties and news organizations in times of crisis.
Methods
We collected 23,705 Facebook posts with 1,019,317 comments from the public pages of representative news organizations in Hong Kong. We used text mining techniques, such as topic models and Bidirectional Encoder Representations from Transformers, to analyze news components and public reactions. Beyond descriptive analysis, we used regression models to shed light on how news coverage on social media is associated with the public’s negative emotional responses.
Results
Our results suggest that occurrences of issues regarding pandemic situations, antipandemic measures, and supportive actions are likely to reduce the public’s negative emotions, while comments on the posts mentioning the central government and the Government of Hong Kong reveal more negativeness. Negative and neutral media tones can alleviate the rage and interact with the subjects and issues in the news to affect users’ negative emotions. Post length is found to have a curvilinear relationship with users’ negative emotions.
Conclusions
This study sheds light on the impacts of various components of news coverage (issues, subjects, media tone, and length) on social media on the public’s negative emotions (anger, fear, and sadness). Our comprehensive analysis provides a reference framework for efficient crisis communication for similar pandemics at present or in the future. This research, although first extending the analysis between the components of news coverage and negative user emotions to the scenario of social media, echoes previous studies drawn from traditional media and its derivatives, such as web newspapers. Although the era of COVID-19 pandemic gradually brings down the curtain, the commonality of this research and previous studies also contributes to establishing a clearer territory in the field of health crises.}
}
@article{KU2021114105,
title = {Computational linguistic analysis applied to a semantic fluency task: A replication among first-episode psychosis patients with and without derailment and tangentiality},
journal = {Psychiatry Research},
volume = {304},
pages = {114105},
year = {2021},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2021.114105},
url = {https://www.sciencedirect.com/science/article/pii/S0165178121004029},
author = {Benson S. Ku and Luca Pauselli and Michael A. Covington and Michael T. Compton},
keywords = {Derailment, First-episode psychosis, Formal thought disorder, Loose associations, Psychosis, Schizophrenia, Semantic fluency tasks},
abstract = {Automated tools do not yet exist to measure formal thought disorder, including derailment and tangentiality, both of which can be subjectively rated using the Scale for the Assessment of Positive Symptoms after a clinical research interview. CoVec, a new automated tool, measures the semantic similarity among words averaged in a five- and ten-word window (Coherence-5 and Coherence-10, respectively). One prior report demonstrated that this tool was able to differentiate between patients with those types of thought disorder and patients without them (and controls). Here, we attempted a replication of the initial findings using data from a different sample of patients hospitalized for initial evaluation of first-episode psychosis. Participants were administered a semantic fluency task and the animal lists were analyzed with CoVec. In this study, we partially replicated the prior findings, showing that first-episode patients with derailment had significantly lower Coherence-5 and Coherence-10 compared with patients without derailment. Further research is warranted on this and other highly reliable and objective methods of detecting formal thought disorder through simple assessments such as semantic fluency tasks.}
}
@article{SLOOT2010131,
title = {The cross-disciplinary road to true computational science},
journal = {Journal of Computational Science},
volume = {1},
number = {3},
pages = {131},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000451},
author = {Peter M.A. Sloot}
}
@article{IGNATOWSKI2014264,
title = {Wishful thinking or effective threat? Tightening bank resolution regimes and bank risk-taking},
journal = {Journal of Financial Stability},
volume = {15},
pages = {264-281},
year = {2014},
issn = {1572-3089},
doi = {https://doi.org/10.1016/j.jfs.2014.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1572308914000485},
author = {Magdalena Ignatowski and Josef Korte},
keywords = {Bank resolution, Orderly Liquidation Authority, FDIC, Bank behavior, Risk-taking},
abstract = {We propose a framework for testing the effects of changes in bank resolution regimes on bank behavior. By exploiting the differential relevance of recent changes in U.S. bank resolution (i.e., the introduction of the Orderly Liquidation Authority, OLA) for different types of banks, we are able to simulate a quasi-natural experiment using a difference-in-difference framework. We find that banks that are more affected by the introduction of the OLA (1) significantly decrease their overall risk-taking and (2) shift their loan origination toward lower risk, indicating the general effectiveness of the regime change. This effect, however, does (3) not hold for the largest and most systemically important banks. Hence, the introduction of the OLA in the U.S. alone does not appear to have solved the too-big-to-fail problem and might need to be complemented with other measures to limit financial institutions’ risk-taking.}
}
@article{LONG201960,
title = {The mammalian kinetochore–microtubule interface: robust mechanics and computation with many microtubules},
journal = {Current Opinion in Cell Biology},
volume = {60},
pages = {60-67},
year = {2019},
note = {Cell Dynamics},
issn = {0955-0674},
doi = {https://doi.org/10.1016/j.ceb.2019.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0955067419300250},
author = {Alexandra F Long and Jonathan Kuhn and Sophie Dumont},
abstract = {The kinetochore drives chromosome segregation at cell division. It acts as a physical link between chromosomes and dynamic microtubules, and as a signaling hub detecting and processing microtubule attachments to control anaphase onset. The mammalian kinetochore is a large macromolecular machine that forms a dynamic interface with the many microtubules that it binds. While we know most of the kinetochore’s component parts, how they work together to give rise to its robust functions remains poorly understood. Here we highlight recent findings that shed light on this question, driven by an expanding physical and molecular toolkit. We present emerging principles that underlie the kinetochore’s robust microtubule grip, such as redundancy, specialization, and dynamicity, and present signal processing principles that connect this microtubule grip to robust computation. Throughout, we identify open questions, and define simple engineering concepts that provide insight into kinetochore function.}
}
@article{ARSLAN2024340,
title = {Computational analysis of linguistic features in speech samples of first-episode bipolar disorder and psychosis},
journal = {Journal of Affective Disorders},
volume = {363},
pages = {340-347},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.07.102},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724011595},
author = {Berat Arslan and Elif Kizilay and Burcu Verim and Cemal Demirlek and Muhammed Demir and Ezgi Cesim and Merve S. Eyuboglu and Simge Uzman Ozbek and Ekin Sut and Berna Yalincetin and Emre Bora},
keywords = {Psychosis, Bipolar, First-episode, Natural language processing, Semantic similarity},
abstract = {Background
In recent years, automated analyses using novel NLP methods have been used to investigate language abnormalities in schizophrenia. In contrast, only a few studies used automated language analyses in bipolar disorder. To our knowledge, no previous research compared automated language characteristics of first-episode psychosis (FEP) and bipolar disorder (FEBD) using NLP methods.
Methods
Our study included 53 FEP, 40 FEBD and 50 healthy control participants who are native Turkish speakers. Speech samples of the participants in the Thematic Apperception Test (TAT) underwent automated generic and part-of-speech analyses, as well as sentence-level semantic similarity analysis based on SBERT.
Results
Both FEBD and FEP were associated with the use of shorter sentences and increased sentence-level semantic similarity but less semantic alignment with the TAT pictures. FEP also demonstrated reduced verbosity and syntactic complexity. FEP differed from FEBD in reduced verbosity, decreased first-person singular pronouns, fewer conjunctions, increased semantic similarity as well as shorter sentence and word length. The mean classification accuracy was 82.45 % in FEP vs HC, 71.1 % in FEBD vs HC, and 73 % in FEP vs FEBD. After Bonferroni correction, the severity of negative symptoms in FEP was associated with reduced verbal output and increased 5th percentile of semantic similarity.
Limitations
The main limitation of this study was the cross-sectional nature.
Conclusion
Our findings demonstrate that both patient groups showed language abnormalities, which were more severe and widespread in FEP compared to FEBD. Our results suggest that NLP methods reveal transdiagnostic linguistic abnormalities in FEP and FEBD.}
}
@article{BARGMANN20242999,
title = {Cori Bargmann},
journal = {Neuron},
volume = {112},
number = {18},
pages = {2999-3002},
year = {2024},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2024.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0896627324006561},
author = {Cori Bargmann},
abstract = {In an interview with Neuron, Cori Bargmann discusses C. elegans as a model organism, the importance of considering the animal’s own world (thinking like a worm), choosing a scientific problem, and her experience as head of science at the Chan Zuckerberg Initiative and co-chair of the BRAIN Initiative.}
}
@incollection{JIAO202081,
title = {Chapter 3 - Theoretical basis of natural computation},
editor = {Licheng Jiao and Ronghua Shang and Fang Liu and Weitong Zhang},
booktitle = {Brain and Nature-Inspired Learning Computation and Recognition},
publisher = {Elsevier},
pages = {81-95},
year = {2020},
isbn = {978-0-12-819795-0},
doi = {https://doi.org/10.1016/B978-0-12-819795-0.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128197950000037},
author = {Licheng Jiao and Ronghua Shang and Fang Liu and Weitong Zhang},
keywords = {Artificial immune system, Evolutionary algorithms, Multiobjective optimization, Theoretical basis},
abstract = {Enlightened by nature, the natural computing method has the ability of self-adaptation, self-organization, and self-learning, and can solve complex problems which are difficult to be solved by traditional computing methods. Natural computing is not only a new hotspot in artificial intelligence research, but also a new thinking in the development of artificial intelligence. It is also a new achievement in the transformation of methodology. Its research results include evolutionary algorithms, artificial immune system, multiobjective optimization, and so on. Natural computing can solve many complex problems which are difficult to be solved by traditional computing methods. It has good application prospects in solving large-scale complex optimization problems, intelligent control, computer network security, and other fields.}
}
@article{WHITE1985287,
title = {Thinking about learning about thinking: An interview with Seymour Papert},
journal = {New Ideas in Psychology},
volume = {3},
number = {3},
pages = {287-292},
year = {1985},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(85)90025-X},
url = {https://www.sciencedirect.com/science/article/pii/0732118X8590025X},
author = {Barbara Y. White}
}
@article{IGAMBERDIEV2021104395,
title = {Mathematics in biological reality: The emergence of natural computation in living systems},
journal = {Biosystems},
volume = {204},
pages = {104395},
year = {2021},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2021.104395},
url = {https://www.sciencedirect.com/science/article/pii/S0303264721000526},
author = {Abir U. Igamberdiev and Joseph E. Brenner},
keywords = {Biological evolution, Biological code, Complexification, Computation, Epistemic cut, Hypercycle, Internal measurement, Relational biology, Univalent foundations},
abstract = {Mathematics is a powerful tool to express the computable part of the reality of the physical world. For living systems, mathematical relations emerge internally as an abstracting capacity in the course of development and adaptation to the external world. All living systems possess internal coding structures which represent their embedded description. They are anticipatory in the sense that the embedded description generates deterministic model of their behavior. If the model does not provide a correct result, they can evolve through the acquisition of new statements inside the embedded description that overcome limitations of the existing model. The newly generated statements acquire meaning in and from the changing environment. The growth of complexity, being a consequence of the internal active adaptation to externality performed by the systems, increases the amount of external work and generates the observed patterns of spatiotemporal structures of evolving systems. In living systems, the symbolic memory constraints are dynamic processes in themselves, co-evolving with the other components of biological systems. Separation of the symbolic memory and the dynamic laws (defined as the epistemic cut), required for self-replication of biological systems, forms the basis for their onto-epistemic relation to reality. In this regard, living systems possess their own internal abstracting capacity and invent mathematics. The digital structure of the genetic code is a manifestation of this mathematics.}
}
@article{RUSCH2020107488,
title = {Theory of mind and decision science: Towards a typology of tasks and computational models},
journal = {Neuropsychologia},
volume = {146},
pages = {107488},
year = {2020},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2020.107488},
url = {https://www.sciencedirect.com/science/article/pii/S0028393220301597},
author = {Tessa Rusch and Saurabh Steixner-Kumar and Prashant Doshi and Michael Spezio and Jan Gläscher},
keywords = {Theory of mind, Computational modeling, Decision making, Interactivity, Uncertainty},
abstract = {The ability to form a Theory of Mind (ToM), i.e., to theorize about others’ mental states to explain and predict behavior in relation to attributed intentional states, constitutes a hallmark of human cognition. These abilities are multi-faceted and include a variety of different cognitive sub-functions. Here, we focus on decision processes in social contexts and review a number of experimental and computational modeling approaches in this field. We provide an overview of experimental accounts and formal computational models with respect to two dimensions: interactivity and uncertainty. Thereby, we aim at capturing the nuances of ToM functions in the context of social decision processes. We suggest there to be an increase in ToM engagement and multiplexing as social cognitive decision-making tasks become more interactive and uncertain. We propose that representing others as intentional and goal directed agents who perform consequential actions is elicited only at the edges of these two dimensions. Further, we argue that computational models of valuation and beliefs follow these dimensions to best allow researchers to effectively model sophisticated ToM-processes. Finally, we relate this typology to neuroimaging findings in neurotypical (NT) humans, studies of persons with autism spectrum (AS), and studies of nonhuman primates.}
}
@article{GARCIANUNES2020102607,
title = {A computational tool for weak signals classification – Detecting threats and opportunities on politics in the cases of the United States and Brazilian presidential elections},
journal = {Futures},
volume = {123},
pages = {102607},
year = {2020},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2020.102607},
url = {https://www.sciencedirect.com/science/article/pii/S0016328720300999},
author = {Pedro Ivo Garcia-Nunes and Pedro Artico Rodrigues and Kaulitz Guimarães Oliveira and Ana Estela Antunes {da Silva}},
keywords = {Conceptual systems, Opportunities, Threats, Weak signals},
abstract = {The literature on weak signals (WS) has been fruitful in recent years and this specific type of information has attracted the attention of several disciplines, notably the futures studies. However, most of these studies still focus on conceptual discussions, terminology, or the proposal for frameworks that do not take advantage of the evolution of information and communication technologies. In this paper, authors discussed the lack of tools to computationally support WS handling. In response to this lack, a computational tool was developed considering a previously published method for WS classification based on conceptual systems. This tool was applied and evaluated in experimental cases about surprising events that occurred in politics in recent years, considering traditional metrics of information retrieval. Experiments illustrate that organizations can create several conceptual systems to represent different scenarios and types of knowledge; after all, results showed that the tool can operate according to different artifacts of knowledge representation. This capacity is useful to mitigate the effects of the surveillance filter though the evidence does not directly confirm its usefulness for the monitoring activities. Furthermore, the tool provides a list of threats, opportunities and unlabeled WS that can trigger other steps of sensemaking about these signals.}
}
@article{BUKOWSKI202116,
title = {Computational medicine, present and the future: obstetrics and gynecology perspective},
journal = {American Journal of Obstetrics and Gynecology},
volume = {224},
number = {1},
pages = {16-34},
year = {2021},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2020.08.057},
url = {https://www.sciencedirect.com/science/article/pii/S0002937820308851},
author = {Radek Bukowski and Karl Schulz and Kelly Gaither and Keri K. Stephens and Dave Semeraro and Justin Drake and Gordon Smith and Craig Cordola and Thaleia Zariphopoulou and Thomas J.R. Hughes and Christopher Zarins and Dimitri Kusnezov and Donna Howard and Tinsley Oden},
keywords = {computation, data, data-driven models, machine learning, modeling, physics-based models, theory-based models, uncertainty},
abstract = {Medicine is, in its essence, decision making under uncertainty; the decisions are made about tests to be performed and treatments to be administered. Traditionally, the uncertainty in decision making was handled using expertise collected by individual providers and, more recently, systematic appraisal of research in the form of evidence-based medicine. The traditional approach has been used successfully in medicine for a very long time. However, it has substantial limitations because of the complexity of the system of the human body and healthcare. The complex systems are a network of highly coupled components intensely interacting with each other. These interactions give those systems redundancy and thus robustness to failure and, at the same time, equifinality, that is, many different causative pathways leading to the same outcome. The equifinality of the complex systems of the human body and healthcare system demand the individualization of medical care, medicine, and medical decision making. Computational models excel in modeling complex systems and, consequently, enabling individualization of medical decision making and medicine. Computational models are theory- or knowledge-based models, data-driven models, or models that combine both approaches. Data are essential, although to a different degree, for computational models to successfully represent complex systems. The individualized decision making, made possible by the computational modeling of complex systems, has the potential to revolutionize the entire spectrum of medicine from individual patient care to policymaking. This approach allows applying tests and treatments to individuals who receive a net benefit from them, for whom benefits outweigh the risk, rather than treating all individuals in a population because, on average, the population benefits. Thus, the computational modeling–enabled individualization of medical decision making has the potential to both improve health outcomes and decrease the costs of healthcare.}
}
@article{KARA2015526,
title = {A Critical Look at the Digital Technologies in Architectural Education: When, where, and how?},
journal = {Procedia - Social and Behavioral Sciences},
volume = {176},
pages = {526-530},
year = {2015},
note = {International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.506},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815005431},
author = {Levent Kara},
keywords = {architectural pedagogy, architectural design, digital architecture, CAD, CAM, computational design, architectural design studio, architectural drawing, architectural modeling, architectural thinking, architectural geometry},
abstract = {In the past decade, architectural education has seen an increasing amount of digital technologies being involved in the design studio curricula. Following the trends in the profession, these various technologies of computer aided drafting, enumerating, modeling, and analysis became not only key pedagogical nodes in the design studio, but also started to shape the overall curricular structure of architectural education as they also needed to be implemented as support courses in order to compensate the learning curves and the number of software available to architects. These digital technologies range from one end of simple drafting, conventional three dimensional modeling, and more sophisticated animation of buildings with a computer, to the other end of inventing new tectonic and spatial geometries using parametric computations. In this context, it will be unrealistic to argue against teaching and using digital technologies in architectural education. When one thinks how the profession has evolved in the past decade, it is necessary to embrace these tools in the architectural curriculum. However, a discussion that has not been clearly resolved is when, where, and how these digital tools are thought and used in the architectural education. My paper argues that the conventional tools of hand drawing, physical modeling, and hand making should be embraced in the foundational levels, and the digital tools should be introduced after developing a certain set of skills of one-to-one physical making where a sense of tectonic resolution, scale, and spatial experience is cultivated as a basis of architectural thinking with digital tools. In what follows, I will discuss this viewpoint through examples from architectural design studio education in the United States and in Turkey.}
}
@article{ANDERSEN2024100697,
title = {Infrastructuring digital literacy in K-12 education: A national case study},
journal = {International Journal of Child-Computer Interaction},
volume = {42},
pages = {100697},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100697},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000667},
author = {Lars Bo Andersen and Ditte Amund Basballe and Lillian Buus and Christian Dindler and Thomas Illum Hansen and Mikkel Hjorth and Ole Sejer Iversen and Christian Mosbæk Johannessen and Katrine Holm Kanstrup and Rasmus Fink Lorentzen and Morten Misfeldt and Line Have Musaeus and Camilla Balslev Nielsen and Marianne Graves Petersen and Vibeke Schrøder and Marie Falkesgaard Slot},
keywords = {Technology comprehension, Digital literacy, Infrastructuring, Strategy},
abstract = {While much CCI research has dealt with the educational challenge of providing children with knowledge and skills for a digital society, little work has dealt with the strategic challenge of developing and implementing a digital literacy subject in K-12 education. In this paper, we explore how to develop, implement, and sustain a national program on technology comprehension by analyzing the newly established Danish knowledge center for digital technology comprehension. We draw on the concept of infrastructuring to shed light on how to create and sustain the social, material, political and organizational structures that form the basis for introducing the new national initiative. Based on our case, we distill seven propositions that describe more generally how to work strategically with this challenge.}
}
@article{KITA202021,
title = {Computational design of generalized centrifugal puzzles},
journal = {Computers & Graphics},
volume = {90},
pages = {21-28},
year = {2020},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2020.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S009784932030056X},
author = {Naoki Kita and Takafumi Saito},
keywords = {Computational design, Digital fabrication, Puzzles},
abstract = {Mechanical puzzles have fascinated many people for a long time. While some puzzles require complex procedures to solve, there are puzzles that can be solved easily if the solver understands the underlying mechanism. In this paper, we focus on mechanical puzzles that can be solved by spin such that centrifugal force is applied to the internal mechanical core to unlock the locked state. While traditional centrifugal puzzles are limited to simple shapes, we propose a computational design method to generalize such puzzles by embedding the mechanical core into 3D models. We parameterize the internal core mechanism and optimize the design under several design constraints, and we generate a support structure that helps users solve puzzles easily because generalized puzzles cannot always be spun steadily and easily due to complex surfaces and non-flat contact areas. Additionally, we embed multiple cores into a model. To solve a multi-core puzzle, the user must follow certain orders to unlock each locking mechanism. We fabricate a variety of designed puzzles and demonstrate whether they can be physically unlocked.}
}
@article{CADDY1996219,
title = {Regime shifts and paradigm changes: is there still a place for equilibrium thinking?},
journal = {Fisheries Research},
volume = {25},
number = {3},
pages = {219-230},
year = {1996},
issn = {0165-7836},
doi = {https://doi.org/10.1016/0165-7836(95)00443-2},
url = {https://www.sciencedirect.com/science/article/pii/0165783695004432},
author = {J.F. Caddy}
}
@article{VANCOUVER201456,
title = {Change one can believe in: Adding learning to computational models of self-regulation},
journal = {Organizational Behavior and Human Decision Processes},
volume = {124},
number = {1},
pages = {56-74},
year = {2014},
issn = {0749-5978},
doi = {https://doi.org/10.1016/j.obhdp.2013.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0749597813001180},
author = {Jeffrey B. Vancouver and Justin M. Weinhardt and Ronaldo Vigo},
keywords = {Computational model, Motivation, Dynamics, Learning},
abstract = {Theories of self-regulation describe motivation as a dynamic process of goal choice and goal striving. To facilitate those processes, individuals learn about themselves and their environment, which is an internal dynamic process. However, the precise nature of the relationship between these learning and motivational processes is not well specified. This article integrates formal models of learning, goal choice, and goal striving using a single information processing structure found in self-regulatory models of motivation. Results from two published studies (DeShon and Rench, 2009, Schmidt and DeShon, 2007) validate the model. In both cases, the integrated model accounts for findings that previous theories of self-regulation could not explain. Discussion focuses on additional tests to validate the model and on the value of incorporating formal models from the cognitive, learning, and motivational literatures to account for behavior in complex settings and over time.}
}
@article{LEE2025100890,
title = {Generative ecodesign for mechanical products: A design workflow},
journal = {Cleaner Engineering and Technology},
volume = {24},
pages = {100890},
year = {2025},
issn = {2666-7908},
doi = {https://doi.org/10.1016/j.clet.2025.100890},
url = {https://www.sciencedirect.com/science/article/pii/S2666790825000138},
author = {Amos Wei Lun Lee and Kevin Kai Wern Seah and Bing Feng Ng and Ee Teng Zhang and Wen Feng Lu and Jonathan Sze Choong Low},
keywords = {Carbon emission, Generative design, Product design, Environmental sustainability, Ecodesign},
abstract = {Harnessing advancements in artificial intelligence, generative design holds great potential to support designers in their ecodesign efforts by enabling them to explore design solutions beyond the limits of their imagination and expertise. However, a systematic literature review on the application of generative design in ecodesign reveals a clear underrepresentation, highlighting a missed opportunity in the field. To bridge this gap, a seven-component generative ecodesign workflow for mechanical products was developed. This workflow combines generative design algorithms, typically used for geometry lightweighting, with life cycle thinking. It facilitates the generation, evaluation, and identification of design solutions by considering the design tri-factor: material choice, manufacturing process, and geometry. This represents the first reported product ecodesign tool to integrate generative design with ecodesign principles while simultaneously addressing all three elements of the design tri-factor. To showcase its utility, environmentally optimal design alternatives were created for a mountain bicycle's handlebar stem.}
}
@article{LU2025103764,
title = {Detection of structural-functional coupling abnormalities using multimodal brain networks in Alzheimer’s disease: A comparison of three computational models},
journal = {NeuroImage: Clinical},
volume = {46},
pages = {103764},
year = {2025},
issn = {2213-1582},
doi = {https://doi.org/10.1016/j.nicl.2025.103764},
url = {https://www.sciencedirect.com/science/article/pii/S2213158225000348},
author = {Yinping Lu and Luyao Wang and Toshiya Murai and Jinglong Wu and Dong Liang and Zhilin Zhang},
keywords = {Structural-functional coupling, Statistical model, Communication model, Graph harmonic model, Brain network, Alzheimer’s disease, Multimodal MRI},
abstract = {Alzheimer’s disease (AD) is a progressive neurodegenerative disorder characterized by the disconnection of white matter fibers and disrupted functional connectivity of gray matter; however, the pathological mechanisms linking structural and functional changes remain unclear. This study aimed to explore the interaction between the structural and functional brain network in AD using advanced structural–functional coupling (S-F coupling) models to assess whether these changes correlate with cognitive function, Aβ deposition levels, and gene expression. In this study, we utilized multimodal magnetic resonance imaging data from 41 individuals with AD, 112 individuals with mild cognitive impairment, and 102 healthy controls to explore these mechanisms. We applied different computational models to examine the changes in the S-F coupling associated with AD. Our results showed that the communication and graph harmonic models demonstrated greater heterogeneity and were more sensitive than the statistical models in detecting AD-related pathological changes. In addition, S-F coupling increases with AD progression at the global, subnetwork, and regional node levels, especially in the medial prefrontal and anterior cingulate cortices. The S-F coupling of these regions also partially mediated cognitive decline and Aβ deposition. Furthermore, gene enrichment analysis revealed that changes in S-F coupling were strongly associated with the regulation of cellular catabolic processes. This study advances our understanding of the interaction between structural and functional connectivity and highlights the importance of S-F coupling in elucidating the neural mechanisms underlying cognitive decline in AD.}
}
@incollection{COUCLELIS2009245,
title = {Computational Human Geography},
editor = {Rob Kitchin and Nigel Thrift},
booktitle = {International Encyclopedia of Human Geography},
publisher = {Elsevier},
address = {Oxford},
pages = {245-250},
year = {2009},
isbn = {978-0-08-044910-4},
doi = {https://doi.org/10.1016/B978-008044910-4.00669-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080449104006696},
author = {H. Couclelis},
keywords = {Agent-based models, Cellular automata, Geocomputation, Geo(infor)matics, GIS, Location-based services, Models/modeling, Public participation GIS, Spatial analysis},
abstract = {Computational human geography refers to the use of computational methods and techniques to solve problems in human geography research and applications. Geographic information systems (GIS) and science are a big part of computational human geography but the notion is considerably broader, encompassing spatial process modeling and simulation, the modeling of spatial decision and behavior, visualization techniques, most aspects of spatial analysis, and an increasing number of other areas. Computation in human geography goes back to the beginnings of the quantitative revolution and is philosophically related though methodologically distinct from it. Two major thrusts have persisted through the years: the use of numerical techniques to solve large, complex quantitative problems; and the development of models of complex spatial processes expressed directly in computational terms. Typical exponents of the latter kinds of applications are cellular automata models of urban and environmental processes, and agent-based models of spatial decision and behavior. More recent developments involve applications of mobile and portable computing. Critiques of computational human geography originate from both within the field and from the humanistic and social theory perspectives. The former address a number of epistemological and methodological problems while the latter tend to focus on issues of ontology and representation.}
}
@article{ALI20201425,
title = {Re-thinking adaptive immunity in the beetles: Evolutionary and functional trajectories of lncRNAs},
journal = {Genomics},
volume = {112},
number = {2},
pages = {1425-1436},
year = {2020},
issn = {0888-7543},
doi = {https://doi.org/10.1016/j.ygeno.2019.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0888754319302034},
author = {Ali Ali and Hesham M. {Abd El Halim}},
keywords = {Immune memory, Priming, , Macrophage},
abstract = {Unlike vertebrate animals, invertebrates lack lymphocytes and therefore have historically been believed not to develop immune memory. A few studies have reported evidence of immune priming in insects; however, these studies lack the molecular mechanism and proposed it might be different among taxa. Since lncRNAs are known to regulate the immune response, we identified 10,120 lncRNAs in Tribolium castaneum genome-wide followed by transcriptome analysis of primed and unprimed larvae of different infectious status. A shift in lncRNA expression between Btt primed larvae and other treatment groups provides evidence of immune memory response. A few “priming” lncRNAs (n = 9) were uniquely regulated in Btt primed larvae. Evidence suggests these lncRNAs are likely controlling immune priming in Tribolium by regulating expression of genes involved in proteasomal machinery, Notch system, zinc metabolism, and methyltransferase activity, which are necessary to modulate phagocytosis. Our results support a conserved immune priming mechanism in a macrophage-dependent manner.}
}
@article{SWANSON2020100961,
title = {The relationship between executive processing and computational growth among monolingual and english learners with and without math difficulties: Does it help to be bilingual?},
journal = {Cognitive Development},
volume = {56},
pages = {100961},
year = {2020},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2020.100961},
url = {https://www.sciencedirect.com/science/article/pii/S0885201420301155},
author = {H. Lee Swanson},
keywords = {Math difficulties, English learner, Bilingual, Working memory, Cognition, Math computation},
abstract = {Does the commonly reported math achievement gap among elementary school monolingual and English learners (ELs) with and without math difficulties reflect variations in executive processing? This cohort-sequential study (N = 841) explored the cognitive processes that underlie in elementary school children’s math computational growth who are monolingual (English-only) or English learners with Spanish as a first language. Three language subgroups (proficient ELs [relatively proficient in both English and Spanish vocabulary], less proficient ELs [more proficient in English when compared to Spanish vocabulary] and monolingual [English-only]) children with and without math difficulties (MD) were compared on measures of math computation and cognitive growth. As expected, children with MD identified at wave 1 underperformed children without MD in their rate of growth and their level of computational and working memory (WM) performance in the final testing wave. However, two additional findings occurred. First, executive processing measures (working memory and inhibition) were significantly related to computational growth even when measures of reading, fluid intelligence, STM, naming speed and SES were partialed in the analysis. Second, no statistical advantages in executive processing or computation emerged in favor of EL children relative to monolingual children. Taken together, the results support the notion that (a) growth in math computation is tied to growth in the executive system and (b) EL children relatively proficient in English and Spanish experience no growth advantages in WM or computation compared to monolingual children.}
}
@article{YANG20101297,
title = {Computational optimization, modelling and simulation–a paradigm shift},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {1297-1300},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.144},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910001456},
author = {Xin-She Yang and Slawomir Koziel},
keywords = {Algorithm, Black-box modelling, Computational optimization, Derivative-free method, Optimization algorithm, Modelling, Nonlinear optimization, Surragate-based optimization, Simulation},
abstract = {Computational optimization forms an integrated part of modern computational science. Any good design should intend to achieve certain optimality, though optimal solutions are often difficult to find in practice since uncertainty and nonlinearity always present in almost all real-world problems. As resources, time and money are always limited, optimization becomes even more important in practice. This workshop on Computational Optimization, Modelling and Simulation (COMS 2010) at ICCS 2010 will summarize the latest developments of optimization and modelling and their applications in science, engineering and industry}
}
@article{AILON2020234,
title = {Paraunitary matrices, entropy, algebraic condition number and Fourier computation},
journal = {Theoretical Computer Science},
volume = {814},
pages = {234-248},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2020.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0304397520300797},
author = {Nir Ailon},
keywords = {Fourier transform, Lower bounds, Complexity, Linear algebraic computation},
abstract = {The Fourier Transform is one of the most important linear transformations used in science and engineering. Cooley and Tukey's Fast Fourier Transform (FFT) from 1964 is a method for computing this transformation in time O(nlog⁡n). From a lower bound perspective, relatively little is known. Ailon shows in 2013 an Ω(nlog⁡n) bound for computing the normalized Fourier Transform assuming only unitary operations on two coordinates are allowed at each step, and no extra memory is allowed. In 2014, Ailon then improved the result to show that, in a κ-well conditioned computation, Fourier computation can be sped up by no more than O(κ). The main conjecture is that Ailon's result can be exponentially improved, in the sense that κ-well condition cannot admit ω(log⁡κ) speedup. The main result here is that ‘algebraic’ κ-well condition cannot admit ω(κ) speedup. One equivalent definition of algebraic condition number is related to the degree of polynomials naturally arising as the computation evolves. Using the maximum modulus theorem from complex analysis, we show that algebraic condition number upper bounds standard condition number, and equals it in certain cases. Algebraic condition number is an interesting measure of numerical computation stability in its own right, and provides a novel computational lens. Moreover, based on evidence from other recent related work, we believe that the approach of algebraic condition number has a good chance of establishing an algebraic version of the main conjecture.}
}
@incollection{WARD2018,
title = {Analogy☆},
booktitle = {Reference Module in Neuroscience and Biobehavioral Psychology},
publisher = {Elsevier},
year = {2018},
isbn = {978-0-12-809324-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.21889-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245218890},
author = {Thomas B. Ward},
keywords = {ACME, Analogy, Case study, Computational modeling, Laboratory study, In vivo study, Mapping, Multiconstraint theory, One-to-one correspondence, Parallel connectivity, Retrieval, SME, Source domain, Structure-mapping theory, Systematicity, Target domain},
abstract = {Analogical thinking is a fundamental cognitive process underlying creativity. Analogies map structured knowledge from one domain to another and serve as information for understanding, explaining and creating. Analogy is studied through case study, laboratory, in vivo, neuroscience and computational modeling approaches. The use of analogy is often suggested to be a helpful technique in applied approaches to creativity.}
}
@article{LOOSEN2020631,
title = {Towards a computational psychiatry of juvenile obsessive-compulsive disorder},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {118},
pages = {631-642},
year = {2020},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2020.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S014976342030484X},
author = {Alisa M. Loosen and Tobias U. Hauser},
keywords = {Juvenile obsessive-compulsive disorder, Adolescence, Neuropsychology, Computational psychiatry, Neuroimaging},
abstract = {Obsessive-Compulsive Disorder (OCD) most often emerges during adolescence, but we know little about the aberrant neural and cognitive developmental mechanisms that underlie its emergence during this critical developmental period. To move towards a computational psychiatry of juvenile OCD, we review studies on the computational, neuropsychological and neural alterations in juvenile OCD and link these findings to the adult OCD and cognitive neuroscience literature. We find consistent difficulties in tasks entailing complex decision making and set shifting, but limited evidence in other areas that are altered in adult OCD, such as habit and confidence formation. Based on these findings, we establish a neurocomputational framework that illustrates how cognition can go awry and lead to symptoms of juvenile OCD. We link these possible aberrant neural processes to neuroimaging findings in juvenile OCD and show that juvenile OCD is mainly characterised by disruptions of complex reasoning systems.}
}
@article{FRISTON2014148,
title = {Computational psychiatry: the brain as a phantastic organ},
journal = {The Lancet Psychiatry},
volume = {1},
number = {2},
pages = {148-158},
year = {2014},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(14)70275-5},
url = {https://www.sciencedirect.com/science/article/pii/S2215036614702755},
author = {Karl J Friston and Klaas Enno Stephan and Read Montague and Raymond J Dolan},
abstract = {Summary
In this Review, we discuss advances in computational neuroscience that relate to psychiatry. We review computational psychiatry in terms of the ambitions of investigators, emerging domains of application, and future work. Our focus is on theoretical formulations of brain function that put subjective beliefs and behaviour within formal (computational) frameworks—frameworks that can be grounded in neurophysiology down to the level of synaptic mechanisms. Understanding the principles that underlie the brain's functional architecture might be essential for an informed phenotyping of psychopathology in terms of its pathophysiological underpinnings. We focus on active (Bayesian) inference and predictive coding. Specifically, we show how basic principles of neuronal computation can be used to explain psychopathology, ranging from impoverished theory of mind in autism to abnormalities of smooth pursuit eye movements in schizophrenia.}
}
@incollection{HUDLICKA2017383,
title = {Chapter 16 - Computational Modeling of Cognition–Emotion Interactions: Theoretical and Practical Relevance for Behavioral Healthcare},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {383-436},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00016-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000161},
author = {Eva Hudlicka},
keywords = {emotion–cognition modeling, modeling mechanism of therapeutic action, computational models of affective disorders and psychopathology, therapeutic games, behavioral healthcare technology, transdiagnostic model},
abstract = {Recent years have witnessed an increasing interest in developing computational models of emotion and emotion–cognition interaction, within the emerging area of computational affective science. At the same time, emotion theorists and clinical psychologists have begun to recognize the importance of moving beyond descriptive characterizations of psychopathology, and identifying the underlying mechanisms that mediate both the etiology of affective disorders, and their treatment: the transdiagnostic approach to psychopathology. Computational models of cognition–emotion interactions have the potential to facilitate more accurate assessment and diagnosis of affective disorders, and to provide a basis for more efficient and targeted approaches to their treatment, through an improved understanding of the underlying mechanisms. This chapter discusses the state-of-the-art in modeling emotion–cognition interaction and the relevance of these models for understanding the mechanisms mediating psychopathology and therapeutic action. The discussion is limited to symbolic models and theories defined at the psychological, versus neural, level. The chapter also outlines how these models can support the development of serious therapeutic games, to enhance assessment and treatment methods in behavioral healthcare.}
}
@article{MAXIM2025,
title = {Identifying Key Principles and Commonalities in Digital Serious Game Design Frameworks: Scoping Review},
journal = {JMIR Serious Games},
volume = {13},
year = {2025},
issn = {2291-9279},
doi = {https://doi.org/10.2196/54075},
url = {https://www.sciencedirect.com/science/article/pii/S2291927925000315},
author = {Raluca Ionela Maxim and Joan Arnedo-Moreno},
keywords = {entertainment game design frameworks, serious game design frameworks, design principles, empathic design thinking, artificial intelligence},
abstract = {Background
Digital serious games (DSGs), designed for purposes beyond entertainment and consumed via electronic devices, have garnered attention for their potential to enhance learning and promote behavior change. Their effectiveness depends on the quality of their design. Frameworks for DSG design can guide the creation of engaging games tailored to objectives such as education, health, and social impact.
Objective
This study aims to review, analyze, and synthesize the literature on digital entertainment game design frameworks and DSG design frameworks (DSGDFWs). The focus is on conceptual frameworks offering high-level guidance for the game creation process rather than component-specific tools. We explore how these frameworks can be applied to create impactful serious games in fields such as health care and education. Key goals include identifying design principles, commonalities, dependencies, gaps, and opportunities in the literature. Suggestions for future research include empathic design thinking, artificial intelligence integration, and iterative improvements. The findings culminate in a synthesized 4-phase design process, offering generic guidelines for designers and developers to create effective serious games that benefit society.
Methods
A 2-phase methodology was used: a scoping literature review and cluster analysis. A targeted search across 7 databases (ACM, Scopus, Springer, IEEE, Elsevier, JMIR Publications, and SAGE) was conducted using PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines. Studies included academic or industry papers evaluating digital game design frameworks. Cluster analysis was applied to categorize the data, revealing trends and correlations among frameworks.
Results
Of 987 papers initially identified, 25 (2.5%) met the inclusion criteria, with an additional 22 identified through snowballing, resulting in 47 papers. These papers presented 47 frameworks, including 16 (34%) digital entertainment game design frameworks and 31 (66%) DSGDFWs. Thematic analysis grouped frameworks into categories, identifying patterns and relationships between design elements. Commonalities, dependencies, and gaps were analyzed, highlighting opportunities for empathic design thinking and artificial intelligence applications. Key considerations in DSG design were identified and presented in a 4-phase design baseline with the outcome of a list of design guidelines that might, according to the literature, be applied to an end-to-end process of designing and building future innovative solutions.
Conclusions
The main benefits of using DSGDFWs seem to be related to enhancing the effectiveness of serious games in achieving their intended objectives, such as learning, behavior change, and social impact. Limitations primarily seem to be related to constraints associated with the specific contexts in which the serious games are developed and used. Approaches in the future should be aimed at refining and adapting existing frameworks to different contexts and purposes, as well as exploring new frameworks that incorporate emerging technologies and design principles.}
}
@article{MITTAL1994253,
title = {Massively parallel finite element computation of incompressible flows involving fluid-body interactions},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {112},
number = {1},
pages = {253-282},
year = {1994},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(94)90029-9},
url = {https://www.sciencedirect.com/science/article/pii/0045782594900299},
author = {S. Mittal and T.E. Tezduyar},
abstract = {We describe our massively parallel finite element computations of unsteady incompressible flows involving fluid-body interactions. These computations are based on the Deforming-Spatial-Domain/Stabilized-Space-Time (DSD/SST) finite element formulation. Unsteady flows past a stationary NACA 0012 airfoil are computed for Reynolds numbers 1000, 5000 and 100 000. Significantly different flow patterns are observed for these three cases. The method is then applied to computation of the dynamics of an airfoil falling in a viscous fluid under the influence of gravity. It is observed that the location of the center of gravity of the airfoil plays an important role in determining its pitch stability. Computations are reported also for simulation of the dynamics of a two-dimensional ‘projectile’ that has a certain initial velocity. Specially designed mesh moving schemes are employed to eliminate the need for remeshing. All these computations were carried out on the Thinking Machines CM-200 and CM-5 supercomputers, with major speed-ups compared to traditional supercomputers. The implicit equation systems arising from the finite element discretizations of these large-scale problems are solved iteratively by using the GMRES update technique with diagonal preconditioners. The finite element formulations and their parallel implementations assume unstructured meshes.}
}
@article{DELGADO2019133,
title = {Computational methods for Gene Regulatory Networks reconstruction and analysis: A review},
journal = {Artificial Intelligence in Medicine},
volume = {95},
pages = {133-145},
year = {2019},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0933365718303865},
author = {Fernando M. Delgado and Francisco Gómez-Vela},
keywords = {Gene Network, Systems biology, Networks validation, Gene Regulatory Network, Gene Network inference},
abstract = {In the recent years, the vast amount of genetic information generated by new-generation approaches, have led to the need of new data handling methods. The integrative analysis of diverse-nature gene information could provide a much-sought overview to study complex biological systems and processes. In this sense, Gene Regulatory Networks (GRN) arise as an increasingly-promising tool for the modelling and analysis of biological processes. This review is an attempt to summarize the state of the art in the field of GRNs. Essential points in the field are addressed, thereof: (a) the type of data used for network generation, (b) machine learning methods and tools used for network generation, (c) model optimization and (d) computational approaches used for network validation. This survey is intended to provide an overview of the subject for readers to improve their knowledge in the field of GRN for future research.}
}
@article{COHEN1981285,
title = {The power of parallel thinking},
journal = {Journal of Economic Behavior & Organization},
volume = {2},
number = {4},
pages = {285-306},
year = {1981},
issn = {0167-2681},
doi = {https://doi.org/10.1016/0167-2681(81)90011-1},
url = {https://www.sciencedirect.com/science/article/pii/0167268181900111},
author = {Michael D. Cohen},
abstract = {A small computer model demonstrates that an appropriate organization of boundedly rational individuals can find optimal policies in an environment that is overwhelmingly complex for unorganized decision makers. The model is also used to identify conditions under which optimal — or even good — policies are not found. The demonstrated adaptive power of the model is interpreted in light of recent developments in the theory of computational complexity that place new stress on powerful methods of search, and of new models from computer science which markedly advance search effectiveness by harnessing parallel structures of information processing.}
}
@article{VELUPILLAI201440,
title = {Computable and computational complexity theoretic bases for Herbert Simon’s cognitive behavioral economics},
journal = {Cognitive Systems Research},
volume = {29-30},
pages = {40-52},
year = {2014},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2013.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S1389041713000405},
author = {K.Vela Velupillai and Ying-Fang Kao},
keywords = {Bounded rationality, Satisficing, Heuristics, Computability, Computational complexity},
abstract = {This paper aims to interpret and formalize Herbert Simon’s cognitive notions of bounded rationality, satisficing and heuristics in terms of computability theory and computational complexity theory. Simon’s theory of human problem solving is analyzed in the light of Turing’s work on Solvable and Unsolvable Problems. It is suggested here that bounded rationality results from the fact that the deliberations required for searching computationally complex spaces exceed the actual complexity that human beings can handle. The immediate consequence is that satisficing becomes the general criterion of decision makers and heuristics are the procedures used for achieving their goals. In such decision problems, it is demonstrated that bounded rationality and satisficing are more general than orthodox, non-cognitive, Olympian rationality and optimization, respectively, and not the other way about.}
}
@article{KACERJA2023101035,
title = {Values in preservice mathematics teachers’ discussions of the Body Mass Index - A critical perspective},
journal = {The Journal of Mathematical Behavior},
volume = {70},
pages = {101035},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101035},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000056},
author = {Suela Kacerja and Cyril Julie},
keywords = {Values, Critical thinking, Preservice teachers, Mathematics in society, Critical mathematics education},
abstract = {This article explores the values that come to the fore when preservice mathematics teachers (PTs) 11In the remaining parts of the text, we will refer to preservice teachers as PTs. engage in critical discussions about the role of mathematical models in society. The specific model that was discussed was the Body Mass Index (BMI) 22From now on, the Body Mass Index will be referred to as BMI and is calculated as mass (m) divided by the square of height (h).. From the analysis of the PTs’ discussions of the BMI from a mathematical and societal point of view several mathematical and mathematics educational values were identified such as openness, rationalism, progress, reasoning, evaluating, and problematizing the instrumental understanding of mathematics. In addition, critical thinking about mathematics in society as emphasized in curricula in the three countries involved in the study, was identified with four categories of complementary pairs. Knowing the mathematical and mathematics educational values underpinning PTs’ discussions and their connection to critical thinking is important for successfully engaging with the role of mathematics in society.}
}
@article{COWARD2014164,
title = {Brain Computational Primitives},
journal = {Procedia Computer Science},
volume = {41},
pages = {164-175},
year = {2014},
note = {5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.11.100},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914015452},
author = {L. Andrew Coward},
abstract = {The brain uses computational primitives that are analogous with but qualitatively different from the computational primitives used in electronic computer systems. The primary computational primitives of the brain are described, and their implementation in anatomy and physiology discussed. Combinations and sequences of these primitives implement cognitive tasks. Many of the primitives have also been implemented electronically. The brain is a very effective general learning system, and although an artificial general intelligence system will be required to learn a different range of behaviours from the brain, the computational primitives used by the brain are the best available guide to appropriate primitives for such an AGI system.}
}
@article{SUN2009124,
title = {Theoretical status of computational cognitive modeling},
journal = {Cognitive Systems Research},
volume = {10},
number = {2},
pages = {124-140},
year = {2009},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000429},
author = {Ron Sun},
keywords = {Cognitive modeling, Cognitive architecture, Theory, Simulation, Validation},
abstract = {This article explores the view that computational models of cognition may constitute valid theories of cognition, often in the full sense of the term “theory”. In this discussion, this article examines various (existent or possible) positions on this issue and argues in favor of the view above. It also connects this issue with a number of other relevant issues, such as the general relationship between theory and data, the validation of models, and the practical benefits of computational modeling. All the discussions point to the position that computational cognitive models can be true theories of cognition.}
}
@article{BEYTIA2022101732,
title = {Towards a Digital Reflexive Sociology: Using Wikipedia's Biographical Repository as a Reflexive Tool},
journal = {Poetics},
volume = {95},
pages = {101732},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101732},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001140},
author = {Pablo Beytía and Hans-Peter Müller},
keywords = {Reflexive sociology, digital sociology, sociology of knowledge, computational social science, digital methods},
abstract = {We propose the development of 'digital reflexive sociology', understood as the use of digital methods and Big Data to reflect on the social and historical circumstances of sociologists and sociological thinking. To show this approach's potential, we employ Wikipedia as a ‘reflexive tool’, i.e., an external artefact of self-observation that can help sociologists to notice conventions, biases, and blind spots within their discipline. We analyse the collective patterns of the 500 most notable sociologists on Wikipedia, performing structural, network, and text analyses of their biographies. Our exploration reveals patterns in their historical frequency, gender composition, geographical concentration, birth-death mobility, centrality degree, biographical clustering, and proximity between countries, also stressing institutions, events, places, and relevant dates from a biographical point of view. Linking these patterns in a diachronic way, we distinguish five generations of sociologists recorded on Wikipedia and emphasise the high historical concentration of the discipline in geographical areas, gender, and schools of thought. Drawing on these results, we discuss the potential of using digital repositories and methods to enhance reflexivity within sociology.}
}
@article{MURRAY2018777,
title = {Biophysical Modeling of Large-Scale Brain Dynamics and Applications for Computational Psychiatry},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {3},
number = {9},
pages = {777-787},
year = {2018},
note = {Computational Methods and Modeling in Psychiatry},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2018.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2451902218301782},
author = {John D. Murray and Murat Demirtaş and Alan Anticevic},
keywords = {Computational model, Functional connectivity, Neuroimaging, Resting-state, Schizophrenia, Transcriptomics},
abstract = {Noninvasive neuroimaging has revolutionized the study of the organization of the human brain and how its structure and function are altered in psychiatric disorders. A critical explanatory gap lies in our mechanistic understanding of how systems-level neuroimaging biomarkers emerge from underlying synaptic-level perturbations associated with a disease state. We describe an emerging computational psychiatry approach leveraging biophysically based computational models of large-scale brain dynamics and their potential integration with clinical and pharmacological neuroimaging. In particular, we focus on neural circuit models, which describe how patterns of functional connectivity observed in resting-state functional magnetic resonance imaging emerge from neural dynamics shaped by inter-areal interactions through underlying structural connectivity defining long-range projections. We highlight the importance of local circuit physiological dynamics, in combination with structural connectivity, in shaping the emergent functional connectivity. Furthermore, heterogeneity of local circuit properties across brain areas, which impacts large-scale dynamics, may be critical for modeling whole-brain phenomena and alterations in psychiatric disorders and pharmacological manipulation. Finally, we discuss important directions for future model development and biophysical extensions, which will expand their utility to link clinical neuroimaging to neurobiological mechanisms.}
}
@article{LIU2017168,
title = {A landmark-based data-driven approach on 2.5D facial attractiveness computation},
journal = {Neurocomputing},
volume = {238},
pages = {168-178},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.01.050},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217301248},
author = {Shu Liu and Yang-Yu Fan and Zhe Guo and Ashok Samal and Afan Ali},
keywords = {Facial attractiveness computation, 2.5 D, Geometric features, Data-driven, BJUT-3D},
abstract = {Investigating the nature and components of face attractiveness from a computational view has become an emerging topic in facial analysis research. In this paper, a multi-view (frontal and profile view, 2.5D) facial attractiveness computational model is developed to explore how face geometry affects its attractiveness. A landmark-based, data-driven method is introduced to construct a huge dimension of three kinds of geometric facial measurements, including ratios, angles, and inclinations. An incremental feature selection algorithm is proposed to systematically select the most discriminative subset of geometric features, which are finally mapped to an attractiveness score through the application of support vector regression (SVR). On a dataset of 360 facial images pre-processed from BJUT-3D Face Database and an attractiveness score dataset collected from human raters, we show that the computational model performs well with low statistic error (MSE=0.4969) and good predictability (R2=0.5756).}
}
@incollection{YERPUDE2022335,
title = {CHAPTER FOURTEEN - Computational analysis of nanofluids-based drug delivery system: Preparation, current development and applications of nanofluids},
editor = {Shriram S. Sonawane and Hussein A. Mohammed and Arvind Kumar Mungray and Shirish H. Sonawane},
booktitle = {Applications of Nanofluids in Chemical and Bio-medical Process Industry},
publisher = {Elsevier},
pages = {335-364},
year = {2022},
isbn = {978-0-323-90564-0},
doi = {https://doi.org/10.1016/B978-0-323-90564-0.00014-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323905640000143},
author = {S.T. Yerpude and A.K. Potbhare and P.R. Bhilkar and Parag Thakur and Pratiksha Khiratkar and Martin F. Desimone and P.R. Dhongle and Shriram S. Sonawane and Clara Goncalves and R.G. Chaudhary},
keywords = {CFD, Computational analysis, Drug delivery, Mathematical modeling, Nanofluids, Nano-drugs},
abstract = {Nanoparticles have been widely employed as a drug delivery carrier and a direct targeting agent. Off course, nanoparticles have been precisely and accurately designed to improve their therapeutical efficacy. Nowadays, computational modeling is frequently used to design novel and smart nanoparticles. In this chapter, we provide an overview and general idea about nanofluids in association with computational applications aimed at the improvement of nano-drug delivery coordination. Nanotechnology and nanobiotechnology-based conceptual innovations in combination with computational modeling are extensively employed in various areas of basic and applied sciences. On the same line, these technologies have a greater impact in the field of medicine and biology. We intended to look upon different aspects regarding nano-drugs and nanofluids comprising their preparation and stabilization methods and also focusing on mathematical modeling, stability mechanism, and biomedical applications of nanofluids. Similarly, imperative and special concern was given to the topic of computational fluid dynamics (CFD).}
}
@incollection{GOMEZPEROSANZ2019906,
title = {Computational Immunogenetics},
editor = {Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology},
publisher = {Academic Press},
address = {Oxford},
pages = {906-930},
year = {2019},
isbn = {978-0-12-811432-2},
doi = {https://doi.org/10.1016/B978-0-12-809633-8.20452-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128096338204524},
author = {Marta {Gómez Perosanz} and Giulia Russo and Jose Luis {Sanchez-Trincado Lopez} and Marzio Pennisi and Pedro A. Reche and Adrian Shepherd and Francesco Pappalardo},
keywords = {Agent based modelling, Antibody modelling, Bioinformatics for immune system modelling, Crystallography, Epitopes prediction, Immune system modelling, Immune system pathways, Immunotherapies, In silico trials, Molecular and cellular modelling, Multi-scale modelling, ODE modelling, Petri nets, T and B cells, Vaccines},
abstract = {Computational immunogenetics encompasses the use and application of bioinformatics methods, mathematical models and statistical techniques for the study of immune system function. The considerable heterogeneity of the immune system requires systems approaches to be used to model such a complexity and to respond to questions posed by biomedical audience to help them solve biomedical questions. Computational approaches are increasingly vital to understand the implications of the wealth of gene expression and epigenomics data being gathered from immune cells, and dozens of immune databases play a vital role in organizing the vast quantities of experimental data generated by modern high-throughput technologies. Multi-scale methodologies are increasingly being used to characterise the interplay between the molecular, cellular and organism levels of the immune system. Finally, computational immunology is making an important contribution to an emerging field of computational biomedicine: in silico clinical trials.}
}
@article{THANATIPANONDA202138,
title = {A multi-computational exploration of some games of pure chance},
journal = {Journal of Symbolic Computation},
volume = {104},
pages = {38-68},
year = {2021},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2020.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747717120300183},
author = {Thotsaporn “Aek” Thanatipanonda and Doron Zeilberger},
keywords = {Experimental mathematics, Games of pure chance, Symbolic computation},
abstract = {In the spirit of “multi-culturalism”, we use four kinds of computations: simulation, numeric, symbolic, and “conceptual”, to explore some “games of pure chance” inspired by children board games like “Snakes and Ladders” (aka “Chutes and Ladders”) and “gambler's ruin with unlimited credit”. Even more interesting than the many computer-generated specific results described in this paper and its web-site extension, is our broad-minded, ecumenical approach, not favoring, a priori, any one of the above four kinds of computation, but showing that, a posteriori, symbolic computation is the most important one, since (except for simulation) numerics can be made more efficient with the help of symbolics (in the “downward” direction), and, (in the “upward” direction) the mere existence of certain symbolic-computational algorithms imply interesting “qualitative” results, that certain numbers are always rational, or always algebraic, and certain sequences are always polynomial, or C-recursive, or algebraic, or holonomic. This article is accompanied by four Maple packages, and numerous input and output files, that readers can use as templates for their own investigations.}
}
@incollection{ERICSSON199437,
title = {CHAPTER 2 - Contemporary Approaches to the Study of Thinking and Problem Solving},
editor = {Robert J. Sternberg},
booktitle = {Thinking and Problem Solving},
publisher = {Academic Press},
address = {San Diego},
pages = {37-79},
year = {1994},
volume = {2},
series = {Handbook of Perception and Cognition},
isbn = {978-0-08-057299-4},
doi = {https://doi.org/10.1016/B978-0-08-057299-4.50008-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080572994500086},
author = {K. Anders Ericsson and Reid Hastie},
abstract = {Publisher Summary
This chapter discusses the contemporary approaches to the study of thinking and problem solving. The modal approach to create a comprehensive theory of thinking strives to identify simple conditions under which a given type of thinking can be reliably reproduced. Following the successful example of experimenters in many of the natural sciences, the goal of this approach is to discover general laws and invariant constraints in well-defined tasks that do not require access to complex knowledge and experience. The most popular alternative approach to the study of thinking starts by examining performance in everyday life and identifying stable and reproducible phenomena. Of particular interest is expert performance, because it offers the highest levels of performance and also the largest stable individual differences in performance when compared with that of beginners. An understanding of thinking is incomplete unless it provides an account of how the elements of adult thought—such as concepts, representations, and skills—are acquired. Research on learning and skill acquisition on the whole range of activities ranging from performance on simple laboratory tasks to complex life-long efforts to attain expert performance shows that effective learning is not an automatic consequence of extended experience.}
}
@article{GIORGI2023101151,
title = {Conceptual development from the perspective of a brain-inspired robotic architecture},
journal = {Cognitive Systems Research},
volume = {82},
pages = {101151},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101151},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723000797},
author = {Ioanna Giorgi and Bruno Golosio and Massimo Esposito and Angelo Cangelosi and Giovanni Luca Masala},
keywords = {Brain-inspired model, Cognitive architecture, Robotic model, High-level cognition, Human language, Concepts, Categorisation, Conceptual development, Understanding},
abstract = {Concepts are central to reasoning and intelligent behaviour. Scientific evidence shows that conceptual development is fundamental for the emergence of high-cognitive phenomena. Here, we model such phenomena in a brain-inspired cognitive robotic model and examine how the robot can learn, categorise, and abstract concepts to voluntary control behaviour. The paper argues that such competence arises with sufficient conceptual content from physical and social experience. Hence, senses, motor abilities and language, all contribute to a robot’s intelligent behaviour. To this aim, we devised a method for attaining concepts, which computationally reproduces the steps of the inductive thinking strategy of the Concept Attainment Model (CAM). Initially, the robot is tutor-guided through socio-centric cues to attain concepts and is then tested consistently to use these concepts to solve complex tasks. We demonstrate how the robot uses language to create new categories by abstraction in response to human language-directed instructions. Linguistic stimuli also change the representations of the robot’s experiences and generate more complex representations for further concepts. Most notably, this work shows that this competence emerges from the robot’s ability to understand the concepts similarly to human understanding. Such understanding was also maintained when concepts were expressed in multilingual lexicalisations showing that labels represent concepts that allowed the model to adapt to unfamiliar contingencies in which it did not have directly related experiences. The work concludes that language is an essential component of conceptual development, which scaffolds the cognitive continuum of a robot from low-to-high cognitive skills, including its skill to understand.}
}
@article{MANCHES2020105859,
title = {Identifying embodied metaphors for computing education},
journal = {Computers in Human Behavior},
volume = {105},
pages = {105859},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S074756321830623X},
author = {Andrew Manches and Peter E. McKenna and Gnanathusharan Rajendran and Judy Robertson},
keywords = {Embodied cognition, Gesture, Metaphor, Computing education, Computational thinking, Representation},
abstract = {Computing education is increasing in global importance, with calls for greater understanding of conceptual development that can inform pedagogy. Here, we report a study investigating elementary computing concepts through the lens of Embodied Cognition. Sixteen students (9 female) studying university-level computing were asked to explain their understanding of computing concepts (without materials) in individually video-recorded sessions. We analysed the gestures generated for three elementary concepts: algorithms, loops, and conditional statements. In total, 368 representational gestures were identified across 48 (16 × 3) explanations, thereby providing evidence that offline thinking in this domain is embodied. Our analysis of representational gestures showed that participants drew upon two overarching embodied metaphors in their explanations: 1) Computing Constructs as Physical Objects, in which participants simulated manipulating physical objects (e.g., pinching) when referring to range of computing constructs, and 2) Computing Processes as Motion along a Path, whereby participants moved their hands along one of three body-based axes when referring to temporal sequences. We contrast our findings to similar research in mathematics and discuss implications for computing pedagogy – namely the role of gesture in the classroom and technologies that can exploit embodied metaphors.}
}
@article{LIU2023340,
title = {Research on the standardization strategy of granular computing},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {4},
pages = {340-348},
year = {2023},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2023.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2666307423000323},
author = {Donghang Liu and Xuekui Shangguan and Keyu Wei and Chensi Wu and Xiaoying Zhao and Qifeng Sun and Yaoyu Zhang and Ruijun Bai},
keywords = {Granular computing, Standardization strategy, Methodology, Standard system},
abstract = {As intelligent systems continue to evolve, problems are becoming increasingly complex. The constant abundance of data puts a higher demand on the value of data utilization. Granular computing is a new computational paradigm for complex problem-solving. It takes structured thinking, structured problem-solving methods, and structured information processing patterns as its research objects and belongs to the scope of higher-level human cognitive mechanism research. The development and application of granular computing must be more standardized and unified. The granular computing standardization strategy is the most direct means to promote the regularization of granular computing. In this paper, we first sort out the main applications of granular computing in standards. According to the characteristics of granular computing, a framework of its standard system is proposed to provide a reference for the subsequent research of granular computing standards. The next direction of the granular computing standards strategy is discussed, and solutions are given.}
}
@article{LEVIN2019125,
title = {Planarian regeneration as a model of anatomical homeostasis: Recent progress in biophysical and computational approaches},
journal = {Seminars in Cell & Developmental Biology},
volume = {87},
pages = {125-144},
year = {2019},
note = {Planarian regeneration},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2018.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1084952117301970},
author = {Michael Levin and Alexis M. Pietak and Johanna Bischof},
keywords = {Planaria, Dugesia japonica, Regeneration, Patterning, Morphostasis},
abstract = {Planarian behavior, physiology, and pattern control offer profound lessons for regenerative medicine, evolutionary biology, morphogenetic engineering, robotics, and unconventional computation. Despite recent advances in the molecular genetics of stem cell differentiation, this model organism’s remarkable anatomical homeostasis provokes us with truly fundamental puzzles about the origin of large-scale shape and its relationship to the genome. In this review article, we first highlight several deep mysteries about planarian regeneration in the context of the current paradigm in this field. We then review recent progress in understanding of the physiological control of an endogenous, bioelectric pattern memory that guides regeneration, and how modulating this memory can permanently alter the flatworm’s target morphology. Finally, we focus on computational approaches that complement reductive pathway analysis with synthetic, systems-level understanding of morphological decision-making. We analyze existing models of planarian pattern control and highlight recent successes and remaining knowledge gaps in this interdisciplinary frontier field.}
}
@article{ROWAN2024171672,
title = {Digital technologies to unlock safe and sustainable opportunities for medical device and healthcare sectors with a focus on the combined use of digital twin and extended reality applications: A review},
journal = {Science of The Total Environment},
volume = {926},
pages = {171672},
year = {2024},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2024.171672},
url = {https://www.sciencedirect.com/science/article/pii/S004896972401814X},
author = {Neil J. Rowan},
keywords = {Medical devices, Digital transformation, Design thinking, Sterilization, Sustainability, Circularity},
abstract = {Medical devices have increased in complexity where there is a pressing need to consider design thinking and specialist training for manufacturers, healthcare and sterilization providers, and regulators. Appropriately addressing this consideration will positively inform end-to-end supply chain and logistics, production, processing, sterilization, safety, regulation, education, sustainability and circularity. There are significant opportunities to innovate and to develop appropriate digital tools to help unlock efficiencies in these important areas. This constitutes the first paper to create an awareness of and to define different digital technologies for informing and enabling medical device production from a holistic end-to-end life cycle perspective. It describes the added-value of using digital innovations to meet emerging opportunities for many disposable and reusable medical devices. It addresses the value of accessing and using integrated multi-actor HUBs that combine academia, industry, healthcare, regulators and society to help meet these opportunities. Such as cost-effective access to specialist pilot facilities and expertise that converges digital innovation, material science, biocompatibility, sterility assurance, business model and sustainability. It highlights the marked gap in academic R&D activities (PRISMA review of best publications conducted between January 2010 and January 2024) and the actual list of U.S. FDA's approved and marketed artificial intelligence/machine learning (AI/ML), and augmented reality/virtual reality (AR/VR) enabled-medical devices for different healthcare applications. Bespoke examples of benefits underlying future use of digital tools includes potential implementation of machine learning for supporting and enabling parametric release of sterilized products through efficient monitoring of critical process data (complying with ISO 11135:2014) that would benefit stakeholders. This paper also focuses on the transformative potential of combining digital twin with extended reality innovations to inform efficiencies in medical device design thinking, supply chain and training to inform patient safety, circularity and sustainability.}
}
@incollection{PHIPPEN20253,
title = {Artificial Intelligence},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {3-11},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00098-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895000985},
author = {Andy Phippen},
keywords = {Artificial intelligence, Computer science, Deep learning, Digital literacy, Ethics, Information science, Large language models, Machine learning, Natural language processing},
abstract = {Artificial Intelligence (AI) is attracting considerable, and justified, attention about its potential and impact on information systems. However, it is important to look at this evolution against its history. AI’s historical evolution has been beset with underperformance and ethical concerns in data training and responsible deployment. Information science has undergone significant changes with AI׳s integration, impacting information retrieval, classification, and library automation. More specifically Machine Learning plays a crucial role in understanding human requirements for information and processing large data set, but challenges like bias persist. Large Language Models (LLMs) like ChatGPT represent the vanguard of public adoption of AI driven information systems and have exhibited remarkable performance in natural language processing. While they enhance information searching and content creation, users must understand limitations, biases, and practice critical thinking for responsible utilisation in a digital age.}
}
@article{HAN2020382,
title = {A computational approach for using social networking platforms to support creative idea generation},
journal = {Procedia CIRP},
volume = {91},
pages = {382-387},
year = {2020},
note = {Enhancing design through the 4th Industrial Revolution Thinking},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.02.190},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120308374},
author = {Ji Han and Dongmyung Park and Hannah Forbes and Dirk Schaefer},
keywords = {Creativity, Social Media, Idea Generation, Social Networking, Ideation},
abstract = {Good design relies upon the generation of good ideas, but producing ideas, especially creative ones, is increasingly challenging. This may be due to limited relevant information, lack of creative skills, design fixation, or as a result of too many previously existing ideas. Conventional creativity tools, such as brainstorming and TRIZ, as well as advanced methods, such as design-by-analogy, are often employed by designers for idea generation to alleviate some of these challenges. In recent years, computational creativity tools have emerged to support creative idea generation. However, most of these computational tools are data-driven, and thereby employ various databases, for example, existing databases such as the ConceptNet containing past common-sense knowledge, and customized ones containing limited information. The limitations of these databases have constrained the capability of the computational creativity tools. Social media platforms, such as Twitter and Wikipedia, which allow users to create web-based content, have been reported to have billions of users. It can be considered a huge ‘unorganized’ database of information created by a crowd. However, to date little work has been done on the utilization of such crowd-generated knowledge from social media to support actual design activities, especially during the early stages of the design process. In this paper, the authors propose a computational approach to retrieve, process, and reuse the textual knowledge from social networks to prompt designers’ creative mind in producing ideas for new product design and development. They also propose a novel approach to construct crowd knowledge databases, which can be employed by computational tools, as well as used individually, for supporting creative idea generation. A case study involving the use of an existing social media analysis tool to construct a crowd database for helping designers produce ideas has been conducted to provide insights on implementing the proposed approach for creative idea generation.}
}
@article{DROSATOS2014170,
title = {Privacy-preserving computation of participatory noise maps in the cloud},
journal = {Journal of Systems and Software},
volume = {92},
pages = {170-183},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214000430},
author = {George Drosatos and Pavlos S. Efraimidis and Ioannis N. Athanasiadis and Matthias Stevens and Ellie D’Hondt},
keywords = {Privacy-preserving computation, Cloud computing, Participatory sensing},
abstract = {This paper presents a privacy-preserving system for participatory sensing, which relies on cryptographic techniques and distributed computations in the cloud. Each individual user is represented by a personal software agent, deployed in the cloud, where it collaborates on distributed computations without loss of privacy, including with respect to the cloud service providers. We present a generic system architecture involving a cryptographic protocol based on a homomorphic encryption scheme for aggregating sensing data into maps, and demonstrate security in the Honest-But-Curious model both for the users and the cloud service providers. We validate our system in the context of NoiseTube, a participatory sensing framework for noise pollution, presenting experiments with real and artificially generated data sets, and a demo on a heterogeneous set of commercial cloud providers. To the best of our knowledge our system is the first operational privacy-preserving system for participatory sensing. While our validation pertains to the noise domain, the approach used is applicable in any crowd-sourcing application relying on location-based contributions of citizens where maps are produced by aggregating data – also beyond the domain of environmental monitoring.}
}
@article{SLOOT2012439,
title = {Young Russian researchers take up challenges in the computational sciences},
journal = {Journal of Computational Science},
volume = {3},
number = {6},
pages = {439-440},
year = {2012},
note = {Next Generation Computational Scientists: Russian Federation},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2012.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S1877750312000981},
author = {Peter M.A. Sloot and Alexander V. Boukhanovsky}
}
@article{SCHORLEMMER2021118,
title = {A uniform model of computational conceptual blending},
journal = {Cognitive Systems Research},
volume = {65},
pages = {118-137},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720300759},
author = {Marco Schorlemmer and Enric Plaza},
keywords = {Conceptual blending, Computational creativity, Amalgams, Category theory, Case-based reasoning},
abstract = {We present a mathematical model for the cognitive operation of conceptual blending that aims at being uniform across different representation formalisms, while capturing the relevant structure of this operation. The model takes its inspiration from amalgams as applied in case-based reasoning, but lifts them into category theory so as to follow Joseph Goguen’s intuition for a mathematically precise characterisation of conceptual blending at a representation-independent level of abstraction. We prove that our amalgam-based category-theoretical model of conceptual blending is essentially equivalent to the pushout model in the ordered category of partial maps as put forward by Goguen. But unlike Goguen’s approach, our model is more suitable to capture computational realisations of conceptual blending, and we exemplify this by concretising our model to computational conceptual blends for various representation formalisms and application domains.}
}
@article{ALEXANDROV20151685,
title = {Computational Science Research Methods for Science Education at PG Level},
journal = {Procedia Computer Science},
volume = {51},
pages = {1685-1693},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.305},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915011138},
author = {Nia Alexandrov and Vassil Alexandrov},
keywords = {Computational Science Research Methods, Postgraduate Education, Science Subjects},
abstract = {The role of Computational Science research methods teaching to science students at PG level is to enhance their research profile developing their abilities to investigate complex problems, analyze the resulting data and use adequately HPC environments and tools for computation and visualization. The paper analyses the current state and proposes a program that encompasses mathematical modelling, data science, advanced algorithms development, parallel programming and visualization tools. It also gives examples of specific scientific domains with explicitly taught and embedded Computational Science subjects.}
}
@article{GARDNER201582,
title = {A new Canadian interdisciplinary Ph.D. in computational sciences},
journal = {Journal of Computational Science},
volume = {9},
pages = {82-87},
year = {2015},
note = {Computational Science at the Gates of Nature},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2015.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S1877750315000666},
author = {William B. Gardner and Gary Grewal and Deborah Stacey and David A. Calvert and Stefan C. Kremer and Fangju Wang},
keywords = {Interdisciplinary, Computational science, Computer science, Postgraduate studies},
abstract = {In response to growing demands of society for experts trained in computational skills applied to various domains, the School of Computer Science at the University of Guelph is creating a new approach to doctoral studies called an interdisciplinary Ph.D. in computational sciences. The program is designed to appeal to candidates with strong backgrounds in either computer science or an application discipline who are not necessarily seeking a traditional academic career. Thesis based, it features minimal course requirements and short duration, with the student’s research directed by co-advisors from computer science and the application discipline. The degree program’s rationale and special characteristics are described. Related programs in Ontario and reception of this innovative proposal at the institutional level are discussed.}
}
@article{JOLLY20171,
title = {Computational systems biology of epithelial-hybrid-mesenchymal transitions},
journal = {Current Opinion in Systems Biology},
volume = {3},
pages = {1-6},
year = {2017},
note = {• Mathematical modelling • Mathematical modelling, Dynamics of brain activity at the systems level • Clinical and translational systems biology},
issn = {2452-3100},
doi = {https://doi.org/10.1016/j.coisb.2017.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S2452310016300191},
author = {Mohit Kumar Jolly and Herbert Levine},
keywords = {Metastasis, Epithelial–mesenchymal plasticity, Hybrid epithelial/mesenchymal, Cancer stem cells, Computational modeling},
abstract = {Metastasis accounts for more than 90% of cancer-related deaths, and is fueled by fine-tuned transitions among many cellular phenotypes. Transitions among epithelial (strong cell–cell adhesion, no or little migration), mesenchymal (no cell–cell adhesion, high migration), and hybrid epithelial/mesenchymal (both cell–cell adhesion and cell migration) phenotypes are considered to be a hallmark of metastasis. Recent years have witnessed rapid progress in mapping the regulatory networks underlying these transitions. This progress has enabled the capability to develop computational systems biology models to characterize how various intracellular and extracellular signals can drive these transitions. Here, we discuss how different mathematical models have contributed to elucidating the underlying principles of these transitions and guided further experiments to address key unanswered questions concerning metastasis.}
}
@article{WANG20152603,
title = {Bayesian Computational Sensor Networks: Small-scale Structural Health Monitoring},
journal = {Procedia Computer Science},
volume = {51},
pages = {2603-2612},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.368},
url = {https://www.sciencedirect.com/science/article/pii/S187705091501176X},
author = {Wenyi Wang and Anshul Joshi and Nishith Tirpankar and Philip Erickson and Michael Cline and Palani Thangaraj and Thomas C. Henderson},
keywords = {Bayesian Computational Sensor Networks, Uncertainty, Structural Health Monitoring, Cloud Computing},
abstract = {The Bayesian Computational Sensor Network methodology is applied to small-scale structural health monitoring. A mobile robot, equipped with vision and ultrasound sensors, maps small-scale structures for damage (e.g., holes, cracks) by localizing itself and the damage in the map. The combination of vision and ultrasound reduces the uncertainty in damage localization. The data storage and analysis takes place exploiting cloud computing mechanisms, and there is also an off-line computational model calibration component which returns information to the robot concerning updated on-board models as well as proposed sampling points. The approach is validated in a set of physical experiments.}
}
@incollection{WEIKUM200220,
title = {Chapter 4 - Self-tuning Database Technology and Information Services: From Wishful Thinking to Viable Engineering},
editor = {Philip A. Bernstein and Yannis E. Ioannidis and Raghu Ramakrishnan and Dimitris Papadias},
booktitle = {VLDB '02: Proceedings of the 28th International Conference on Very Large Databases},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {20-31},
year = {2002},
isbn = {978-1-55860-869-6},
doi = {https://doi.org/10.1016/B978-155860869-6/50011-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558608696500111},
author = {Gerhard Weikum and Axel Moenkeberg and Christof Hasse and Peter Zabback},
abstract = {Publisher Summary
The COMFORT project was started in 1990, and it was then expected that automatic tuning could be achieved with a few simple principles. While the feedback control loop framework provides useful guidance, the difficult problems are in the details of the various tuning issues. For robust solutions, workload statistics and mathematical models are key assets, and for viable engineering, these must be carefully designed to ensure acceptable overhead. The field, in general, has made significant progress towards self-tuning database technology, but there is no breakthrough. The biggest challenges that the research community should address as high-priority problems are the interactions of different system components and their tuning knobs, and the interference between different workload classes. For tackling this complexity, it is believed that a drastic simplification of today's overly complex system architectures is overdue. If one is able to build individually self-tuning components, the composition of these building blocks into higher-level e-services with service-quality guarantees seems feasible only with sufficiently simple component interfaces and radical minimization of cross talk.}
}