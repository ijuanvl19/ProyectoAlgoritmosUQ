@article{FEDORENKO2014120,
title = {Reworking the language network},
journal = {Trends in Cognitive Sciences},
volume = {18},
number = {3},
pages = {120-126},
year = {2014},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2013.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S136466131300288X},
author = {Evelina Fedorenko and Sharon L. Thompson-Schill},
keywords = {domain specificity, domain generality, language network, cognitive control, fMRI},
abstract = {Prior investigations of functional specialization have focused on the response profiles of particular brain regions. Given the growing emphasis on regional covariation, we propose to reframe these questions in terms of brain ‘networks’ (collections of regions jointly engaged by some mental process). Despite the challenges that investigations of the language network face, a network approach may prove useful in understanding the cognitive architecture of language. We propose that a language network plausibly includes a functionally specialized ‘core’ (brain regions that coactivate with each other during language processing) and a domain-general ‘periphery’ (a set of brain regions that may coactivate with the language core regions at some times but with other specialized systems at other times, depending on task demands). Framing the debate around network properties such as this may prove to be a more fruitful way to advance our understanding of the neurobiology of language.}
}
@article{NG2025100807,
title = {Proteome-wide assessment of differential missense variant clustering in neurodevelopmental disorders and cancer},
journal = {Cell Genomics},
volume = {5},
number = {4},
pages = {100807},
year = {2025},
issn = {2666-979X},
doi = {https://doi.org/10.1016/j.xgen.2025.100807},
url = {https://www.sciencedirect.com/science/article/pii/S2666979X25000631},
author = {Jeffrey K. Ng and Yilin Chen and Titilope M. Akinwe and Hillary B. Heins and Elvisa Mehinovic and Yoonhoo Chang and David H. Gutmann and Christina A. Gurnett and Zachary L. Payne and Juana G. Manuel and Rachel Karchin and Tychele N. Turner},
keywords = {neurodevelopmental disorders, cancer, clustering algorithm, 3D protein structure models, missense, , somatic, variant interpretation, protein},
abstract = {Summary
Prior studies examining genomic variants suggest that some proteins contribute to both neurodevelopmental disorders (NDDs) and cancer. While there are several potential etiologies, here, we hypothesize that missense variation in proteins occurs in different clustering patterns, resulting in distinct phenotypic outcomes. This concept was first explored in 1D protein space and expanded using 3D protein structure models. Missense de novo variants were examined from 39,883 families with NDDs and missense somatic variants from 10,543 sequenced tumors covering five The Cancer Genome Atlas (TCGA) cancer types and two Catalog of Somatic Mutations in Cancer (COSMIC) pan-cancer aggregates of tissue types. We find 18 proteins with differential missense variation clustering in NDDs compared to cancers and 19 in cancers relative to NDDs. These proteins may be important for detailed assessments in thinking of future prognostic and therapeutic applications. We establish a framework for interpreting missense patterns in NDDs and cancer, using advances in 3D protein structure prediction.}
}
@article{ZAHRAH2024100481,
title = {Unmasking hate in the pandemic: A cross-platform study of the COVID-19 infodemic},
journal = {Big Data Research},
volume = {37},
pages = {100481},
year = {2024},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2024.100481},
url = {https://www.sciencedirect.com/science/article/pii/S2214579624000558},
author = {Fatima Zahrah and Jason R.C. Nurse and Michael Goldsmith},
keywords = {Social media analysis, Cross-platform analysis, Online hate, COVID-19},
abstract = {The past few decades have established how digital technologies and platforms have provided an effective medium for spreading hateful content, which has been linked to several catastrophic consequences. Recent academic studies have also highlighted how online hate is a phenomenon that strategically makes use of multiple online platforms. In this article, we seek to advance the current research landscape by harnessing a cross-platform approach to computationally analyse content relating to the 2020 COVID-19 pandemic. More specifically, we analyse content on hate-specific environments from Twitter, Reddit, 4chan and Stormfront. Our findings show how content and posting activity can change across platforms, and how the psychological components of online content can differ depending on the platform being used. Through this, we provide unique insight into the cross-platform behaviours of online hate. We further define several avenues for future research within this field so as to gain a more comprehensive understanding of the global hate ecosystem.}
}
@article{SUN2025129677,
title = {StereoSqueezeNet: With fewer parameters but higher accuracy than SqueezeNet},
journal = {Neurocomputing},
volume = {627},
pages = {129677},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129677},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225003492},
author = {Qiaoyan Sun and Jianfei Chen},
keywords = {SSNet, Stereo, SqueezeNet, Network compression, Network parameters},
abstract = {Convolutional neural networks (CNNs) have evolved from the initial LeNet to date, and network models have become increasingly deep and comprehensive. It has been proven that deeper networks have better fitting effects, but the corresponding parameter size and computational complexity increase rapidly. With the continuous development of mobile Internet technology, portable devices have been rapidly popularized, and users have put forward more and more demands. Thus, how to design efficient and high-performance lightweight convolutional neural networks (CNNs) is the key to solve this challenging problem. Recently, this type of convolutional neural networks (CNNs)--lightweight convolutional neural networks (CNNs), which adopt the design concept of compression networks and maintain high accuracy with fewer parameters, has attracted increasing attention. SqueezeNet is a lightweight CNN adapting to edge device deployment. Its number of parameters is only 1/50 of AlexNet, but it achieves the same accuracy as AlexNet. In order to make the network more lightweight, inspired by SqueezeNet, MobileNet, SENet, SKNet, AlexNet, etc., in this paper we propose StereoSqueezeNet, using much fewer parameters but achieving even better accuracy than SqueezeNet.}
}
@article{ROHLFS2025128701,
title = {Generalization in neural networks: A broad survey},
journal = {Neurocomputing},
volume = {611},
pages = {128701},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128701},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224014723},
author = {Chris Rohlfs},
keywords = {Literature review, Deep learning, Overfitting, Causality, Domain generalization, Transfer learning, Foundation models, Multimodal, Semantic knowledge, Abstraction, Biologically-inspired},
abstract = {This paper reviews concepts, modeling approaches, and recent findings along a spectrum of different levels of abstraction of neural network models including generalization across (1) Samples, (2) Distributions, (3) Domains, (4) Tasks, (5) Modalities, and (6) Scopes. Strategies for (1) sample generalization from training to test data are discussed, with suggestive evidence presented that, at least for the ImageNet dataset, popular classification models show substantial overfitting. An empirical example and perspectives from statistics highlight how models’ (2) distribution generalization can benefit from consideration of causal relationships and counterfactual scenarios. Transfer learning approaches and results for (3) domain generalization are summarized, as is the wealth of domain generalization benchmark datasets available. Recent breakthroughs surveyed in (4) task generalization include few-shot meta-learning approaches and the emergence of transformer-based foundation models such as those used for language processing. Studies performing (5) modality generalization are reviewed, including those that integrate image and text data and that apply a biologically-inspired network across olfactory, visual, and auditory modalities. Higher-level (6) scope generalization results are surveyed, including graph-based approaches to represent symbolic knowledge in networks and attribution strategies for improving networks’ explainability. Additionally, concepts from neuroscience are discussed on the modular architecture of brains and the steps by which dopamine-driven conditioning leads to abstract thinking.}
}
@article{NIKZAINAL2024101739,
title = {Prof. Serena Nik-Zainal},
journal = {Cell Reports Medicine},
volume = {5},
number = {9},
pages = {101739},
year = {2024},
issn = {2666-3791},
doi = {https://doi.org/10.1016/j.xcrm.2024.101739},
url = {https://www.sciencedirect.com/science/article/pii/S2666379124004695},
author = {Serena Nik-Zainal},
abstract = {Serena Nik-Zainal, MD, PhD, is professor of genomic medicine and bioinformatics and an honorary consultant in clinical genetics at the University of Cambridge. Prof. Nik-Zainal has dedicated her career to studying the physiology of cancer mutagenesis via a combination of computational and experimental work, as well as validation with clinical data. Among the many awards she has earned for her work, she has recently received the 2024 ESMO Award for Translational Research, for the research in the field of mutational signatures and her efforts in translating their use into clinics.}
}
@article{LIU2025103127,
title = {Rethinking multi-level information fusion in temporal graphs: Pre-training then distilling for better embedding},
journal = {Information Fusion},
volume = {121},
pages = {103127},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103127},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525002003},
author = {Meng Liu and Yong Liu and Qianqian Ren and Meng Han},
keywords = {Graph learning, Temporal graph, Pre-training},
abstract = {Temporal graphs occupy an important place in graph data, which store node interactions in sequences, thus enabling a more microscopic view of each node’s dynamics. However, many temporal graph methods primarily concentrate on shallow-level temporal or neighborhood information, while acquiring deep-level community or global graph information necessitates increased computational costs, thereby significantly impacting model efficiency. Inspired by this, we rethink how this information is acquired: if it is difficult to acquire it during model training, why not obtain it before training? Consequently, we propose ReMIT, a novel method for temporal graph learning, which incorporates the concepts of feature pre-training and knowledge distillation to Rethink the embedding of Multi-level Information fusion in Temporal graphs. ReMIT facilitates the “remitting” of prior knowledge to model, wherein hard-to-access information is captured and distilled to the train module by introducing a pre-train module. Experimental results on multiple real-world datasets validate the validity and feasibility of our proposed framework. Our method improves performance by up to 10.2% while reducing almost 30% training time.}
}
@article{ROSS2021100069,
title = {Kinenoetic analysis: Unveiling the material traces of insight},
journal = {Methods in Psychology},
volume = {5},
pages = {100069},
year = {2021},
issn = {2590-2601},
doi = {https://doi.org/10.1016/j.metip.2021.100069},
url = {https://www.sciencedirect.com/science/article/pii/S2590260121000266},
author = {Wendy Ross and Frédéric Vallée-Tourangeau},
keywords = {Insight, Case study, Observation},
abstract = {Research on insight problem solving sets itself a challenging goal: How to explain the origin of a new idea. It compounds the difficulty of this challenge by traditionally seeking to explain the phenomenon in strictly mental terms. Rather, we suggest that thoughts and actions are bound to objects, inviting a granular description of the world within which thinking proceeds. As the reasoner transforms the world, the physical traces of these changes can be mapped in space and time. Not only can the reasoner see these changes, and act upon them, the researcher can develop new inscription devices that captures the trajectory of the creative arc along spatial and temporal coordinates. Kinenoetic is a term we employ to capture the idea that knowledge comes from the movement of objects and that this knowledge is both at the level of the problem-solver and at the level of the researcher. This form of knowledge can only be constructed in problem solving environments where reasoners can manipulate physical elements. A kinenoetic analysis tracks and maps the changes to the object-qua-models of proto solutions, and in the process unveils the physical genesis of new ideas and creativity. Our aim here is to lay out a method for using the objects commonly employed in interactive problem-solving research, tracing the process of thought to elucidate underlying cognitive mechanisms. Thus, the focus turns from the effects of objects on thoughts, to tracing object-thought mutualities as they are enacted and made visible.}
}
@article{WEYDMANN2025111173,
title = {Disentangling negative reinforcement, working memory, and deductive reasoning deficits in elevated BMI},
journal = {Progress in Neuro-Psychopharmacology and Biological Psychiatry},
volume = {136},
pages = {111173},
year = {2025},
issn = {0278-5846},
doi = {https://doi.org/10.1016/j.pnpbp.2024.111173},
url = {https://www.sciencedirect.com/science/article/pii/S0278584624002410},
author = {Gibson Weydmann and Igor Palmieri and Reinaldo A.G. Simões and Samara Buchmann and Eduardo Schmidt and Paulina Alves and Lisiane Bizarro},
keywords = {Overweight, Reinforcement Learning, Working Memory, Computational Modelling},
abstract = {Neuropsychological data suggest that being overweight or obese is associated with a tendency to perseverate behavior despite negative feedback. This deficit might be observed due to other cognitive factors, such as working memory (WM) deficits or decreased ability to deduce model-based strategies when learning by trial-and-error. In the present study, a group of subjects with overweight or obesity (Ow/Ob, n = 30) was compared to normal-weight individuals (n = 42) in a modified Reinforcement Learning (RL) task. The task was designed to control WM effects on learning by manipulating cognitive load and to foster model-based learning via deductive reasoning. Computational modelling and analysis were conducted to isolate parameters related to RL mechanisms, WM use, and model-based learning (deduction parameter). Results showed that subjects with Ow/Ob had a higher number of perseverative errors and used a weaker deduction mechanism in their performance than control individuals, indicating impairments in negative reinforcement and model-based learning, whereas WM impairments were not responsible for deficits in RL. The present data suggests that obesity is associated with impairments in negative reinforcement and model-based learning.}
}
@article{KITTAS2010401,
title = {Evolution of the rate of biological aging using a phenotype based computational model},
journal = {Journal of Theoretical Biology},
volume = {266},
number = {3},
pages = {401-407},
year = {2010},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2010.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022519310003619},
author = {Aristotelis Kittas},
keywords = {Evolution, Aging, Computer simulations, Age-structured populations, Modelling},
abstract = {In this work I introduce a simple model to study how natural selection acts upon aging, which focuses on the viability of each individual. It is able to reproduce the Gompertz law of mortality and can make predictions about the relation between the level of mutation rates (beneficial/deleterious/neutral), age at reproductive maturity and the degree of biological aging. With no mutations, a population with low age at reproductive maturity R stabilizes at higher density values, while with mutations it reaches its maximum density, because even for large pre-reproductive periods each individual evolves to survive to maturity. Species with very short pre-reproductive periods can only tolerate a small number of detrimental mutations. The probabilities of detrimental (Pd) or beneficial (Pb) mutations are demonstrated to greatly affect the process. High absolute values produce peaks in the viability of the population over time. Mutations combined with low selection pressure move the system towards weaker phenotypes. For low values in the ratio Pd/Pb, the speed at which aging occurs is almost independent of R, while higher values favor significantly species with high R. The value of R is critical to whether the population survives or dies out. The aging rate is controlled by Pd and Pb and the amount of the viability of each individual is modified, with neutral mutations allowing the system more “room” to evolve. The process of aging in this simple model is revealed to be fairly complex, yielding a rich variety of results.}
}
@incollection{DUNBAR200113746,
title = {Scientific Reasoning and Discovery, Cognitive Psychology of},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {13746-13749},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/01602-8},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767016028},
author = {K. Dunbar},
abstract = {The cognitive mechanisms underlying scientific thinking and discovery have been investigated using approaches from cognitive psychology, cognitive science, and artificial intelligence. In this article, six overlapping approaches are discussed. First, historical analyses and interviews have provided important information on the types of thinking involved in particular discoveries or used by individual scientists. Second, scientific reasoning has been thought of as a form of inductive thinking, and as a form of problem solving. Researchers using this approach have delineated some of the problem solving and inductive reasoning strategies used in science. Third, much research on errors in scientific reasoning, particularly on the topic of ‘confirmation bias’ has revealed some of the circumstances under which science can go awry. Fourth, many researchers have investigated how children's thinking is similar to, or different from, that of scientists. A fifth approach has been to investigate scientists reasoning live or ‘in vivo’ in their own labs. This work has shown how processes such as analogy, distributed cognition, and specific types of inductive and deductive reasoning strategies are used together by scientists. Finally, the incorporation of cognitive mechanisms into computer programs that make discoveries is seen as an important development in the cognitive psychology of scientific thinking.}
}
@article{BELVEDERE201218,
title = {A computational index derived from whole-genome copy number analysis is a novel tool for prognosis in early stage lung squamous cell carcinoma},
journal = {Genomics},
volume = {99},
number = {1},
pages = {18-24},
year = {2012},
issn = {0888-7543},
doi = {https://doi.org/10.1016/j.ygeno.2011.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0888754311002424},
author = {Ornella Belvedere and Stefano Berri and Rebecca Chalkley and Caroline Conway and Fabio Barbone and Federica Pisa and Kenneth MacLennan and Catherine Daly and Melissa Alsop and Joanne Morgan and Jessica Menis and Peter Tcherveniakov and Kostas Papagiannopoulos and Pamela Rabbitts and Henry M. Wood},
keywords = {Lung cancer, Copy number, Survival, Next-generation sequencing},
abstract = {Squamous cell carcinoma of the lung is remarkable for the extent to which the same chromosomal abnormalities are detected in individual tumours. We have used next generation sequencing at low coverage to produce high resolution copy number karyograms of a series of 89 non-small cell lung tumours specifically of the squamous cell subtype. Because this methodology is able to create karyograms from formalin-fixed paraffin-embedded material, we were able to use archival stored samples for which survival data were available and correlate frequently occurring copy number changes with disease outcome. No single region of genomic change showed significant correlation with survival. However, adopting a whole-genome approach, we devised an algorithm that relates to total genomic damage, specifically the relative ratios of copy number states across the genome. This algorithm generated a novel index, which is an independent prognostic indicator in early stage squamous cell carcinoma of the lung.}
}
@article{ARCHAMBAULT2024102865,
title = {Ethical dimensions of algorithmic literacy for college students: Case studies and cross-disciplinary connections},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {3},
pages = {102865},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102865},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000260},
author = {Susan Gardner Archambault and Shalini Ramachandran and Elisa Acosta and Sheree Fu},
keywords = {Algorithmic literacy, Information literacy, Algorithmic bias, AI ethics, Algorithmic fairness, Computer science education},
abstract = {This article addresses three key questions related to the ethical facets of algorithmic literacy. First, it synthesizes existing literature to identify six core ethical components, including bias, privacy, transparency, accountability, accuracy, and non-maleficence. Second, a crosswalk maps the intersections of these principles across the Association of College and Research Libraries' Framework for Information Literacy for Higher Education and the Association of Computing Machinery's Code of Ethics and Professional Conduct and Joint Statement on Principles for Responsible Algorithmic Systems. This analysis reveals significant overlap on issues like unfairness and transparency, helping prioritize topics for instruction. Finally, case studies showcase pedagogical strategies for teaching ethical considerations, informed by the crosswalk. Workshops for diverse undergraduates and computer science students employed reallife instances of algorithmic bias to prompt reflection on unintended harm, contestability, and responsible development. Pre-post surveys indicated expanded critical perspectives after the interventions. By systematically examining shared values and testing instructional approaches, this study provides practical tools to shape ethical thinking on algorithms. It also demonstrates promising practices for responsibly advancing algorithmic literacy across disciplines. Ultimately, fostering interdisciplinary awareness and multipronged educational initiatives can empower students to question algorithmic authority and biases.}
}
@article{KRONICK2011435,
title = {Compensatory beliefs and intentions contribute to the prediction of caloric intake in dieters},
journal = {Appetite},
volume = {57},
number = {2},
pages = {435-438},
year = {2011},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2011.05.306},
url = {https://www.sciencedirect.com/science/article/pii/S0195666311004636},
author = {Ilana Kronick and Randy P. Auerbach and Christine Stich and Bärbel Knäuper},
keywords = {Compensatory beliefs, Compensatory intentions, Restraint, Disinhibition, Caloric intake, Experience sampling methodology},
abstract = {One cognitive process that impacts dieters’ decision to indulge is the activation of compensatory beliefs. Compensatory beliefs (CBs) are convictions that the consequences of engaging in an indulgent behaviour (eating cake) can be neutralized by the effects of another behaviour (skipping dinner). Using experience sampling methodology, this study hypothesized that, in addition to the cognitive processes associated with restraint and disinhibition, compensatory thinking contributes to the prediction of caloric intake. Results indicated that higher scores on CB, CI and TFEQ-D predicted a greater number of portions eaten signifying that, along with disinhibition, compensatory thinking predicts caloric intake in dieters.}
}
@article{DIAS2022140,
title = {Utilization of the Arena simulation software and Lean improvements in the management of metal surface treatment processes},
journal = {Procedia Computer Science},
volume = {204},
pages = {140-147},
year = {2022},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922007554},
author = {A.S.M.E. Dias and R.M.G. Antunes and A. Abreu and V. Anes and H.V.G. Navas and T. Morgado and J.M.F. Calado},
keywords = {Process management, Arena software, Lean tools, Case study, Metal surface treatments},
abstract = {For companies to stand out in increasingly competitive, dynamic and global markets, they must have customer satisfaction goals, create value through their processes, products and services and also aim for innovation. In this context, computer sciences combined with engineering processes constitutes a powerful way for companies to be able to improve process management, to interact with such markets in an efficient and effective way. The main objective of this article is to use Arena simulation software, to quantitatively predict the impact of improvements applied in metal surface treatment processes, based on tools to support Lean thinking. A case study in a Portuguese company in the metalworking sector is presented, in which it is verified that the proposed improvements in terms of the factory layout and resource management, suggested by the comparison between simulations of the current state of the company and the improved one, streamline the processes of finishing in metals, namely zinc coating and lacquering which prevent the occurrence of oxidation and the consequent corrosion of the base metals, by adding other metals and materials to their surface, which adhere and protect it. Through the results obtained, it is concluded that the reduction of waiting times and transport of stocks without production and of work-in-progress, as well as the increase of the productive capacity, make the company more able to guarantee the satisfaction of the requirements of its customers and improve its positioning in the market compared to its competitors.}
}
@article{JOHNSTON2003325,
title = {Biological computation of image motion from flows over boundaries},
journal = {Journal of Physiology-Paris},
volume = {97},
number = {2},
pages = {325-334},
year = {2003},
note = {Neurogeometry and visual perception},
issn = {0928-4257},
doi = {https://doi.org/10.1016/j.jphysparis.2003.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0928425703000664},
author = {A. Johnston and P.W. McOwan and C.P. Benton},
keywords = {Optic flow, Cortex, Differential forms, Vision, Motion},
abstract = {A theory of early motion processing in the human and primate visual system is presented which is based on the idea that spatio-temporal retinal image data is represented in primary visual cortex by a truncated 3D Taylor expansion that we refer to as a jet vector. This representation allows all the concepts of differential geometry to be applied to the analysis of visual information processing. We show in particular how the generalised Stokes theorem can be used to move from the calculation of derivatives of image brightness at a point to the calculation of image brightness differences on the boundary of a volume in space–time and how this can be generalised to apply to integrals of products of derivatives. We also provide novel interpretations of the roles of direction selective, bi-directional and pan-directional cells and of type I and type II cells in V5/MT.}
}
@article{GOERTZEL199595,
title = {Self-reference, computation, and mind},
journal = {Journal of Social and Evolutionary Systems},
volume = {18},
number = {1},
pages = {95-101},
year = {1995},
issn = {1061-7361},
doi = {https://doi.org/10.1016/1061-7361(95)90018-7},
url = {https://www.sciencedirect.com/science/article/pii/1061736195900187},
author = {Ben Goertzel and Harold Bowman}
}
@incollection{SALTZER20091,
title = {Chapter 1 - Systems},
editor = {Jerome H. Saltzer and M. Frans Kaashoek},
booktitle = {Principles of Computer System Design},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {1-42},
year = {2009},
isbn = {978-0-12-374957-4},
doi = {https://doi.org/10.1016/B978-0-12-374957-4.00010-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780123749574000104},
author = {Jerome H. Saltzer and M. Frans Kaashoek},
abstract = {Publisher Summary
This chapter introduces some of the vocabulary and concepts used in designing computer systems. It also introduces the “systems perspective,” a way of thinking about systems that is global and encompassing rather than focused on particular issues. The usual course of study of computer science and engineering begins with linguistic constructs for describing computations (software) and physical constructs for realizing computations (hardware). To develop applications that have these requirements, the designer must look beyond the software and hardware and view the computer system as a whole. In doing so, the designer encounters many new problems—so many that the limit on the scope of computer systems generally arises neither from laws of physics nor from theoretical impossibility, but rather from limitations of human understanding.}
}
@article{ARUN2009S1116,
title = {P03-117 A bedside schizophrenia thought disorder scale},
journal = {European Psychiatry},
volume = {24},
pages = {S1116},
year = {2009},
note = {17th EPA Congress - Lisbon, Portugal, January 2009, Abstract book},
issn = {0924-9338},
doi = {https://doi.org/10.1016/S0924-9338(09)71349-5},
url = {https://www.sciencedirect.com/science/article/pii/S0924933809713495},
author = {C.P. Arun},
abstract = {Present classification systems for thought disorder lack consistency and require one to remember long-winded definitions limiting their use to research settings. As an extension of recent work in this area (World Congress, 2008), we classify the characteristic thought disorder patterns seen in schizophrenia according to the location of the lesion in notional "threads" of mental computational processes that string speech together. These threads must take both semantics and syntax into consideration in performing their function. When we speak - just as when we write - there is a natural hierarchy topic thread (the topic of the ‘essay’) and multiples of paragraph threads, sentence threads, clause threads, word threads and phoneme threads. Intuitively, we grade the severity of thought disorder depending upon whether a particular thread gets stuck (S), reconnects abnormally (R) or is absent altogether: I.paragraph thread R: Disjointed sentences S: Circumstantiality;II.topic threadR: Tangentiality S: Preoccupatory thinking;III.sentence threads R: Knight's move thinking S: Clause perseveration;IV.clause threads R: Word salad S: Word perseveration, fusion;V.word threads R: Incoherent sounds/ neologisms/ paraphasias S: Phoneme/syllable perseveration;VI.phoneme threads - Failure of production: Mutism.Of course, one must record all the lesions that are present at any given time. This scale incorporates a intuitive progression from mild to severe thought disorder in Schizophrenia. Using the STDS would allow the straightforward ‘bedside’ quantification of the severity of thought disorder and enforce discipline into the thought assessment section of the Mental State Examination.}
}
@article{SU2024108233,
title = {Musical protein: Mapping the time sequence of music onto the spatial architecture of proteins},
journal = {Computer Methods and Programs in Biomedicine},
volume = {252},
pages = {108233},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108233},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724002281},
author = {Jun Su and Peng Zhou},
keywords = {Musical protein, Life of music, Bioinformatics, Stave, Note, Piano, Conversion of music to protein},
abstract = {Background and objective
Music, the ubiquitous language across human cultures, is traditionally considered as a form of art but has been linked to biomolecules in recent years. However, previous efforts have only been addressed on sonification of nucleic acids and proteins to produce so-called life music, the soundscape from the basic building blocks of life. In this study, we attempted to, for the first time, conduct a reverse operation of this process, i.e. conversion of music to protein (CoMtP).
Methods
A novel notion termed musical protein (MP) –– the protein defined by music –– was proposed and, on this basis, we described a computational strategy to map the time sequence of music onto the spatial architecture of proteins, which considered that each note in the stave of a music (target) can be simply characterized by two acoustical quantities and that each residue in the primary sequence of a protein (hit) was represented by amino acid descriptors.
Results
A simulated annealing (SA) algorithm was applied to iteratively generate the best matched MP hit for a music target and structural bioinformatics was then used to model spatial advanced structure for the resulting MP. We also demonstrated that some small MPs derived from music segments may have potential biological functions, which, for example, can serve as antimicrobial peptides (AMPs) to inhibit clinical bacterial strains with moderate or high antibacterial potency.
Conclusions
This work may benefit many aspects; for example, it would open a door for the hearing-impaired persons to ‘listen’ music in a biological vision and could be a mean of exposing students to the concepts of biomolecules at an earlier age through the use of auditory characteristics. The CoMtP would also facilitate the rational design of proteins with biological and medicinal significance.}
}
@article{BLACK202010653,
title = {A revolution in biochemistry and molecular biology education informed by basic research to meet the demands of 21st century career paths},
journal = {Journal of Biological Chemistry},
volume = {295},
number = {31},
pages = {10653-10661},
year = {2020},
issn = {0021-9258},
doi = {https://doi.org/10.1074/jbc.AW120.011104},
url = {https://www.sciencedirect.com/science/article/pii/S0021925817501040},
author = {Paul N. Black},
keywords = {biochemistry, molecular biology, teaching, learning, primary research, leadership, environment, inclusive excellence, STEM education, biochemistry and molecular biology teaching and learning},
abstract = {The National Science Foundation estimates that 80% of the jobs available during the next decade will require math and science skills, dictating that programs in biochemistry and molecular biology must be transformative and use new pedagogical approaches and experiential learning for careers in industry, research, education, engineering, health-care professions, and other interdisciplinary fields. These efforts require an environment that values the individual student and integrates recent advances from the primary literature in the discipline, experimentally directed research, data collection and analysis, and scientific writing. Current trends shaping these efforts must include critical thinking, experimental testing, computational modeling, and inferential logic. In essence, modern biochemistry and molecular biology education must be informed by, and integrated with, cutting-edge research. This environment relies on sustained research support, commitment to providing the requisite mentoring, access to instrumentation, and state-of-the-art facilities. The academic environment must establish a culture of excellence and faculty engagement, leading to innovation in the classroom and laboratory. These efforts must not lose sight of the importance of multidimensional programs that enrich science literacy in all facets of the population, students and teachers in K-12 schools, nonbiochemistry and molecular biology students, and other stakeholders. As biochemistry and molecular biology educators, we have an obligation to provide students with the skills that allow them to be innovative and self-reliant. The next generation of biochemistry and molecular biology students must be taught proficiencies in scientific and technological literacy, the importance of the scientific discourse, and skills required for problem solvers of the 21st century.}
}
@article{LONGIN2022103280,
title = {Augmenting perception: How artificial intelligence transforms sensory substitution},
journal = {Consciousness and Cognition},
volume = {99},
pages = {103280},
year = {2022},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2022.103280},
url = {https://www.sciencedirect.com/science/article/pii/S1053810022000125},
author = {Louis Longin and Ophelia Deroy},
keywords = {Sensory substitution, Sensory extension, Intelligent sensory augmentation, Information quality, Senses, Artificial intelligence},
abstract = {What happens when artificial sensors are coupled with the human senses? Using technology to extend the senses is an old human dream, on which sensory substitution and other augmentation technologies have already delivered. Laser tactile canes, corneal implants and magnetic belts can correct or extend what individuals could otherwise perceive. Here we show why accommodating intelligent sensory augmentation devices not just improves but also changes the way of thinking and classifying former sensory augmentation devices. We review the benefits in terms of signal processing and show why non-linear transformation is more than a mere improvement compared to classical linear transformation.}
}
@article{LORE2024105149,
title = {Using multiple, dynamically linked representations to develop representational competency and conceptual understanding of the earthquake cycle},
journal = {Computers & Education},
volume = {222},
pages = {105149},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105149},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524001635},
author = {Christopher Lore and Hee-Sun Lee and Amy Pallant and Jie Chao},
keywords = {Teaching/learning strategies, Simulations, Pedagogical issues, Applications in subject areas},
abstract = {Using computational methods to produce and interpret multiple scientific representations is now a common practice in many science disciplines. Research has shown students have difficulty in moving across, connecting, and sensemaking from multiple representations. There is a need to develop task-specific representational competencies for students to reason and conduct scientific investigations using multiple representations. In this study, we focus on three representational competencies: 1) linking between representations, 2) disciplinary sensemaking from multiple representations, and 3) conceptualizing domain-relevant content derived from multiple representations. We developed a block code-based computational modeling environment with three different representations and embedded it within an online activity for students to carry out investigations around the earthquake cycle. The three representations include a procedural representation of block codes, a geometric representation of land deformation build-up, and a graphical representation of deformation build-up over time. We examined the extent of students' representational competencies and which competencies are most correlated with students’ future performance in a computationally supported geoscience investigation. Results indicate that a majority of the 431 students showed at least some form of representational competence. However, a relatively small number of students showed sophisticated levels of linking, sensemaking, and conceptualizing from the representations. Five of seven representational competencies, the most prominent being code sensemaking (η2 = 0.053, p < 0.001), were significantly correlated to student performance on a summative geoscience investigation.}
}
@article{ANDERSON2023102027,
title = {Nurse scholars of the Robert Wood Johnson Foundation Harold Amos Medical Faculty Development Program},
journal = {Nursing Outlook},
volume = {71},
number = {5},
pages = {102027},
year = {2023},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2023.102027},
url = {https://www.sciencedirect.com/science/article/pii/S002965542300132X},
author = {Cindy M. Anderson and Nina Ardery and Daniel Pesut and Carmen Alvarez and Tamryn F. Gray and Karen M. Rose and Jasmine L. Travers and Janiece Taylor and Kathy D. Wright},
keywords = {Health professions diversity, Equity, Inclusive excellence, Robert Wood Johnson Foundation, Nurse faculty scholars, Harold Amos, Medical faculty development, Legacy leadership},
abstract = {Background
The challenge to increase the diversity, inclusivity, and equity of nurse scientists is a critical issue to enhance nursing knowledge development, health care, health equity, and health outcomes in the United States.
Purpose
The purpose of this paper is to highlight the current nurse scholars in the Robert Wood Johnson Foundation (RWJF) Harold Amos Medical Faculty Development Program (AMFDP).
Discussion
Profiles and the programs of research and scholarship of the current AMFDP nurse scholars are described and discussed. Scholars share lessons learned, and how the AMFDP program has influenced their thinking and commitments to future action in service of nursing science, diversity efforts, legacy leadership, issues of health equity.
Conclusion
RWJF has a history of supporting the development of nursing scholars. AMFDP is an example of legacy leadership program that contributes to a culture of health and the development of next-generation nursing science scholars.}
}
@article{GOLDBERG2012261,
title = {An efficient tree-based computation of a metric comparable to a natural diffusion distance},
journal = {Applied and Computational Harmonic Analysis},
volume = {33},
number = {2},
pages = {261-281},
year = {2012},
issn = {1063-5203},
doi = {https://doi.org/10.1016/j.acha.2011.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1063520311001266},
author = {Maxim J. Goldberg and Seonja Kim},
keywords = {Tree, Diffusion, Distance, Metric},
abstract = {Using diffusion to define distances between points on a manifold (or a sampled data set) has been successfully employed in various applications such as data organization and approximately isometric embedding of high dimensional data in low dimensional Euclidean space. Recently, P. Jones has proposed a diffusion distance which is both intuitively appealing and scales appropriately with increasing time. In the first part of our paper, we present an efficient tree-based approach to computing an approximation to Jonesʼs diffusion distance. We also show our approximation is comparable to Jonesʼs distance. Neither Jonesʼs distance, nor our approximation, satisfies the triangle inequality; in particular, in the case of heat flow on Rn, Jonesʼs separation distance gives a scaled square of the Euclidean distance. In the second part of our paper, we present a general construction to obtain an “almost” metric from a general distance. We also discuss a numerical procedure to implement our construction. Additionally, we show that in the case of heat flow on Rn, we recover (scaled) Euclidean distance from Jonesʼs distance.}
}
@article{PARK2023101271,
title = {The impact of research and representation of site analysis for creative design approach in architectural design studio},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101271},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101271},
url = {https://www.sciencedirect.com/science/article/pii/S187118712300041X},
author = {Eun Joo Park and Keunhye Lee and Eunki Kang},
keywords = {Architectural design studio, Creative thinking, Design education, Design methodology, Site analysis},
abstract = {In the context of architectural education, design studio projects generally begin with the research of design themes and contexts; however, few attempts have been made to appreciate site analysis as reliable architectural design research. This study aims to explore strategies that link site analysis and design application to bridge the gap between research and representation as a framework for applying architectural design education. To bridge this knowledge gap, this study describes four phases of site analysis—(1) site selection, (2) site survey, (3) problem identification, and (4) suggestion for the design approach —in which visual expression of the representation technique was explored to develop a creative design approach through observation and analysis of students’ work. A curriculum that adopts the four phases of site analysis was developed based on the SPC and expanded for second-year architecture students in the university. The results showed that there are differences between architecture students in schematizing specific ideas and analysis methods, and that a substantial change in the process occurs when including visual expression in site analysis. In addition, the combination of group-based work and site analysis led to problem-solving that showed co-evolution. Finally, the study describes how research shapes site analysis and explains how representation can contribute to understanding the research. Site analysis consists of an initial attempt to explore research related to creative approaches, and may benefit both architecture educators and students.}
}
@article{OMORI19991157,
title = {Emergence of symbolic behavior from brain like memory with dynamic attention},
journal = {Neural Networks},
volume = {12},
number = {7},
pages = {1157-1172},
year = {1999},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(99)00054-4},
url = {https://www.sciencedirect.com/science/article/pii/S0893608099000544},
author = {T. Omori and A. Mochizuki and K. Mizutani and M. Nishizaki},
keywords = {Symbolic behavior, Associative memory, Attention, PATON, Inference, Hippocampus, Model, Computational theory},
abstract = {An important feature of human intelligence is the use of symbols. This is seen in our daily use of language and logical thinking. However, the use of symbols is not limited to humans. We observe planned action sequences in primate behavior and prediction-based action in higher mammals. For the representation and operation of symbols by the brain neural circuit, no specific construction principle or computational theory is known so far. In this paper, we regard the brain as a complex of associative memory and dynamic attentional system, and starting from two hypotheses on information representation and operation in the brain, we propose a model of primitive symbolic behavior emergence that is consistent with the conventional symbolic processing model. We also describe a computational theory of the symbolic processing model in associative memory. Through computer simulation studies on a language-like memory search and map learning by a moving robot, we discuss the validity of the model.}
}
@incollection{MARON1965118,
title = {On Cybernetics, Information Processing, and Thinking},
editor = {Norbert Wiener and J.P. Schadé},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {17},
pages = {118-138},
year = {1965},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(08)60158-2},
url = {https://www.sciencedirect.com/science/article/pii/S0079612308601582},
author = {M.E. Maron},
abstract = {Publisher Summary
It is the purpose of this chapter to examine the origins, development, and present status of those key cybernetic notions that provide an information-flow framework within which to attack one aspect of the question of how a person thinks— that is,.the question of the information mechanisms and processes that underlie and are correlated with thinking. After an introductory survey of the scope and ramifications of the information sciences, the cybernetic way of looking at the information processing in the nervous system is examined, so as to see in what sense it provides new and sharp tools of analysis for the neurophysiologist. With this as background, the problem of artificial intelligence is considered and with that the logical and linguistic difficulties in talking about the relationship between thinking and brain activity. An information-flow model of an artificial brain mechanism is described whose activity; it is argued is the correlate to activity, such as perceiving, learning, thinking, knowing, etc. This leads finally to a consideration of the impact of these notions on theoretical neurophysiology and its attempt to frame suitable hypotheses and on epistemology that is concerned with the logical analysis of measures, methods, and techniques, which can justify the activity of knowing.}
}
@article{MACHADO2023101290,
title = {A multiple criteria framework to assess learning methodologies},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101290},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101290},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000603},
author = {Rafaela Heloisa Carvalho Machado and Samuel Vieira Conceição and Renata Pelissari and Sarah Ben Amor and Thiago Lombardi Resende},
keywords = {Active learning methodologies, Skills, Multiple criteria decision making, MCDA, MCDM},
abstract = {New job skills required by the professional market have been causing significant changes in the learning process of undergraduate students. Different learning methodologies can be adopted to assist in the development of those skills, and the process of choosing the most suitable learning methodology for each situation may be complex, involving multiple and conflicting criteria. In order to support the choice of learning methodologies for the development of the “4C skills”, i.e, collaboration, communication, creativity and critical thinking, we propose a new framework based on the multiple criteria decision-making approach PROMETHEE II (Preference Ranking Organization Method for Enrichment of Evaluations), considering as criteria the “4C skills”, student motivation, level of learning, student comfort, decision-making capacity and time required for class preparation. Passive methods and active learning methodologies such as Guided Reciprocal Peer Questioning (GRPQ), Think-Pair-Share (TPS), and Problem Based Learning (PBL) are compared. Each methodology was applied to three groups of students of Industrial Engineering of a Brazilian University, totaling 138 students. As a result, PBL obtained the best assessment in the three groups, followed by GRPQ. The proposed framework validates the assessment of learning methodologies, providing a structure and guideline for its replication in other educational institutions.}
}
@article{CEKIRGE199465,
title = {An appropriate algorithm in parallel computations for three-dimensional hydrodynamics},
journal = {Mathematical and Computer Modelling},
volume = {20},
number = {1},
pages = {65-84},
year = {1994},
issn = {0895-7177},
doi = {https://doi.org/10.1016/0895-7177(94)90219-4},
url = {https://www.sciencedirect.com/science/article/pii/0895717794902194},
author = {H.M. Cekirge and J. Berlin and R.A. Bernatz and M. Koch},
keywords = {Methods of characteristics, Tidal currents, Parallel computations, Three-dimensional hydrodynamics, Tidal currents in the Arabian Gulf},
abstract = {There are a number of numerical methods for solving three-dimensional hydrodynamical models. An important aspect of any method is its efficient use of parallel computer architectures in an effort to minimize the clock time requirements in certain simulations such as oil spill modeling which uses three-dimensional hydrodynamics. The vertical-horizontal splitting (VHS) algorithm, using the method of characteristics for the two-dimensional horizontal plane and a generalization of the Crank-Nicholson method for vertical integration, is well-suited for the parallel architecture of the CM-2 machine.}
}
@article{CHINTA20248181,
title = {Cascade reactions of HDDA-benzynes with tethered cyclohexadienones: strain-driven events originating from ortho-annulated benzocyclobutenes††Electronic supplementary information (ESI) available. CCDC 2302618–2302621. For ESI and crystallographic data in CIF or other electronic format see DOI: https://doi.org/10.1039/d4sc00571f},
journal = {Chemical Science},
volume = {15},
number = {21},
pages = {8181-8189},
year = {2024},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d4sc00571f},
url = {https://www.sciencedirect.com/science/article/pii/S2041652024006813},
author = {Bhavani Shankar Chinta and Dorian S. Sneddon and Thomas R. Hoye},
abstract = {Intramolecular net [2 + 2] cycloadditions between benzyne intermediates and an electron-deficient alkene to give benzocyclobutene intermediates are relatively rare. Benzynes are electrophilic and generally engage nucleophiles or electron-rich π-systems. We describe here reactions in which an alkene of a tethered enone traps thermally generated benzynes in a variety of interesting ways. The number of atoms that link the benzyne to C4 of a cyclohexa-2,5-dienone induces varying amounts of strain in the intermediates and products. This leads to a variety of different reaction outcomes by way of various strain-releasing events that are mechanistically intriguing. This work demonstrates an underappreciated class of strain that originates from the adjacent fusion of two rings to both C1–C2 and C2–C3 of a benzenoid ring – i.e. ‘ortho-annulation strain’. DFT computations shed considerable light on the mechanistic diversions among various reaction pathways as well as allow more fundamental evaluation of the strain in a homologous series of ortho-annulated carbocycles.}
}
@article{BEAR2020104057,
title = {What comes to mind?},
journal = {Cognition},
volume = {194},
pages = {104057},
year = {2020},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2019.104057},
url = {https://www.sciencedirect.com/science/article/pii/S0010027719302306},
author = {Adam Bear and Samantha Bensinger and Julian Jara-Ettinger and Joshua Knobe and Fiery Cushman},
keywords = {Sampling, Decision-making, Consciousness, Computation},
abstract = {When solving problems, like making predictions or choices, people often “sample” possibilities into mind. Here, we consider whether there is structure to the kinds of thoughts people sample by default—that is, without an explicit goal. Across three experiments we found that what comes to mind by default are samples from a probability distribution that combines what people think is likely and what they think is good. Experiment 1 found that the first quantities that come to mind for everyday behaviors and events are quantities that combine what is average and ideal. Experiment 2 found, in a manipulated context, that the distribution of numbers that come to mind resemble the mathematical product of the presented statistical distribution and a (softmax-transformed) prescriptive distribution. Experiment 3 replicated these findings in a visual domain. These results provide insight into the process generating people’s conscious thoughts and invite new questions about the value of thinking about things that are both likely and good.}
}
@article{MARRET2025597,
title = {Turning the kaleidoscope: Innovations shaping the future of clinical trial design},
journal = {Cancer Cell},
volume = {43},
number = {4},
pages = {597-605},
year = {2025},
issn = {1535-6108},
doi = {https://doi.org/10.1016/j.ccell.2025.02.019},
url = {https://www.sciencedirect.com/science/article/pii/S1535610825000716},
author = {Grégoire Marret and Mercedes Herrera and Lillian L. Siu},
abstract = {Current clinical trials are based on rigid designs and drug-centric approaches that can stifle flexibility and innovation. With advances in molecular biology and technology, there is an urgent call to revitalize trial designs to meet these evolving demands. We propose a reshaped, prismatic vision of clinical trials combining different knowledge layers, synergized with modern computational approaches. This paradigm based on iterative learning will enable a more adaptive and precise framework for oncology drug development.}
}
@article{BERRUTO2024858,
title = {Engineering agricultural soil microbiomes and predicting plant phenotypes},
journal = {Trends in Microbiology},
volume = {32},
number = {9},
pages = {858-873},
year = {2024},
issn = {0966-842X},
doi = {https://doi.org/10.1016/j.tim.2024.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0966842X2400043X},
author = {Chiara A. Berruto and Gozde S. Demirer},
keywords = {rhizosphere engineering, plant microbiome, machine learning, community modeling, host–microbe interactions, microbiome-associated phenotype},
abstract = {Plant growth-promoting rhizobacteria (PGPR) can improve crop yields, nutrient use efficiency, plant tolerance to stressors, and confer benefits to future generations of crops grown in the same soil. Unlocking the potential of microbial communities in the rhizosphere and endosphere is therefore of great interest for sustainable agriculture advancements. Before plant microbiomes can be engineered to confer desirable phenotypic effects on their plant hosts, a deeper understanding of the interacting factors influencing rhizosphere community structure and function is needed. Dealing with this complexity is becoming more feasible using computational approaches. In this review, we discuss recent advances at the intersection of experimental and computational strategies for the investigation of plant–microbiome interactions and the engineering of desirable soil microbiomes.}
}
@article{FILIPPOU2016892,
title = {Modelling the impact of study behaviours on academic performance to inform the design of a persuasive system},
journal = {Information & Management},
volume = {53},
number = {7},
pages = {892-903},
year = {2016},
note = {Special Issue on Papers Presented at Pacis 2015},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2016.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0378720616300507},
author = {Justin Filippou and Christopher Cheong and France Cheong},
keywords = {Study behaviour, Persuasive systems, Linear modelling, Higher education},
abstract = {Information technology is deeply ingrained in most aspects of everyday life and can be designed to influence users to behave in a certain way. Influencing students to improve their study behaviour would be a useful application of this technology. As a preamble to the design of a persuasive system for learning, we collected data to identify the study behaviours of students and recent alumni. We then developed two models to measure which behaviours have the most significant impact on learning performance. Current students reported more foundational behaviours whereas alumni demonstrated more higher-order thinking traits.}
}
@article{VERNON2019122,
title = {Internal simulation in embodied cognitive systems: Comment on “Muscleless motor synergies and actions without movements: From motor neuroscience to cognitive robotics” by Vishwanathan Mohan et al.},
journal = {Physics of Life Reviews},
volume = {30},
pages = {122-125},
year = {2019},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2019.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S1571064519300429},
author = {David Vernon},
keywords = {Internal simulation, Embodied cognition, Cognitive robotics, Episodic future thinking}
}
@article{VIERTEL2019109,
title = {A Computational model of the mammalian external tufted cell},
journal = {Journal of Theoretical Biology},
volume = {462},
pages = {109-121},
year = {2019},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2018.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0022519318304752},
author = {Ryan Viertel and Alla Borisyuk},
keywords = {External tufted cell, Bursting, Glomerulus, Olfactory bulb, Hodgkin Huxley model},
abstract = {We introduce a novel detailed conductance-based model of the bursting activity in external tufted (ET) cells of the olfactory bulb. We investigate the mechanisms underlying their bursting, and make experimentally-testable predictions. The ionic currents included in the model are specific to ET cells, and their kinetic and other parameters are based on experimental recordings. We validate the model by showing that its bursting characteristics under various conditions (e.g. blocking various currents) are consistent with experimental observations. Further, we identify the bifurcation structure and dynamics that explain bursting behavior. This analysis allows us to make predictions of the response of the cell to current pulses at different burst phases. We find that depolarizing (but not hyperpolarizing) inputs received during the interburst interval can advance burst timing, creating the substrate for synchronization by excitatory connections. It has been hypothesized that such synchronization among the ET cells within one glomerulus might help coordinate the glomerular output. Next we investigate model parameter sensitivity and identify parameters that play the most prominent role in controlling each burst characteristic, such as the burst frequency and duration. Finally, the response of the cell to periodic inputs is examined, reflecting the sniffing-modulated input that these cell receive in vivo. We find that individual cells can be better entrained by inputs with higher, rather than lower, frequencies than the intrinsic bursting frequency of the cell. Nevertheless, a heterogeneous population of ET cells (as may be found in a glomerulus) is able to produce reliable periodic population responses even at lower input frequencies.}
}
@article{ZHOU2025101900,
title = {Parking Vehicle-Assisted Task Offloading in Edge Computing: A dynamic multi-objective evolutionary algorithm with multi-strategy fusion response},
journal = {Swarm and Evolutionary Computation},
volume = {94},
pages = {101900},
year = {2025},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2025.101900},
url = {https://www.sciencedirect.com/science/article/pii/S2210650225000586},
author = {Yingbo Zhou and Zheng-Yi Chai and Ya-Lun Li and Jun-Jie Li},
keywords = {Vehicle edge computing, Dynamic multi-objective optimization, Evolutionary algorithms, Computational offloading, Vehicle collaboration},
abstract = {Vehicle-edge computing, as a promising paradigm, is employed to support applications that require low latency and high computational capability. In this study, we consider the idle resources of the surrounding parked vehicles (PVs) and roadside units (RSUs) as service providers to enhance the performance of User Equipment (UE). We propose a joint offloading architecture that uses parked vehicles. Additionally, owing to the dynamic and uncertain nature of the environment, we model computation offloading as a dynamic multi-objective optimization problem to simultaneously optimize the latency and energy consumption of UE applications. In this study, we propose a dynamic multi-objective evolutionary algorithm with a multi-strategy fusion response (DMOEA/D-MSFR). Specifically, we introduce a population center positioning strategy and a learnable prediction mechanism using Long Short-Term Memory (LSTM) in DMOEA-MSFR, which divides the prediction optimization process into two stages and exhibits a rapid response to environmental changes. In the static optimization phase, an adaptive weight vector adjustment strategy is employed, which significantly aids in the distribution and diversity of the solutions. Comprehensive experiments demonstrate that our proposed framework balances the trade-off between latency and energy consumption, and the convergence, feasibility, and diversity of the non-dominated solutions obtained.}
}
@article{DIACOPOULOS2020103911,
title = {A systematic review of mobile learning in social studies},
journal = {Computers & Education},
volume = {154},
pages = {103911},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103911},
url = {https://www.sciencedirect.com/science/article/pii/S036013152030110X},
author = {Mark Michael Diacopoulos and Helen Crompton}
}
@article{RICHARDSON1991305,
title = {Computational physics on the CM-2 supercomputer},
journal = {Physics Reports},
volume = {207},
number = {3},
pages = {305-320},
year = {1991},
issn = {0370-1573},
doi = {https://doi.org/10.1016/0370-1573(91)90149-G},
url = {https://www.sciencedirect.com/science/article/pii/037015739190149G},
author = {John L. Richardson},
abstract = {The Connection Machine Supercomputer system is described with emphasis on the solution to large scale physics problems. Numerous parallel algorithms as well as their implementation are given that demonstrate the use of the Connection Machine for physical simulations. Applications discussed include classical mechanics, quantum mechanics, electromagnetism, fluid flow, statistical physics and quantum field theories. The visualization of physical phenomena is also discussed and in the lectures video tapes demonstrating this capability are shown. Connection Machine performance and I/O characteristics are also described as well as the CM-2 software.}
}
@article{TEO2024102655,
title = {Age-appropriate adaptation of creativity tasks for infants aged 12–24 months},
journal = {MethodsX},
volume = {12},
pages = {102655},
year = {2024},
issn = {2215-0161},
doi = {https://doi.org/10.1016/j.mex.2024.102655},
url = {https://www.sciencedirect.com/science/article/pii/S2215016124001092},
author = {Ling Zheng Teo and Victoria Leong},
keywords = {Precursors of creativity, Infancy, Measurements of creativity},
abstract = {Creativity is an important skill that relates to innovation, problem-solving and artistic achievement. However, relatively little is known about the early development of creative potential in very young children, in part due to a paucity of tasks suitable for use during infancy. Current measures of creativity in early childhood include the Unusual Box Test, Torrance's Thinking Creatively in Action and Movement (TCAM) task and the Toca Kitchen Monsters task. These tasks are designed for children aged above 12, 36 and 18 months respectively, but very few measures of creativity can be used for infants aged below 2. Accordingly, here we report age-appropriate adaptations of TCAM and Toca Kitchen Monsters tasks for infants as young as 12 to 24 months. Considerations taken into account include (1) infants’ cognitive capacities (i.e., attention span, language comprehension skills, motor skills, and approach to play), and (2) practicality of the stimuli, including suitability for use amid the COVID-19 pandemic. The modified creativity battery for infants includes three tasks: Music Play, Object Play and Exploratory Play tasks. The task protocols elaborated in this paper are intended to facilitate studies on the early development of creativity in infants aged between 12 and 24 months. Primary highlights include:•Age-appropriate adaptation of creativity tasks for use with infants aged between 12 and 24 months.•Consideration of infants’ cognitive capacities and stimulus practicality.•Innovative use of movement as expression of infants’ creative behaviour.}
}
@incollection{KIHLSTROM2018,
title = {Cognitive Psychology: Overview☆},
booktitle = {Reference Module in Neuroscience and Biobehavioral Psychology},
publisher = {Elsevier},
year = {2018},
isbn = {978-0-12-809324-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.21702-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245217021},
author = {John F. Kihlstrom and Lillian Park},
keywords = {Cognition, Sensation, Perception, Attention, Memory, Categorization, Learning, Language, Reasoning, Judgment, Decision-making, Choice, Cognitive development, Cognitive neuroscience, Cognitive sociology},
abstract = {Cognitive psychology seeks to understand how we acquire knowledge about ourselves and the world, how this knowledge is represented in the mind and brain, and how we use knowledge to guide behavior. Major topics in cognitive psychology include sensation and perception, attention, memory, categorization, learning, language and communication, and thinking, reasoning, judgment, and decision-making. Cognitive development is discussed from both an ontogenetic and phylogenetic point of view. Cognitive neuroscience explores the neural substrates of cognitive processes. The cognitive point of view has been extended to personality, social, and clinical psychology, as well as to sociology, anthropology, and other social-science disciplines.}
}
@article{IYER2024e32546,
title = {Inspiring a convergent engineering approach to measure and model the tissue microenvironment},
journal = {Heliyon},
volume = {10},
number = {12},
pages = {e32546},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32546},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024085773},
author = {Rishyashring R. Iyer and Catherine C. Applegate and Opeyemi H. Arogundade and Sushant Bangru and Ian C. Berg and Bashar Emon and Marilyn Porras-Gomez and Pei-Hsuan Hsieh and Yoon Jeong and Yongdeok Kim and Hailey J. Knox and Amir Ostadi Moghaddam and Carlos A. Renteria and Craig Richard and Ashlie Santaliz-Casiano and Sourya Sengupta and Jason Wang and Samantha G. Zambuto and Maria A. Zeballos and Marcia Pool and Rohit Bhargava and H. Rex Gaskins},
keywords = {Bioengineering, Interdisciplinary research, Bioimaging, Biomaterials, Biosensing, Computational biology, Biomedical devices, Biotechnology},
abstract = {Understanding the molecular and physical complexity of the tissue microenvironment (TiME) in the context of its spatiotemporal organization has remained an enduring challenge. Recent advances in engineering and data science are now promising the ability to study the structure, functions, and dynamics of the TiME in unprecedented detail; however, many advances still occur in silos that rarely integrate information to study the TiME in its full detail. This review provides an integrative overview of the engineering principles underlying chemical, optical, electrical, mechanical, and computational science to probe, sense, model, and fabricate the TiME. In individual sections, we first summarize the underlying principles, capabilities, and scope of emerging technologies, the breakthrough discoveries enabled by each technology and recent, promising innovations. We provide perspectives on the potential of these advances in answering critical questions about the TiME and its role in various disease and developmental processes. Finally, we present an integrative view that appreciates the major scientific and educational aspects in the study of the TiME.}
}
@article{PAN2025125506,
title = {CISL-PD: A deep learning framework of clinical intervention strategies for Parkinson’s disease based on directional counterfactual Dual GANs},
journal = {Expert Systems with Applications},
volume = {261},
pages = {125506},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125506},
url = {https://www.sciencedirect.com/science/article/pii/S095741742402373X},
author = {Changrong Pan and Yu Tian and Lingyan Ma and Tianshu Zhou and Shuyu Ouyang and Jingsong Li},
keywords = {Parkinson’s disease, Intervention strategies, Counterfactual generation, Generative Adversarial Network},
abstract = {Parkinson’s disease (PD) is a prevalent chronic neurodegenerative disorder characterized by both motor and non-motor symptoms. The significant heterogeneity among PD patients poses a major challenge for treatment interventions. Current clinical interventions for PD primarily target motor symptoms, often neglecting non-motor symptoms, which can lead to unnecessary complications in non-motor symptoms while treating motor symptoms. Therefore, it is crucial to provide comprehensive and precise intervention strategies that encompass both symptom types. To address this issue, we develop a deep learning framework of clinical intervention strategies for PD (CISL-PD) based on counterfactual thinking. This framework introduces Directional Counterfactual Dual Generative Adversarial Networks (DCD-GANs), which apply various counterfactual constraints to longitudinal data to generate practical and plausible counterfactual instances aligned with clinical reality. By analyzing these counterfactual instances and their differences from the original instances, we explore PD intervention strategies with duration-specific fine regulation of multidimensional features. Experiments conducted on 374 PD patients from the Parkinson’s Progression Markers Initiative (PPMI) demonstrate that the counterfactual instances generated by DCD-GANs surpass other state-of-the-art models in terms of similarity (0.307 ± 0.246), sparsity (0.513 ± 0.161), smoothness (0.238 ± 0.135), and trend consistency (0.100 ± 0.089). From these generated counterfactual instances, we develop three clinically feasible intervention strategies that address both motor and non-motor symptoms and identify corresponding patterns of PD with distinct progression differences. Validation on an independent cohort of 351 patients from the National Institute of Neurological Disorders and Stroke Parkinson’s Disease Biomarkers Program (PDBP) confirmed the framework’s robustness and generalizability. By offering precise, multidimensional intervention strategies that can address both motor and non-motor symptoms, the CISL-PD framework has the potential to enhance patient outcomes, reduce complications, improve overall quality of life, and guide clinical decision-making.}
}
@article{ZHANG2024100667,
title = {Research on the application value of Multimedia-Based virtual reality technology in drama education activities},
journal = {Entertainment Computing},
volume = {50},
pages = {100667},
year = {2024},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100667},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124000351},
author = {Bingyu Zhang and Wenwen Jiang},
keywords = {Multimedia, Virtual reality, Academic technology, Drama education, and ANOVA},
abstract = {The research and moral use of academic technology focuses on developing, implementing, and overseeing the use of suitable technical resources and procedures to enhance learning and achievement. Multimedia has found its position in some form as an educational technology platform in the contemporary environment of academic universities. The use of virtual reality software as an intellectual tool and learning provider allows students to perform cognitive rehabilitation of preexisting information frameworks. People are paying more and more attention to how preschoolers' holistic skills develop as education reform progresses. Drama education is incorporated into the school curriculum to enhance young children's artistic, intellectual, and linguistic skills. Therefore, this study aims to examine the potential of multimedia-based virtual reality technology (MVRT) in drama education. The participants in this study were students from different universities in China. Students were exposed to multimedia-based virtual reality technology, and its efficacy was assessed using a statistical analytic approach called Analysis of variance (ANOVA). Drama understanding rate, educational improvement ratio, teaching quality rate, student achievement ratio, computation time, and parental support rate are among the performance metrics used to assess performance. Multimedia-based virtual reality technology (MVRT) for drama education showed outstanding success, with a 98% improvement ratio in educational outcomes and higher teaching quality. Students exhibited improved performance, supported by solid parental approval, demonstrating the effectiveness of MVRT in enhancing educational experiences.}
}
@article{MORABIA2020164,
title = {Pandemics and methodological developments in epidemiology history},
journal = {Journal of Clinical Epidemiology},
volume = {125},
pages = {164-169},
year = {2020},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2020.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0895435620306454},
author = {Alfredo Morabia},
keywords = {Epidemiology, History, Pandemics, Covid-19, Plague, Cholera, Tuberculosis, Influenza, HIV/AIDS},
abstract = {The crisis spurred by the pandemic of COVID-19 has revealed weaknesses in our epidemiologic methodologic corpus, which scientists are struggling to compensate. This article explores whether this phenomenon is characteristic of pandemics or not. Since the emergence of population-based sciences in the 17th century, we can observe close temporal correlations between the plague and the discovery of population thinking, cholera and population-based group comparisons, tuberculosis and the formalization of cohort studies, the 1918 Great Influenza and the creation of an academic epidemiologic counterpart to the public health service, the HIV/AIDS epidemic, and the formalization of causal inference concepts. The COVID-19 pandemic seems to have promoted the widespread understanding of population thinking both with respect to ways of flattening an epidemic curve and the societal bases of health inequities. If the latter proves true, it will support my hypothesis that pandemics did accelerate profound changes in epidemiologic methods and concepts.}
}
@article{RYLE1953189,
title = {Thinking},
journal = {Acta Psychologica},
volume = {9},
pages = {189-196},
year = {1953},
issn = {0001-6918},
doi = {https://doi.org/10.1016/0001-6918(53)90012-2},
url = {https://www.sciencedirect.com/science/article/pii/0001691853900122},
author = {Gilbert Ryle}
}
@incollection{MAIDA201639,
title = {Chapter 2 - Cognitive Computing and Neural Networks: Reverse Engineering the Brain},
editor = {Venkat N. Gudivada and Vijay V. Raghavan and Venu Govindaraju and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {35},
pages = {39-78},
year = {2016},
booktitle = {Cognitive Computing: Theory and Applications},
issn = {0169-7161},
doi = {https://doi.org/10.1016/bs.host.2016.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0169716116300529},
author = {A.S. Maida},
keywords = {Brain simulation, Deep belief networks, Convolutional networks, Liquid computing, Biological neural networks, Neocortex},
abstract = {Cognitive computing seeks to build applications which model and mimic human thinking. One approach toward achieving this goal is to develop brain-inspired computational models. A prime example of such a model is the class of deep convolutional networks which is currently used in pattern recognition, machine vision, and machine learning. We offer a brief review of the mammalian neocortex, the minicolumn, and the ventral pathway. We provide descriptions of abstract neural circuits that have been used to model these areas of the brain. This include Poisson spiking networks, liquid computing networks, spiking models of feature discovery in the ventral pathway, spike-timing-dependent plasticity learning, restricted Boltzmann machines, deep belief networks, and deep convolutional networks. In summary, this chapter explores abstractions of neural networks found within the mammalian neocortex that support cognition and the beginnings of cognitive computation.}
}
@incollection{ADRIAANS2008133,
title = {LEARNING AND THE COOPERATIVE COMPUTATIONAL UNIVERSE},
editor = {Pieter Adriaans and Johan {van Benthem}},
booktitle = {Philosophy of Information},
publisher = {North-Holland},
address = {Amsterdam},
pages = {133-167},
year = {2008},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-51726-5.50010-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517265500108},
author = {Pieter Adriaans}
}
@article{GROSBERG2009359,
title = {Computational models of heart pumping efficiencies based on contraction waves in spiral elastic bands},
journal = {Journal of Theoretical Biology},
volume = {257},
number = {3},
pages = {359-370},
year = {2009},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2008.11.022},
url = {https://www.sciencedirect.com/science/article/pii/S0022519308006103},
author = {Anna Grosberg and Morteza Gharib},
keywords = {Cardiac modeling, Left ventricular twist, Myocardium macro-structure, Finite element simulations},
abstract = {We present a framework for modeling biological pumping organs based on coupled spiral elastic band geometries and active wave-propagating excitation mechanisms. Two pumping mechanisms are considered in detail by way of example: one of a simple tube, which represents a embryonic fish heart and another more complicated structure with the potential to model the adult human heart. Through finite element modeling different elastic contractions are induced in the band. For each version the pumping efficiency is measured and the dynamics are evaluated. We show that by combining helical shapes of muscle bands with a contraction wave it is possible not only to achieve efficient pumping, but also to create desired dynamics of the structure. As a result we match the function of the model pumps and their dynamics to physiological observations.}
}
@article{DUAN2021107596,
title = {Equidistant k-layer multi-granularity knowledge space},
journal = {Knowledge-Based Systems},
volume = {234},
pages = {107596},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107596},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121008583},
author = {Jiangli Duan and Guoyin Wang and Xin Hu},
keywords = {Granular computing, Multi-granularity knowledge space, Knowledge space distance, Hierarchical quotient space},
abstract = {A multi-granularity knowledge space is a computational model that simulates human thinking and solves complex problems. However, as the amount of data increases, the multi-granularity knowledge space will have a larger number of layers, which will reduce its problem-solving ability. Therefore, we define a knowledge space distance measurement and propose two algorithms to select k representative layers from the multi-granularity knowledge space, where k is specified by the user according to the needs in problem solving, and k representative layers are approximately equidistant. First, we propose a knowledge space distance to measure the distance between any two layers in a multi-granularity knowledge space with superset-subset relationships, and the rationality of the knowledge space distance is verified by theory and experiment. Second, relying on the knowledge space distance and knowledge space distance variance, we propose two algorithms (i.e., a deterministic algorithm and a heuristic algorithm) to select an approximate equidistant k-layer multi-granularity knowledge space. Third, in addition to verifying the effectiveness of the knowledge space distance, the knowledge space distance variance, the deterministic algorithm and the heuristic algorithm, we verify that the equidistant k-layer multi-granularity knowledge space is more efficient than the original multi-granularity knowledge space.}
}
@article{CANIZARES2024100020,
title = {Taming the Rhinoceros: A brief history of a ubiquitous tool},
journal = {Perspectives in Architecture and Urbanism},
volume = {1},
number = {2},
pages = {100020},
year = {2024},
issn = {2950-2675},
doi = {https://doi.org/10.1016/j.pau.2024.100020},
url = {https://www.sciencedirect.com/science/article/pii/S2950267524000241},
author = {Galo Canizares},
keywords = {Software, History, Parametric design, Digital fabrication, Theory},
abstract = {At the turn of the millennium, architects and educators, propelled by the demise of critical theory, found a space to speculate about technology’s role in the future of architecture. As Michael Speaks wrote in 2002, “if philosophy was the intellectual dominant of early twentieth century vanguards and theory the intellectual dominant of late twentieth century vanguards, then intelligence has become the intellectual dominant of twenty-first century post-vanguards” (Speaks, 2010, p. 211). This emphasis on intelligence fostered a progressive narrative around the increasing reliance on software in design processes. This paper examines architectural practice during this period, with a specific focus on the rise of a new set of values, priorities, and factors that transformed architectural thinking and making. In contrast to existing accounts of digital design’s history, this paper places less importance on outputs and more on the shifts in modes of working and enacting design labor. More specifically, it narrows in on a software application that, as will be argued, drastically changed both cultural values and design knowledge: Rhinoceros. Beyond simply facilitating the production of geometrically intricate and complex architectural assemblies, Rhinoceros helped shape the discourse on parametric, computational, and algorithmic design, redefining the role of the designer as a creative technologist. In doing so, it also engendered a specific community of practice, which in turn produced its own culture and folklore. The spread of this software greatly contributed to the rise of two new kinds of architectural technologists: the “parametric designer” and the “digital fabricator,” two actors who would significantly impact how architecture was imagined and produced from the mid-2000s through the 2010s.}
}
@article{LOPEZBRAU2023105524,
title = {People can use the placement of objects to infer communicative goals},
journal = {Cognition},
volume = {239},
pages = {105524},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105524},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723001580},
author = {Michael Lopez-Brau and Julian Jara-Ettinger},
keywords = {Computational modeling, Social objects, Theory of Mind},
abstract = {Beyond words and gestures, people have a remarkable capacity to communicate indirectly through everyday objects: A hat on a chair can mean it is occupied, rope hanging across an entrance can mean we should not cross, and objects placed in a closed box can imply they are not ours to take. How do people generate and interpret the communicative meaning of objects? We hypothesized that this capacity is supported by social goal inference, where observers recover what social goal explains an object being placed in a particular location. To test this idea, we study a category of common ad-hoc communicative objects where a small cost is used to signal avoidance. Using computational modeling, we first show that goal inference from indirect physical evidence can give rise to the ability to use object placement to communicate. We then show that people from the U.S. and the Tsimane’—a farming-foraging group native to the Bolivian Amazon—can infer the communicative meaning of object placement in the absence of a pre-existing convention, and that people’s inferences are quantitatively predicted by our model. Finally, we show evidence that people can store and retrieve this meaning for use in subsequent encounters, revealing a potential mechanism for how ad-hoc communicative objects become quickly conventionalized. Our model helps shed light on how humans use their ability to interpret other people’s behavior to embed social meaning into the physical world.}
}
@article{FRITSCH2024100297,
title = {Teaching advanced topics in econometrics using introductory textbooks: The case of dynamic panel data methods},
journal = {International Review of Economics Education},
volume = {47},
pages = {100297},
year = {2024},
issn = {1477-3880},
doi = {https://doi.org/10.1016/j.iree.2024.100297},
url = {https://www.sciencedirect.com/science/article/pii/S147738802400015X},
author = {Markus Fritsch and Andrew Adrian Yu Pua and Joachim Schnurbus},
keywords = {Teaching econometrics, instrumental variables, linear dynamic panel data methods, cigarette demand, lagged variables},
abstract = {We show how to use the introductory econometrics textbook by Stock and Watson (2019) as a starting point for teaching and studying dynamic panel data methods. The materials are intended for undergraduate students taking their second econometrics course, undergraduate students in seminar-type courses, independent study courses, capstone, or thesis projects, and beginning graduate students in a research methods course. First, we distill the methodological core necessary to understand dynamic panel data methods. Second, we design an empirical and a theoretical case study to highlight the capabilities, downsides, and hazards of the method. The empirical case study is based on the cigarette demand example in Stock and Watson (2019) and illustrates that economic and methodological issues are interrelated. The theoretical case study shows how to evaluate current empirical practices from a theoretical standpoint. We designed both case studies to boost students’ confidence in working with technical material and to provide instructors with more opportunities to let students develop econometric thinking and to actively communicate with applied economists. Although we focus on Stock and Watson (2019) and the statistical software R, we also show how to modify the material for use with another introductory textbook by Wooldridge (2020) and Stata, and highlight some possible further pathways for instructors and students to reuse and extend our materials.}
}
@article{BIBRI2018758,
title = {A foundational framework for smart sustainable city development: Theoretical, disciplinary, and discursive dimensions and their synergies},
journal = {Sustainable Cities and Society},
volume = {38},
pages = {758-794},
year = {2018},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.12.032},
url = {https://www.sciencedirect.com/science/article/pii/S2210670717313069},
author = {Simon Elias Bibri},
keywords = {Smart sustainable cities, Theories, Academic disciplines, Academic discourses, Multidimensional framework, Interdisciplinarity and transdisciplinarity, Systems thinking, Complexity science, Sustainability, Computing and ICT},
abstract = {In the subject of smart sustainable cities, the underlying theories are a foundation for practice. Moreover, scholarly research in the field of smart sustainable cities operates out of the understanding that advances in the underlying knowledge necessitate pursuing multifaceted questions that can only be resolved from the vantage point of interdisciplinarity or transdisciplinarity. Indeed, research problems in this field are inherently too complex to be addressed by single disciplines. The PhD study addressing the topic of smart sustainable city development falls within the broad research field of sustainability transition and sustainability science where ICT is seen as a salient factor given its transformational, disruptive, and synergetic effects as an enabling, integrative, and constitutive technology. In light of this, the approach to the PhD study is of an applied theoretical kind, and its aim is to investigate and analyze how to advance and sustain the contribution of sustainable urban forms to the goals of sustainable development with support of ICT of pervasive computing. This is to primarily create a framework for strategic smart sustainable city development based on scientific principles, theories, and academic disciplines and discourses used to guide urban actors in their practice towards sustainability and analyze its impact. This involves the application of a set of integrative foundational elements drawn from urban planning, urban design, sustainability, sustainable development, sustainability science, data science, computer science, complexity science, systems theory, systems thinking, and ICT. Accordingly, it is deemed of high significance to devise a multidimensional framework consisting of relevant theories and academic disciplines and discourses that underpin the development of smart sustainable cities as a set of future practices. This framework in turn emphasizes the interdisciplinary and transdisciplinary nature and orientation of the topic of smart sustainable cities and thus the relevance of pursuing an interdisciplinary and transdisciplinary approach into studying this topic. Therefore, this paper endeavors to systematize the very complex and dense scientific area of smart sustainable cities in terms of identifying, distilling, and structuring the core dimensions of a foundational framework for smart sustainable city development as a set of future practices. In doing so, it focuses on a number of fundamental theories along with academic disciplines and discourses, with the aim of setting a framework that analytically relates city development, sustainability, and ICT, while emphasizing how and to what extent sustainability and ICT have particularly become influential in city development in modern society. In addition, this paper offers an in–depth interdisciplinary and transdisciplinary discussion covering topics of high relevance to the PhD study and at the heart of the very synergic relationship between the theoretical, disciplinary, and discursive dimensions of the foundational framework underpinning smart sustainable city development. These dimensions thus form the basis for the framework for strategic smart sustainable city development that is under investigation and will be developed based on a backcasting approach to strategic planning. This study provides an important lens through which to understand a set of influential theories and established academic disciplines and discourses with high potential for integration, fusion, and practicality in relation to the practice of smart sustainable city development.}
}
@article{STATHOPOULOS20031565,
title = {Wind loads on low buildings: in the wake of Alan Davenport's contributions},
journal = {Journal of Wind Engineering and Industrial Aerodynamics},
volume = {91},
number = {12},
pages = {1565-1585},
year = {2003},
note = {ENGINEERING SYMPOSIUM To Honour ALAN G. DAVENPORT for his 40 Years of Contributions},
issn = {0167-6105},
doi = {https://doi.org/10.1016/j.jweia.2003.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S0167610503001302},
author = {Ted Stathopoulos},
keywords = {Building, Code, Computational wind engineering, Design, Load, Pressure, Standard, Time series, Wind},
abstract = {The paper reviews the evolution of knowledge and its current state regarding the evaluation of wind loads on low buildings by placing particular emphasis on Alan Davenport's contributions. These contributions have paved the way to the current state-of-the-art and have influenced the thinking of not only Alan's closest collaborators but also of other researchers in this area around the world. The paper will provide a brief historical perspective, followed by some detailed description of the University of Western Ontario's research on wind loads on low buildings carried out in the 1970s. Visualizing the wake of Davenport's contributions in this area, the paper will refer to the influence of this knowledge in the formulation of design load provisions in contemporary wind standards and codes of practice. The paper will also discuss the status of computational wind engineering as well as the so-called computer-aided wind engineering in the evaluation of wind pressures on low buildings.}
}
@article{ALVARADO20043,
title = {Autonomous agents and computational intelligence: the future of AI application for petroleum industry},
journal = {Expert Systems with Applications},
volume = {26},
number = {1},
pages = {3-8},
year = {2004},
note = {Intelligent Computing in the Petroleum Industry, ICPI-02},
issn = {0957-4174},
doi = {https://doi.org/10.1016/S0957-4174(03)00103-9},
url = {https://www.sciencedirect.com/science/article/pii/S0957417403001039},
author = {Matı&#x0301;as Alvarado and Leonid Cheremetov and Francisco Cantú}
}
@incollection{RZESZEWSKI2024219,
title = {Chapter 10 - Augmented reality content and relations of power in smart spaces},
editor = {Zhihan Lyu},
booktitle = {Smart Spaces},
publisher = {Academic Press},
pages = {219-234},
year = {2024},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-13462-3},
doi = {https://doi.org/10.1016/B978-0-443-13462-3.00008-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044313462300008X},
author = {Michal Rzeszewski and Leighton Evans},
keywords = {Augmented reality, Smart space, Agency of place, Power relations},
abstract = {This chapter’s main aim is to interrogate how augmented reality (AR) content can change the relations of power within a place and transform the perception of place from being a material background for social interactions into a living agent that can have its own agency. We use the concept of sociotechnical imaginary and thematic analysis of AR-related media content to explore main narrations in the current discourse on AR and smart urban spaces. We identify two dominant themes: “smart information in place” and “subversion of meaning” that combine two ways of thinking about relation between place and AR. In the first one, AR acts not as an augmentation of place, but as a reducer of the experience of place down to seeing the world as information and data for the achievement of efficiencies in late capitalism. In the second one, AR can be seen as transcending the traditional constellations of power relations that shape places and spaces of modern cities, skewing them toward nonhuman actors, of which AR may be the most visible and influential. Through the visible differentiation of users, alteration of perception and the forcing of presence and behavior, AR is a technology that makes visible the systems and processes of control and mediation of space and place. As such, the smart space itself will become visible through the presence, use, and functioning of AR in a manner that has not been the case previously. We posit, therefore, that AR can be seen as a physical manifestation of the agency of place. This position can have consequences for the practical development of smart spaces and for theoretical consideration of the human-technology interaction in urban space in its material and digital dimensions.}
}
@article{LOCK2023102310,
title = {Conserving complexity: A complex systems paradigm and framework to study public relations’ contribution to grand challenges},
journal = {Public Relations Review},
volume = {49},
number = {2},
pages = {102310},
year = {2023},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2023.102310},
url = {https://www.sciencedirect.com/science/article/pii/S0363811123000255},
author = {Irina Lock},
keywords = {Grand challenges, Public issues, Public relations, Strategic communication, Complex adaptive systems, Digital communication, Complexity},
abstract = {Sustainable development poses a grand challenge for society, addressed by organisations through their public relations activities. Grand challenges are complex by nature and call for nontrivial solutions whose effects show at the level of society. That is why studying public relations’ contribution to grand challenges requires a macro perspective that accounts for the dynamic interaction between individual, organisational, and system levels in a digital communication environment. This paper offers a new paradigm to analyse organisations’ significant and at times undue impact on grand challenges through public relations. It develops a framework inspired by complex adaptive systems thinking and adopts its ten properties for public relations: emergence, adaptivity, heterogeneous actors, nonlinear effects, feedback mechanisms, self-organisation, phase transitions, networks, scaling, and cooperation. The paper applies the framework to the example of sustainable development. It shows why research on grand challenges requires a holistic perspective and how it can help study digitally born communication phenomena. The proposed complex systems paradigm provides space for critical, social scientific, and interpretative research lines in public relations. Inquiries start from the grand challenge and study the communicative interactions between organisations and other actors from existing theory while accounting for the ten properties of complex adaptive systems. The paper outlines how future research can enrich the study of public relations and discusses its limits.}
}
@article{SARTON195551,
title = {The astral religion of antiquity and the “thinking machines” of to-day},
journal = {Vistas in Astronomy},
volume = {1},
pages = {51-60},
year = {1955},
issn = {0083-6656},
doi = {https://doi.org/10.1016/0083-6656(55)90012-X},
url = {https://www.sciencedirect.com/science/article/pii/008366565590012X},
author = {George Sarton}
}
@article{PRINA2024132735,
title = {Machine learning as a surrogate model for EnergyPLAN: Speeding up energy system optimization at the country level},
journal = {Energy},
volume = {307},
pages = {132735},
year = {2024},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2024.132735},
url = {https://www.sciencedirect.com/science/article/pii/S036054422402509X},
author = {Matteo Giacomo Prina and Mattia Dallapiccola and David Moser and Wolfram Sparber},
keywords = {Energy system modelling, Energy scenarios, Energy planning, Machine learning},
abstract = {In the field of energy system modelling, increasing complexity and optimization analysis are essential for understanding the most effective decarbonization options. However, the growing need for intricate models leads to increased computational time, which can hinder progress in research and policy-making. This study aims to address this issue by integrating machine learning algorithms with EnergyPLAN and EPLANopt, a coupling of EnergyPLAN software and a multi-objective evolutionary algorithm, to expedite the optimization process while maintaining accuracy. By saving computational time, we can increase the number of evaluations, thereby enabling deeper exploration of uncertainty in energy system modelling. Although machine learning models have been widely employed as surrogate models to accelerate optimization problems, their application in energy system modeling at the national scale, while preserving high temporal resolution and extensive sector-coupling, remains scarce. Several machine learning models were evaluated, and an artificial neural network was selected as the most effective surrogate model. The findings demonstrate that incorporating this surrogate model within the optimization process reduces computational time by 64 % compared to the conventional EPLANopt approach, while maintaining an accuracy level close to that obtained by running EPLANopt without the surrogate model.}
}
@article{JU2022101062,
title = {Proposal for a STEAM education program for creativity exploring the roofline of a hanok using GeoGebra and 4Dframe},
journal = {Thinking Skills and Creativity},
volume = {45},
pages = {101062},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101062},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122000657},
author = {Hyunshik Ju and Hogul Park and Eun Young Jung and Seoung-Hey Paik},
keywords = {STEAM education program, Creativity, Catenary curve, Korean traditional architecture, Modelling, GeoGebra, 4Dframe},
abstract = {This research was conducted to confirm the feasibility of a STEAM education program in which the mathematics, physics, and Korean traditional arts underlying the hanok roofline are investigated using educational tools of GeoGebra and 4Dframe. This paper contends that this program has the potential to engage students in knowledge restructuring regarding the perception of the hanok’s architectural beauty, Newton's concept of gravity, and mathematical functions. The Octagonal Pavilion in Tapgol Park in Seoul, South Korea, a representative hanok, was used as an educational resource. GeoGebra is used to determine that the roofline of the Octagonal Pavilion generally follows the formula of the catenary curve and then the roofline is modelled using 4Dframe. The catenary form of the roofline of the hanok is linked to the Korean sense of beauty in the pursuit of naturalness under the influence of gravity and organically harmonizes with the environment. The class described in this study, in which the curve of the roofline of the Octagonal Pavilion is explored using GeoGebra and 4Dframe, can help develop creative and critical thinking in students in the context of STEAM education. The findings of this study have the potential to expand the scope of STEAM education to include content for creative education.}
}
@article{GIRARD2005215,
title = {From brainstem to cortex: Computational models of saccade generation circuitry},
journal = {Progress in Neurobiology},
volume = {77},
number = {4},
pages = {215-251},
year = {2005},
issn = {0301-0082},
doi = {https://doi.org/10.1016/j.pneurobio.2005.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S030100820500153X},
author = {B. Girard and A. Berthoz},
keywords = {Saccade generation circuitry, Computational models, Brainstem, Superior colliculus, Cerebellum, Basal ganglia, Cortex},
abstract = {The brain circuitry of saccadic eye movements, from brainstem to cortex, has been extensively studied during the last 30 years. The wealth of data gathered allowed the conception of numerous computational models. These models proposed descriptions of the putative mechanisms generating this data, and, in turn, made predictions and helped to plan new experiments. In this article, we review the computational models of the five main brain regions involved in saccade generation: reticular formation saccadic burst generators, superior colliculus, cerebellum, basal ganglia and premotor cortical areas. We present the various topics these models are concerned with: location of the feedback loop, multimodal saccades, long-term adaptation, on the fly trajectory correction, strategy and metrics selection, short-term spatial memory, transformations between retinocentric and craniocentric reference frames, sequence learning, to name the principle ones. Our objective is to provide a global view of the whole system. Indeed, narrowing too much the modelled areas while trying to explain too much data is a recurrent problem that should be avoided. Moreover, beyond the multiple research topics remaining to be solved locally, questions regarding the operation of the whole structure can now be addressed by building on the existing models.}
}
@article{PAPADOPOULOS2019210,
title = {Using mobile puzzles to exhibit certain algebraic habits of mind and demonstrate symbol-sense in primary school students},
journal = {The Journal of Mathematical Behavior},
volume = {53},
pages = {210-227},
year = {2019},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2018.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S073231231730189X},
author = {Ioannis Papadopoulos},
keywords = {Algebraic habits of mind, mobile puzzles, Symbol sense},
abstract = {Given the growing concern for developing students’ algebraic ideas and thinking in earlier grades (NCTM, 2000) it is important for students to have experiences that better prepare them for their formal introduction to algebra. Mobile puzzles seem to be an opportunity for exhibiting certain algebraic habits of mind as well as for demonstrating symbol-sense which might support students in their transition from arithmetic to algebra. These puzzles include multiple balanced collections of objects whose weights must be determined by the solver. The arms/beams must be perfectly balanced for it to hang properly. Therefore, they represent, in a pictorial way, systems of equations. Each arm/beam that balances two sets of objects (representing variables as unknown “weights”) represents an equation. The data derived from Grade-6 students who were asked to solve a collection of tasks reflect the presence of the “Puzzling and Persevering” and “Seeking and Using Structure” habits of mind. At the same time these data incorporate instances of some main components of symbol-sense such as “friendliness with symbols”, “manipulating and ‘reading through’ symbolic expressions”, and “choice of symbols”. Also discussed is the way this experience contributes to an intuitive application of the conventional rules for solving equations that will be later introduced to the students as the standard algebraic “moves”.}
}
@article{LEBARON2000679,
title = {Agent-based computational finance: Suggested readings and early research},
journal = {Journal of Economic Dynamics and Control},
volume = {24},
number = {5},
pages = {679-702},
year = {2000},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(99)00022-6},
url = {https://www.sciencedirect.com/science/article/pii/S0165188999000226},
author = {Blake LeBaron},
keywords = {Agents, Heterogeneous information, Simulated markets, Learning, Evolution},
abstract = {The use of computer simulated markets with individual adaptive agents in finance is a new, but growing field. This paper explores some of the early works in the area concentrating on a set of some of the earliest papers. Six papers are summarized in detail, along with references to many other pieces of this wide ranging research area. It also covers many of the questions that new researchers will face when getting into the field, and hopefully can serve as a kind of minitutorial for those interested in getting started.}
}
@article{OLSON1995183,
title = {Emergent computation and the modeling and management of ecological systems},
journal = {Computers and Electronics in Agriculture},
volume = {12},
number = {3},
pages = {183-209},
year = {1995},
issn = {0168-1699},
doi = {https://doi.org/10.1016/0168-1699(94)00022-I},
url = {https://www.sciencedirect.com/science/article/pii/016816999400022I},
author = {Richard L. Olson and Ronaldo A. Sequeira},
keywords = {Emergent computation, Ecosystem dynamics, Ecosystem management},
abstract = {This paper introduces the emergent computational paradigm, discusses its applicability and potential in ecosystem management, and reviews the literature. Emergent computation is significantly different from the “classic” computational paradigm, where control is top-down and centralized. In emergent systems, overall system dynamics emerge from the local interactions of independent agents. In such systems, overall global control is minimized or eliminated altogether. Applications in ecosystem management include use of “artificial ecosystems” as surrogate experimental systems, and genetics-based machine learning systems to evolve management rule-sets for complex domains. Cellular automata, neural networks, genetic algorithms and classifier systems are discussed as examples of the emergent approach. Finally, an in-depth literature review of artificial ecosystems is provided.}
}
@article{YAP19973,
title = {Towards exact geometric computation},
journal = {Computational Geometry},
volume = {7},
number = {1},
pages = {3-23},
year = {1997},
issn = {0925-7721},
doi = {https://doi.org/10.1016/0925-7721(95)00040-2},
url = {https://www.sciencedirect.com/science/article/pii/0925772195000402},
author = {Chee-Keng Yap},
abstract = {Exact computation is assumed in most algorithms in computational geometry. In practice, implementors perform computation in some fixed-precision model, usually the machine floating-point arithmetic. Such implementations have many well-known problems, here informally called “robustness issues”. To reconcile theory and practice, authors have suggested that theoretical algorithms ought to be redesigned to become robust under fixed-precision arithmetic. We suggest that in many cases, implementors should make robustness a non-issue by computing exactly. The advantages of exact computation are too many to ignore. Many of the presumed difficulties of exact computation are partly surmountable and partly inherent with the robustness goal. This paper formulates the theoretical framework for exact computation based on algebraic numbers. We then examine the practical support needed to make the exact approach a viable alternative. It turns out that the exact computation paradigm encompasses a rich set of computational tactics. Our fundamental premise is that the traditional “BigNumber” package that forms the work-horse for exact computation must be reinvented to take advantage of many features found in geometric algorithms. Beyond this, we postulate several other packages to be built on top of the BigNumber package.}
}
@incollection{SCHOMMERS201991,
title = {Chapter 2 - Theoretical and Computational Methods},
editor = {Wolfram Schommers},
booktitle = {Basic Physics of Nanoscience},
publisher = {Elsevier},
pages = {91-202},
year = {2019},
isbn = {978-0-12-813718-5},
doi = {https://doi.org/10.1016/B978-0-12-813718-5.00002-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128137185000028},
author = {Wolfram Schommers},
keywords = {Simulation methods, interaction potentials, anharmonicities, temperature effects, molecular dynamics, nanosystems, structures, dynamics},
abstract = {It is underlined that typical nanosystems are adequately described only by the fundamental laws of theoretical physics. It is in particular argued that phenomenological models are in most cases not sophisticated enough. For the description of such nanosystems the theoretical and computational tools have to be selected carefully and have in particular to be improved in many cases. In this connection the interaction laws (potentials) between the atoms, forming a nanosystem, are critical functions because the structure and dynamics of such systems are very sensitive to small variations in the potentials. This point has been studied in detail. Various potential laws have been introduced and discussed in connection with applications. The most relevant simulations methods are quoted and their relevance for nanotechnology is discussed. In particular, the molecular dynamics method is described in detail. We give typical examples, which demonstrate the fact the molecular dynamics method is a powerful and reliable tool for the investigation of typical nanosystems with their large variety of structures and complex dynamical states. The examples deal with wear at the nanotechnological level and with metallic nanoclusters as building blocks.}
}
@article{KESIC2024101072,
title = {Complexity and biocomplexity: Overview of some historical aspects and philosophical basis},
journal = {Ecological Complexity},
volume = {57},
pages = {101072},
year = {2024},
issn = {1476-945X},
doi = {https://doi.org/10.1016/j.ecocom.2023.101072},
url = {https://www.sciencedirect.com/science/article/pii/S1476945X23000442},
author = {Srdjan Kesić},
keywords = {Cybernetics, General systems theory, Complexity, Modeling, Biocomplexity, Emergence, Autopoiesis},
abstract = {Complexity has radically changed human understanding of the world environment and continues challenging our best scientific theories. In a rapidly changing research landscape, historical and philosophical insights into Complexity can heighten awareness of the proper theoretical perspectives scientists should adopt to advance the study of biocomplexity, including ecological complexity. The present work aims to deepen this awareness and disclose how researchers should generally approach, scientifically and philosophically, the question of what Complexity is, which is of great importance not only to the scientific community but also far beyond. First, this article reviews some critical historical turning points that led to Complexity. Second, the paper discusses philosophical-scientific approaches to the emergence as one of the most critical features of complex systems. The critical ideas behind attempts to understand the generators of complexity in nature are then presented, focusing on the living world. Finally, the review focuses on understanding the ecosystem- and organism-oriented perspectives of biocomplexity. We conclude that the genuine problem of the origin of complexity theory and biocomplexity will continue to inspire generations of researchers to search for new, more comprehensive mathematical and computational frameworks to explain biological hierarchies in order to further advance the scientific understanding of life.}
}
@article{PEARSON1994203,
title = {Report on University of Wales Institute of non-Newtonian Fluid Mechanics Mini-Symposium on “Continuum and Microstructural Modelling in Computational Rheology” Seiont Manor, Gwynedd, 11–12 April 1994},
journal = {Journal of Non-Newtonian Fluid Mechanics},
volume = {55},
number = {2},
pages = {203-205},
year = {1994},
issn = {0377-0257},
doi = {https://doi.org/10.1016/0377-0257(94)80006-5},
url = {https://www.sciencedirect.com/science/article/pii/0377025794800065},
author = {J.R.A. Pearson}
}
@article{NOH2006554,
title = {Computational tools for isotopically instationary 13C labeling experiments under metabolic steady state conditions},
journal = {Metabolic Engineering},
volume = {8},
number = {6},
pages = {554-577},
year = {2006},
issn = {1096-7176},
doi = {https://doi.org/10.1016/j.ymben.2006.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S1096717606000449},
author = {Katharina Nöh and Aljoscha Wahl and Wolfgang Wiechert},
keywords = {Instationary C metabolic flux analysis, C labeling experiment, C labeling dynamics, Parameter identifiability, Optimal experimental design, },
abstract = {13C metabolic flux analysis (MFA) has become an important and powerful tool for the quantitative analysis of metabolic networks in the framework of metabolic engineering. Isotopically instationary 13C MFA under metabolic stationary conditions is a promising refinement of classical stationary MFA. It accounts for the experimental requirements of non-steady-state cultures as well as for the shortening of the experimental duration. This contribution extends all computational methods developed for classical stationary 13C MFA to the instationary situation by using high-performance computing methods. The developed tools allow for the simulation of instationary carbon labeling experiments (CLEs), sensitivity calculation with respect to unknown parameters, fitting of the model to the measured data, statistical identifiability analysis and an optimal experimental design facility. To explore the potential of the new approach all these tools are applied to the central metabolism of Escherichia coli. The achieved results are compared to the outcome of the stationary counterpart, especially focusing on statistical properties. This demonstrates the specific strengths of the instationary method. A new ranking method is proposed making both an a priori and an a posteriori design of the sampling times available. It will be shown that although still not all fluxes are identifiable, the quality of flux estimates can be strongly improved in the instationary case. Moreover, statements about the size of some immeasurable pool sizes can be made.}
}
@article{FUXJAGER2023105340,
title = {Systems biology as a framework to understand the physiological and endocrine bases of behavior and its evolution—From concepts to a case study in birds},
journal = {Hormones and Behavior},
volume = {151},
pages = {105340},
year = {2023},
issn = {0018-506X},
doi = {https://doi.org/10.1016/j.yhbeh.2023.105340},
url = {https://www.sciencedirect.com/science/article/pii/S0018506X23000387},
author = {Matthew J. Fuxjager and T. Brandt Ryder and Nicole M. Moody and Camilo Alfonso and Christopher N. Balakrishnan and Julia Barske and Mariane Bosholn and W. Alice Boyle and Edward L. Braun and Ioana Chiver and Roslyn Dakin and Lainy B. Day and Robert Driver and Leonida Fusani and Brent M. Horton and Rebecca T. Kimball and Sara Lipshutz and Claudio V. Mello and Eliot T. Miller and Michael S. Webster and Morgan Wirthlin and Roy Wollman and Ignacio T. Moore and Barney A. Schlinger},
keywords = {Systems biology, Animal behavior, Organismal physiology, Adaptive evolution, Manakin birds, Androgenic hormones, Robustness},
abstract = {Organismal behavior, with its tremendous complexity and diversity, is generated by numerous physiological systems acting in coordination. Understanding how these systems evolve to support differences in behavior within and among species is a longstanding goal in biology that has captured the imagination of researchers who work on a multitude of taxa, including humans. Of particular importance are the physiological determinants of behavioral evolution, which are sometimes overlooked because we lack a robust conceptual framework to study mechanisms underlying adaptation and diversification of behavior. Here, we discuss a framework for such an analysis that applies a “systems view” to our understanding of behavioral control. This approach involves linking separate models that consider behavior and physiology as their own networks into a singular vertically integrated behavioral control system. In doing so, hormones commonly stand out as the links, or edges, among nodes within this system. To ground our discussion, we focus on studies of manakins (Pipridae), a family of Neotropical birds. These species have numerous physiological and endocrine specializations that support their elaborate reproductive displays. As a result, manakins provide a useful example to help imagine and visualize the way systems concepts can inform our appreciation of behavioral evolution. In particular, manakins help clarify how connectedness among physiological systems—which is maintained through endocrine signaling—potentiate and/or constrain the evolution of complex behavior to yield behavioral differences across taxa. Ultimately, we hope this review will continue to stimulate thought, discussion, and the emergence of research focused on integrated phenotypes in behavioral ecology and endocrinology.}
}
@article{CAO2024102160,
title = {Self-assembly of peptides: The acceleration by molecular dynamics simulations and machine learning},
journal = {Nano Today},
volume = {55},
pages = {102160},
year = {2024},
issn = {1748-0132},
doi = {https://doi.org/10.1016/j.nantod.2024.102160},
url = {https://www.sciencedirect.com/science/article/pii/S174801322400015X},
author = {Nana Cao and Kang Huang and Jianjun Xie and Hui Wang and Xinghua Shi},
keywords = {Peptides, Self-assembly, Molecular dynamics, Machine learning},
abstract = {Peptides, biopolymeric compounds connected by peptide bonds, have garnered significant attention in recent years as their potential wide applications in fields such as drug delivery, tissue engineering, and antibiotics. Peptides exhibit excellent biocompatibility and stability due to their structural similarities to many bioactive substances found in human bodies. The self-assembly of peptides has piqued considerable interest with groundbreaking advancements achieved in experimental research. However, it is still a big challenge to establish comprehensive theoretical model to accurately describe the behavior of peptide self-assembly. Current peptide self-assembly designs primarily rely on experimental outcomes and general rules, which is inefficient and susceptible to human errors. In recent years, thanks to rapid advancements in computer techniques and theoretical methods, computational research has become a vital tool in complementing experimental research with rapid development witted in this field. This review delves into the description of peptide self-assembly, covering relevant sequences, structures, morphologies, rules, and application areas. It places particular emphasis on the recent progress in computational methods such as molecular dynamics (MD) simulations and machine learning (ML) techniques in the study. Finally, we provide a perspective on the application of computational methods to expedite exploration in the realm of multi-peptide self-assembly.}
}
@article{PORNSUWANCHAROEN20181034,
title = {Meditation mathematical formalism and Lorentz factor calculation based-on Mindfulness foundation},
journal = {Results in Physics},
volume = {11},
pages = {1034-1038},
year = {2018},
issn = {2211-3797},
doi = {https://doi.org/10.1016/j.rinp.2018.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S2211379718325294},
author = {N. Pornsuwancharoen and I.S. Amiri and J. Ali and P. Youplao and P. Yupapin},
keywords = {Meditation science, Mindfulness Foundation, Buddhism philosophy, Mathematics foundation, Natural science},
abstract = {Mindfulness foundation is an excellent method of the human spiritual development by the reasonable thinking and consideration, which was established by Lord Buddha a long time ago. There are four ways of thinking and consideration-(i) form (body), (ii) sensation, (iii) spiritual and (iv) Dhamma. In this paper, we propose the use of the form consideration for the spiritual development, in which the form can be considered thoroughly inside the body by the spiritual projection. By using the nonlinear microring resonator known as a Panda-ring resonator, the electromagnetic (EM) signals called polaritons can be generated by the coupling interaction between the intense EM fields and the ionic diploes within the almost closed system, where the dipoles can obtain from the coupling between the gold grating and the strong electromagnetic fields. In the manipulation, cells, tissues, and organs inside the human body can communicate with the spiritual (polaritonic) signals and investigation. The simulation results obtained have shown that the Lorentz factor of 0.99999959 is obtained. The successively filtering of the signal circulation within the body during the meditation can be formulated and the meditation behaviors modeled. The aura, the stopping, and the cold body states can be configured and explained.}
}
@article{OLIVER2014289,
title = {Crack-path field and strain-injection techniques in computational modeling of propagating material failure},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {274},
pages = {289-348},
year = {2014},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2014.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0045782514000139},
author = {J. Oliver and I.F. Dias and A.E. Huespe},
keywords = {Fracture, Computational material failure, Strong discontinuities, Crack-path field, Strain injection, Finite elements with embedded discontinuities},
abstract = {The work presents two new numerical techniques devised for modeling propagating material failure, i.e. cracks in fracture mechanics or slip-lines in soil mechanics. The first one is termed crack-path-field technique and is conceived for the identification of the path of those cracks, or slip-lines, represented by strain-localization based solutions of the material failure problem. The second one is termed strain-injection, and consists of a procedure to insert, during specific stages of the simulation and in selected areas of the domain of analysis, goal oriented specific strain fields via mixed finite element formulations. In the approach, a first injection, of elemental constant strain modes (CSM) in quadrilaterals, is used, in combination of the crack-path-field technique, for obtaining reliable information that anticipates the position of the crack-path. Based on this information, in a subsequent stage, a discontinuous displacement mode (DDM) is efficiently injected, ensuring the required continuity of the crack-path across sides of contiguous elements. Combination of both techniques results in an efficient and robust procedure based on the staggered resolution of the crack-path-field and the mechanical failure problems. It provides the classical advantages of the “intra-elemental” methods for capturing complex propagating displacement discontinuities in coarse meshes, as E-FEM or X-FEM methods, with the non-code-invasive character of the crack-path-field technique. Numerical representative simulations of a wide range of benchmarks, in terms of the type of material and the failure problem, show the broad applicability, accuracy and robustness of the proposed methodology. The finite element code used for the simulations is open-source and available at http://www.cimne.com/compdesmat/.}
}
@article{NISHI2022314,
title = {Health and landscape approaches: A comparative review of integrated approaches to health and landscape management},
journal = {Environmental Science & Policy},
volume = {136},
pages = {314-325},
year = {2022},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2022.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S1462901122002027},
author = {Maiko Nishi and Shizuka Hashimoto},
keywords = {Landscape approaches, One Health, Ecohealth, Planetary Health, Social-ecological systems, Sustainability transformation},
abstract = {Landscape approaches are integrated place-based approaches and provide cross-sectoral opportunities to facilitate sustainability transformations. The COVID-19 outbreak has profound ramifications for multiple dimensions of landscapes, ranging from mobility and lifestyle to value to environment and society. Therefore, integrated approaches to “health” have been more vigorously promoted in the policy arena dealing with human–nature interactions. The ecosystem principles of the Convention on Biological Diversity, which resonate with landscape approaches, are generally aligned with integrated approaches to health. However, commonalities and distinctions between these integrated approaches in both political and scientific domains have not been clarified. Drawing on a narrative review of the literature on “One Health,” “Ecohealth,” and “Planetary Health” as major health-oriented approaches in comparison with landscape approaches, the aspects of landscape approaches to be complemented in addressing health-related challenges were examined in this study. In addition to the review on the intellectual roots and evolutionary pathways, a comparative analysis of these relevant approaches was conducted in terms of three realms including theoretical assumptions, knowledge bases, and research paradigms. The results of the comparative review show that all approaches share systems thinking, interdisciplinarity, cross-sectoral collaboration, and holistic paradigm but differ with respect to their focused management problems, disciplines, and sectors as well as ontological and epistemological underpinnings. Pointing to the recent theoretical and methodological development in integrating health in placemaking, the results of this study suggest that pragmatic landscape approaches could be strengthened by using health-related research paradigms to achieve better constructivism–positivism meeting grounds regarding health–landscape intersections.}
}
@article{VANDENHURK2023106030,
title = {Consideration of compound drivers and impacts in the disaster risk reduction cycle},
journal = {iScience},
volume = {26},
number = {3},
pages = {106030},
year = {2023},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2023.106030},
url = {https://www.sciencedirect.com/science/article/pii/S2589004223001074},
author = {Bart J.J.M. {van den Hurk} and Christopher J. White and Alexandre M. Ramos and Philip J. Ward and Olivia Martius and Indiana Olbert and Kathryn Roscoe and Henrique M.D. Goulart and Jakob Zscheischler},
keywords = {Earth sciences, Social sciences, Decision science},
abstract = {Summary
Consideration of compound drivers and impacts are often missing from applications within the Disaster Risk Reduction (DRR) cycle, leading to poorer understanding of risk and benefits of actions. The need to include compound considerations is known, but lack of guidance is prohibiting practitioners from including these considerations. This article makes a step toward practitioner guidance by providing examples where consideration of compound drivers, hazards, and impacts may affect different application domains within disaster risk management. We discern five DRR categories and provide illustrative examples of studies that highlight the role of “compound thinking” in early warning, emergency response, infrastructure management, long-term planning, and capacity building. We conclude with a number of common elements that may contribute to the development of practical guidelines to develop appropriate applications for risk management.}
}
@incollection{RUNCO201469,
title = {Chapter 3 - Biological Perspectives on Creativity},
editor = {Mark A. Runco},
booktitle = {Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {69-108},
year = {2014},
isbn = {978-0-12-410512-6},
doi = {https://doi.org/10.1016/B978-0-12-410512-6.00003-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780124105126000035},
author = {Mark A. Runco},
keywords = {Split brain, Corpus callosum, Pre-frontal cortex, Cerebellum, Altered states of consciousness, Exercise, Stress, Dreams, Drugs, Genetics, Dopamine, Adoption studies, Genealogies},
abstract = {This chapter discusses various aspects of biological perspectives on creativity. Some of the research on creativity as of late involves the brain and biological correlates of originality, novelty, and insight. Handedness is sometimes used as an indication of hemispheric dominance or hemisphericity, with right-handed people being compared with left-handed people. There are several reports of left-handed persons outnumbering the right-handed in creative and eminent samples. Hemisphericity and other important brain structures and processes contributing to creative thinking and behavior have been studied with electroencephalogram (EEG), positron emission topography (PET), cerebral blood flow, and magnetic resonance imaging (MRI) techniques. Numerous EEG studies suggest that there are particular brain wave patterns and brain structures that are associated with creative problem solving, or at least specific phases within the problem solving process. EEGs suggest a complex kind of activity while individuals work on divergent thinking tasks. The complexity disappears when those same individuals work on convergent thinking tasks. It is found that the role of the prefrontal cortex in creative thinking and behavior comes from several sources and uses different methodologies.}
}
@article{VALLESPERIS2024102448,
title = {Digital citizenship at school: Democracy, pragmatism and RRI},
journal = {Technology in Society},
volume = {76},
pages = {102448},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102448},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23002531},
author = {Núria Vallès-Peris and Miquel Domènech},
keywords = {Science and technology studies, Digital citizenship, Responsible research and innovation, Democracy, Pragmatism},
abstract = {This paper presents a strategy for fostering digital citizenship at school that transcends the mere use of digital devices or instructional methods focused solely on their use. The core premise of this proposal rests on the need for an ethical-political debate concerning digitization in education. In addition, it emphasizes the need to cultivate a form of digital literacy that blends science and technology with the humanities, and erases the traditional boundaries between making and thinking. The proposed approach encapsulates two primary concerns: firstly, it asserts that digital literacy serves as a foundation for meaningful participation in digital societies; secondly, it underscores the importance of democratizing digital technologies by incorporating the perspectives, needs, and concerns of children. Drawing inspiration from the theories of pragmatism and responsible research and innovation (RRI), we present a conceptual framework for digital citizenship. To operationalize this approach, we adapt John Dewey's pragmatic model of inquiry as a method that can be applied within the school setting. This pragmatic methodology serves as a conduit for developing hands-on experience geared towards developing digital citizenship. The practical implementation of this methodology is illustrated through an actualized experience with 10- and 11-year-old children in a public primary school, regarding the issue of care robots. This paper advocates for a symbiotic relationship between theoretical understanding and practical application, and puts forward a concrete proposal for the integration of digital citizenship in schools in the form of a four-phase procedural model, based on the creation of what we term ‘the encounter’ between the educational community and the research and development community.}
}
@incollection{SHI2021117,
title = {Chapter 4 - Mind model},
editor = {Zhongzhi Shi},
booktitle = {Intelligence Science},
publisher = {Elsevier},
pages = {117-149},
year = {2021},
isbn = {978-0-323-85380-4},
doi = {https://doi.org/10.1016/B978-0-323-85380-4.00004-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032385380400004X},
author = {Zhongzhi Shi},
keywords = {Mind model, Turing machine, physical symbol system, SOAR model, ACT-R model, CAM model, cognitive cycle, PMJ model},
abstract = {The technology of building mind model is often called mind modeling, which aims to explore and study the human thinking mechanism.}
}
@article{COOPER19821,
title = {Energy conservation in buildings: Part 2-A commentary on British government thinking},
journal = {Applied Energy},
volume = {10},
number = {1},
pages = {1-45},
year = {1982},
issn = {0306-2619},
doi = {https://doi.org/10.1016/0306-2619(82)90058-7},
url = {https://www.sciencedirect.com/science/article/pii/0306261982900587},
author = {Ian Cooper},
abstract = {Like my previous paper in this journal this commentary is focused on government statements published during the period 1974 to 1979. It is intended as an introductory guide aimed at two overlapping audiences. First, it is addressed to those interested in the reasoning which lies behind the Government's technical arguments on energy conservation in buildings. Secondly, it is directed towards those who seek to understand the social implications and consequences of this area of government endeavour. Not all the statements examined in this commentary represent official expressions of government policy. Some, indeed, are prefaced in their originals by specific disclaimers to this effect. Rather, they should be read as examples of arguments voiced by a variety of individuals and groups who are capable of informing, influencing or making decisions that affect this field of government activity. It should not be supposed that the government statements brought together in this commentary are necessarily consistent or coherent. Instead, in some cases at least, they seem incompatible and may even be irreconcilable. But, given that the source material is drawn from a wide range of documents with a broad range of authors and was published over a number of years, the extent of their unanimity is remarkable. As an introductory guide, this commentary is not offered as exhaustive, as representative of all aspects or shades of government thinking on this subject. On the contrary, only statements published in documents emanating from, or associated with, the Department of Energy have, for the most part, been cited. For the sake of brevity, statements published by other government departments with responsibility for the conservation of energy in buildings—such as the Department of the Environment—have not been drawn upon.}
}
@article{INTRONE201479,
title = {Improving decision-making performance through argumentation: An argument-based decision support system to compute with evidence},
journal = {Decision Support Systems},
volume = {64},
pages = {79-89},
year = {2014},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2014.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167923614001262},
author = {Joshua Introne and Luca Iandoli},
keywords = {Computer-supported argumentation, Evidence-based reasoning, Dempster–Shafer belief aggregation, Housing market prediction},
abstract = {While research has shown that argument based systems (ABSs) can be used to improve aspects of individual thinking and learning, relatively few studies have shown that ABSs improve decision performance in real world tasks. In this article, we strive to improve the value-proposition of ABSs for decision makers by showing that individuals can, with minimal training, use a novel ABS called Pendo to improve their ability to predict housing market trends. Pendo helps to weight and aggregate evidence through a computational engine to support evidence-based reasoning, a well-documented deficiency in human decision-making. It also supports individuals in the creation of knowledge artifacts that can be used to solve similar problems in the same domain. An unexpected finding and one of the major contributions of this work is that individual unaided decision-making performance was not predictive of an individual's performance with Pendo, even though the average performance of assisted individuals was higher. We infer that the skills activated when using the tool are substantially different than those enacted to solve the same problem without that tool. We discuss the implications this result has for the design and application of ABSs to decision-making, and possibly other decision support technologies.}
}
@article{CANADAS201687,
title = {Second graders articulating ideas about linear functional relationships},
journal = {The Journal of Mathematical Behavior},
volume = {41},
pages = {87-103},
year = {2016},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2015.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312315300055},
author = {María C. Cañadas and Bárbara M. Brizuela and Maria Blanton},
keywords = {Quantities, Functional thinking, Early algebra, Elementary students},
abstract = {In this paper, we explore the ideas that second grade students articulate about functional relationships. We adopt a function-based approach to introduce elementary school children to algebraic content. We present results from a design-based research study carried out with 21 second-grade students (approximately 7 years of age). We focus on a lesson from our classroom teaching experiment in which the students were working on a problem that involved a linear functional relationship (y=2x). From the analysis of students’ written work and classroom video, we illustrate two different approaches that students adopt to express the relationship between two quantities. Students show fluency recontextualizing the problem posed, moving between extra-mathematical and intra-mathematical contexts.}
}
@article{SPINU2022100205,
title = {A matter of trust: Learning lessons about causality will make qAOPs credible},
journal = {Computational Toxicology},
volume = {21},
pages = {100205},
year = {2022},
issn = {2468-1113},
doi = {https://doi.org/10.1016/j.comtox.2021.100205},
url = {https://www.sciencedirect.com/science/article/pii/S2468111321000517},
author = {Nicoleta Spînu and Mark T.D. Cronin and Judith C. Madden and Andrew P. Worth},
keywords = {Model credibility, Adverse Outcome Pathway, qAOP, Causality, Next Generation Risk Assessment},
abstract = {Toxicology in the 21st Century has seen a shift from chemical risk assessment based on traditional animal tests, identifying apical endpoints and doses that are “safe”, to the prospect of Next Generation Risk Assessment based on non-animal methods. Increasingly, large and high throughput in vitro datasets are being generated and exploited to develop computational models. This is accompanied by an increased use of machine learning approaches in the model building process. A potential problem, however, is that such models, while robust and predictive, may still lack credibility from the perspective of the end-user. In this commentary, we argue that the science of causal inference and reasoning, as proposed by Judea Pearl, will facilitate the development, use and acceptance of quantitative AOP models. Our hope is that by importing established concepts of causality from outside the field of toxicology, we can be “constructively disruptive” to the current toxicological paradigm, using the “Causal Revolution” to bring about a “Toxicological Revolution” more rapidly.}
}
@article{BARELI2013472,
title = {Sketching profiles: Awareness to individual differences in sketching as a means of enhancing design solution development},
journal = {Design Studies},
volume = {34},
number = {4},
pages = {472-493},
year = {2013},
note = {Special Issue: Articulating Design Thinking},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2013.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X13000197},
author = {Shoshi Bar-Eli},
keywords = {design processes, design research, design behavior, problem solving, design tools},
abstract = {This paper focuses on the differences between interior design students' design processes as derived from an analysis of their sketching and design behavior. By implementing qualitative methodologies in the analysis of the sketches produced in the conceptual phase of the design process, the experiment allows identifying sketching characteristics and profiles. The motivation is to show that sketches can serve as a tool to differentiate between designers and recognize their personal approach and design strategies. The results point to three distinct sketching profiles that characterize designers' use of sketches as a tool for thinking and communicating ideas during their solution generation process. Awareness to differences between students' sketches and design behavior may support the development of pedagogical concepts, strategies and tools.}
}
@article{CAMPAGNOLO2007387,
title = {The Methods of Approximation and Lifting in Real Computation},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {167},
pages = {387-423},
year = {2007},
note = {Proceedings of the Third International Conference on Computability and Complexity in Analysis (CCA 2006)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2006.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S1571066107000229},
author = {Manuel L. Campagnolo and Kerry Ojakian},
keywords = {Computable Analysis, Real Recursive Functions, Elementary Computable},
abstract = {The basic motivation behind this work is to tie together various computational complexity classes, whether over different domains such as the naturals or the reals, or whether defined in different manners, via function algebras (Real Recursive Functions) or via Turing Machines (Computable Analysis). We provide general tools for investigating these issues, using a technique we call the method of approximation. We give the general development of this method, and apply it to obtain 2 theorems. First we connect the discrete operation of linear recursion (basically equivalent to the combination of bounded sums and bounded products) to linear differential equations, thus providing an alternative proof of the result from Campagnolo, Moore and Costa [M.L. Campagnolo, C. Moore and J. F. Costa, An analog characterization of the Grzegorczyk hierarchy, Journal of Complexity 18 (2002) 977–100]. Secondly, we extend this to prove a result similar to that of Bournez and Hainry [O. Bournez and E. Hainry, Elementarily computable functions over the real numbers and R-sub-recursive functions, Theoretical Computer Science 348 (2005) 130–147], providing a function algebra for the real functions computable in elementary time. Their proof involves simulating the operation of a Turing Machine using a function algebra. We avoid this simulation, using a technique we call “lifting,” which allows us to lift the classic result regarding the Kalmar elementary computable functions to a result on the reals. While we do not claim that our result is necessarily an improvement (perhaps just different), we do want to make the point that our two techniques appear readily applicable to other problems of this sort.}
}
@article{DASILVA2022402,
title = {A Predictive, Context-Dependent Stochastic Model for Engineering Applications},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {2},
pages = {402-407},
year = {2022},
note = {14th IFAC Workshop on Intelligent Manufacturing Systems IMS 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.04.227},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322002282},
author = {Márcio J. {da Silva} and Gustavo Künzel and Carlos E. Pereira},
keywords = {Data Mining, Predictive Situation, Context Testing, Industrial Alarm System, Recommendation Systems},
abstract = {This work explores the architecture of a context-dependent probabilistic model. We identify opportunities for providing reminders to operators in their environment as a means to address information overload. Hence, there is a need to represent a state of knowledge and help them stay vigilant during their jobs. Along with the architectural improvements, which further specialize information flows and develop a data-driven approach, continual learning techniques covered events in a probabilistic graphical model called Context-Dependent Recommendation Systems (CD-RS). We demonstrated, as a result, the use of statistical thinking and Design of Experiments (DoE), which are most clear in conducting a suitable experiment. Moreover, the validation of the model and experiments of the novel architecture based on the collected data from a real case study demonstrates the value of the proposed methods.}
}
@article{ZHAO2023100891,
title = {Meet the authors: Yuxuan Zhao, Enmeng Lu, and Yi Zeng},
journal = {Patterns},
volume = {4},
number = {12},
pages = {100891},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100891},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923002933},
author = {Yuxuan Zhao and Enmeng Lu and Yi Zeng},
abstract = {Yuxuan Zhao, associate professor, Enmeng Lu, research engineer, and Yi Zeng, professor and lab director, have proposed a brain-inspired bodily self-perception model based on biological findings on monkeys and humans. This model can reproduce various rubber hand illusion (RHI) experiments, which helps reveal the RHI’s computational and biological mechanisms. They talk about their view of data science and research plans for brain-inspired robot self-modeling and ethical robots.}
}
@article{HUBERMAN19981169,
title = {Computation as economics},
journal = {Journal of Economic Dynamics and Control},
volume = {22},
number = {8},
pages = {1169-1186},
year = {1998},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(98)00008-6},
url = {https://www.sciencedirect.com/science/article/pii/S0165188998000086},
author = {Bernardo A. Huberman},
abstract = {We use computers to study economics, but few people realize that we can use economics to study and design computational systems. The reason is that computer networks can be regarded as a community of processes that in their interactions, strategies and lack of perfect knowledge face the same issues as people in markets. This paper describes how computers have evolved to a point where economics approaches are useful for designing them and understanding their dynamics. Examples are given of existing computer systems that use market mechanisms and of novel phenomena, such as clustered volatility, that we uncovered when studying their evolution.}
}
@article{JIANG2024102530,
title = {Product innovation design approach driven by implicit relationship completion via patent knowledge graph},
journal = {Advanced Engineering Informatics},
volume = {61},
pages = {102530},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102530},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624001782},
author = {Shaofei Jiang and Jingwei Yang and Jing Xie and Xuesong Xu and Yubo Dou and Liting Jing},
keywords = {Product innovation design, Patent text, Knowledge graph, RFSB ontology model, Implicit relationship completion},
abstract = {Product innovation design process involves a great deal of discrete engineering knowledge, limiting the ability of designers to quickly utilize this knowledge to support design innovation. Nowadays, innovation design based on knowledge graphs has enhanced the ability to explore design knowledge, improving the efficiency of knowledge retrieval. Previous studies have focused on mining more design knowledge to enrich the knowledge graph overlooks the implicit relationships with potential value among design knowledge, wasting design resources. To address these issues, an approach for product innovation design based on implicit knowledge relationship completion in the patent knowledge graph is proposed, which explores the implicit relationships between design knowledge to provide new knowledge satisfying design preferences and enhance the innovativeness of solutions. First, a requirements-function-structure-benefit (RFSB) knowledge ontology is constructed and extracted from the benefit knowledge of patents to build the knowledge graph. Second, an implicit relationship completion model based on the similarity of function or benefit entities explores the implicit relationships, replacing structure entities directly connected to similar function or benefit entities to generate new relationships and outputs novel ideas. Third, a scheme improvement process based on the co-occurrence frequency of requirement and structure knowledge supplements neglected design preferences. Final, a pipeline inspection robot case study is further employed to verify the proposed approach, and a patent knowledge graph assisted design solution prototype system is developed to assist in the utilization of innovative design knowledge. Evaluation results show the significant design potential of the proposed approach in inspiring innovative thinking and knowledge reuse.}
}
@article{MALLETT20241105,
title = {New strategies for the cognitive science of dreaming},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {12},
pages = {1105-1117},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S136466132400264X},
author = {Remington Mallett and Karen R. Konkoly and Tore Nielsen and Michelle Carr and Ken A. Paller},
keywords = {sleep, dreams, memory, neuroscience, natural language processing},
abstract = {Dreams have long captivated human curiosity, but empirical research in this area has faced significant methodological challenges. Recent interdisciplinary advances have now opened up new opportunities for studying dreams. This review synthesizes these advances into three methodological frameworks and describes how they overcome historical barriers in dream research. First, with observable dreaming, neural decoding and real-time reporting offer more direct measures of dream content. Second, with dream engineering, targeted stimulation and lucidity provide routes to experimentally manipulate dream content. Third, with computational dream analysis, the generation and exploration of large dream-report databases offer powerful avenues to identify patterns in dream content. By enabling researchers to systematically observe, engineer, and analyze dreams, these innovations herald a new era in dream science.}
}
@article{OLIVEIRA2022102347,
title = {Beyond energy services: A multidimensional and cross-disciplinary agenda for home energy management research},
journal = {Energy Research & Social Science},
volume = {85},
pages = {102347},
year = {2022},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2021.102347},
url = {https://www.sciencedirect.com/science/article/pii/S2214629621004382},
author = {Sonja Oliveira and Lidia Badarnah and Merate Barakat and Anna Chatzimichali and Ed Atkins},
keywords = {Architecture, Biomimetics, Computational design, Cross-disciplinary methods, Home energy management},
abstract = {Home Energy Management (HEM) has a significantly growing impact on strategic energy policy, digital equity, as well as housing development and transport issues. With the proliferation of home working, reliance on electricity for heating and cooling and the increasing needs for electric charging for transportation, there is an urgent need to develop novel ways for efficient management of home energy use. Current efforts focus on HEM technologies at individual household levels, without considering the social or spatial context or their collective community-wide interrelated dependencies. We propose a multifaceted agenda at the intersection of disciplinary domains to tackle this problem by using a multidimensional lens that draws on energy behaviour, architectural research, biomimetics, and computational design, simultaneously. Optimal and effective behavioural patterns can be extracted and abstracted from nature, informing a more collective and interrelated behavioural dependencies approach that considers the complex multidimensional energy use patterns of different housing typologies. This paper discusses the analytical benefits of this new research approach through a study of home energy management behaviour. The approach though could be expanded to consider other similar empirical contexts whereby sustainable multidimensional resource management is sought such as water use, food distribution as well as transport and mobility.}
}
@incollection{VALLERO2021601,
title = {Chapter 14 - The Future},
editor = {Daniel A. Vallero},
booktitle = {Environmental Systems Science},
publisher = {Elsevier},
pages = {601-613},
year = {2021},
isbn = {978-0-12-821953-9},
doi = {https://doi.org/10.1016/B978-0-12-821953-9.00004-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128219539000040},
author = {Daniel A. Vallero},
keywords = {Precautionary principle, Evidence-based risk assessment, Exposome, Translational science, Scientific workflow, Ontologies, Resilience, Data-driven decision-making, Precision science, Life cycle risk assessment (LCRA)},
abstract = {Solving and preventing environmental problems will continue to rely on systems thinking that translates and combines data, information, knowledge, and wisdom from numerous scientific and other perspectives. The chapter provides insights into possible directions for environmental systems science, especially ways to address complexities at every scale from cellular to planetary. Environmental scientists and engineers will engage in precision science and customized approaches to reduce risks, improve reliability and resilience, and ensure sustainability.}
}
@article{ASSIOURAS2025104063,
title = {The evolution of artificial empathy in the hospitality metaverse era},
journal = {International Journal of Hospitality Management},
volume = {126},
pages = {104063},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2024.104063},
url = {https://www.sciencedirect.com/science/article/pii/S027843192400375X},
author = {Ioannis Assiouras and Cornelia Laserer and Dimitrios Buhalis},
keywords = {Empathy, Artificial empathy, Artificial intelligence, Metaverse, Hospitality, Artificial intelligence agents},
abstract = {As hospitality enters the metaverse era, artificial empathy becomes essential for developing of artificial intelligence (AI) agents. Using the empathy cycle model, computational empathy frameworks and interdisciplinary research, this conceptual paper proposes a model explaining how artificial empathy will evolve in the hospitality metaverse era. The paper also addresses customer empathy and responses towards AI agents and other human actors with in the hospitality context. It explores how metaverse characteristics such as immersiveness, sociability, experiential nature, interoperability, blended virtual and physical environments as well as environmental fidelity will shape computational models and evolution of artificial empathy. Findings suggests that metaverse enables AI agents to form a seamless cycle of detection, resonation, and response to consumers’ affective states, facilitating the evolution of artificial empathy. Additionally, the paper outlines conditions under which the artificial empathy cycle may be disrupted and proposes future research questions that can advance our understanding of artificial empathy.}
}
@article{HEIDELBERGER1996627,
title = {Accelerating mean time to failure computations},
journal = {Performance Evaluation},
volume = {27-28},
pages = {627-645},
year = {1996},
issn = {0166-5316},
doi = {https://doi.org/10.1016/S0166-5316(96)90049-8},
url = {https://www.sciencedirect.com/science/article/pii/S0166531696900498},
author = {Philip Heidelberger and Jogesh K. Muppala and Kishor S. Trivedi},
keywords = {Markov chains, Mean time to failure, Numerical methods},
abstract = {In this paper we consider the problem of numerical computation of the mean time to failure (MTTF) in Markovian dependability and/or performance models. The problem can be cast as a system of linear equations which is solved using an iterative method preserving sparsity of the Markov chain matrix. For highly dependable systems, system failure is a rare event and the above system solution can take an extremely large number of iterations. We propose to solve the problem by dividing the computation in two parts. First, by making some of the high probability states absorbing, we compute the MTTF of the modified Markov chain. In a subsequent step, by solving another system of linear equations, we are able to compute the MTTF of the original model. We prove that for a class of highly dependable systems, the resulting method can speed up computation of the MTTF by orders of magnitude. Experimental results supporting this claim are presented. We also obtain bounds on the convergence rate for computing the mean entrance time of a rare set of states in a class of queueing models.}
}
@article{LAKAMSANI1995993,
title = {Mapping molecular dynamics computations on to hypercubes},
journal = {Parallel Computing},
volume = {21},
number = {6},
pages = {993-1013},
year = {1995},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(95)00006-A},
url = {https://www.sciencedirect.com/science/article/pii/016781919500006A},
author = {Vamsee Lakamsani and Laxmi N. Bhuyan and D.Scott Linthicum},
keywords = {Mapping problem, Recursive mincut, Molecular dynamics, Compact MD graph, Hypercube},
abstract = {We propose an approach for partitioning an irregular application problem in computational biology called Molecular Dynamics (MD) of Macromolecules. We model the application as a task graph which we call a compact MD graph. Such a modeling allows existing mapping heuristics to be applied to this problem. We then provide a parallel algorithm for this application, by using an efficient mapping heuristic called Allocation By Recursive Mincut (ARM) to map the compact MD graph to a hypercube connected parallel computer, the nCUBE 2S. A canonical model for executing parallel computations modeled as graphs is described. Thus, we attempt to provide the missing link between the mapping research and application implementation research, and demonstrate that the execution time can be sufficiently reduced by considering formal mapping techniques, while designing parallel programs for important applications.}
}
@article{BLOCK20191003,
title = {What Is Wrong with the No-Report Paradigm and How to Fix It},
journal = {Trends in Cognitive Sciences},
volume = {23},
number = {12},
pages = {1003-1013},
year = {2019},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2019.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661319302360},
author = {Ned Block},
keywords = {consciousness, perception, rivalry, frontal, global workspace, higher order},
abstract = {Is consciousness based in prefrontal circuits involved in cognitive processes like thought, reasoning, and memory or is it based in sensory areas in the back of the neocortex? The no-report paradigm has been crucial to this debate because it aims to separate the neural basis of the cognitive processes underlying post-perceptual decision and report from the neural basis of conscious perception itself. However, the no-report paradigm is problematic because, even in the absence of report, subjects might engage in post-perceptual cognitive processing. Therefore, to isolate the neural basis of consciousness, a no-cognition paradigm is needed. Here, I describe a no-cognition approach to binocular rivalry and outline how this approach can help to resolve debates about the neural basis of consciousness.}
}
@incollection{WU2012223,
title = {10 - Computational modeling and ab initio calculations in MAX phases – II},
editor = {I.M. Low},
booktitle = {Advances in Science and Technology of Mn+1AXn Phases},
publisher = {Woodhead Publishing},
pages = {223-270},
year = {2012},
isbn = {978-1-84569-991-8},
doi = {https://doi.org/10.1533/9780857096012.223},
url = {https://www.sciencedirect.com/science/article/pii/B9781845699918500102},
author = {E. Wu},
keywords = {computational modeling,  calculations, density function theory, energy band, electronic properties, density of states},
abstract = {Abstract:
This chapter reviews the latest researches and advances in the uses of the computational modeling and ab initio calculations on the study of the MAX phases and their properties. The fundamentals and approaches of the density functional theory in the ab initio quantum mechanical calculations and the importance of the theory in the study of the MAX phases are introduced. The studies of the electronic structures and properties, in particular, the energy band structures and total and/or partial density of states of the MAX phases, by using the means of the density function theory are illustrated and discussed. The stability and occurrence of the MAX phases predicted and confirmed by the density functional theory based energetic calculations are addressed. The ab initio calculated elastic and other physical properties of the MAX phases, and the effects of pressure, defects and impurities on the various structural and physical properties are also discussed.}
}
@article{HIPOLITO2017432,
title = {Mind-life continuity: A qualitative study of conscious experience},
journal = {Progress in Biophysics and Molecular Biology},
volume = {131},
pages = {432-444},
year = {2017},
note = {Integral Biomathics 2017: The Necessary Conjunction of Western and Eastern Thought Traditions for Exploring the Nature of Mind and Life},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717301165},
author = {Inês Hipólito and Jorge Martins},
keywords = {Conscious experience, Qualitative study, Meditation, , Mind-life continuity thesis},
abstract = {There are two fundamental models to understanding the phenomenon of natural life. One is the computational model, which is based on the symbolic thinking paradigm. The other is the biological organism model. The common difficulty attributed to these paradigms is that their reductive tools allow the phenomenological aspects of experience to remain hidden behind yes/no responses (behavioral tests), or brain ‘pictures’ (neuroimaging). Hence, one of the problems regards how to overcome methodological difficulties towards a non-reductive investigation of conscious experience. It is our aim in this paper to show how cooperation between Eastern and Western traditions may shed light for a non-reductive study of mind and life. This study focuses on the first-person experience associated with cognitive and mental events. We studied phenomenal data as a crucial fact for the domain of living beings, which, we expect, can provide the ground for a subsequent third-person study. The intervention with Jhana meditation, and its qualitative assessment, provided us with experiential profiles based upon subjects' evaluations of their own conscious experiences. The overall results should move towards an integrated or global perspective on mind where neither experience nor external mechanisms have the final word.}
}
@article{KELLEY2021439,
title = {Applying Independent Core Observer Model Cognitive Architecture to a Collective Intelligence System},
journal = {Procedia Computer Science},
volume = {190},
pages = {439-449},
year = {2021},
note = {2020 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: Eleventh Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.06.052},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921012977},
author = {David Kelley},
keywords = {Collective Intelligence Systems, Independent Core Observer Model, Artificial General Intelligence, mediated Artificial Superintelligence, Hive Mind, AGI, ICOM, mASI.},
abstract = {This paper shows how the Independent Core Observer Model (ICOM) Cognitive Architecture for Artificial General Intelligence (AGI) can be applied to building a collective intelligence system called a mediated Artificial Superintelligence (mASI). The details include breaking down the ICOM implementation in the form of the mASI system and the general performance of initial studies with the mASI. Details of the primary difference between the Independent Core Observer Model Cognitive Architecture and the mASI architecture variant include inserting humanity in the contextual engine components of ICOM, creating a type of collective intelligence. Humans can ‘mediate’ new system-generated thinking keeping the thought process accessible and slow enough for humans to oversee and understand. This also allows the modification of emotional valences of the thought process of the mASI system to help the system generate complex contextual models (knowledge graphs) of new ideas and which speeds up the learning process. With the humans acting as control rods in a reactor and emotional drivers, the mASI system maintains safety where the system would cease to function if humans walked away.}
}