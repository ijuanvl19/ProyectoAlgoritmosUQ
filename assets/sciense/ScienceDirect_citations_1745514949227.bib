@article{WU2018127,
title = {Single dose testosterone administration modulates emotional reactivity and counterfactual choice in healthy males},
journal = {Psychoneuroendocrinology},
volume = {90},
pages = {127-133},
year = {2018},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2018.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S0306453017312532},
author = {Yin Wu and Luke Clark and Samuele Zilioli and Christoph Eisenegger and Claire M. Gillan and Huihua Deng and Hong Li},
keywords = {Testosterone, Reward, Regret, Emotion, Human male, Dual process},
abstract = {Testosterone has been implicated in the regulation of emotional responses and risky decision-making. However, the causal effect of testosterone upon emotional decision-making, especially in non-social settings, is still unclear. The present study investigated the role of testosterone in counterfactual thinking: regret is an intense negative emotion that arises from comparison of an obtained outcome from a decision against a better, non-obtained (i.e. counterfactual) alternative. Healthy male participants (n = 64) received a single-dose of 150 mg testosterone Androgel in a double-blind, placebo-controlled, between-participants design. At 180 min post-administration, participants performed the counterfactual thinking task. We applied a computational model derived from behavioral economic principles to uncover latent decision-making mechanisms that may be invisible in simple choice analyses. Our data showed that testosterone increased the ability to use anticipated regret to guide choice behavior, while reducing choice based on expected value. On affective ratings, testosterone increased sensitivity to both obtained and counterfactual outcomes. These findings provide evidence that testosterone causally modulates emotional decision-making, and highlight the role of testosterone in affective sensitivity.}
}
@incollection{CRUZQUIROGA2016103,
title = {Chapter 5 - Neurobiological Computation and Neural Networks},
editor = {Munish Puri and Yashwant Pathak and Vijay Kumar Sutariya and Srinivas Tipparaju and Wilfrido Moreno},
booktitle = {Artificial Neural Network for Drug Design, Delivery and Disposition},
publisher = {Academic Press},
address = {Boston},
pages = {103-120},
year = {2016},
isbn = {978-0-12-801559-9},
doi = {https://doi.org/10.1016/B978-0-12-801559-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128015599000053},
author = {Luis Fernando {Cruz Quiroga} and Wilfrido Alejandro Moreno},
keywords = {Complex problem solving, Neural networks, Neurobiology, Neuroscience},
abstract = {This chapter presents the neurobiological basis for the convergence of interdisciplinary work (Nano-Bio-Info-Cogno) in the research of artificial neural networks. The neurobiological study was conducted from neuroscience and technology; the topics explained are genetics and cognition, complexity of information, information processing, brain and problem solving, emotions, and solutions as well as the relationship between the nervous system cells and biological synthesis of information as part of studies to the given problems. The most specific cognitive functions related to decision making and problem solving—attention, time, process, motion, relevance of information, and memory—as well as reasoning processes not typically associated with solving complex problems are reviewed.}
}
@article{NAKHLEH2013719,
title = {Computational approaches to species phylogeny inference and gene tree reconciliation},
journal = {Trends in Ecology & Evolution},
volume = {28},
number = {12},
pages = {719-728},
year = {2013},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2013.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0169534713002139},
author = {Luay Nakhleh},
abstract = {An intricate relation exists between gene trees and species phylogenies, due to evolutionary processes that act on the genes within and across the branches of the species phylogeny. From an analytical perspective, gene trees serve as character states for inferring accurate species phylogenies, and species phylogenies serve as a backdrop against which gene trees are contrasted for elucidating evolutionary processes and parameters. In a 1997 paper, Maddison discussed this relation, reviewed the signatures left by three major evolutionary processes on the gene trees, and surveyed parsimony and likelihood criteria for utilizing these signatures to elucidate computationally this relation. Here, I review progress that has been made in developing computational methods for analyses under these two criteria, and survey remaining challenges.}
}
@article{KEITZER20161322,
title = {Thinking outside of the lake: Can controls on nutrient inputs into Lake Erie benefit stream conservation in its watershed?},
journal = {Journal of Great Lakes Research},
volume = {42},
number = {6},
pages = {1322-1331},
year = {2016},
issn = {0380-1330},
doi = {https://doi.org/10.1016/j.jglr.2016.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0380133016300958},
author = {S. Conor Keitzer and Stuart A. Ludsin and Scott P. Sowa and Gust Annis and Jeff G. Arnold and Prasad Daggupati and August M. Froehlich and Matt E. Herbert and Mari-Vaughn V. Johnson and Anthony M. Sasson and Haw Yen and Mike J. White and Charles A. Rewa},
keywords = {Best management practices, SWAT, Non-point source pollution, Great Lakes, Ecosystem-based management, Index of Biotic Integrity},
abstract = {Investment in agricultural conservation practices (CPs) to address Lake Erie's re-eutrophication may offer benefits that extend beyond the lake, such as improved habitat conditions for fish communities throughout the watershed. If such conditions are not explicitly considered in Lake Erie nutrient management strategies, however, this opportunity might be missed. Herein, we quantify the potential for common CPs that will be used to meet nutrient management goals for Lake Erie to simultaneously improve stream biological conditions throughout the western Lake Erie basin (WLEB) watershed. To do so, we linked a high-resolution watershed-hydrology model to predictive biological models in a conservation scenario framework. Our modeling simulations showed that the implementation of CPs on farm acres in critical and moderate need of treatment, representing nearly half of the watershed, would be needed to reduce spring/early summer total phosphorus loads from the WLEB watershed to acceptable levels. This widespread CP implementation also would improve potential stream biological conditions in >11,000km of streams and reduce the percentage of streams where water quality is limiting biological conditions, from 31% to 20%. Despite these improvements, we found that even with additional treatment of acres in low need of CPs, degraded water quality conditions would limit biological conditions in >3200streamkm. Thus, while we expect CPs to play an important role in mitigating eutrophication problems in the Lake Erie ecosystem, additional strategies and emerging technologies appear necessary to fully reduce water quality limitation throughout the watershed.}
}
@article{ORTEGA2010171,
title = {Parallel drainage network computation on CUDA},
journal = {Computers & Geosciences},
volume = {36},
number = {2},
pages = {171-178},
year = {2010},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0098300409002970},
author = {L. Ortega and A. Rueda},
keywords = {GPU, GPGPU, CUDA, Drainage network, D8 algorithm},
abstract = {Drainage networks determination from digital elevation models (DEM) has been a widely studied problem in the last three decades. During this time, satellite technology has been improving and optimizing digitalized images, and computers have been increasing their capabilities to manage such a huge quantity of information. The rapid growth of CPU power and memory size has concentrated the discussion of DEM algorithms on the accuracy of their results more than their running times. However, obtaining improved running times remains crucial when DEM dimensions and their resolutions increase. Parallel computation provides an opportunity to reduce run times. Recently developed graphics processing units (GPUs) are computationally fast not only in Computer Graphics but in General Purpose Computation, the so-called GPGPU. In this paper we explore the parallel characteristics of these GPUs for drainage network determination, using the C-oriented language of CUDA developed by NVIDIA. The results are simple algorithms that run on low-cost technology with a high performance response, obtaining CPU improvements of up to 8×.}
}
@article{GOK201249,
title = {A philosophical assessment of computational models of consciousness},
journal = {Cognitive Systems Research},
volume = {17-18},
pages = {49-62},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000635},
author = {Selvi Elif Gök and Erdinç Sayan},
keywords = {Consciousness, Computational cognitive modeling, Clarion, LIDA, ACT-R, Neuronal Work Space Model, ART, GMU-BICA},
abstract = {There has been a recent flurry of activity in consciousness research. Although an operational definition of consciousness has not yet been developed, philosophy has come to identify a set of features and aspects that are thought to be associated with the various elements of consciousness. On the other hand, there have been several recent attempts to develop computational models of consciousness that are claimed to capture or illustrate one or more aspects of consciousness. As a plausible substitute to evaluating how well the current computational models model consciousness, this study examines how the current computational models fare in modeling those aspects and features of consciousness identified by philosophy. Following a review of the literature on the philosophy of consciousness, this study constructs a list of features and aspects that would be expected in any successful model of consciousness. The study then evaluates, from the viewpoint of that list, some of the current self-claimed and implemented computational models of consciousness. The computational models studied are evaluated with respect to each identified aspect and feature of consciousness.}
}
@article{GU2024825,
title = {Enhancing campus OS community engagement through the miniOS pilot class: A nine-year journey},
journal = {Future Generation Computer Systems},
volume = {160},
pages = {825-834},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24003042},
author = {Jianhua Gu and Mingxuan Liu and Tianhai Zhao},
keywords = {Community engagement, Software engineering education, Operating system, Software engineering management},
abstract = {Recognized as the crown jewel of system software, Operating System (OS) is notoriously challenging to teach and learn, given its abstract concepts, broad scope, and the imperative for hands-on experience. How to cater to the keen interest in OS among students across all universities while providing a rich system software engineering experience? Engaging the OS community on campus plays a pivotal role in enhancing undergraduate education. Our institution has implemented a novel approach over the past nine years through the miniOS pilot class initiative. This program allows students enrolled in the OS course to opt into an additional, practical component where they engage in developing the OS kernel using miniOS, our teaching platform. Participants dedicate their spare time to a series of labs aimed at incrementally introducing them to miniOS, collaborate on a project to add a new functional module to miniOS, and ultimately present their work in a formal defense. This hands-on experience supplements the theoretical coursework, with the notable advantage that pilot class participants are exempt from the traditional final exam. Instead, their grade is determined by their contributions to the pilot class, with distinguished projects being integrated into the evolving miniOS kernel—a witness to the collective effort of each class. Since its inception in 2015, the miniOS pilot class has nurtured 182 undergraduates and 22 graduate students, contributing significantly to the OS community engagement on campus. Through this initiative, we have gleaned six key insights and six lessons, which we are eager to share with the broader educational community.}
}
@incollection{BODEN2008741,
title = {INFORMATION, COMPUTATION, AND COGNITIVE SCIENCE},
editor = {Pieter Adriaans and Johan {van Benthem}},
booktitle = {Philosophy of Information},
publisher = {North-Holland},
address = {Amsterdam},
pages = {741-761},
year = {2008},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-51726-5.50023-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517265500236},
author = {Margaret A. Boden}
}
@article{ARDALAN2018170,
title = {Neurofinance versus the efficient markets hypothesis},
journal = {Global Finance Journal},
volume = {35},
pages = {170-176},
year = {2018},
issn = {1044-0283},
doi = {https://doi.org/10.1016/j.gfj.2017.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1044028317302715},
author = {Kavous Ardalan},
keywords = {Neurofinance, Behavioral finance, Costly thinking, Efficient markets hypothesis},
abstract = {This paper develops the implication of neurofinance with respect to the efficient markets hypothesis. Neurofinance informs us that thinking imposes strain on the mind, in the sense that thinking is a comparatively laborious, biologically costly, and neurologically expensive cognitive process. The paper shows that people balance the costs and benefits of thinking and demonstrates mathematically that such balancing makes financial markets inefficient.}
}
@article{SHI2018117,
title = {Toward automated reasoning for analog IC design by symbolic computation – A survey},
journal = {Integration},
volume = {60},
pages = {117-131},
year = {2018},
issn = {0167-9260},
doi = {https://doi.org/10.1016/j.vlsi.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167926017304182},
author = {Guoyong Shi},
keywords = {Analog integrated circuit (IC), Computer-aided reasoning (CAR), Formal information processing, Graph-pair decision diagram (GPDD), Knowledge representation, Operational amplifier (opamp), Symbolic computation},
abstract = {Analog integrated circuit (IC) design highly depends on reasoning, which distinguishes itself from other areas of IC design. Most of its innovation arises from qualitative reasoning by a pencil and paper. Innovation on the circuit structure needs quick analytical justification. Circuit-level reduced-scale modeling is a popular reasoning means. Circuit simulation tools can only serve partial justification on a design, while design insight still has to be acquired via manual analysis. A basic question has been in existence for many decades: how can we automate the analog IC design process? Many analog synthesis tools proposed decades ago could not make it to this date in the design practice. In this survey the major reason is attributed to the black-box style of the tool design. Human designer's creativity is shielded away from the tool operation while the formal design knowledge hardcoded in those tools remains at a very primitive level. By analyzing the defects of those existing tools, this survey advocates an open tool development philosophy whose major goal is to support human-machine interaction. On the one side a design automation tool is mainly aimed at providing aid for tasks that require analytical deduction while on the other side designers are expected to exercise their creativity based on the machine-generated results. Such human-machine co-working style is believed to be a more feasible solution to analog IC design automation based on the currently available computation technology. In this survey the art of symbolic computation is promoted to be the enabling technology for computer-aided analytical generation. The symbolic computation technology today can support topological and analytical reasoning that is the most demanding need in the analog IC design practice. This survey further calls for more research on the formal methods that are applicable to design knowledge representation, human-machine interaction, and design inference. Some preliminary research results are reviewed and future research directions are pointed out.}
}
@article{KHAN2022200147,
title = {An effective approach to address processing time and computational complexity employing modified CCT for lung disease classification},
journal = {Intelligent Systems with Applications},
volume = {16},
pages = {200147},
year = {2022},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2022.200147},
url = {https://www.sciencedirect.com/science/article/pii/S2667305322000849},
author = {Inam Ullah Khan and Sami Azam and Sidratul Montaha and Abdullah Al Mahmud and A.K.M. Rakibul Haque Rafid and Md. Zahid Hasan and Mirjam Jonkman},
keywords = {COVID-19, Chest X-rays, Image Preprocessing, Modified compact convolutional transformer, Deep convolutional GAN, Hyper-parameter Tuning},
abstract = {Early identification and adequate treatment can help prevent lung disorders from becoming chronic, severe, and life-threatening. X-ray images are commonly used and an automated and effective method involving deep learning techniques can potentially contribute to quick and accurate diagnosis of lung disorders. However, in the study of medical imaging using deep learning, two obstacles limit interpretability. One is an insufficient and imbalanced number of training samples in most medical datasets. The other is excessive training time. Although training time can be reduced by decreasing the number of pixels in the images, training with low resolution images tends to result in poor performance. This study represents a solution to overcome these impediments by balancing the number of images and reducing overall processing time while preserving accuracy. The dataset used in this research contains an unequal number of images in the different classes. The quantity of data in the classes is balanced by creating synthetic images based on the patterns and characteristics of the original images, using a Deep Convolutional Generative Adversarial Network (DCGAN). Unwanted regions are removed from the X-ray images, the brightness and contrast of the images are enhanced, and the abnormalities are highlighted by using different artifact removal, noise reduction, and enhancement techniques. We propose a Modified Compact Convolutional Transformer (MCCT) model using 32 × 32 sized images for the categorization of lung disorders into four classes. An ablation study of eleven cases is employed to adjust several hyper parameters and layer topologies. This reduces training time while preserving accuracy. Six transfer learning models, VGG19, VGG16, ResNet152, ResNet50, ResNet50V2, and MobileNet are applied with the same image size the performance is compared with the proposed MCCT model. Our MCCT model records the greatest test accuracy of 95.37%, requiring a short training time, 10-12 s/epoch, whereas the other models only reach near-moderate performance with accuracies ranging from 43% to 79% and training times of 80-90 s/epoch. The robustness of the model with regards to the number of training samples is validated by training the model multiple times reducing the number of training images gradually from 49621 images to 6204 images. Results suggest that even with a smaller dataset, the performance is sustained. Our proposed approach may contribute to an effective CAD based diagnostic system by addressing the issues of insufficient and imbalanced numbers of medical images, excessive training times and low-resolution images.}
}
@article{BEGGS20091311,
title = {Computations via Newtonian and relativistic kinematic systems},
journal = {Applied Mathematics and Computation},
volume = {215},
number = {4},
pages = {1311-1322},
year = {2009},
note = {Physics and Computation},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2009.04.052},
url = {https://www.sciencedirect.com/science/article/pii/S0096300309004214},
author = {E.J. Beggs and J.V. Tucker},
keywords = {Foundations of computation, Computable functions and sets, Newtonian kinematic systems, Relativistic kinematic systems, Foundations of mechanics, Theory of Gedanken experiments, Non-computable physical systems},
abstract = {We are developing a rigorous methodology to analyse experimental computation, by which we mean the idea of computing a set or function by experimenting with some physical equipment. Here we consider experimental computation by kinematic systems under both Newtonian and relativistic kinematics. An experimental procedure, expressed in a language similar to imperative programming languages, is applied to equipment, having the form of a bagatelle, and is interpreted using the two theories. We prove that for any set A of natural numbers there exists a two-dimensional kinematic system BA with a single particle P whose observable behaviour decides n∈A for all n∈N. The procedure can operate under (a) Newtonian mechanics or (b) relativistic mechanics. The proofs show how any information (coded by some A) can be embedded in the structure of a simple kinematic system and retrieved by simple observations of its behaviour. We reflect on the methodology, which seeks a formal theory for performing abstract experiments with physical restrictions on the construction of systems. We conclude with some open problems.}
}
@article{NEUMANN2020281,
title = {Parametrised second-order complexity theory with applications to the study of interval computation},
journal = {Theoretical Computer Science},
volume = {806},
pages = {281-304},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519302889},
author = {Eike Neumann and Florian Steinberg},
keywords = {Second-order complexity, Type two complexity, Interval computation, Computable analysis},
abstract = {We extend the framework for complexity of operators in analysis devised by Kawamura and Cook (2012) to allow for the treatment of a wider class of representations. The main novelty is to endow represented spaces of interest with an additional function on names, called a parameter, which measures the complexity of a given name. This parameter generalises the size function which is usually used in second-order complexity theory and therefore also central to the framework of Kawamura and Cook. The complexity of an algorithm is measured in terms of its running time as a second-order function in the parameter, as well as in terms of how much it increases the complexity of a given name, as measured by the parameters on the input and output side. As an application we develop a rigorous computational complexity theory for interval computation. In the framework of Kawamura and Cook the representation of real numbers based on nested interval enclosures does not yield a reasonable complexity theory. In our new framework this representation is polytime equivalent to the usual Cauchy representation based on dyadic rational approximation. By contrast, the representation of continuous real functions based on interval enclosures is strictly smaller in the polytime reducibility lattice than the usual representation, which encodes a modulus of continuity. Furthermore, the function space representation based on interval enclosures is optimal in the sense that it contains the minimal amount of information amongst those representations which render evaluation polytime computable.}
}
@article{SANGALLI2018117,
title = {Matrix-free weighted quadrature for a computationally efficient isogeometric k-method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {338},
pages = {117-133},
year = {2018},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2018.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S0045782518302081},
author = {G. Sangalli and M. Tani},
keywords = {Isogeometric analysis, 
               -method, Matrix-free, Weighted quadrature, Preconditioner},
abstract = {The k-method is the isogeometric method based on splines (or NURBS, etc.) with maximum regularity. When implemented following the paradigms of classical finite element methods, the computational resources required by the k-method are prohibitive even for moderate degree. In order to address this issue, we propose a matrix-free strategy combined with weighted quadrature, which is an ad-hoc strategy to compute the integrals of the Galerkin system. Matrix-free weighted quadrature (MF-WQ) speeds up matrix operations, and, perhaps even more important, greatly reduces memory consumption. Our strategy also requires an efficient preconditioner for the linear system iterative solver. In this work we deal with an elliptic model problem, and adopt a preconditioner based on the Fast Diagonalization method, an old idea to solve Sylvester-like equations. Our numerical tests show that the isogeometric solver based on MF-WQ is faster than standard approaches (where the main cost is the matrix formation by standard Gaussian quadrature) even for low degree. But the main achievement is that, with MF-WQ, the k-method gets orders of magnitude faster by increasing the degree, given a target accuracy. Therefore, we are able to show the superiority, in terms of computational efficiency, of the high-degree k-method with respect to low-degree isogeometric discretizations. What we present here is applicable to more complex and realistic differential problems, but its effectiveness will depend on the preconditioner stage, which is as always problem-dependent. This situation is typical of modern high-order methods: the overall performance is mainly related to the quality of the preconditioner.}
}
@article{MATOS2025100571,
title = {A systematic review of artificial intelligence applications in education: Emerging trends and challenges},
journal = {Decision Analytics Journal},
pages = {100571},
year = {2025},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2025.100571},
url = {https://www.sciencedirect.com/science/article/pii/S277266222500027X},
author = {Tomás Matos and Walter Santos and Eftim Zdravevski and Paulo Jorge Coelho and Ivan Miguel Pires and Filipe Madeira},
keywords = {Artificial intelligence, ChatGPT, Educational technology, Machine learning, Adaptive learning, Systematic review},
abstract = {The academic world is becoming increasingly interested in the applications of Artificial Intelligence technology in education. A systematic review examines AI applications in education, focusing on their effectiveness, challenges, and implications. A comprehensive analysis of studies published between 2011 and 2024 encompassed 45 research articles from major databases, such as PubMed Central, IEEE Xplore, Elsevier, Springer, MDPI, ACM, and PMC. The findings highlight the predominant use of generative AI tools like ChatGPT (30%), followed by other advanced technologies, such as GPT-4, machine learning, and virtual reality. Research across global regions, particularly in Canada (18%), the United States (12%), and China (8%), highlights the multifaceted applications of AI in enhancing personalized learning, fostering critical thinking, and supporting professional education. Tools such as ChatGPT have demonstrated strong performance in theoretical knowledge delivery and medical education, while augmented and virtual reality excels in practical skill development. Despite these advances, challenges such as data privacy concerns, algorithmic bias, and the need for specialized educator training remain critical.}
}
@article{DUKHANOV20141433,
title = {Double-degree Master's Program in Computational Science: Experiences of ITMO University and University of Amsterdam},
journal = {Procedia Computer Science},
volume = {29},
pages = {1433-1445},
year = {2014},
note = {2014 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.130},
url = {https://www.sciencedirect.com/science/article/pii/S187705091400307X},
author = {Alexey V. Dukhanov and Valeria V. Krzhizhanovskaya and Anna Bilyatdinova and Alexander V. Boukhanovsky and Peter M.A. Sloot},
keywords = {teaching computational science, M aster's program, double degree, curriculum, enrollment, student research, funding opportunities},
abstract = {We present a new double-degree graduate (Master's) programme developed together by the ITMO University, Russia and University of Amsterdam, The Netherlands. First, we look into the global aspects of integration of d ifferent educational systems and list some funding opportunities fro m European foundations. Then we describe our double-degree program curricu lu m, suggest the time line of enrollment and studies, and give some e xa mples of student research topics. Finally, we d iscuss the peculiarities of joint progra ms with Russia, re flect on the first lessons learnt, and share our thoughts and experiences that could be of interest to the international community e xpanding the educational ma rkets to the vast countries like Russia, Ch ina or India. The paper is written for education professionals and contains useful information for potential students.}
}
@article{BURTONROBERTS20112089,
title = {On the grounding of syntax and the role of phonology in human cognition},
journal = {Lingua},
volume = {121},
number = {14},
pages = {2089-2102},
year = {2011},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2011.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S002438411100146X},
author = {Noel Burton-Roberts},
keywords = {Syntactic grounding, Interface interpretation, Language faculty, Language of thought, Phonology-free generativity, Phonology in human cognition},
abstract = {Chomskyan generative grammar has long been committed to the ‘double-interface’ assumption that the faculty of language (FL) serves two interfaces, PF and LF, and correlatively that expressions have phonological and semantic properties. The paper argues this gives rise to (a) a grounding problem for syntax – i.e. for the interpretable content of syntax – and (b) a problem for the assumption that FL is a generative computation. It is argued these problems are resolved if we think of syntax as grounded exclusively in semantic/conceptual properties. Since this implies that FL is phonology-free, it is argued that FL should not be distinguished from a generative computation describable as ‘the language of thought’ (LOT). The paper explores to what extent this (FL=LOT) thesis is consistent with Chomsky's thinking. Chomsky's recent work can be seen as pointing in that direction but it is not consistent with the double-interface assumption, which he continues to regard as conceptually necessary. In the light of discussion of the issues, the paper concludes with a speculation on the role of phonology in human cognition and its evolution.}
}
@article{ZHAN2022100096,
title = {The effectiveness of gamification in programming education: Evidence from a meta-analysis},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100096},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100096},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000510},
author = {Zehui Zhan and Luyao He and Yao Tong and Xinya Liang and Shihao Guo and Xixin Lan},
keywords = {Programming education, Gamification, Meta-analysis, Game-based learning},
abstract = {This paper aimed at constructing a systematic framework and examining the effect of gamification in programming education through a meta-analysis conducted on 21 empirical studies published in the last decade. We examined the effects of game types, gamification applications, pedagogical agents, programming types, and schooling levels on students' academic achievement, cognitive load, motivation, and thinking skills in programming education by cross-tabulation analysis. Results verified the positive impact of gamification in programming education. Gamification has the largest effect on students' motivation, followed by academic achievement, whereas it has the least effect on students' cognitive load. As for game types, the reasoning strategy game is most effective on academic achievement, while the puzzle game is most effective on motivation. As for gamification application, the games as a competitive mechanism has the greatest impact on students’ thinking skills and motivation. However, when games were adopted as teaching tools or student works, the effects are mainly represented in academic achievement. Pedagogical agents have a limited effect on programming education. With regard to programming types, the effect of gamification is more pronounced in text-based programming rather than graphical programming. This study provided an analytic framework and shed light on potential directions for further studies in the field.}
}
@article{HODGMAN2012261,
title = {Cell-free synthetic biology: Thinking outside the cell},
journal = {Metabolic Engineering},
volume = {14},
number = {3},
pages = {261-269},
year = {2012},
note = {Synthetic Biology: New Methodologies and Applications for Metabolic Engineering},
issn = {1096-7176},
doi = {https://doi.org/10.1016/j.ymben.2011.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1096717611000929},
author = {C. Eric Hodgman and Michael C. Jewett},
keywords = {Cell-free biology,  protein synthesis, Metabolic engineering, Synthetic biology, Synthetic enzymatic pathways, Biocatalysis},
abstract = {Cell-free synthetic biology is emerging as a powerful approach aimed to understand, harness, and expand the capabilities of natural biological systems without using intact cells. Cell-free systems bypass cell walls and remove genetic regulation to enable direct access to the inner workings of the cell. The unprecedented level of control and freedom of design, relative to in vivo systems, has inspired the rapid development of engineering foundations for cell-free systems in recent years. These efforts have led to programmed circuits, spatially organized pathways, co-activated catalytic ensembles, rational optimization of synthetic multi-enzyme pathways, and linear scalability from the micro-liter to the 100-liter scale. It is now clear that cell-free systems offer a versatile test-bed for understanding why nature's designs work the way they do and also for enabling biosynthetic routes to novel chemicals, sustainable fuels, and new classes of tunable materials. While challenges remain, the emergence of cell-free systems is poised to open the way to novel products that until now have been impractical, if not impossible, to produce by other means.}
}
@article{IBARRATORRES2024413,
title = {Use of basic programming tools to foster programming logic in university students with school preparation other than computer science},
journal = {Procedia Computer Science},
volume = {237},
pages = {413-419},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.122},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011384},
author = {Fernando Ibarra-Torres and Gustavo Caiza and Marcelo V. García and Valeria Barona-Pico},
keywords = {Programming logic, programming tools, software development, undergraduate student},
abstract = {Teaching programming logic to students who do not have a background in computer science is challenging, as the instructor has to awaken problem-solving, critical thinking, and logical reasoning skills Several programming tools have been created to teach coding concepts to computer science students of different ages. However, these tools are not well designed to meet the challenge of teaching programming to new developers who come with school training in other areas such as accounting, management, etc. Therefore, this research focused on analyzing the importance of the application of online programming tools to students starting college who come with a school background in an area other than technology. A pre/post experimental design was carried out with 82 first-level students of the Technical University of Ambato in the careers of Systems and Electronics. The results revealed that 45% of the students increased their levels of application and analysis in programming processes. In addition, the research revealed that students who come from a background other than computer science agree with the integration of online programming tools from the first level of university entrance since this method helps to improve their learning capacity.}
}
@incollection{BONSIGNORE2019291,
title = {Chapter 14 - Device Design and Computational Simulation},
editor = {Christopher P. Cheng},
booktitle = {Handbook of Vascular Motion},
publisher = {Academic Press},
pages = {291-312},
year = {2019},
isbn = {978-0-12-815713-8},
doi = {https://doi.org/10.1016/B978-0-12-815713-8.00014-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128157138000140},
author = {C. Bonsignore},
keywords = {Device design, boundary conditions, simulation, stress and strain, finite element analysis, nitinol, prototyping, iteration, design control},
abstract = {Medical device development consists of ideation, prototyping, simulation, preclinical testing, and clinical trials. In the early stages, design and test iterations offer insights to incorporate into subsequent iterations and should be repeated often with only as much complexity as necessary. Computational simulations, in the form of analytic calculations or finite element analysis (FEA), can be utilized for design concept screening all the way to design verification testing under design control. For FEA, while the mathematics is complicated, and the programming is intricate, the utility of the simulation is only as good as the realism of the anatomic loading boundary conditions. While boundary conditions may not be able to be prescribed exactly as they happen in vivo, good engineering intuition and judgment are invaluable for making reasonable approximations.}
}
@article{STENROOS2019116159,
title = {Real-time computation of the TMS-induced electric field in a realistic head model},
journal = {NeuroImage},
volume = {203},
pages = {116159},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2019.116159},
url = {https://www.sciencedirect.com/science/article/pii/S1053811919307505},
author = {Matti Stenroos and Lari M. Koponen},
keywords = {Transcranial magnetic stimulation (TMS), Navigated transcranial magnetic stimulation, Electric field calculation, Coil model, Volume conductor model},
abstract = {Transcranial magnetic stimulation (TMS) is often targeted using a model of TMS-induced electric field (E). In such navigated TMS, the E-field models have been based on spherical approximation of the head. Such models omit the effects of cerebrospinal fluid (CSF) and gyral folding, leading to potentially large errors in the computed E-field. So far, realistic models have been too slow for interactive TMS navigation. We present computational methods that enable real-time solving of the E-field in a realistic five-compartment (5-C) head model that contains isotropic white matter, gray matter, CSF, skull and scalp. Using reciprocity and Geselowitz integral equation, we separate the computations to coil-dependent and -independent parts. For the Geselowitz integrals, we present a fast numerical quadrature. Further, we present a moment-matching approach for optimizing dipole-based coil models. We verified and benchmarked the new methods using simulations with over 100 coil locations. The new quadrature introduced a relative error (RE) of 0.3–0.6%. For a coil model with 42 dipoles, the total RE of the quadrature and coil model was 0.44–0.72%. Taking also other model errors into account, the contribution of the new approximations to the RE was 0.1%. For comparison, the RE due to omitting the separation of white and gray matter was >11%, and the RE due to omitting also the CSF was >23%. After the coil-independent part of the model has been built, E-fields can be computed very quickly: Using a standard PC and basic GPU, our solver computed the full E-field in a 5-C model in 9000 points on the cortex in 27 coil positions per second (cps). When the separation of white and gray matter was omitted, the speed was 43–65 cps. Solving only one component of the E-field tripled the speed. The presented methods enable real-time solving of the TMS-induced E-field in a realistic head model that contains the CSF and gyral folding. The new methodology allows more accurate targeting and precise adjustment of stimulation intensity during experimental or clinical TMS mapping.}
}
@article{GOLLISCH2010150,
title = {Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina},
journal = {Neuron},
volume = {65},
number = {2},
pages = {150-164},
year = {2010},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2009.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0896627309009994},
author = {Tim Gollisch and Markus Meister},
abstract = {We rely on our visual system to cope with the vast barrage of incoming light patterns and to extract features from the scene that are relevant to our well-being. The necessary reduction of visual information already begins in the eye. In this review, we summarize recent progress in understanding the computations performed in the vertebrate retina and how they are implemented by the neural circuitry. A new picture emerges from these findings that helps resolve a vexing paradox between the retina's structure and function. Whereas the conventional wisdom treats the eye as a simple prefilter for visual images, it now appears that the retina solves a diverse set of specific tasks and provides the results explicitly to downstream brain areas.}
}
@article{SUN2001241,
title = {Computation, reduction, and teleology of consciousness},
journal = {Cognitive Systems Research},
volume = {1},
number = {4},
pages = {241-249},
year = {2001},
issn = {1389-0417},
doi = {https://doi.org/10.1016/S1389-0417(00)00013-9},
url = {https://www.sciencedirect.com/science/article/pii/S1389041700000139},
author = {Ron Sun},
keywords = {Consciousness, Cognition, Qualia, Implicit learning, Computation, Reduction, Teleology},
abstract = {This paper aims to explore mechanistic and teleological explanations of consciousness. In terms of mechanistic explanations, it critiques various existing views, especially those embodied by existing computational cognitive models. In this regard, the paper argues in favor of the explanation based on the distinction between localist (symbolic) representation and distributed representation (as formulated in the connectionist literature), which reduces the phenomenological difference to a mechanistic difference. Furthermore, to establish a teleological explanation of consciousness, the paper discusses the issue of the functional role of consciousness on the basis of the aforementioned mechanistic explanation. A proposal based on synergistic interaction between the conscious and the unconscious is advanced that encompasses various existing views concerning the functional role of consciousness. This two-step deepening explanation has some empirical support, in the form of a cognitive model and various cognitive data that it captures.}
}
@incollection{PETRUZZELLI20121,
title = {1 - Re-thinking the innovation approach},
editor = {ANTONIO MESSENI PETRUZZELLI and VITO ALBINO},
booktitle = {When Tradition Turns Into Innovation},
publisher = {Chandos Publishing},
pages = {1-18},
year = {2012},
isbn = {978-1-84334-664-7},
doi = {https://doi.org/10.1016/B978-1-84334-664-7.50007-0},
url = {https://www.sciencedirect.com/science/article/pii/B9781843346647500070},
author = {ANTONIO MESSENI PETRUZZELLI and VITO ALBINO},
keywords = {triple crisis, innovation, tradition},
abstract = {Abstract
This chapter presents a review and criticism of the actual innovation approaches, highlighting how the social and economic scenario imposes the necessity of rethinking innovation and consumption models. Specifically, we discuss how the recent crises – which together affect finance, food and climate change and their implications for human development – are forcing organisations to find new solutions and models for responding to emerging needs and expectations. In this regard, we elaborate on the important role that may be played by traditional knowledge as a source of inspiration for innovation, since creativity can find a reliable support in what society has found to be suitable in the past for its development needs.}
}
@article{HALEEM2024100006,
title = {Perspective of leadership 4.0 in the era of fourth industrial revolution: A comprehensive view},
journal = {Journal of Industrial Safety},
volume = {1},
number = {1},
pages = {100006},
year = {2024},
issn = {2950-2764},
doi = {https://doi.org/10.1016/j.jinse.2024.100006},
url = {https://www.sciencedirect.com/science/article/pii/S2950276424000060},
author = {Abid Haleem and Mohd Javaid and Ravi Pratap Singh},
keywords = {Leadership 4.0, Industry 4.0, Industrial Safety, Technologies, Management},
abstract = {Leadership 4.0 focuses on leaders developing their digital transformation strategy and ensuring alignment with the organization’s business and development ambitions. This is accomplished by successfully displaying disruptive digital leadership characteristics, which include emotional and social intelligence abilities such as empathy and relationship management, cognitive preparedness, critical thinking, inventive thinking, agility, and resilience. Academics and consultants increasingly use Leadership 4.0 to describe the new leadership style required for the Fourth Industrial Revolution (Industry 4.0). It strategically addresses people’s concerns, which are crucial for the effective integration of Industry 4.0, and plays a significant and crucial role in integrating Industry 4.0 into modern workplaces. The primary purpose of this paper is to explore Leadership 4.0 and its needs. Several quality characteristics associated with Digital Leadership 4.0 are investigated, and two-dimensional style matrix presentations for Leadership 4.0 are briefed. Finally, this study identifies and addresses the role of Leadership 4.0 in upcoming industrial management systems. Because digital technologies now impact the entire business, advancing digital strategies requires strong leadership at all levels. With the increasing prevalence of digital transformation in the business sector and the intensification of the "battle for talent," organizations need to consider a more methodical approach to building a solid leadership pipeline with the capabilities required to lead in the digital era. They may place future leaders in positions that require them to go beyond their current competencies and skills to instruct and motivate them to promptly acquire new digital skills. In a new working setting, effectively managing the dynamic interactions between machines, technology, and people is essential for influential digital leaders. Leadership 4.0 is expected to foster an open and innovative culture that welcomes change and progress. This will encourage and inspire their teams to adapt to the ongoing changes in the market.}
}
@article{PERFORS2012486,
title = {When do memory limitations lead to regularization? An experimental and computational investigation},
journal = {Journal of Memory and Language},
volume = {67},
number = {4},
pages = {486-506},
year = {2012},
issn = {0749-596X},
doi = {https://doi.org/10.1016/j.jml.2012.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X12000800},
author = {Amy Perfors},
keywords = {Regularization, Less is More, Computational modeling, Language acquisition},
abstract = {The Less is More hypothesis suggests that one reason adults and children differ in their ability to learn language is that they also differ in other cognitive capacities. According to one version of this hypothesis, children’s relatively poor memory may make them more likely to regularize inconsistent input (Hudson Kam and Newport, 2005, Hudson Kam and Newport, 2009). This paper reports the result of an experimental and computational investigation of one aspect of this version of the hypothesis. A series of seven experiments in which adults were placed under a high cognitive load during a language-learning task reveal that in adults, increased load during learning (as opposed to retrieval) does not result in increased regularization. A computational model offers a possible explanation for these results. It demonstrates that, unless memory limitations distort the data in a particular way, regularization should occur only in the presence of both memory limitations and a prior bias for regularization. Taken together, these findings suggest that the difference in regularization between adults and children may not be solely attributable to differences in memory limitations during learning.}
}
@article{QUIANQUIROGA2020994,
title = {No Pattern Separation in the Human Hippocampus},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {12},
pages = {994-1007},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320302278},
author = {Rodrigo {Quian Quiroga}},
keywords = {episodic memory, Concept Cells, engram, conjunctive coding, neural coding, human intelligence},
abstract = {Pattern separation is a basic principle of neuronal coding that precludes memory interference in the hippocampus. Its existence is supported by numerous theoretical, computational, and experimental findings in different species. However, I argue that recent evidence from single-neuron recordings suggests that pattern separation may not be present in the human hippocampus and that memories are instead coded by the coactivation of invariant and context-independent engrams. This alternative model prompts a reassessment of the definition of episodic memory and its distinction from semantic memory. Furthermore, I propose that a lack of pattern separation in memory coding may have profound implications that could explain cognitive abilities that are uniquely developed in humans, such as our power of generalization and of creative and abstract thinking.}
}
@article{DEHOLLANDER2016101,
title = {Different Ways of Linking Behavioral and Neural Data via Computational Cognitive Models},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {1},
number = {2},
pages = {101-109},
year = {2016},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S2451902215000166},
author = {Gilles {de Hollander} and Birte U. Forstmann and Scott D. Brown},
keywords = {Cognition, Computational models, Functional neuroimaging, Joint modeling, Linking, Mathematical models},
abstract = {Cognitive neuroscientists sometimes apply formal models to investigate how the brain implements cognitive processes. These models describe behavioral data in terms of underlying, latent variables linked to hypothesized cognitive processes. A goal of model-based cognitive neuroscience is to link these variables to brain measurements, which can advance progress in both cognitive and neuroscientific research. However, the details and the philosophical approach for this linking problem can vary greatly. We propose a continuum of approaches that differ in the degree of tight, quantitative, and explicit hypothesizing. We describe this continuum using four points along it, which we dub qualitative structural, qualitative predictive, quantitative predictive, and single model linking approaches. We further illustrate by providing examples from three research fields (decision making, reinforcement learning, and symbolic reasoning) for the different linking approaches.}
}
@article{TRNKOVA2019106900,
title = {Rigorous computations with an approximate Dirichlet domain},
journal = {Topology and its Applications},
volume = {268},
pages = {106900},
year = {2019},
issn = {0166-8641},
doi = {https://doi.org/10.1016/j.topol.2019.106900},
url = {https://www.sciencedirect.com/science/article/pii/S0166864119303116},
author = {Maria Trnková},
keywords = {Length spectrum, Dirichlet domain, Hyperbolic 3-manifold},
abstract = {In this paper we address some problems concerning an approximate Dirichlet domain. We show that under some assumptions an approximate Dirichlet domain can work equally well as an exact Dirichlet domain. In particular, we consider a problem of tiling a hyperbolic ball with copies of the Dirichlet domain. This problem arises in the construction of the length spectrum algorithm which is implemented by the computer program SnapPea. Our result explains the empirical fact that the program works surprisingly well despite it does not use exact data. Also we demonstrate a rigorous verification whether two words of the fundamental group of a hyperbolic 3-manifold are the same or not.}
}
@article{SALAJ2024298,
title = {Competencies for Smart City Challenges},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {3},
pages = {298-303},
year = {2024},
note = {22nd IFAC Conference on Technology, Culture and International Stability TECIS 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.07.167},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324002507},
author = {Alenka Temeljotov Salaj and Olav Torp and Elham Andalib},
keywords = {smart solutions, competencies, AI, education},
abstract = {It is acknowledged that technological innovation is needed in all sectors to cope with new demands. From social innovations, it introduces novel ideas, whether products, services, or models, to fulfil societal needs and foster new partnerships or collaborations. The aim is to enhance social interactions and elevate human well-being. Development of cutting-edge digital technologies is reality. The challenge is on human resource side, how quickly we can prepare employees to adapt to the requirements of Industry 4.0 and Society 5.0. In the paper, the new competencies were identified with the business stakeholders by conducting a survey among industry partners to recognize the requirements for the future labor market. The stakeholders in the construction field act as target groups for monitoring and development of the competencies. The focus of the result part is on the competencies companies mostly miss from their employees from digital perspectives, e.g. reason to hire highly educated people, training possibilities for digitally upskilling employees, lacking appropriate competencies (critical thinking, systems and analytical thinking, information management, advanced computer/IT skills (AI), ensuring security). Digital skills Advanced data/IT skills were the competencies in that companies defined as key competencies expected to be developed in 21st-century higher education employees. It is highly important to consider the job market needs for development and to adopt the engineering education system to be responsive to the needs of labor market.}
}
@incollection{MAERTENS2025352,
title = {Green Toxicology},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {352-357},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00098-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157424000983},
author = {Alexandra Maertens and Thomas Hartung},
keywords = {Exposomics, In Silico, In Vitro, QSAR, SAR},
abstract = {Green toxicology is an emerging discipline that seeks to make toxicology a partner in the field of green chemistry, by providing chemists and toxicologists the tools necessary to identify potential hazards based on chemical structure alone, test efficiently for bioactivity, and better predict the human health impacts of chemicals. It seeks to make toxicology a data-driven, 21st century science by incorporating advanced techniques such as computational modeling, high-throughput screening, and alternative testing methods to assess chemical safety.}
}
@article{AHLQUIST201584,
title = {Development of a digital framework for the computation of complex material and morphological behavior of biological and technological systems},
journal = {Computer-Aided Design},
volume = {60},
pages = {84-104},
year = {2015},
note = {Material Ecology},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2014.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010448514000141},
author = {Sean Ahlquist and Tim Kampowski and Omid {Oliyan Torghabehi} and Achim Menges and Thomas Speck},
keywords = {Material behavior, Spring-based simulation, Computational design, Biomimetic research},
abstract = {Research in material behavior involves the study of relationships between material composition and capacities to negotiate internal and external pressures. Tuning material composition for performance allows for the integration of multifaceted functionality and embedded responsiveness within minimal material means. The relationships of material composition and system performance can be dissected into properties of topology (in count, type and association), forces (as the simulation of contextual pressures), and materiality (material properties and constraints of fabrication). When resourcing information about these aspects of material behavior from biological or technological systems, the physical precedents, as specimens and/or models, serve as the primary, and often sole, exemplar. While this is necessary to initiate the study of material make-up as it relates to specific morphological performance, there is an inherent limit when asking how and to what degree the knowledge resourced from that instance applies when alterations from the norm are generated. This research proposes the possibility for testing variants of a morphological system using physical models as the precedent while incorporating multiple means of computational analysis for extensive exploration. The framework begins with the initial stage of deducing principles, regarding material organization and behavior, through comparative physical and computational study. Subsequently, through methods of abduction, new vocabularies of form and potentials in performance are generated primarily through computational exploration. The framework is shaped by research into the design and materialization of complex pre-stressed form- and bending-active architectures. A novel aspect of this framework is the development of a software environment called springFORM. In this environment, material behavior is simulated using basic spring-based (particle system) methods. The novel contribution of this software is in providing means for both manual and algorithmic manipulations of mesh topologies and material properties during the form-finding process. A series of architectural prototypes, which range in scale, define rules for the relationship between topological-material complexity and the sequencing of particular exploratory methods. The studies define the value of the physical precedent as it engenders further material prototypes, spring-based explorations and simulations with finite element analysis. These rules and methods are further elaborated upon through studying the particularly fascinating structural capacity of banana leaf stalks, a material system which is stiff in bending yet highly flexible in torsion. Of interest is a functional robustness which allows for the negotiation of both self-weight and wind loading for a large and fully integrated leaf structure. Methods of simulation and meta-heuristics are developed to address the continual material and topological differentiation of the banana leaf stalk. Case studies are based upon examination of specimens from the species Musa acuminata and Ensete ventricosum. Mechanical properties and geometric descriptions of isolated moments within the stalk provide the basis for computational comparison. Fundamental properties and behaviors are extracted from the plant specimens, yet a full description is not possible because of the plant’s intricate spatial structure. In this case, the computational means serve to elucidate upon the behavior of the complete system as well as provide avenues for exploring its variants. This paper describes an extensible and calibrated framework which can foster enhanced biomimetic insights by explorations which are based upon but extend well beyond initial biological and/or technological precedents.}
}
@article{SHARMA2022132755,
title = {Conformational stability, quantum computational, spectroscopic, molecular docking and molecular dynamic simulation study of 2-hydroxy-1-naphthaldehyde},
journal = {Journal of Molecular Structure},
volume = {1259},
pages = {132755},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2022.132755},
url = {https://www.sciencedirect.com/science/article/pii/S0022286022004288},
author = {Arun Sharma and Ghazala Khanum and Anuj Kumar and Aysha Fatima and Meenakshi Singh and Khamael M. Abualnaja and Khaled Althubeiti and S. Muthu and Nazia Siddiqui and Saleem Javed},
keywords = {DFT studies, Fukui Function, MEP, ELF, Hirshfeld, Molecular docking},
abstract = {Experimental FTIR, NMR and UV-visible spectrum analyses were used to describe the title compound 2-Hydroxy-1-Naphthaldehyde. The optimized molecular geometry and vibrational wave numbers were determined by using the DFT approach and B3LYP/6-311++G(d, p) basis set. VEDA was used to determine the vibrational assignments. The GIAO technique was used to compute carbon and proton NMR chemical shifts in CDCl3. The most reactive location of the 2H1NA molecule, according to MEP map analysis, is the site containing the oxygen atom. TD-DFT approach was used to produce the theoretical UV-visible spectrum in MeOH and gas phase. HOMO-LUMO and Donor-Acceptor (NBO) interactions were investigated for the title compound. In addition, nonlinear optical characteristics, ELF and Fukui activity were investigated. Temperature-dependent thermodynamic characteristics were also computed. The 3D intermolecular interactions of the crystal surface were characterised using Hirshfeld surface analysis, whereas the 2D interactions were explained using fingerprint plots. 2H1NA was stabilized by the development of H—H/H—C/H—O contacts. The bioactive probability of the title molecule was theoretically demonstrated by computing the electrophilicity index. In a biological study six different receptors, molecular docking was performed to evaluate the best ligand-protein interactions and likeness to the active substance. Biomolecular stability was investigated using a molecular dynamics simulation.}
}
@article{OESCH2021990,
title = {How REM sleep shapes hypothalamic computations for feeding behavior},
journal = {Trends in Neurosciences},
volume = {44},
number = {12},
pages = {990-1003},
year = {2021},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0166223621001831},
author = {Lukas T. Oesch and Antoine R. Adamantidis},
keywords = {sleep, feeding, goal-directed behavior, hypothalamus, population coding},
abstract = {The electrical activity of diverse brain cells is modulated across states of vigilance, namely wakefulness, non-rapid eye movement (NREM) sleep, and rapid eye movement (REM) sleep. Enhanced activity of neuronal circuits during NREM sleep impacts on subsequent awake behaviors, yet the significance of their activation, or lack thereof, during REM sleep remains unclear. This review focuses on feeding-promoting cells in the lateral hypothalamus (LH) that express the vesicular GABA and glycine transporter (vgat) as a model to further understand the impact of REM sleep on neural encoding of goal-directed behavior. It emphasizes both spatial and temporal aspects of hypothalamic cell dynamics across awake behaviors and REM sleep, and discusses a role for REM sleep in brain plasticity underlying energy homeostasis and behavioral optimization.}
}
@article{CAPUTO2023113309,
title = {Building T-shaped professionals for mastering digital transformation},
journal = {Journal of Business Research},
volume = {154},
pages = {113309},
year = {2023},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.113309},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322007640},
author = {Francesco Caputo and Valentina Cillo and Fabio Fiano and Marco Pironti and Marco Romano},
keywords = {Digital transformation, T-shaped professionals, Systems thinking, Soft skills, Cognitive domain},
abstract = {Digital transformation is a multidimensional challenge that is requiring to change consolidated approaches and managerial models. New organized entities are emerging because of this ongoing transformation and new competences are required for managing and living them. Thanks to the interpretative contribution provided by the systems thinking, the paper focuses the attention on the paradigm shift required for defining t-shaped professionals able to master digital transformation in emerging dynamics. A conceptual model is proposed and discussed building upon the T-shaped model with the aim to enrich current theoretical and managerial debates about strategies for supporting both individuals and organizations in facing the challenges imposed by the digital transformation.}
}
@article{DENEF201893,
title = {Computational complexity of the landscape II—Cosmological considerations},
journal = {Annals of Physics},
volume = {392},
pages = {93-127},
year = {2018},
issn = {0003-4916},
doi = {https://doi.org/10.1016/j.aop.2018.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S000349161830068X},
author = {Frederik Denef and Michael R. Douglas and Brian Greene and Claire Zukowski},
keywords = {Computational complexity, String theory, Multiverse, Measures},
abstract = {We propose a new approach for multiverse analysis based on computational complexity, which leads to a new family of “computational” measure factors. By defining a cosmology as a space–time containing a vacuum with specified properties (for example small cosmological constant) together with rules for how time evolution will produce the vacuum, we can associate global time in a multiverse with clock time on a supercomputer which simulates it. We argue for a principle of “limited computational complexity” governing early universe dynamics as simulated by this supercomputer, which translates to a global measure for regulating the infinities of eternal inflation. The rules for time evolution can be thought of as a search algorithm, whose details should be constrained by a stronger principle of “minimal computational complexity”. Unlike previously studied global measures, ours avoids standard equilibrium considerations and the well-known problems of Boltzmann Brains and the youngness paradox. We also give various definitions of the computational complexity of a cosmology, and argue that there are only a few natural complexity classes.}
}
@article{KESICI2011472,
title = {Self-regulated learning strategies in relation with statistics anxiety},
journal = {Learning and Individual Differences},
volume = {21},
number = {4},
pages = {472-477},
year = {2011},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2011.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S1041608011000203},
author = {Şahin Kesici and Mustafa Baloğlu and M. Engin Deniz},
keywords = {Statistical anxiety, Statistics learning, Learning strategies, Metacognition},
abstract = {Dealing with students' attitudinal problems related to statistics is an important aspect of statistics instruction. Employing the appropriate learning strategies may have a relationship with anxiety during the process of statistics learning. Thus, the present study investigated multivariate relationships between self-regulated learning strategies and statistical anxiety using canonical correlation analysis (CCA). Three hundred twenty Turkish college students responded to the Motivated Strategies for Learning Questionnaire and the Statistical Anxiety Rating Scale. Of the group, 189 (59.1%) were women and 131 (40.9%) were men. Participants' ages ranged from 18 to 33years with a mean of 21.28years (SD=1.53). Bivariate correlation coefficients showed significant relationships between the dimensions of learning strategies and statistical anxiety. CCA showed that students who used more rehearsal, elaboration, organization, critical thinking, metacognitive regulation, time and study environment management, and effort regulation strategies experienced lower computational anxiety and had more positive attitudes toward statistics. Additionally, a combination of effort regulation and help seeking strategies is associated with test/class anxiety.}
}
@article{CAI2024102329,
title = {Student learning and instructional tasks in different curricular contexts: A longitudinal study},
journal = {International Journal of Educational Research},
volume = {125},
pages = {102329},
year = {2024},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2024.102329},
url = {https://www.sciencedirect.com/science/article/pii/S0883035524000168},
author = {Jinfa Cai and John C. Moyer and Chuang Wang and Ning Wang and Bikai Nie},
keywords = {Longitudinal study, Problem solving, Instructional tasks, Mathematics learning, Curricular effect},
abstract = {This paper compares the longitudinal effect of instructional tasks on algebra learning that used a Standards-based curriculum [Connected Mathematics Project (CMP)] to that of classrooms that used a traditional curriculum (non-CMP). CMP was developed based on the National Council of Teachers of Mathematics (NCTM) Standards and can be characterized as a problem-based curriculum. CMP teachers were more than three times as likely to implement high-level instructional tasks than non-CMP teachers. Increases in the cognitive demand were associated with enhanced growth rates in problem solving, computation, and equation solving. Notably, when controlling for the cognitive demand of the instructional tasks, the advantage of the CMP curriculum over the non-CMP curricula on students’ growth in problem solving disappeared. However, non-CMP curricula had an advantage on students’ growth over the CMP curriculum after the cognitive demand of the instructional tasks was controlled.}
}
@article{BOSSE201239,
title = {A computational model for dynamics of desiring and feeling},
journal = {Cognitive Systems Research},
volume = {19-20},
pages = {39-61},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2012.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041712000228},
author = {Tibor Bosse and Mark Hoogendoorn and Zulfiqar A. Memon and Jan Treur and Muhammad Umair},
keywords = {Desire, Feeling, Computational model},
abstract = {In this paper a computational model is presented for how a desire triggers responses and feelings. The model shows how these feelings can be biased, for example due to addicting experiences in the past. Both the strength of a response and of the associated feeling result from a converging dynamic pattern modeled by reciprocal causal interactions between the two. The model has been used to conduct a number of simulation experiments under varying circumstances. Moreover, it has been evaluated by formal analysis of emerging patterns entailed by the model. Furthermore, it has been pointed out how the computational model can be applied within an ambient agent system supporting a human in not being tempted. In a simple example scenario it is shown such an ambient agent system is able to predict and assess a human’s desire state, and use this assessment to suggest alternatives to avoid falling for certain temptations.}
}
@article{BRAMLEY2023105471,
title = {Active inductive inference in children and adults: A constructivist perspective},
journal = {Cognition},
volume = {238},
pages = {105471},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105471},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723001051},
author = {Neil R. Bramley and Fei Xu},
keywords = {Hypothesis generation, Active learning, Inductive inference, Developmental change, Concept learning, Program induction},
abstract = {A defining aspect of being human is an ability to reason about the world by generating and adapting ideas and hypotheses. Here we explore how this ability develops by comparing children’s and adults’ active search and explicit hypothesis generation patterns in a task that mimics the open-ended process of scientific induction. In our experiment, 54 children (aged 8.97±1.11) and 50 adults performed inductive inferences about a series of causal rules through active testing. Children were more elaborate in their testing behavior and generated substantially more complex guesses about the hidden rules. We take a ‘computational constructivist’ perspective to explaining these patterns, arguing that these inferences are driven by a combination of thinking (generating and modifying symbolic concepts) and exploring (discovering and investigating patterns in the physical world). We show how this framework and rich new dataset speak to questions about developmental differences in hypothesis generation, active learning and inductive generalization. In particular, we find children’s learning is driven by less fine-tuned construction mechanisms than adults’, resulting in a greater diversity of ideas but less reliable discovery of simple explanations.}
}
@incollection{KANELLOPOULOS2024111,
title = {Chapter Five - Adversarial modeling},
editor = {Aris Kanellopoulos and Lijing Zhai and Filippos Fotiadis and Kyriakos G. Vamvoudakis},
booktitle = {Control and Game Theoretic Methods for Cyber-Physical Security},
publisher = {Academic Press},
pages = {111-170},
year = {2024},
series = {Emerging Methodologies and Applications in Modelling, Identification and Control},
isbn = {978-0-443-15408-9},
doi = {https://doi.org/10.1016/B978-0-44-315408-9.00011-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443154089000117},
author = {Aris Kanellopoulos and Lijing Zhai and Filippos Fotiadis and Kyriakos G. Vamvoudakis},
keywords = {Bounded rationality, Differential games, Attack prediction},
abstract = {In this chapter we utilize results from game theory to model the interactions of the CPS operator with different types of adversarial agents. To approach accurate prediction of realistic attacks, we present and exploit results from behavioral game theory, namely level-k thinking and cognitive hierarchy. Finally, we propose a method of predicting future adversarial behavior of adapting, learning opponents.}
}
@article{CHEN2021101001,
title = {Instructed concept appropriation for developing knowledge of second language academic discourse context},
journal = {Journal of English for Academic Purposes},
volume = {52},
pages = {101001},
year = {2021},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2021.101001},
url = {https://www.sciencedirect.com/science/article/pii/S147515852100045X},
author = {Jing Chen and Danli Li},
keywords = {Concept-based language instruction, , Mediation, Concept appropriation, Writing activity, Academic literacy},
abstract = {Recent studies from sociocultural perspectives have explored the effects of Concept-based Language Instruction (C-BLI) on L2 development through the explicit teaching of scientific concepts. However, there has been little research into the effects of C-BLI on the development of L2 academic literacy. This article reports on a case study of how C-BLI mediated a Chinese doctoral student's development of conceptual knowledge of context and subsequent context-specific performance in academic writing. Drawing on data from writing tutorials and interviews, the learner's drafts and invited comments, and think-aloud protocols, the study revealed that the C-BLI interventions that integrated symbolic and dialogic mediation helped the learner attain and enhance awareness of contextual components. The learner appropriated the concept as a tool for thinking in judging appropriateness of rules of thumb and choices of exclusive discourse features in specific contexts of use, which consequently mediated his planning for writing and resulted in the development of performance. The study demonstrates the potential of C-BLI as a driving force for the development of conceptual knowledge and context-specific performance in the academic literacy of L2 learners. It has pedagogical implications for curriculum design, C-BLI-informed literacy and concept-based materials, and teacher development to stimulate teacher awareness in C-BLI.}
}
@article{HUANG201727,
title = {A computational cognitive modeling approach to understand and design mobile crowdsourcing for campus safety reporting},
journal = {International Journal of Human-Computer Studies},
volume = {102},
pages = {27-40},
year = {2017},
note = {Special Issue on Mobile and Situated Crowdsourcing},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916301549},
author = {Yun Huang and Corey White and Huichuan Xia and Yang Wang},
keywords = {Mobile crowdsourcing, Cognitive computational method, Public safety, User contribution, Drift-diffusion decision model, Nudge mechanism},
abstract = {The under-reporting of public safety incidents is a long-standing issue. In this paper, we propose a computational cognitive modeling approach to understand and design a mobile crowdsourcing system for improving campus safety reporting. In particular, we adopt drift-diffusion models (DDMs) from cognitive psychology to investigate the effect of various factors on users’ reporting tendency for public safety. Our lab experiment and online study show consistent results on how location context impacts people's reporting decisions. This finding informs the design of a novel location-based nudge mechanism, which is tested in another lab experiment with 84 participants and proved to be effective in changing users’ reporting decisions. Our follow-up interview study further suggests that the influence of people's mobility patterns (e.g., expected walking distance) could explain why the nudge design is effective. Our work not only informs the design of mobile crowdsourcing for public safety reporting but also demonstrates the value of applying a computational cognitive modeling approach to address HCI research questions more broadly.}
}
@article{WU2024101625,
title = {The moderating effects of brain network connectivity on the relationship between individual and interactive creativity},
journal = {Thinking Skills and Creativity},
volume = {54},
pages = {101625},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101625},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001639},
author = {Ching-Lin Wu},
keywords = {Connectome, Diffusion tensor imaging, Divergent thinking, Online creativity task, Remote associates test},
abstract = {The correlation between individuals’ creativity performances in a one-to-one interactive situation was preliminarily explored. Neuroimaging has provided many insights into the neural connectome that underlies creativity; however, the role of brain structure in individuals’ creativity performance when collaborating with others remains largely unexplored. Therefore, this study collected data from 74 single- and paired-player participants using an interactive creativity task platform, including the alternative use task (AUT) and the Chinese Radical Remote Associates Test (CRRAT). Participants’ AUT and CRRAT scores in the above two modes were collected to analyze the moderating effects of connective efficiency (CE). The results showed that the relationship between originality performance in the single- and paired-player modes was moderated by four theoretical graph measures. Specifically, in the case of a high clustering coefficient, local efficiency, global efficiency, or low characteristic path length, individual originality performance was more predictive of interactive originality. Additionally, the relationship between fluency performance in the above two modes was not moderated by CE, flexibility, or CRRAT performance. This study identified the effects of neural transmission efficiency on the relationship between creativity in the two modes. This study investigated neurocognitive factors influencing creativity performance in interactive situations.}
}
@article{TELIKANI2020318,
title = {A survey of evolutionary computation for association rule mining},
journal = {Information Sciences},
volume = {524},
pages = {318-352},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.02.073},
url = {https://www.sciencedirect.com/science/article/pii/S002002552030164X},
author = {Akbar Telikani and Amir H. Gandomi and Asadollah Shahbahrami},
keywords = {Data mining, Association rule mining, Evolutionary computation, Swarm intelligent},
abstract = {Association Rule Mining (ARM) is a significant task for discovering frequent patterns in data mining. It has achieved great success in a plethora of applications such as market basket, computer networks, recommendation systems, and healthcare. In the past few years, evolutionary computation-based ARM has emerged as one of the most popular research areas for addressing the high computation time of traditional ARM. Although numerous papers have been published, there is no comprehensive analysis of existing evolutionary ARM methodologies. In this paper, we review emerging research of evolutionary computation for ARM. We discuss the applications on evolutionary computations for different types of ARM approaches including numerical rules, fuzzy rules, high-utility itemsets, class association rules, and rare association rules. Evolutionary ARM algorithms were classified into four main groups in terms of the evolutionary approach, including evolution-based, swarm intelligence-based, physics-inspired, and hybrid approaches. Furthermore, we discuss the remaining challenges of evolutionary ARM and discuss its applications and future topics.}
}
@article{CHIASTRA20162102,
title = {Computational replication of the patient-specific stenting procedure for coronary artery bifurcations: From OCT and CT imaging to structural and hemodynamics analyses},
journal = {Journal of Biomechanics},
volume = {49},
number = {11},
pages = {2102-2111},
year = {2016},
note = {Selected Articles from the International Conference on CFD in Medicine and Biology (Albufeira, Portugal – August 30th - September 4th, 2015)},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2015.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0021929015006661},
author = {Claudio Chiastra and Wei Wu and Benjamin Dickerhoff and Ali Aleiou and Gabriele Dubini and Hiromasa Otake and Francesco Migliavacca and John F. LaDisa},
keywords = {Mathematical model, Finite element analysis, Computational fluid dynamics, Coronary bifurcation, Stent},
abstract = {The optimal stenting technique for coronary artery bifurcations is still debated. With additional advances computational simulations can soon be used to compare stent designs or strategies based on verified structural and hemodynamics results in order to identify the optimal solution for each individual’s anatomy. In this study, patient-specific simulations of stent deployment were performed for 2 cases to replicate the complete procedure conducted by interventional cardiologists. Subsequent computational fluid dynamics (CFD) analyses were conducted to quantify hemodynamic quantities linked to restenosis. Patient-specific pre-operative models of coronary bifurcations were reconstructed from CT angiography and optical coherence tomography (OCT). Plaque location and composition were estimated from OCT and assigned to models, and structural simulations were performed in Abaqus. Artery geometries after virtual stent expansion of Xience Prime or Nobori stents created in SolidWorks were compared to post-operative geometry from OCT and CT before being extracted and used for CFD simulations in SimVascular. Inflow boundary conditions based on body surface area, and downstream vascular resistances and capacitances were applied at branches to mimic physiology. Artery geometries obtained after virtual expansion were in good agreement with those reconstructed from patient images. Quantitative comparison of the distance between reconstructed and post-stent geometries revealed a maximum difference in area of 20.4%. Adverse indices of wall shear stress were more pronounced for thicker Nobori stents in both patients. These findings verify structural analyses of stent expansion, introduce a workflow to combine software packages for solid and fluid mechanics analysis, and underscore important stent design features from prior idealized studies. The proposed approach may ultimately be useful in determining an optimal choice of stent and position for each patient.}
}
@article{SIMMONS2022103318,
title = {Freedom from what? Separating lay concepts of freedom},
journal = {Consciousness and Cognition},
volume = {101},
pages = {103318},
year = {2022},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2022.103318},
url = {https://www.sciencedirect.com/science/article/pii/S1053810022000502},
author = {Claire Simmons and Paul Rehren and John-Dylan Haynes and Walter Sinnott-Armstrong},
abstract = {Debates about freedom of will and action and their connections with moral responsibility have raged for centuries, but the opposing sides might disagree because they use different concepts of freedom. Based on previous work, we hypothesized that people who assert freedom in a determined (D) or counterfactual-intervener (CI) scenario assert this because they are thinking about freedom from constraint and not about freedom from determination (in D) or from inevitability (in CI). We also hypothesized that people who deny that freedom in D or in CI deny this because they are thinking about freedom from determination or from inevitability, respectively, and not about freedom from constraint. To test our hypotheses, we conducted two main online studies. Study I supported our hypotheses that people who deny freedom in D and CI are thinking about freedom from determinism and from inevitability, respectively, but these participants seemed to think about freedom from constraint when they were later considering modified scenarios where acts were not determined or inevitable. Study II investigated a contrary bypassing hypothesis that those who deny freedom in D denied this because they took determinism to exclude mental causation and hence to exclude freedom from constraint. We found that participants who took determinism to exclude freedom generally did not deny causation by mental states, here represented by desires and decisions. Their responses regarding causation by desires and decisions at most weakly mediated the relation between determinism and freedom or responsibility among this subgroup of our participants. These results speak against the bypassing hypothesis and in favor of our hypothesis that these participants were not thinking about freedom from constraint.}
}
@article{BATINI2025101896,
title = {Shared reading aloud fosters intelligence: Three cluster-randomized control trials in elementary and middle school},
journal = {Intelligence},
volume = {108},
pages = {101896},
year = {2025},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2024.101896},
url = {https://www.sciencedirect.com/science/article/pii/S0160289624000904},
author = {Federico Batini and Marco Bartolucci and Giulia Toti and Emanuele Castano},
keywords = {Intelligence, Cognitive development, Narrative fiction, Storytelling, Reading},
abstract = {Storytelling played a crucial role in human evolution. To this day, through stories humans gain declarative and procedural knowledge, and learn the skills that support learning itself. Research shows that reading stories to children enhances their reading and language skills. Does it also enhance their intelligence? To answer this question, we conducted three (N = 626, 254, 195) longitudinal, cluster-randomized control trials in Italian elementary and middle schools. Over a 4-month period, for half of the participants 1 h/day of standard, active language instructional activities were substituted with reading-aloud of stories by a teacher. Compared to those who kept doing language instructional activities, read-aloud condition children showed a stronger increase on two measures of intelligence focusing on knowing things and thinking skills. This result, which emerged in three independent trials conducted in different regions of Italy, suggests avenues for easily scalable interventions to improve children's intelligence.}
}
@incollection{GEYER2020125,
title = {Chapter 6 - Physical meets digital: Blending reality and computational power with digital sticky notes},
editor = {Bo T. Christensen and Kim Halskov and Clemens N. Klokmose},
booktitle = {Sticky Creativity},
publisher = {Academic Press},
pages = {125-151},
year = {2020},
series = {Explorations in Creativity Research},
isbn = {978-0-12-816566-9},
doi = {https://doi.org/10.1016/B978-0-12-816566-9.00006-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128165669000069},
author = {Florian Geyer and Johannes Zagermann and Harald Reiterer},
keywords = {Affinity diagramming, Blended interaction, Post-WIMP user interface, Interaction design, Tangible user interface, User interface design framework, Creativity tool},
abstract = {The high utility and usability of paper sticky notes support workflows and social dynamics of collaborative design activities and methods like affinity diagramming. In this chapter, we show how these natural collaboration activities can be blended with computational power by applying our framework Blended Interaction for a case study on affinity diagramming. Based on four domains of design, we embed our design solutions in a specific physical environment, preserve workflows, and emphasize individual and social interaction. Our proposed design solution to augment sticky notes with digital power blends the benefits of physical materials with the digital power of interactive surfaces, tangibles, and digital pens in an outstanding way. We hope that our design solutions inspire other researchers and practitioners to find innovative solutions that carefully blend real-world practices with the power of digital computing.}
}
@article{DOGAN2018464,
title = {Differing instructional modalities and cognitive structures: Linear algebra},
journal = {Linear Algebra and its Applications},
volume = {542},
pages = {464-483},
year = {2018},
note = {Proceedings of the 20th ILAS Conference, Leuven, Belgium 2016},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0024379517304172},
author = {Hamide Dogan},
keywords = {Mathematics education, Linear algebra, Thinking modes, Instructional modalities, Cognitive schemes},
abstract = {This paper discusses the aspects of twelve first-year linear algebra students' thinking modes displayed on their interview responses to questions addressing linear independence ideas. Studying thinking modes allowed us to make inferences about the role of differing instructional modalities in shaping one's cognitive structures.}
}
@article{DEUTSCH2018156,
title = {Computational mechanisms in genetic regulation by RNA},
journal = {Journal of Theoretical Biology},
volume = {458},
pages = {156-168},
year = {2018},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2018.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0022519318304466},
author = {J.M. Deutsch},
abstract = {The evolution of the genome has led to very sophisticated and complex regulation. Because of the abundance of non-coding RNA (ncRNA) in the cell, different species will promiscuously associate with each other, suggesting collective dynamics similar to artificial neural networks. A simple mechanism is proposed allowing ncRNA to perform computations equivalent to neural network algorithms such as Boltzmann machines and the Hopfield model. The quantities analogous to the neural couplings are the equilibrium constants between different RNA species. The relatively rapid equilibration of RNA binding and unbinding is regulated by a slower process that degrades and creates new RNA. The model requires that the creation rate for each species be an increasing function of the ratio of total to unbound RNA. Similar mechanisms have already been found to exist experimentally for ncRNA regulation. With the overall concentration of RNA regulated, equilibrium constants can be chosen to store many different patterns, or many different input–output relations. The network is also quite insensitive to random mutations in equilibrium constants. Therefore one expects that this kind of mechanism will have a much higher mutation rate than ones typically regarded as being under evolutionary constraint.}
}
@article{LIGOMENIDES200910,
title = {The reality of Mathematics},
journal = {Journal of Computational and Applied Mathematics},
volume = {227},
number = {1},
pages = {10-16},
year = {2009},
note = {Special Issue of Proceedings of NUMAN 2007 Conference: Recent Approaches to Numerical Analysis: Theory, Methods and Applications},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2008.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0377042708003257},
author = {Panos A. Ligomenides},
keywords = {Languages of mathematics, Mathematical reality, Information science, Cyber-world},
abstract = {The power of mathematics is discussed as a way of expressing reasoning, aesthetics and insight in symbolic non-verbal communication. The human culture of discovering mathematical ways of thinking in the enterprise of exploring the understanding of the nature and the evolution of our world through hypotheses, theories and experimental affirmation of the scientific notion of algorithmic and non-algorithmic ‘computation’, is examined and commended upon.}
}
@article{GARFIELD19844,
title = {Artificial intelligence: Using computers to think about thinking, part I: Representing knowledge},
journal = {Computer Compacts},
volume = {2},
number = {1},
pages = {4-9},
year = {1984},
issn = {0167-7136},
doi = {https://doi.org/10.1016/0167-7136(84)90071-4},
url = {https://www.sciencedirect.com/science/article/pii/0167713684900714},
author = {Eugene Garfield}
}
@article{YAO199959,
title = {Evolutionary computation comes of age},
journal = {Cognitive Systems Research},
volume = {1},
number = {1},
pages = {59-64},
year = {1999},
issn = {1389-0417},
doi = {https://doi.org/10.1016/S1389-0417(99)00006-6},
url = {https://www.sciencedirect.com/science/article/pii/S1389041799000066},
author = {Xin Yao},
abstract = {Evolutionary computation is a field of study of computational systems which uses ideas and gets inspirations from natural evolution and adaptation. Although the history of evolutionary computation can be traced back to 1950s, it was only in the last decade or so that the field started to grow rapidly. In recent years, there have been many successful applications of various evolutionary computation techniques in artificial intelligence, machine learning, numerical optimization, combinatorial optimization, etc. The theory of evolutionary computation has also been enriched greatly. There is a much better understanding of why and how evolutionary computation techniques work (or do not work) than five or six years ago. This article reports some of the latest developments presented at the recent 1999 Congress on Evolutionary Computation (CEC '99).}
}
@article{NUGRAHA2023406,
title = {A SEM-neural network approach for understanding the entrepreneurial competence development of freshmen engineering and computing students},
journal = {Procedia Computer Science},
volume = {216},
pages = {406-414},
year = {2023},
note = {7th International Conference on Computer Science and Computational Intelligence 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.152},
url = {https://www.sciencedirect.com/science/article/pii/S187705092202230X},
author = {Rendika Nugraha and Nanang Ali Sutisna and Adhi Setyo Santoso and Ihsan Hadiansah and Johan Krisnanto Runtuk},
keywords = {Entrepreneurial competence, techno-entrepreneurship, creativity, ethical, sustainable thinking, motivation, perseverance, mobilizing others, learning through experience taking initiative, cope with uncertainty},
abstract = {The discussion of enhancing entrepreneurial competence in Higher Education Institution (HEI), especially in engineering and computing major, has increased for the recent years. This study aims to propose and test a structural model of relationship of Indonesian HEI entrepreneurship education with entrepreneurship competence to assess student entrepreneurship competences especially in undergraduate level. Thus, this study provides the contribution in this stream by creating a subject specialized that fit with specific study program to enhance entrepreneurial competence for freshmen student called Integrative Survival Experience especially in engineering and computing major. We measure its output by using EntreComp questionnaires framework from European Commission. A combination of Structural Equation Modelling (SEM) and neural network was implemented as analytic approach in this study. The results show that the freshmen engineering and computing students develop entrepreneurial competence by enhancing the specific sets of ideas and opportunities as well as the capability to manage resources for taking the action afterwards. Apparently, the entrepreneurial competence development process of engineering and computing students differs with that of business and management students.}
}
@article{MAVRIDIS202311223,
title = {Attack Identification for Cyber-Physical Security in Dynamic Games under Cognitive Hierarchy},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {11223-11228},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.851},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323012314},
author = {Christos N. Mavridis and Aris Kanellopoulos and Kyriakos G. Vamvoudakis and John S. Baras and Karl Henrik Johansson},
abstract = {This paper considers the problem of identifying the profiles and capabilities of attackers injecting adversarial inputs to a cyber-physical system. The system in question interacts with attackers of different levels of intelligence, each employing different feedback controllers against the system. Principles of behavioral game theory – specifically the concept of level-k thinking – is employed to construct a database of potential attack vectors. By observing the state trajectories under sequential interactions with different adversaries, the defender adaptively estimates both the number and profiles of the different attack signals using an online deterministic annealing approach. This information is used to dynamically estimate the level of intelligence of the attackers. Simulation results showcase the efficacy of the proposed method.}
}
@article{LIN2021103944,
title = {Lessons learned from critical accidental fires in tunnels},
journal = {Tunnelling and Underground Space Technology},
volume = {113},
pages = {103944},
year = {2021},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2021.103944},
url = {https://www.sciencedirect.com/science/article/pii/S0886779821001358},
author = {Chien Liang Lin and Chao Fu Chien},
keywords = {Systems thinking, Lessons learned, Accidental tunnel fires, Causal loop diagram},
abstract = {Historical data indicate that tunnel fires often cause casualties and damage to both vehicles and tunnels. These severe consequences suggest that (1) humans seldom effectively learn from history, and (2) people lack optimal safety response strategies for tunnel fires. To investigate the root causes of accidental tunnel fires and learn from them, we first surveyed the literature on historical tunnel accidents and described the common timeline of accidental tunnel fires. We employed systems thinking, based on the past research, to depict a causal loop diagram of common accidental tunnel fires. We arrived at the following three findings: (1) the literature review proved that the causes of tunnel fires are far more complex than other types of fires, and the damage they generate is greater; (2) in the context of systems thinking, accidental tunnel fires involve many causal relationships which are both continuous and dynamic, including at least three systems, namely vehicles, tunnel control, and safety response; (3) the mental models “the experience of the operators at the tunnel operation control center is just as vital as the safety response” and “safety is more critical than the traffic volume in the tunnel”, can strengthen safety response systems and ensure safe driving in tunnels. Although the structure of each tunnel and the characteristics of each fire differ and present different causal relationships, this study elucidated lessons from accidental tunnel fires and provided required messages for establishing effective safety measures. The results of this study can be used to establish systems thinking models of tunnel fires and can serve as a reference for policy planning and establishing standard operating procedures for safety responses.}
}
@article{LIU2024108212,
title = {Analysis of translation teaching skills in colleges and universities based on deep learning},
journal = {Computers in Human Behavior},
volume = {157},
pages = {108212},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108212},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000803},
author = {Yan Liu and Shuhua Li and Dan Cui},
keywords = {Deep learning, Colleges and universities, Translation education, Machine learning applications, Teaching strategy},
abstract = {With the progress of the times and the improvement of science and technique, network message technique has occupied a vital position in people's lives. At the same time, society has been implementing university English education reform in recent years, and the “internet plus” wisdom education model is the product of the improvement of the times. This new education model has gradually integrated into the education of various subjects. Introducing the concept of message technique and wisdom education into university translation education can innovate education mode, optimize education content, and integrate high-quality education resources. Cultivating applied translators has become the trend of educational reform. Based on deep learning, this paper studies translation education skills in universities. In-depth education enables learners to acquire systematic knowledge, critical spirit, creative thinking, etc. This kind of learning fully taps individual potential to cultivate a complete personality. According to the research in this paper, wisdom education is 12% better than traditional education, and it is suitable to be widely put into practice.}
}
@article{LEROYER20112070,
title = {Numerical strategies to speed up CFD computations with free surface—Application to the dynamic equilibrium of hulls},
journal = {Ocean Engineering},
volume = {38},
number = {17},
pages = {2070-2076},
year = {2011},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2011.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0029801811002009},
author = {Alban Leroyer and Jeroen Wackers and Patrick Queutey and Emmanuel Guilmineau},
keywords = {Marine hydrodynamics, Free surface capturing, Dynamic equilibrium, RANS simulation},
abstract = {This article presents two numerical procedures to speed up computations when dealing with a Reynolds Averaged Navier Stokes (RANS) solver based on the Volume of Fluid (VoF) or multifluid method to treat the free surface. The first one is a time-splitting procedure for the volume fraction equation, enabling the use of larger time steps for the resolution of the flow, without penalizing accuracy. However, these large time steps destabilize the coupling with the ship motion simulation when computing a dynamic equilibrium position in marine applications. The second procedure is therefore a quasi-static approach to solve the coupled problem of dynamic equilibrium. A comparison of these procedures with classical simulations shows that numerical solutions of realistic problems can be obtained up to four times faster.}
}
@article{BAN2020102789,
title = {3D Computational Sketch Synthesis Framework: Assisting Design Exploration Through Generating Variations of User Input Sketch and Interactive 3D Model Reconstruction},
journal = {Computer-Aided Design},
volume = {120},
pages = {102789},
year = {2020},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2019.102789},
url = {https://www.sciencedirect.com/science/article/pii/S0010448518301726},
author = {Seonghoon Ban and Kyung Hoon Hyun},
keywords = {Intelligent design system, Assisted creativity, Sketch-based modeling, Computational design, Virtual reality},
abstract = {A framework is proposed for facilitating the exploration process during the early design phase through computational sketch synthesis and interactive 3D reconstruction. In that phase, designers concentrate on developing concepts through numerous alternatives. Therefore, they constantly sketch so that they can rapidly visualize their ideas. Recently, the design industry has attempted to streamline the design process by implementing 3D model generation in the early design phase so that ideas may be more thoroughly explored, thus improving concept and final design conformance; however, efficiency issues have arisen. In this study, a 3D computational sketch synthesis framework was developed comprising two major components. First, a robust method was proposed to synthesize design alternatives by interpolating an input sketch with sketches in a database so that unvisited combinations may be explored. Secondly, a novel interactive 3D model reconstruction method was developed to facilitate the shape transition of design elements so that designers can quickly evaluate the potential of a large number of design variations. Finally, an interface for design refinement was developed so that designs may be embodied by sketching over the 3D model. To test the proposed methodology, expert designers were recruited for a validation experiment with two conditions followed up by in-depth interviews. In the first condition, the participants were asked to sketch based on a design brief in their current working manner. In the second condition, they were asked to create designs using the proposed framework. It was tested whether there was a difference in the design outcomes. It was demonstrated that the proposed framework resulted in more satisfactory and higher-quality designs and generated design alternatives faster and in greater quantities. All participants agreed that the framework could be useful in the early design phase and responded that the proposed system provides more design inspiration than traditional design methods. Most importantly, it was demonstrated that the proposed framework could enhance the reevaluation potential of design concepts and assist in making better-informed design decisions.}
}
@article{DEBER200449,
title = {Medical savings accounts in a universal system: wishful thinking meets evidence},
journal = {Health Policy},
volume = {70},
number = {1},
pages = {49-66},
year = {2004},
issn = {0168-8510},
doi = {https://doi.org/10.1016/j.healthpol.2004.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168851004000119},
author = {Raisa B Deber and Evelyn L Forget and Leslie L Roos},
keywords = {Medical savings accounts, Canada, Health care financing, Distribution of expenditures},
abstract = {Medical savings accounts (MSAs) and similar approaches based on flowing reimbursements through individuals/consumers rather than providers are unsuited for systems with universal coverage. Data from Manitoba, Canada reveal that, because expenditures for physician and hospital services are highly skewed in all age groups, MSAs would substantially increase both public expenditures and out-of-pocket costs for the most ill. The empirical distribution of health expenditures limits the potential impact of many current ‘demand-based’ approaches to cost control. Because most of the population is relatively healthy and uses few hospital and physician services, inducing the general population to spend less will not yield substantial savings.}
}
@article{WANG2024119888,
title = {Progressive reinforcement learning for video summarization},
journal = {Information Sciences},
volume = {655},
pages = {119888},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119888},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523014731},
author = {Guolong Wang and Xun Wu and Junchi Yan},
keywords = {Video summarization, Progressive reinforcement learning, Hierarchical strategy},
abstract = {Video summarization addresses generating video summaries to help watchers grasp the content of a video without watching it entirely. Many methods have engaged in automatic video summarization. Although these methods have performed well, they still suffer from limited training data and sparse reward problems. We propose a Progressive Reinforcement Learning Video Summarization structure (PRLVS) with an unsupervised reward. The reward measures the information and quality the selected frames convey without annotations. Striving to earn higher rewards, our PRLVS adopts a “T”-type human thinking paradigm: choosing some key frames and checking if their adjacent frames are better than them. To simulate this paradigm, we decompose the flat strategy into a hierarchical strategy consisting of a horizontal policy and a vertical policy. These two policies are optimized alternatively, which densifies the reward while reducing the exploration space. Their cooperation also makes the agent capture the context information of the whole video at every step. Extensive experimental results on two benchmark databases (i.e., SumMe, TVSum) show that our PRLVS outperforms the comparisons and approaches the supervised methods, which indicates that it is significant to integrate our unsupervised reward into the progressive reinforcement learning structure to address limited annotation and sparse reward problems.}
}
@incollection{WARE20221,
title = {Chapter 1 - Visual Queries},
editor = {Colin Ware},
booktitle = {Visual Thinking for Information Design (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
pages = {1-22},
year = {2022},
isbn = {978-0-12-823567-6},
doi = {https://doi.org/10.1016/B978-0-12-823567-6.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012823567600001X},
author = {Colin Ware},
keywords = {Visual queries, visual search, distributed cognition, predictive cognition, visual system, visual thinking},
abstract = {The mechanisms and processes of visual thinking are introduced together with how this knowledge can help us make design decisions. We begin with a review of the evidence that we actually take in very little information with each glance and the implication that seeing is a process exquisitely tuned to our cognitive task of the moment. As a key part of this process, our brains execute visual queries using eye movements; visual features are detected in parallel to pick out just what is needed to resolve part of a cognitive problem and move on the next step. We begin to understand how seeing can be a distributed cognitive process executed partly in the brain and partly using a visualization as a tool. In particular, when the visualization is part of an interactive computer application, it provides the primary interface between cognitive operations in the human brain and computational operations. The theory of predictive cognition is introduced as a basis for how we should design presentations.}
}
@article{YON2021R1026,
title = {Precision and the Bayesian brain},
journal = {Current Biology},
volume = {31},
number = {17},
pages = {R1026-R1032},
year = {2021},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2021.07.044},
url = {https://www.sciencedirect.com/science/article/pii/S0960982221010344},
author = {Daniel Yon and Chris D. Frith},
abstract = {Summary
Scientific thinking about the minds of humans and other animals has been transformed by the idea that the brain is Bayesian. A cornerstone of this idea is that agents set the balance between prior knowledge and incoming evidence based on how reliable or ‘precise’ these different sources of information are — lending the most weight to that which is most reliable. This concept of precision has crept into several branches of cognitive science and is a lynchpin of emerging ideas in computational psychiatry — where unusual beliefs or experiences are explained as abnormalities in how the brain estimates precision. But what precisely is precision? In this Primer we explain how precision has found its way into classic and contemporary models of perception, learning, self-awareness, and social interaction. We also chart how ideas around precision are beginning to change in radical ways, meaning we must get more precise about how precision works.}
}
@article{DROZDZEWSKI2024100086,
title = {Developing QualNotes: A collaborative and cross-disciplinary ethnography},
journal = {Digital Geography and Society},
volume = {6},
pages = {100086},
year = {2024},
issn = {2666-3783},
doi = {https://doi.org/10.1016/j.diggeo.2024.100086},
url = {https://www.sciencedirect.com/science/article/pii/S2666378324000084},
author = {Danielle Drozdzewski and Jose Oriol Lopez Berengueres},
keywords = {QualNotes, Collaborative ethnography, Cross-disciplinary, Mobile application, Digital},
abstract = {Rarely do academics reveal the ‘backend’ of their research; the hours of labour invested into question generation, ethics compliance, transcription, translation, and data analysis, and in our case, coding. Further, when working collaboratively, the conversations that occur between collaborators seldom appear in final publications either. The development of the mobile application QualNotes, provided a productive digital space for collaboration across disciplines. In this paper, we use three vignettes to explicate the ‘backend’ of the development of that mobile application. We chart howour collaborative cross-disciplinary ethnography revealed the generative potential of thinking-with the digital and across disciplinary divides. This paper's contribution is in revealing ‘how’ we work using our disciplinary expertise, but at the same time at the edges of those disciplines too, where we contest, argue, adapt, understand, and, where we learn.}
}
@article{VARMA2024101673,
title = {Recruitment of magnitude representations to understand graded words},
journal = {Cognitive Psychology},
volume = {153},
pages = {101673},
year = {2024},
issn = {0010-0285},
doi = {https://doi.org/10.1016/j.cogpsych.2024.101673},
url = {https://www.sciencedirect.com/science/article/pii/S0010028524000446},
author = {Sashank Varma and Emily M. Sanford and Vijay Marupudi and Olivia Shaffer and R. {Brooke Lea}},
keywords = {Magnitude representations, Numerical cognition, Graded words, Distributional word semantics, Multi-dimensional scaling, Machine learning},
abstract = {Language understanding and mathematics understanding are two fundamental forms of human thinking. Prior research has largely focused on the question of how language shapes mathematical thinking. The current study considers the converse question. Specifically, it investigates whether the magnitude representations that are thought to anchor understanding of number are also recruited to understand the meanings of graded words. These are words that come in scales (e.g., Anger) whose members can be ordered by the degree to which they possess the defining property (e.g., calm, annoyed, angry, furious). Experiment 1 uses the comparison paradigm to find evidence that the distance, ratio, and boundary effects that are taken as evidence of the recruitment of magnitude representations extend from numbers to words. Experiment 2 uses a similarity rating paradigm and multi-dimensional scaling to find converging evidence for these effects in graded word understanding. Experiment 3 evaluates an alternative hypothesis – that these effects for graded words simply reflect the statistical structure of the linguistic environment – by using machine learning models of distributional word semantics: LSA, word2vec, GloVe, counterfitted word vectors, BERT, RoBERTa, and GPT-2. These models fail to show the full pattern of effects observed of humans in Experiment 2, suggesting that more is needed than mere statistics. This research paves the way for further investigations of the role of magnitude representations in sentence and text comprehension, and of the question of whether language understanding and number understanding draw on shared or independent magnitude representations. It also informs the role of machine learning models in cognitive psychology research.}
}
@article{TRAYLOR2024110895,
title = {Model-based experiments as epistemic evidence in paleoecology},
journal = {Ecological Modelling},
volume = {498},
pages = {110895},
year = {2024},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2024.110895},
url = {https://www.sciencedirect.com/science/article/pii/S0304380024002837},
author = {Wolfgang Traylor},
keywords = {Epistemology, Bayesian, Preregistration, Blinding, Uncertainty analysis},
abstract = {Where ordinary experiments are impossible and observational data scarce and indirect—particularly in paleoecosystems—computational experiments are often our only means to learn about reality. There are good arguments to count such model-based predictions as evidence, testing hypotheses and updating our beliefs about the world. However, the epistemic weight of computational experiments depends on an adequate model representation of the target system, transparency about predictive uncertainty, and the avoidance of confirmation bias. I argue that mechanistic models are particularly suited for paleoecological predictions but that iterative uncertainty analyses should guide their development. Using a Bayesian framework I propose preregistration and blinded analysis as tools to strengthen the epistemic value of computational experiments. Here, a preregistration marks the boundary between exploratory model development, which establishes credence in the model, and predictive model application, which tests hypotheses. As good modeling practice I suggest clarifying epistemic goals at the outset of a project and accordingly choose methods to maximize the epistemic weight of the computational experiment.}
}
@article{GUHE2011249,
title = {A computational account of conceptual blending in basic mathematics},
journal = {Cognitive Systems Research},
volume = {12},
number = {3},
pages = {249-265},
year = {2011},
note = {Special Issue on Complex Cognition},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000155},
author = {Markus Guhe and Alison Pease and Alan Smaill and Maricarmen Martinez and Martin Schmidt and Helmar Gust and Kai-Uwe Kühnberger and Ulf Krumnack},
keywords = {Mathematical cognition, Metaphor, Mathematical reasoning, Analogy, Anti-unification, Conceptual blending, HDTP},
abstract = {We present an account of a process by which different conceptualisations of number can be blended together to form new conceptualisations via recognition of common features, and judicious combination of their distinctive features. The accounts of number are based on Lakoff and Núñez’s cognitively-based grounding metaphors for arithmetic. The approach incorporates elements of analogical inference into a generalised framework of conceptual blending, using some ideas from the work of Goguen. The ideas are worked out using Heuristic-Driven Theory Projection (HDTP, a method based on higher-order anti-unification). HDTP provides generalisations between domains, giving a crucial step in the process of finding commonalities between theories. In addition to generalisations, HDTP can also transfer concepts from one domain to another, allowing the construction of new conceptual blends. Alongside the methods by which conceptual blends may be constructed, we provide heuristics to guide this process.}
}
@incollection{WILLETT2018231,
title = {Chapter 8 - Application of Mathematical Models and Computation in Plant Metabolomics},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry},
publisher = {Elsevier},
pages = {231-254},
year = {2018},
isbn = {978-0-12-812364-5},
doi = {https://doi.org/10.1016/B978-0-12-812364-5.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128123645000080},
author = {Denis S. Willett and Caitlin C. Rering and Dominique A. Ardura and John J. Beck},
keywords = {Big data, Machine learning, Data science, Agriculture},
abstract = {The investigation and reporting of plant chemical constituents has greatly evolved over the course of natural products and phytochemical research. Starting from the extraction and identification of plant-based bioactive components, such as historical salicin or more recent paclitaxel, phytochemistry-based research now includes plant metabolomics that help delineate chemotaxonomy, phylogenetic biomarkers and the functional genetics of a plant’s response to biotic or abiotic stressors. Here, we examine the invaluable contributions of mathematical models and computation for analysing plant metabolomics data and discuss the analytics mindset, highlight best practices, provide example workflows, as well as introduce future opportunities. Important in this chapter is the application of statistical methods for the improved visualization and interpretation of plant metabolomics data and their relevance for future project planning.}
}
@article{COTTAM2024105343,
title = {Intelligence: Natural, artificial, or what?},
journal = {BioSystems},
volume = {246},
pages = {105343},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105343},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002284},
author = {Ron Cottam and Roger Vounckx},
abstract = {We consider the competing attributes of natural intelligence (NI) and artificial intelligence (AI). Attention is paid to conceptual, theoretical, stylistic and structural aspects of both, and non-human intelligence. Intelligence is related to information processing and current views of physical structuring. Means of distinguishing between NI and AI are noted, and neural and digital structures are described. Pribram's bi-computational neural networks are introduced, and high-level Pribram computation is discussed. We describe the hierarchical Aquarium scheme, along with an AI implementation, and conclude with a proposition for future quantum-based artificial intelligence.}
}
@incollection{CARLSON2017425,
title = {Chapter 20 - Computational Perspectives on Adult Neurogenesis},
editor = {Arjen {van Ooyen} and Markus Butz-Ostendorf},
booktitle = {The Rewiring Brain},
publisher = {Academic Press},
address = {San Diego},
pages = {425-441},
year = {2017},
isbn = {978-0-12-803784-3},
doi = {https://doi.org/10.1016/B978-0-12-803784-3.00020-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128037843000202},
author = {Kristofor D. Carlson and Fred Rothganger and James B. Aimone},
keywords = {Adult neurogenesis, structural plasticity, computational neural model, hippocampus, dentate gyrus},
abstract = {The continuous integration of young neurons into the adult brain represents a novel form of structural plasticity and has inspired the creation of numerous computational models to understand the functional role of adult neurogenesis. These computational models consist of abstract models that focus on the utility of new neurons in simple neural networks and biologically based models constrained by anatomical data that explore the role of new neurons in specific neural circuits such as the hippocampus. Simulation results from both classes of models have suggested a number of theoretical roles for neurogenesis such as increasing the capacity to learn novel information, promoting temporal context encoding, and influencing pattern separation. In this review, we discuss strategies and findings of past computational modeling efforts, current challenges and limitations, and new computational approaches pertinent to modeling adult neurogenesis.}
}
@article{SKRYD2024,
title = {ChatGPT as a Tool for Medical Education and Clinical Decision-Making on the Wards: Case Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/51346},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24002671},
author = {Anthony Skryd and Katharine Lawrence},
keywords = {ChatGPT, medical education, large language models, LLMs, clinical decision-making},
abstract = {Background
Large language models (LLMs) are computational artificial intelligence systems with advanced natural language processing capabilities that have recently been popularized among health care students and educators due to their ability to provide real-time access to a vast amount of medical knowledge. The adoption of LLM technology into medical education and training has varied, and little empirical evidence exists to support its use in clinical teaching environments.
Objective
The aim of the study is to identify and qualitatively evaluate potential use cases and limitations of LLM technology for real-time ward-based educational contexts.
Methods
A brief, single-site exploratory evaluation of the publicly available ChatGPT-3.5 (OpenAI) was conducted by implementing the tool into the daily attending rounds of a general internal medicine inpatient service at a large urban academic medical center. ChatGPT was integrated into rounds via both structured and organic use, using the web-based “chatbot” style interface to interact with the LLM through conversational free-text and discrete queries. A qualitative approach using phenomenological inquiry was used to identify key insights related to the use of ChatGPT through analysis of ChatGPT conversation logs and associated shorthand notes from the clinical sessions.
Results
Identified use cases for ChatGPT integration included addressing medical knowledge gaps through discrete medical knowledge inquiries, building differential diagnoses and engaging dual-process thinking, challenging medical axioms, using cognitive aids to support acute care decision-making, and improving complex care management by facilitating conversations with subspecialties. Potential additional uses included engaging in difficult conversations with patients, exploring ethical challenges and general medical ethics teaching, personal continuing medical education resources, developing ward-based teaching tools, supporting and automating clinical documentation, and supporting productivity and task management. LLM biases, misinformation, ethics, and health equity were identified as areas of concern and potential limitations to clinical and training use. A code of conduct on ethical and appropriate use was also developed to guide team usage on the wards.
Conclusions
Overall, ChatGPT offers a novel tool to enhance ward-based learning through rapid information querying, second-order content exploration, and engaged team discussion regarding generated responses. More research is needed to fully understand contexts for educational use, particularly regarding the risks and limitations of the tool in clinical settings and its impacts on trainee development.}
}
@article{RINGACH2009439,
title = {Spontaneous and driven cortical activity: implications for computation},
journal = {Current Opinion in Neurobiology},
volume = {19},
number = {4},
pages = {439-444},
year = {2009},
note = {Sensory systems},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0959438809000786},
author = {Dario L Ringach},
abstract = {The traditional view of spontaneous neural activity as ‘noise’ has been challenged by recent findings suggesting that: (a) spontaneous activity in cortical populations is highly structured in both space and time, (b) the spatio-temporal structure of spontaneous activity is linked to the underlying connectivity of the cortical network, (c) spontaneous cortical activity interacts with external stimulation to generate responses to the individual presentations of a stimulus, (d) network connectivity is shaped in part by the statistics of natural signals and (e) ongoing cortical activity represents a continuous top-down prediction/expectation signal that interacts with incoming input to generate an updated representation of the world. These results can be integrated to provide a new framework for the study of cortical computation.}
}
@article{WANG2024102579,
title = {Artificial intelligence in dance education: Using immersive technologies for teaching dance skills},
journal = {Technology in Society},
volume = {77},
pages = {102579},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102579},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24001271},
author = {Zheng Wang},
keywords = {Artificial intelligence, Dance education, Dance mobile applications, Educational ecosystem, Immersive technologies, Intelligent action recognition system, Interactive dance training, Virtual, Augmented and mixed reality, Virtual mentoring},
abstract = {Artificial intelligence (AI) has led to a shift in modern dance education. Immersive technologies have become increasingly common worldwide, helping educators to improve the quality of dance pedagogy and increase the effectiveness of dance training. The article investigates the ways of using immersive technologies powered by artificial intelligence in dance education. The research explores the theoretical literature on dance education and the use of artificial intelligence in dance education and dance choreography. The scholars examine the impact of innovative technology solutions used in dance pedagogical practice on the development of dance skills in students. The study also discusses the functionality of interactive and multimedia dance teaching systems, including AI-powered virtual mentoring and cognitive simulations of human mind operations. The research analysed the use of virtual reality (VR), augmented reality (AR), and mixed reality (MR) in dance education. This research also focuses on mobile applications used for teaching modern dance. The proposed framework for dance education is based on digital technologies, which help to develop dance skills and improve teaching practices. The scholars conclude that the development and improvement of dance skills are possible only if a teacher combines virtual and real environments in everyday practices. The findings can be used by dance teachers, professional dancers, software developers, and researchers who examine the innovative practices and the application of artificial intelligence in dance education. The ecosystem model reframes thinking about approaches to dance education and can serve as the basis for further development of dance courses and dance style teaching modes.}
}
@article{MILLER1990489,
title = {Towards a believable theory of planning: D. E. Wilkins. Practical Planning. San Mateo, CA: Morgan Kaufmann, 1988. Pp. xii + 205. $49.95. S. L. Friedman. E. K. Scholnick, and R. R. Cocking. Blueprints for Thinking, London/New York: Cambridge Univ. Press, 1987. Pp. xv + 559. $58.50 K. Hammond. Case-Based Planning. San Diego: Academic Press, 1989. Pp. xviii + 277. $34.95},
journal = {Journal of Mathematical Psychology},
volume = {34},
number = {4},
pages = {489-498},
year = {1990},
issn = {0022-2496},
doi = {https://doi.org/10.1016/0022-2496(90)90028-8},
url = {https://www.sciencedirect.com/science/article/pii/0022249690900288},
author = {David P. Miller}
}
@article{BATEMAN2021100502,
title = {What are digital media?},
journal = {Discourse, Context & Media},
volume = {41},
pages = {100502},
year = {2021},
issn = {2211-6958},
doi = {https://doi.org/10.1016/j.dcm.2021.100502},
url = {https://www.sciencedirect.com/science/article/pii/S2211695821000386},
author = {John A. Bateman},
keywords = {Digital media, Digital information, Literacy, Models of communication, Multimodality, Medium, Development of media, Computational media},
abstract = {This essay addresses the nature of so–called ‘digital media’ in a literacy context from the perspectives of semiotics, theories of the ‘medium’, and computation. It argues that most accounts that attempt to work with some notion of ‘digital media’ anchor themselves insufficiently in semiotics and computation and the essential combination of these that is necessary when discussing digital media as an object of study. This weakens approaches, particularly when the concern is to develop ways of teaching engagement with contemporary communication practices at any level, i.e., improving ‘digital literacies’ of various kinds. Achieving more robust foundations is important for interventions which are not only more effective but also sustainable, minimizing the danger of obsolescence with each new technological turn of the screw. Foundations are also essential for a more balanced perspective on learning situations that does not dichotomize allegedly ‘digital’ and ‘non–digital’ practices and skills. Many such boundaries are deeply misleading and so unnecessarily compartmentalize thinking and restrict the application of relevant research results and methods. The focus of this essay is therefore to consider how a closer examination of media and their development, combined with the contributions made by information technologies, may help articulate notions of digital media that are more supportive of productive engagements with research and issues of literacy.}
}
@article{SANTOS2015127,
title = {Phenotypic plasticity, the Baldwin effect, and the speeding up of evolution: The computational roots of an illusion},
journal = {Journal of Theoretical Biology},
volume = {371},
pages = {127-136},
year = {2015},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2015.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022519315000715},
author = {Mauro Santos and Eörs Szathmáry and José F. Fontanari},
keywords = {Evolutionary search, Genetic algorithm, Learning, The Baldwin effect, Speed of evolution},
abstract = {An increasing number of dissident voices claim that the standard neo-Darwinian view of genes as ‘leaders’ and phenotypes as ‘followers’ during the process of adaptive evolution should be turned on its head. This idea is older than the rediscovery of Mendel’s laws of inheritance, with the turn-of-the-twentieth-century notion eventually labeled as the ‘Baldwin effect’ as one of the many ways in which the standard neo-Darwinian view can be turned around. A condition for this effect is that environmentally induced variation such as phenotypic plasticity or learning is crucial for the initial establishment of a trait. This gives the additional time for natural selection to act on genetic variation and the adaptive trait can be eventually encoded in the genotype. An influential paper published in the late 1980s claimed the Baldwin effect to happen in computer simulations, and avowed that it was crucial to solve a difficult adaptive task. This generated much excitement among scholars in various disciplines that regard neo-Darwinian accounts to explain the evolutionary emergence of high-order phenotypic traits such as consciousness or language almost hopeless. Here, we use analytical and computational approaches to show that a standard population genetics treatment can easily crack what the scientific community has granted as an unsolvable adaptive problem without learning. Evolutionary psychologists and linguists have invoked the (claimed) Baldwin effect to make wild assertions that should not be taken seriously. What the Baldwin effect needs are plausible case-histories.}
}
@article{ZHANG202524,
title = {Farmers’ decisions on crop residues utilization, greenhouse gases reduction and subsidy of crop residue-based bioenergy: An agent-based life cycle model},
journal = {Sustainable Production and Consumption},
volume = {55},
pages = {24-36},
year = {2025},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2025.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352550925000235},
author = {Jiaqi Zhang and Chengxiang Zhuge and Qitong Huang and Bin Wang and Yu'e Li and Peter Oosterveer},
keywords = {Agent-based model, Crop residue-based bioenergy, Life cycle thinking, Environmental and economic impacts, Farmer decision making},
abstract = {To further advance the crop residue-based bioenergy (CRB) industry for climate change mitigation, it is crucial to better understand the influence of stakeholders' behaviours on greenhouse gases (GHG) mitigation potentials. However, the heterogeneity and social dynamics of stakeholders, particularly farmers, have received less attention. This study develops an Agent-based Environmental and Economic assessment (AEE) model that integrates agent-based model and life cycle thinking methods to simulate the CRB system. The AEE model was applied in Heilongjiang Province of China, to investigate how stakeholder decisions affect CRB's GHG reduction potential and government subsidies. Scenario analyses explore the effects of grain markets, subsidies, and collection distance on environmental and economic outcomes. The findings indicate that more farmers are willing to adopt crop residues collection than those currently practicing it, primarily due to logistical constraints. Key factors influencing adoption include farming income, age, farm size and crop types. CRB contributed to 70.6 % of overall GHG reductions with only 41.6 % of the subsidy, demonstrating higher mitigation efficiency. In conclusion, the government must address the deficiency in crop residues logistics to promote CRB development. Additionally, agricultural policies play a crucial role in ensuring CRB feedstock availability by guiding crop types selection. The results suggest that AEE model is adequate in simulating both micro and macro dynamics in the context of CRB, highlighting the robustness of integrating agent-based model and life cycle thinking methods to study complex issues.}
}
@article{MARTI2025345,
title = {Fifty years of metaheuristics},
journal = {European Journal of Operational Research},
volume = {321},
number = {2},
pages = {345-362},
year = {2025},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2024.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0377221724002637},
author = {Rafael Martí and Marc Sevaux and Kenneth Sörensen},
keywords = {Heuristics, Combinatorial optimization, Critical review, Metaheuristics},
abstract = {In this paper, we review the milestones in the development of heuristic methods for optimization over the last 50 years. We propose a critical analysis of the main findings and contributions, mainly from a European perspective. Starting with the roots of the area that can be traced back to the classical philosophers, we follow the historical path of heuristics and metaheuristics in the field of operations research and list the main milestones, up to the latest proposals to hybridize metaheuristics with machine learning. We pay special attention to the theories that changed our way of thinking about problem solving, and to the role played by the European Journal of Operational Research in the development of these theories. Our approach emphasizes methodologies and their connections with related areas, which permits to identify potential lines of future research.}
}
@incollection{ELNAKIB202159,
title = {3 - Computational methods for identifying left ventricle heart pathologies},
editor = {Ayman S. El-Baz and Jasjit S. Suri},
booktitle = {Diabetes and Cardiovascular Disease},
publisher = {Elsevier},
pages = {59-93},
year = {2021},
volume = {3},
series = {Computer-Assisted Diagnosis},
isbn = {978-0-12-817428-9},
doi = {https://doi.org/10.1016/B978-0-12-817428-9.00003-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128174289000036},
author = {Ahmed Elnakib and Mohammed Ghazal and Fatma Taher and Ali H. Mahmoud and Ayman El-Baz},
keywords = {Computational methods, Left ventricle, Heart, Pathologies, Cardiac MRI (CMRI), Segmentation},
abstract = {Globally, the cardiovascular diseases are the first cause of death. The early detection and quantification of these diseases can significantly reduce the mortality rate. Recent advances in cardiac MRI (CMRI) enable the detection of the left ventricle (LV) wall pathologies and the estimation of different quantification metrics that characterize the working of the heart. Examples of these metrics include the area of pathological tissue in the LV wall, the transmural extent of pathology, and other indexes such as wall thickening, functional strain, and the ejection fraction metrics. In the literature, several computational methods have been proposed in order to estimate these metrics based on using different CMRI acquisition techniques, such as cardiac-enhanced CMRI (CE-CMRI) and cine CMRI. This chapter overviews these computational methods and explains their basic ideas, focusing on the metrics extracted using CE-CMRI and cine CMRI.}
}
@article{MAHMOUDZAKIALI2022100579,
title = {The computation intelligent in teaching using digital communication},
journal = {Measurement: Sensors},
volume = {24},
pages = {100579},
year = {2022},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2022.100579},
url = {https://www.sciencedirect.com/science/article/pii/S2665917422002136},
author = {Hossam {Mahmoud Zaki Ali} and Mohammed Hasan Ali Al-Abyadh},
keywords = {Computation intelligent, Digital communication, Skills, Non-verbal communication skills, School health promotion, Teachers},
abstract = {Teaching is all about communication. Teachers who sharpen their communication skills are prepared to instruct, advise, and mentor their students. They communicate well to effectively collaborate within a healthy educational process. This research aims to Make sure the communication scale prepared for the current research has statistical validity to be applied in the current research, identify the teachers' verbal non-verbal communication skills level, to explore the differences in these variables due to gender. A sample of (376) elementary and preparatory stage teachers, Minia Governorate, Egypt (188 male, 188 female) was chosen. For data collection, the researchers utilized the verbal and non-verbal communication scale (prepared by the researchers). They were applied electronically during the 2020 academic year. The research was a descriptive research design. Results demonstrated The communication scale prepared for the current research has statistical validity to be applied in the current research, there was a high level of verbal and nonverbal communication skills among the research sample. Besides, there were no statistically significant differences between male and female teachers in the levels of verbal communication skills, non-verbal communication skills. Some recommendations regarding the necessity to specify courses for pre-service teachers on verbal communication skills, nonverbal communication skills, were presented. Also, suggestions for those in charge of the educational administration process to improve teachers and school health promotion were illustrated.}
}
@article{MACCORMAC1984207,
title = {Men and machines: The computational metaphor},
journal = {Technology in Society},
volume = {6},
number = {3},
pages = {207-216},
year = {1984},
note = {Special Issue Technology and Philosophy},
issn = {0160-791X},
doi = {https://doi.org/10.1016/0160-791X(84)90033-2},
url = {https://www.sciencedirect.com/science/article/pii/0160791X84900332},
author = {Earl R. MacCormac},
abstract = {In the 20th century the interpretation of the human mind and brain as a computer has replaced the 18th century metaphor of “man as a machine”. This paper traces the development of the computational metaphor with some attention to its 18th century roots, and then argues that its employment need not lead to the mechanization of thinking and the autonomy of technique. An awareness of the metaphoric and, therefore, hypothetical status of the computational metaphor will prevent technique from escaping intentional human control. This is a shortened version of a paper included in C. Mitcham and Alois Huning, eds., Philosophy and Technology II: Information Technology and Computers in Theory and Practice (Boston: D. Reidel, in press), and is included here with permission.}
}
@article{JUHOLA2021106367,
title = {On computational classification of genetic cardiac diseases applying iPSC cardiomyocytes},
journal = {Computer Methods and Programs in Biomedicine},
volume = {210},
pages = {106367},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2021.106367},
url = {https://www.sciencedirect.com/science/article/pii/S0169260721004417},
author = {Martti Juhola and Henry Joutsijoki and Kirsi Penttinen and Disheet Shah and Katriina Aalto-Setälä},
keywords = {Genetic cardiac diseases, Induced pluripotent stem cells, Cardiomyocytes, Transient profiles, Machine learning, Classification, Leave-one-out, -fold cross-validation},
abstract = {Background
Cardiomyocytes differentiated from human induced pluripotent stem cells (iPSC-CMs) can be used to study genetic cardiac diseases. In patients these diseases are manifested e.g. with impaired contractility and fatal cardiac arrhythmias, and both of these can be due to abnormal calcium transients in cardiomyocytes. Here we classify different genetic cardiac diseases using Ca2+ transient data and different machine learning algorithms.
Methods
By studying calcium cycling of disease-specific iPSC-CMs and by using calcium transients measured from these cells it is possible to classify diseases from each other and also from healthy controls by applying machine learning computation on the basis of peak attributes detected from calcium transient signals.
Results
In the current research we extend our previous study having Ca-transient data from four different genetic diseases by adding data from two additional diseases (dilated cardiomyopathy and long QT Syndrome 2). We also study, in the light of the current data, possible differences and relations when machine learning modelling and classification accuracies were computed by using either leave-one-out test or 10-fold cross-validation.
Conclusions
Despite more complex classification tasks compared to our earlier research and having more different genetic cardiac diseases in the analysis, it is still possible to attain good disease classification results. As excepted, leave-one-out test and 10-fold cross-validation achieved virtually equal results.}
}
@article{BOHMANN2018185,
title = {Computational tools for topological coHochschild homology},
journal = {Topology and its Applications},
volume = {235},
pages = {185-213},
year = {2018},
issn = {0166-8641},
doi = {https://doi.org/10.1016/j.topol.2017.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0166864117306442},
author = {Anna Marie Bohmann and Teena Gerhardt and Amalie Høgenhaven and Brooke Shipley and Stephanie Ziegenhagen},
keywords = {Topological Hochschild homology, Coalgebra, Hochschild–Kostant–Rosenberg},
abstract = {In recent work, Hess and Shipley [18] defined a theory of topological coHochschild homology (coTHH) for coalgebras. In this paper we develop computational tools to study this new theory. In particular, we prove a Hochschild–Kostant–Rosenberg type theorem in the cofree case for differential graded coalgebras. We also develop a coBökstedt spectral sequence to compute the homology of coTHH for coalgebra spectra. We use a coalgebra structure on this spectral sequence to produce several computations.}
}
@article{BICER2021100823,
title = {Investigating creativity-directed tasks in middle school mathematics curricula},
journal = {Thinking Skills and Creativity},
volume = {40},
pages = {100823},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100823},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121000389},
author = {Ali Bicer and Aylin Marquez and Karla Valesca Matute Colindres and Angela Ann Schanke and Libni Berenice Castellon and Luke M. Audette and Celal Perihan and Yujin Lee},
keywords = {Creativity-directed tasks, Creativity in mathematics textbooks, Creativity in mathematics curricula, Creative thinking in mathematics},
abstract = {Developing students’ creative thinking abilities while learning mathematics has been recently emphasized by many scholars, with many nations including creative thinking in mathematics as one of their overarching curriculum goals. The first purpose of the present study is to develop a framework to identify what type of mathematical tasks promote the mathematical creativity of students. The second purpose is to analyze to what degree the most commonly used three middle school curricula (i.e., Eureka, The Go Math!, and CPM) in the U.S. include creativity-directed tasks in their textbooks using this framework. Analyzing 1,500 mathematical tasks in each curriculum revealed that different curricula emphasize different dimensions of the creativity-directed tasks categories (i.e., open-ended tasks, problem-posing, connections, extensions, visualizations, and communication) presented in the framework. The result also revealed that open-ended problems are more common in the 6th grade textbooks than 7th and 8th grade textbooks regardless of the three selected middle school mathematics curricula. The implication of this study is to guide teachers with the strength and weakness of textbooks in terms of their inclusiveness of creativity-directed tasks to inform their teaching. Additionally, it is critical for curriculum developers to pay particular attention in including tasks that supporting each category and subcategory proportionately across the three years of middle school rather than emphasizing a few of them in one grade and almost completely ignoring them in previous or later years.}
}
@article{CABITZA201765,
title = {The semiotics of configurations for the immanent design of interactive computational systems},
journal = {Journal of Visual Languages & Computing},
volume = {40},
pages = {65-90},
year = {2017},
note = {Semiotics, Human-Computer Interaction and End-User Development},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X16300246},
author = {Federico Cabitza and Alvise Mattozzi},
keywords = {Semiotics of Configurations, Immanent design, End-User Development platforms, Document management systems, Electronic Health Record},
abstract = {In this paper the authors propose a novel semiotic approach to the design of interactive systems and computational systems, grounded in the most recent contributions within the debate around semiotic theory and analysis. This approach, that is here called Semiotics of Configurations (SoC), is proposed for its analytic power in describing material artifacts and settings with a purposely a-conceptualistic stance. The resulting analysis informs a kind of design that is aimed at reproducing and supporting the programs of action detected in the use of artifacts, as this use is “abducted” from the physical and material form of the artifacts themselves and from the observation of how content is transformed within and across them. This approach to design, called immanent design, has inspired a platform for the user-driven development and use of electronic documents and forms in cooperative and organizational domains. The framework is illustrated with a case drawn from a study performed in the domain of hospital work.}
}
@article{DOGANDUNLAP20102141,
title = {Linear algebra students’ modes of reasoning: Geometric representations},
journal = {Linear Algebra and its Applications},
volume = {432},
number = {8},
pages = {2141-2159},
year = {2010},
note = {Special issue devoted to the 15th ILAS Conference at Cancun, Mexico, June 16-20, 2008},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2009.08.037},
url = {https://www.sciencedirect.com/science/article/pii/S0024379509004728},
author = {Hamide Dogan-Dunlap},
keywords = {Mathematics education, Linear algebra, Thinking modes, Geometric representations},
abstract = {Main goal of our research was to document differences on the types of modes linear algebra students displayed in their responses to the questions of linear independence from two different assignments. In this paper, modes from the second assignment are discussed in detail. Second assignment was administered with the support of graphical representations through an interactive web-module. Additionally, for comparison purposes, we briefly talk about the modes from the first assignment. First assignment was administered with the support of computational devices such as calculators providing the row reduced echelon form (rref) of matrices. Sierpinska’s framework on thinking modes (2000) was considered while qualitatively documenting the aspects of 45 matrix algebra students’ modes of reasoning. Our analysis revealed 17 categories of the modes of reasoning for the second assignment, and 15 categories for the first assignment. In conclusion, the findings of our analysis support the view of the geometric representations not replacing one’s arithmetic or algebraic modes but encouraging students to utilize multiple modes in their reasoning. Specifically, geometric representations in the presence of algebraic and arithmetic modes appear to help learners begin to consider the diverse representational aspects of a concept flexibly.}
}
@article{KALELIOGLU2015200,
title = {A new way of teaching programming skills to K-12 students: Code.org},
journal = {Computers in Human Behavior},
volume = {52},
pages = {200-210},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.05.047},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215004288},
author = {Filiz Kalelioğlu},
keywords = {Improving classroom teaching, Programming and programming languages, Elementary education},
abstract = {This study attempts to investigate the effect of teaching code.org site on reflective thinking skills towards problem solving. More specifically, this study attempts to investigate whether there is a gender difference in terms of students’ reflective thinking skills towards problem solving. This triangulation study was conducted with 32 primary school students. The quantitative part of the study was conducted in pre-test/post-test comparison design of quasi-experimental design. The scores of reflective problem solving skills were gathered through the reflective thinking skill scale towards problem solving and the students’ performances in the code-org site were examined. In the qualitative part of the research, after the five-week experimental process, focus group interviews were conducted with ten students and a reflection paper from the IT teacher was analysed. According to the t-test results, teaching programming to primary school students in the code.org site did not cause any differences in reflective thinking skills towards problem solving. However, there is a slight increment in the means of female students’ reflective thinking skills towards problem solving over the males’ reflective thinking skills towards problem solving. On the other hand, qualitative data provided more information about the students’ experiences. Students developed a positive attitude towards programming, and female students showed that they were as successful as their male counterparts, and that programming could be part of their future plans.}
}
@article{AALTO2019145,
title = {Modeling of biomass supply system by combining computational methods – A review article},
journal = {Applied Energy},
volume = {243},
pages = {145-154},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.03.201},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919306178},
author = {Mika Aalto and Raghu KC and Olli-Jussi Korpinen and Kalle Karttunen and Tapio Ranta},
keywords = {Biomass, Supply chain, Life cycle assessment, Geographical information system, Agent-based modeling and simulation, Discrete-event simulation},
abstract = {As computing power increases, more complex computational models are utilized for biomass supply system studies. The paper describes three commonly used modeling methods in this context, geographic information systems, life-cycle assessment, and discrete-time simulation and presents bibliometric analysis of work using these three study methods. Of the 498 publications identified in searches of the Scopus and Web of Science databases, 17 reported on combinations of methods: 10 on life-cycle assessment and geographic information systems, six on joint use of life-cycle assessment and discrete-time simulation, and one on use of geographic information systems jointly with discrete-time simulation. While no articles dealt directly with simultaneous use of all three methods, several acknowledged the potential of this. The authors discuss numerous challenges identified in the review that arise in combining methods, among them computational load, the increasing number of assumptions, guaranteeing coherence between the models used, and the large quantities of data required. Discussion of issues such as the complexity of reporting and the need for standard procedures and terms becomes more critical as repositories bring together research materials, including entire models, from various sources. Efforts to mitigate many of modeling’s challenges have involved phase-specific modeling and use of such methods as expressions or uncertainty analysis in place of a complex secondary model. The authors conclude that combining modeling methods offer considerable potential for taking more variables into account; improving the results; and benefiting researchers, decision–makers, and operation managers by producing more reliable information.}
}
@article{PESKIN201213,
title = {Fostering symbolic interpretation during adolescence},
journal = {Journal of Applied Developmental Psychology},
volume = {33},
number = {1},
pages = {13-23},
year = {2012},
issn = {0193-3973},
doi = {https://doi.org/10.1016/j.appdev.2011.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0193397311000931},
author = {Joan Peskin and Rebecca Wells-Jopling},
keywords = {Adolescence, Symbolic interpretation, Domain-specific knowledge, Poetry, Concrete scaffolds, Computational skills},
abstract = {Although by 11years children demonstrate impressive performance on various tasks that assess symbolic thinking in language development, research suggests that few young adolescents demonstrate evidence of symbolic processing when reading literature. This study investigated whether the difficulty might be due to a lack of adequate exposure to domain-specific knowledge. Students in the experimental groups in three age groups — preadolescence, middle adolescence and later adolescence — received concrete scaffolds designed to foster domain-specific knowledge of the symbolic process. A comparison of the experimental and control groups showed that students at all three ages who had experienced the scaffolds demonstrated significantly greater symbolic interpretation. Furthermore, despite concerns that the scaffolds might dampen the readers' personal response, the experimental groups at all three ages provided significantly higher enjoyment ratings of the test poems.}
}
@article{POSTAN2018111,
title = {Dioids for Computational Effects},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {339},
pages = {111-134},
year = {2018},
note = {The XLII Latin American Computing Conference},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300525},
author = {Ezequiel Postan and Exequiel Rivas and Mauro Jaskelioff},
keywords = {dioid, monad, Haskell, computational effect},
abstract = {There are different algebraic structures that one can use to model notions of computation. The most well- known are monads, but lately, applicative functors have been gaining popularity. These two structures can be understood as instances of the unifying notion of monoid in a monoidal category. When dealing with non-determinism, it is usual to extend monads and applicative functors with additional structure. However, depending on the desired non-determinism, there are different options of interaction between the existing and the additional structure. This article studies one of those options, which is captured algebraically by dioids. We generalise dioids to dioid categories and show how dioids in such a category model non- determinism in monads and applicative functors. Moreover, we study the construction of free dioids in a programming context.}
}
@article{KUO201232,
title = {Conceptual study of micro-tab device in airframe noise reduction: (II) 3D computation},
journal = {Aerospace Science and Technology},
volume = {17},
number = {1},
pages = {32-39},
year = {2012},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2011.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S127096381100040X},
author = {Brian C. Kuo and Nesrin Sarigul-Klijn},
keywords = {Computational aeroacoustics, High-lift devices, Micro-tab, Airframe noise},
abstract = {A three-dimensional numerical study is conducted to better understand noise reduction results seen in the previous two-dimensional investigation of the acoustic effects of micro-tab device on airframe noise reduction. Without sacrificing the aerodynamic performance, it is possible to achieve high-lift noise reduction with the application of the micro-tab device attached to the pressure side of the flap surface near its trailing-edge. This study was carried out by numerical hybrid method, which combines Computational Fluid Dynamics and acoustic analogy to predict the farfield noise spectrum. The near-full-scale computational results show that the micro-tab device with reduced deflection of the high-lift devices achieves noise reduction in mid-to-high frequency domain, in particular the range that human beings are most sensitive to. In addition, a parametric study in terms of geometric variation of the micro-tab was also investigated and reported. The three-dimensional results obtained thus far show reduction in noise levels with use of micro-tab.}
}
@article{KUMAR2006806,
title = {Applying computational modeling to drug discovery and development},
journal = {Drug Discovery Today},
volume = {11},
number = {17},
pages = {806-811},
year = {2006},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2006.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S1359644606002868},
author = {Neil Kumar and Bart S. Hendriks and Kevin A. Janes and David {de Graaf} and Douglas A. Lauffenburger},
abstract = {Computational models of cells, tissues and organisms are necessary for increased understanding of biological systems. In particular, modeling approaches will be crucial for moving biology from a descriptive to a predictive science. Pharmaceutical companies identify molecular interventions that they predict will lead to therapies at the organism level, suggesting that computational biology can play a key role in the pharmaceutical industry. We discuss pharmaceutically-relevant computational modeling approaches currently used as predictive tools. Specific examples demonstrate how companies can employ these computational models to improve the efficiency of transforming targets into therapies.}
}
@article{SAUNDERS20121024,
title = {Children without parents in the TANF caseload: Thinking beyond the child-only label},
journal = {Children and Youth Services Review},
volume = {34},
number = {5},
pages = {1024-1034},
year = {2012},
issn = {0190-7409},
doi = {https://doi.org/10.1016/j.childyouth.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0190740912000771},
author = {Correne Saunders and Andrea Hetling and Pamela C. Ovwigho and Catherine E. Born},
keywords = {Kinship care, Child-only cases, Temporary Assistance for Needy Families, Relative caregiver, Child welfare policy},
abstract = {Child welfare policy has historically emphasized the positive impact relative caregivers can have on foster children. This emphasis coupled with recent changes in the composition of the Temporary Assistance for Needy Families (TANF) caseload has led to interest in child-only, relative caregiver cases. Child-only research, however, ignores cases in which the relative caregiver is also receiving benefits. Using the universe of welfare cases in Maryland in October 2005, this article compares and contrasts the demographic and case characteristics of parental and relative caregiver cases, also analyzing differences between cases with and without an adult receiving benefits. Findings indicate that relative caregivers have service needs that differ from those of parents and that recipient relative caregivers are more disadvantaged than child-only cases.}
}
@article{ESTRELLA20221,
title = {Early statistics in kindergarten: analysis of an educator's pedagogical content knowledge in lessons promoting informal inferential reasoning},
journal = {International Journal for Lesson and Learning Studies},
volume = {11},
number = {1},
pages = {1-13},
year = {2022},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-07-2021-0061},
url = {https://www.sciencedirect.com/science/article/pii/S2046825322000348},
author = {Soledad Estrella and Maritza Mendez-Reina and Raimundo Olfos and Jocelyn Aguilera},
keywords = {Pedagogical content knowledge, Early statistics, Informal inferential reasoning, Lesson study},
abstract = {Purpose
This study aims to describe the pedagogical content knowledge (PCK) of a kindergarten educator who implements a lesson plan about informal inferential reasoning designed in a lesson study group.
Design/methodology/approach
To this end, we analyzed teaching interventions in two kindergarten lessons focused on the playful task of tossing two coins, associated with inferential statistical reasoning. The study highlights the importance of arguing and promoting this reasoning to develop statistical thinking. It is crucial to recognize how early students can be subject to learning experiences that promote a language of uncertainty, assess the evidence provided by the data, and make generalizations.
Findings
The results reveal that while the educator demonstrated knowledge and skills relevant to the curriculum and conceptual teaching strategies, the understanding of the content by the students and the integration of the PCK components still present a challenge.
Practical implications
The lesson study collaborative teaching practices that promote PCK have proven effective for informing the design and implementation of instructional practices supporting the development of early statistical thinking in young children.
Originality/value
The study enriches the knowledge regarding the potential of the lesson study (LS) in the professional learning of kindergarten educators. It also contributes to a comprehensive approach based on authentic playful experiences in grade K that supports the development of early statistical thinking in young children.}
}
@incollection{VAMVOUDAKIS2024,
title = {Multi Agent Q-Learning With Adversaries in Nash Equilibrium and Non Equilibrium Settings},
booktitle = {Reference Module in Materials Science and Materials Engineering},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-12-803581-8},
doi = {https://doi.org/10.1016/B978-0-443-14081-5.00082-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443140815000829},
author = {Kyriakos G. Vamvoudakis},
keywords = {Adaptive control, Adaptive learning, Bounded rationality, Cyber-physical systems, Game theory, Model-free, Multi-agent systems, Nash games, Networked systems, Optimal control, Q-learning, Reinforcement learning},
abstract = {The purpose of this chapter is to demonstrate how to solve optimal control problems, both for single-player games and multiplayer games with intermittent and continuous feedback in centralized and multi agent settings. We achieve this by using Q-learning, leveraging data measured along the trajectories. Importantly, our approaches do not require any prior knowledge of the system dynamics. This model-free and dynamic framework allows learning agents to adapt their objectives or optimality criteria on the fly. In addressing nonequilibrium results in shifting, dynamical environments, a control-oriented multi agent formulation of the interactions between different thinking agents is also shown.}
}
@article{DAVELAAR2018175,
title = {Mechanisms of Neurofeedback: A Computation-theoretic Approach},
journal = {Neuroscience},
volume = {378},
pages = {175-188},
year = {2018},
note = {Neurofeedback and Functional Enhancement: Mechanisms, Methodology, Behavioral and Clinical Applications},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2017.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S030645221730386X},
author = {Eddy J. Davelaar},
keywords = {neurofeedback, electroencephalography, computational neuroscience, computer model},
abstract = {Neurofeedback training is a form of brain training in which information about a neural measure is fed back to the trainee who is instructed to increase or decrease the value of that particular measure. This paper focuses on electroencephalography (EEG) neurofeedback in which the neural measures of interest are the brain oscillations. To date, the neural mechanisms that underlie successful neurofeedback training are still unexplained. Such an understanding would benefit researchers, funding agencies, clinicians, regulatory bodies, and insurance firms. Based on recent empirical work, an emerging theory couched firmly within computational neuroscience is proposed that advocates a critical role of the striatum in modulating EEG frequencies. The theory is implemented as a computer simulation of peak alpha upregulation, but in principle any frequency band at one or more electrode sites could be addressed. The simulation successfully learns to increase its peak alpha frequency and demonstrates the influence of threshold setting – the threshold that determines whether positive or negative feedback is provided. Analyses of the model suggest that neurofeedback can be likened to a search process that uses importance sampling to estimate the posterior probability distribution over striatal representational space, with each representation being associated with a distribution of values of the target EEG band. The model provides an important proof of concept to address pertinent methodological questions about how to understand and improve EEG neurofeedback success.}
}
@article{CUADRA20161223,
title = {Computational intelligence in wave energy: Comprehensive review and case study},
journal = {Renewable and Sustainable Energy Reviews},
volume = {58},
pages = {1223-1246},
year = {2016},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2015.12.253},
url = {https://www.sciencedirect.com/science/article/pii/S1364032115016366},
author = {L. Cuadra and S. Salcedo-Sanz and J.C. Nieto-Borge and E. Alexandre and G. Rodríguez},
keywords = {Computational intelligence techniques, Wave energy, Renewable energy, Wave energy converters, Environmental impact},
abstract = {Wind-generated wave energy is a renewable energy source that exhibits a huge potential for sustainable growth. The design and deployment of wave energy converters at a given location require the prediction of the amount of available wave energy flux. This and other wave parameters can be estimated by means of Computational Intelligence techniques (Neural, Fuzzy, and Evolutionary Computation). This paper reviews those used in wave energy applications, both in the resource estimation and in the design and control of wave energy converters. In particular, most of the applications of Neural Computation techniques, considered here in a broad sense, focus on the prediction of a variety of wave energy parameters by means of Multilayer Perceptrons and, at a lesser extent, by Support Vector Machines, and Extreme Learning Machines. Fuzzy Computation is also applied to estimate wave parameters and control floating wave energy converter. Evolutionary Computation algorithms are used to estimate parameters and design wave energy collectors. We complete this paper with a case study that illustrates, for the first time to the best of our knowledge, the potential of hybridizing a Coral Reefs Optimization algorithm with an Extreme Learning Machine to tackle the problem of significant wave height reconstruction.}
}
@article{LORD2023490,
title = {The sustainability of the gig economy food delivery system (Deliveroo, UberEATS and Just-Eat): Histories and futures of rebound, lock-in and path dependency},
journal = {International Journal of Sustainable Transportation},
volume = {17},
number = {5},
pages = {490-502},
year = {2023},
issn = {1556-8318},
doi = {https://doi.org/10.1080/15568318.2022.2066583},
url = {https://www.sciencedirect.com/science/article/pii/S1556831822007018},
author = {Carolynne Lord and Oliver Bates and Adrian Friday and Fraser McLeod and Tom Cherrett and Antonio Martinez-Sykora and Andy Oakey},
keywords = {Gig economy couriers, path dependence, rebounds, sustainability, systems thinking},
abstract = {ABSTRACT
Online food delivery has transformed the last-mile of food and grocery delivery, with unnoticed yet often significant impacts upon the transport and logistics network. This new model of food delivery is not just increasing congestion in urban centers though, it is also changing the contours and qualities of those doing delivery—namely through gig economy work. This new system of food consumption and provision is rapidly gaining traction, but assessments around its current and future sustainability tend to hold separate the notions of social, environmental and economic sustainability—with few to date working to understand how these can interact, influence and be in conflict with one another. This paper seeks to work with this broader understanding of sustainability, whilst also foregrounding the perspectives of gig economy couriers who are often marginalized in such assessments of the online food delivery system. We make use of systems thinking and Campbell’s conflict model of sustainability to do this. In assessing the online food delivery in this way, we seek to not only provide a counternarrative to some of these previous assessments, but to also challenge those proposing the use of gig economy couriers as an environmentally sustainable logistics intervention in other areas of last-mile logistics to consider how this might impact the broader sustainability of their system, now and in the future.}
}