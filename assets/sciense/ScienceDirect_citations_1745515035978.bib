@article{MULLER1987271,
title = {Computational problems in supernova simulations},
journal = {Computer Physics Communications},
volume = {44},
number = {3},
pages = {271-277},
year = {1987},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(87)90082-8},
url = {https://www.sciencedirect.com/science/article/pii/0010465587900828},
author = {Ewald Müller},
abstract = {Theoretical models of type I and type II supernova explosions are reviewed from a computational physics point of view. After discussing briefly the underlying physics the numerical problems and challenges encountered in the simulation of type I and type II supernova are addressed.}
}
@article{LAWRENCE2023100786,
title = {Translational argument technology: Engineering a step change in the argument web},
journal = {Journal of Web Semantics},
volume = {77},
pages = {100786},
year = {2023},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2023.100786},
url = {https://www.sciencedirect.com/science/article/pii/S157082682300015X},
author = {John Lawrence and Jacky Visser and Chris Reed},
keywords = {Argumentation, Argument analytics, Argument mining, Argument technology, Argument web, Debate technology},
abstract = {Following the establishment in 2006 of a representational standard for the computational handling of structures of argumentation, the Argument Interchange Format, it became possible to develop a vision for the coherent integration of multifarious services, components and tools that create, consume, navigate, analyse, evaluate and manipulate arguments and debates. This vision was the Argument Web with theoretical foundations laid by Rahwan et al. (2007), and practical engineering work described by Bex et al. (2013). Over the intervening period, the key challenge has been to demonstrate the practical and societal value of the Argument Web by taking its tools and applications to larger audiences. This paper lays out three approaches by which the Argument Web has been scaled up in this way, each in partnership with the BBC, and each with different kinds of evaluation and impact. Transitioning these technologies to large user groups paves the way for broader-scale uptake of the Argument Web and heralds the translation from lab to real-world application for a substantial research community working in argument technology.}
}
@article{PANESCU2013375,
title = {At the Crossroads between Western and Eastern Views on Psychotherapy: An Integrative Approach},
journal = {Procedia - Social and Behavioral Sciences},
volume = {78},
pages = {375-379},
year = {2013},
note = {PSIWORLD 2012},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.04.314},
url = {https://www.sciencedirect.com/science/article/pii/S1877042813008835},
author = {Oana Pănescu and Alexandra Timofte and Melania Macovei and Carmen Popescu},
keywords = {Psychoterapy, Body, Mind, Meditation, Transactional analysis},
abstract = {This paper aims at indicating the convergence points between what is habitually understood as a pair of opposing terms: mind (as in thinking) and body (as in sensation). Structural models in psychotherapy conceptualize human mind in terms of levels of information processing (both internal and external information). We suggest that a mental split between mind and body leads to a feeling of estrangement from self, as well as an estrangement from external world. Drawing on relational approaches on psychotherapy, we suggest that focusing on perceiving own sensations does not necessarily imply a state of personal isolation from outside world; rather, this simultaneously means the perceiving and acceptance of “otherness”.}
}
@article{THOMPSON2024100094,
title = {Alzheimer’s disease and the mathematical mind},
journal = {Brain Multiphysics},
volume = {6},
pages = {100094},
year = {2024},
issn = {2666-5220},
doi = {https://doi.org/10.1016/j.brain.2024.100094},
url = {https://www.sciencedirect.com/science/article/pii/S2666522024000054},
author = {Travis B. Thompson and Bradley Z. Vigil and Robert S. Young},
keywords = {Alzheimer’s disease, Mathematical modeling, Scientific computing},
abstract = {Throughout the 19th and 20th centuries, aided by advances in medical imaging, discoveries in physiology and medicine have added nearly 25 years to the average life expectancy. This resounding success brings with it a need to understand a broad range of age-related health conditions, such as dementia. Today, mathematics, neuroimaging and scientific computing are being combined with fresh insights, from animal models, to study the brain and to better understand the etiology and progression of Alzheimer’s disease, the most common cause of age-related dementia in humans. In this manuscript, we offer a brief primer to the reader interested in engaging with the exciting field of mathematical modeling and scientific computing to advance the study of the brain and, in particular, human AD research. Statement of Significance Modeling Alzheimer’s disease is a highly interdisciplinary field and finding an effective starting point can be a considerable challenge. To address this challenge, this manuscript briefly highlights some central components of AD related protein pathology, useful classes of mathematical models for brain and AD research and effective computational resources for the practical prospective practitioner.}
}
@article{CHEN2024e26409,
title = {Physiological records-based situation awareness evaluation under aviation context: A comparative analysis},
journal = {Heliyon},
volume = {10},
number = {5},
pages = {e26409},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e26409},
url = {https://www.sciencedirect.com/science/article/pii/S240584402402440X},
author = {Jun Chen and Anqi Chen and Bingkun Jiang and Xinyu Zhang},
keywords = {Situation awareness, Electroencephalogram, Brain electrical activity mapping, Convolutional neural network, Multi-class classification, Aviation decision-making},
abstract = {Situational Awareness (SA) assessment is of paramount importance in various domains, with particular significance in the military for safe aviation decision-making. It involves encompassing perception, comprehension, and projection levels in human beings. Accurate evaluation of SA statuses across these three levels is crucial for mitigating human false-positive and false-negative rates in monitoring complex scenarios in the aviation context. This study proposes a comprehensive comparative analysis by involving two types of physiological records: electroencephalogram (EEG) signals and brain electrical activity mapping (BEAM) images. These two modalities are leveraged to automate precise SA evaluation using both conventional machine learning and advanced deep learning techniques. Benchmarking experiments reveal that the BEAM-based deep learning models attain state-of-the-art performance scores of 0.955 for both SA perception and comprehension levels, respectively. Conversely, the EEG signals-based manual feature extraction, selection, and classification approach achieved a superior accuracy of 0.929 for the projection level of SA. These findings collectively highlight the potential of deploying diverse physiological records as valuable computational tools for enhancing SA evaluation throughout aviation decision-making safety.}
}
@article{SAYALI2023614,
title = {The costs and benefits of psychedelics on cognition and mood},
journal = {Neuron},
volume = {111},
number = {5},
pages = {614-630},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322011527},
author = {Ceyda Sayalı and Frederick S. Barrett},
keywords = {psychedelics, cognitive control, meta-control, creativity, cognitive flexibility, cognitive stability, dopamine, serotonin, dose-dependency, baseline dependency},
abstract = {Summary
Anecdotal evidence has indicated that psychedelic substances may acutely enhance creative task performance, although empirical support for this claim is mixed at best. Clinical research has shown that psychedelics might have enduring effects on mood and well-being. However, there is no neurocognitive framework that ties acute changes in cognition to long-term effects in mood. In this review, we operationalize creativity within an emerging cognitive control framework and assess the current empirical evidence of the effects of psychedelics on creativity. Next, we leverage insights about the mechanisms and computations by which other psychoactive drugs act to enhance versus impair cognition, in particular to those that act on catecholamines, the neurophysiological consequences of which are relatively well understood. Finally, we use the same framework to link the suggested psychedelic-induced improvements in creativity with enduring psychedelic-induced improvements in mood.}
}
@article{VERDECCHIA2022100767,
title = {The future of sustainable digital infrastructures: A landscape of solutions, adoption factors, impediments, open problems, and scenarios},
journal = {Sustainable Computing: Informatics and Systems},
volume = {35},
pages = {100767},
year = {2022},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2022.100767},
url = {https://www.sciencedirect.com/science/article/pii/S2210537922000889},
author = {Roberto Verdecchia and Patricia Lago and Carol {de Vries}},
keywords = {Sustainability, Green IT, Energy efficiency, Digital infrastructures, Data centers, Cloud, Landscape, Qualitative research},
abstract = {Background:
Digital infrastructures, i.e., ICT systems, or system-of-systems, providing digital capabilities, such as storage and computational services, are experiencing an ever-growing demand for data consumption, which is only expected to increase in the future. This trend leads to a question we need to answer: How can we evolve digital infrastructures to keep up with the increasing data demand in a sustainable way?
Objective:
The goal of this study is to understand what is the future of sustainable digital infrastructures, in terms of: which solutions are, or will be, available to sustainably evolve digital infrastructures, and which are the related adoption factors, impediments, and open problems.
Method:
We carried out a 3-phase mixed-method qualitative empirical study, comprising semi-structured interviews, followed by focus groups, and a plenary session with parallel working groups. In total, we conducted 13 sessions involving 48 digital infrastructure practitioners and researchers.
Results:
From our investigation emerges a landscape for sustainable digital infrastructures, composed of 30 solutions, 5 adoption factors, 4 impediments, and 13 open problems. We further synthesized our results in 4 incremental scenarios, which outline the future evolution of sustainable digital infrastructures.
Conclusions:
From an initial shift from on-premise to the cloud, as time progresses, digital infrastructures are expected to become increasingly distributed, till it will be possible to dynamically allocate resources by following time, space, and energy. Numerous solutions will support this change, but digital infrastructures are envisaged to be able to evolve sustainably only by (i) gaining a wider awareness of digital sustainability, (ii) holding every party accountable for their sustainability throughout value chains, and (iii) establishing cross-domain collaborations.}
}
@article{HUNT201645,
title = {Levels of participatory conception of fractional quantity along a purposefully sequenced series of equal sharing tasks: Stu's trajectory},
journal = {The Journal of Mathematical Behavior},
volume = {41},
pages = {45-67},
year = {2016},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312315300122},
author = {Jessica H. Hunt and Arla Westenskow and Juanita Silva and Jasmine Welch-Ptak},
keywords = {Conceptions, Cognition, Learning disabilities, Rational number, Pedagogy, Constructivism},
abstract = {Current intervention research in special education focuses on children's responsiveness to teacher modeled strategies and not conceptual development within children's thinking. As a result, there is a need for research that provides a characterization of key understandings (KUs) of fractional quantity evidenced by children with learning disabilities (LD) and how growth of conceptual knowledge may occur within these children's mathematical activity. This case study extends current literature by presenting KUs of fractional quantity, evidenced through problem solving strategies, observable operations, and naming/quantification of one fifth grader with LD before, during, and after seven instructional sessions situated in equal sharing. The researchers utilized a characterization of evolving fraction conceptions developed from research of children without disabilities that was ultimately productive in facilitating conceptual advances of the child with LD. We hypothesize that the trajectory of the child's conceptions is a case of something more general. Pending future research, the trajectory may be a useful tool to practitioners wishing to plan thoughtful, conceptually-based fraction instruction that is responsive to all children's evolving conceptions of fractions as quantities built through their own mathematical activity.}
}
@article{HUSSAIN2025109490,
title = {A neural network integrated mathematical model to analyze the impact of nutritional status on cognitive development of child},
journal = {Computers in Biology and Medicine},
volume = {185},
pages = {109490},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.109490},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524015750},
author = {Zakir Hussain and Malaya Dutta Borah},
keywords = {Cognitive development, Cognition, Nutritional status, Neural network, Mathematical model},
abstract = {Cognitive development is a crucial developmental aspect of children. It is a concise field of study in psychology and neuroscience that focuses on various developmental aspects of the brain. Among all other factors, nutritional status is believed to play a very important role in cognitive development. The purpose of this work is to analyze the impacts of different nutritional status levels on the child’s cognitive development. This work designs a model that uses a neural network and differential equations. The neural network is applied on a dataset called “Child Birth Weight Dataset” available at IEEE Dataport ( http://dx.doi.org/10.21227/dvd4-3232) for finding the nutritional status of a child. The different levels of nutritional status, such as low-nutritional status, normal-nutritional status, and over-nutritional status are integrated with the formulated differential equations. The model is computationally simulated considering four different sets of parameter values that represent four different perspectives such as ‘only positive’, ‘only negative’, ‘mix and unequal weight’, and ‘mix and equal weight’ of the influencing factors. The experimental results show that normal-nutritional status is the best nutritional status for cognitive development. However, the best cognitive development happens when all other influencing factors like environmental effects, socioeconomic status, heredity, learning opportunities, and use of experiences are given equal importance. The results also depict that the low- and over-nutritional status cannot restrict cognitive development for a long time. After a certain period, the development gets triggered and it happens. It may be slow and not up to the mark of the development under normal-nutritional status, but it happens. Simply it can be said that nutritional status alone does not have control over the cognitive development of a child. Along with nutritional status, other influencing factors are important too.}
}
@article{WU2020107246,
title = {miRNA-324/-133a essential for recruiting new synapse innervations and associative memory cells in coactivated sensory cortices},
journal = {Neurobiology of Learning and Memory},
volume = {172},
pages = {107246},
year = {2020},
issn = {1074-7427},
doi = {https://doi.org/10.1016/j.nlm.2020.107246},
url = {https://www.sciencedirect.com/science/article/pii/S1074742720300903},
author = {Ruixiang Wu and Shan Cui and Jin-Hui Wang},
keywords = {Associative learning, Memory cell, Neural circuit, Barrel cortex, Piriform cortex},
abstract = {After the integrative storage of associated signals, a signal induces the recollection of its associated signal, or the other way around. This associative memory is essential to associative thinking, logical reasoning, imagination and computation. In terms of cellular mechanisms underlying associative memory, new mutual synapse innervations are formed among those coactivated neurons, so that they are recruited to be associative memory cells or associative memory neurons. These associative memory cells receive new synapse innervations alongside innate synapse inputs and encode signals carried by these inputs. We proposed to examine microRNAs as initiative factors for recruiting new synapse innervations and associative memory cells. In a mouse model of associative memory characterized as the reciprocal retrieval of associated whisker and odor signals, barrel and piriform cortical neurons gain their ability to encode whisker and odorant signals based on the newly formed synapse innervations between these coactivated cortices besides innate synapse inputs. miRNA-324 and miRNA-133a are required for recruiting these new synapse innervations and associative memory cells as well as sufficient for facilitating their recruitments, but not for innate synapse inputs. Therefore, the coactivation of sensory cortices through microRNA as initiative factor to recruit new mutual synapse innervations and associative memory cells for associative memory.}
}
@article{BEDOGNI2025107855,
title = {Fluid Computing & Digital Twins for intelligent interoperability in the IoT ecosystem},
journal = {Future Generation Computer Systems},
pages = {107855},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107855},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25001505},
author = {Luca Bedogni and Marco Mamei and Marco Picone and Marcello Pietri and Franco Zambonelli},
keywords = {Digital twins, Intelligence, Fluid Computing, Interoperability},
abstract = {The integration of physical and digital systems is fundamental to enabling intelligent, adaptive, and scalable solutions in modern IoT environments. This paper explores Fluid Digital Twins (FDTs), a novel framework combining Fluid Computing (FC) principles with Digital Twin (DT) technology, to address challenges related to interoperability, dynamic functionality, and adaptability in IoT ecosystems. FC introduces a paradigm shift, enabling seamless data and computational task flow across heterogeneous environments, dynamically adjusting to resource availability and system needs. This paper focuses on embedding intelligence within FDTs to enhance interoperability and enable IoT applications to adapt to changes across both physical and digital domains. By integrating intelligent interoperability mechanisms, FDTs ensure smooth data alignment and compatibility across platforms, adapting to both physical and digital changes. The proposed framework has been implemented, prototyped, and evaluated in the Modena Automotive Smart Area (MASA), a smart city testbed. The evaluation demonstrates FDTs’ ability to enhance smart mobility, optimize transportation systems, and provide actionable insights, highlighting their transformative potential in dynamic, data-rich environments. The results emphasize the practical applicability of FDTs in addressing real-world challenges and advancing the capabilities of IoT-driven smart cities.}
}
@article{DUAN2024101258,
title = {Concept cognition for knowledge graphs: Mining multi-granularity decision rule},
journal = {Cognitive Systems Research},
volume = {87},
pages = {101258},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101258},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724000524},
author = {Jiangli Duan and Guoyin Wang and Xin Hu and Qun Liu and Qin Jiang and Huamin Zhu},
keywords = {Granular computing, Cognitive intelligence, Concept cognition, Knowledge graph, Decision rule},
abstract = {As part of cognitive intelligence, concept cognition for knowledge graphs aims to clearly grasp the typical characteristics of the things referred to by the concept, which can provide prior knowledge for machine understanding and thinking. Different from concept learning and formal concept analysis that learn new concepts from data and the general decision rule that comes from an independent decision table, this paper cognizes an existing concept by decision rules that come from multiple granularities. Specifically, 1) concept cognition for knowledge graphs is realized from the perspective of mining multi-granularity decision rule. 2) Decision tables corresponding to four granularities form a multi-granularity decision table group, and then the result from coarser granularity can guide and help obtaining the result from finer granularity. 3) We propose a framework for mining multi-granularity decision rules, which involves going from a multi-granularity decision table group to the frequent maximal attribute patterns to the decision rules to the credible decision rules. Finally, we verified effectiveness of dividing positive and negative data, monotonicity of attribute patterns in a multi-granularity decision table group, and downward monotonicity of credibility, and observed the impact of the parameter min_cov and min_conf on execution times.}
}
@article{BACHMANN2020102937,
title = {Account of consciousness by Christof Koch: Review and questions},
journal = {Consciousness and Cognition},
volume = {82},
pages = {102937},
year = {2020},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2020.102937},
url = {https://www.sciencedirect.com/science/article/pii/S1053810020300143},
author = {Talis Bachmann},
keywords = {Consciousness, Integrated information, Cognitive computation, Microgenesis, Phenomenal experience},
abstract = {This review is set to present the gist of the theoretical account of consciousness recently presented by Christof Koch and pose a couple of questions instigated by this account. The expected answers to these questions would hopefully help to advance our understanding of the basic nature of the conscious mind.}
}
@article{ALI2024100170,
title = {A conceptual IoT framework based on Anova-F feature selection for chronic kidney disease detection using deep learning approach},
journal = {Intelligence-Based Medicine},
volume = {10},
pages = {100170},
year = {2024},
issn = {2666-5212},
doi = {https://doi.org/10.1016/j.ibmed.2024.100170},
url = {https://www.sciencedirect.com/science/article/pii/S2666521224000371},
author = {Md Morshed Ali and Md Saiful Islam and Mohammed Nasir Uddin and Md. Ashraf Uddin},
keywords = {IoT Framework, Machine learning, Deep learning, Feature selection techniques, ANOVA F-test, Healthcare technology, Medical diagnosis, Kidney disease prediction, Classification},
abstract = {Chronic kidney disease (CKD) is becoming an increasingly significant health issue, especially in low-income countries where access to affordable treatment is limited. Additionally, CKD is associated with various dietary factors, including liver failure, diabetes, anemia, nerve damage, inflammation, peroxidation, obesity, and other related conditions. Therefore, early prediction of CKD is important to progress the functionality of the kidney. In recent times, IoT has been widely used in a diversity of healthcare sectors through the incorporation of monitoring devices such as digital sensors and medical devices for patient monitoring from remote places. To overcome the problem, this research proposed a conceptual architecture for CKD detection. The sensor layer of the architecture includes IoT devices to collect data and the proposed classifier, MLP (Multi-Layer Perceptron), utilizes the Anova-F feature selection technique to effectively detect CKD (Chronic Kidney Disease). In addition to MLP, four other classifiers including ANN (Artificial Neural Network), Simple RNN (Recurrent Neural Network), GRU (Gated Recurrent Unit), and SVM (Support Vector Machine), are employed for comparative analysis of accuracy. Furthermore, three additional feature selection techniques, namely Chi-squared, SFFS (Sequential Floating Forward Selection), and SBFS (Sequential Backward Floating Selection), are utilized to evaluate their impact on the accuracy of CKD detection. Our proposed method outperforms all other approaches with a remarkable accuracy of 99 % while maintaining efficient computational time. This advancement is crucial in developing a highly accurate machine capable of predicting CKD in remote areas with ease.}
}
@article{HELBING2023102061,
title = {Democracy by Design: Perspectives for Digitally Assisted, Participatory Upgrades of Society},
journal = {Journal of Computational Science},
volume = {71},
pages = {102061},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102061},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001217},
author = {Dirk Helbing and Sachit Mahajan and Regula Hänggli Fricker and Andrea Musso and Carina I. Hausladen and Cesare Carissimo and Dino Carpentras and Elisabeth Stockinger and Javier {Argota Sanchez-Vaquerizo} and Joshua C. Yang and Mark C. Ballandies and Marcin Korecki and Rohit K. Dubey and Evangelos Pournaras},
keywords = {Computational diplomacy, Digital democracy, Participation, Collective intelligence, Value-based engineering},
abstract = {The technological revolution, particularly the availability of more data and more powerful computational tools, has led to the emergence of a new scientific field called “Computational Diplomacy”. Our work tries to define its scope and focuses on a popular subarea of it, namely “Digital Democracy”. In recent years, there has been a surge of interest in using digital technologies to promote more participatory forms of democracy. While there are numerous potential benefits to using digital tools to enhance democracy, significant challenges must be addressed. It is essential to ensure that digital technologies are used in an accessible, equitable, and fair manner rather than reinforcing existing power imbalances. This paper investigates how digital tools can be used to help design more democratic societies by investigating three key research areas: (1) the role of digital technologies for facilitating civic engagement in collective decision-making; (2) the use of digital tools to improve transparency and accountability in governance; and (3) the potential for digital technologies to enable the formation of more inclusive and representative democracies. We argue that more research on how digital technologies can be used to support democracy upgrade is needed. Along these lines, we lay out a research agenda for the future.}
}
@article{COSMIDES198951,
title = {Evolutionary psychology and the generation of culture, part II: Case study: A computational theory of social exchange},
journal = {Ethology and Sociobiology},
volume = {10},
number = {1},
pages = {51-97},
year = {1989},
issn = {0162-3095},
doi = {https://doi.org/10.1016/0162-3095(89)90013-7},
url = {https://www.sciencedirect.com/science/article/pii/0162309589900137},
author = {Leda Cosmides and John Tooby},
keywords = {Reciprocal Altruism, Cooperation, Tit for tat, Cognition, Reasoning, Evolution, Learning, Culture},
abstract = {Models of the various adaptive specializations that have evolved in the human psyche could become the building blocks of a scientific theory of culture. The first step in creating such models is the derivation of a so-called “computational theory” of the adaptive problem each psychological specialization has evolved to solve. In Part II, as a case study, a sketch of a computational theory of social exchange (cooperation for mutual benefit) is developed. The dynamics of natural selection in Pleistocene ecological conditions define adaptive information processing problems that humans must be able to solve in order to participate in social exchange: individual recognition, memory for one's history of interaction, value communication, value modeling, and a shared grammar of social contracts that specifies representational structure and inferential procedures. The nature of these adaptive information processing problems places constraints on the class of cognitive programs capable of solving them; this allows one to make empirical predictions about how the cognitive processes involved in attention, communication, memory, learning, and reasoning are mobilized in situations of social exchange. Once the cognitive programs specialized for regulating social exchange are mapped, the variation and invariances in social exchange within and between cultures can be meaningfully discussed.}
}
@incollection{ZIELINSKI2024116,
title = {Coupled-Cluster Theories for Excited States},
editor = {Manuel Yáñez and Russell J. Boyd},
booktitle = {Comprehensive Computational Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {116-140},
year = {2024},
isbn = {978-0-12-823256-9},
doi = {https://doi.org/10.1016/B978-0-12-821978-2.00035-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128219782000350},
author = {Patrik Zielinski and Andreas Köhn},
keywords = {Accurate computations, Analytic gradients, Basis-set convergence, Benchmark computations, Cluster expansion, Coupled-cluster theory, Equation of motion, Excited-state properties, Gradient theory, Linear response, Multireference, Open-shell systems, Single-reference, Size consistency, Transition moments},
abstract = {Coupled-cluster theory offers a hierarchy of increasingly accurate methods and provides thus an important basis for accurate quantum chemistry, also for the computation of electronic excited states. This chapter explains and compares the two main approaches, equation-of-motion and linear-response theory and sketches the computation of transition moments and expectation values, as well as analytic geometric gradients. The basic approaches to arrive at approximations are discussed, and recent benchmark works are used to demonstrate their relative accuracy. Some challenges in coupled-cluster theory, like going to large systems, open-shell and multireference theory and the slow basis-set convergence are also covered.}
}
@article{SHARMA201524,
title = {Urban greenways: Operationalizing design syntax and integrating mathematics and science in design},
journal = {Frontiers of Architectural Research},
volume = {4},
number = {1},
pages = {24-34},
year = {2015},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2014.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095263514000727},
author = {Archana Sharma},
keywords = {Design thinking, Syntax, Greenway, Urban, Planning, Landscape, STEM integrated design, Inter-disciplinary},
abstract = {The ubiquitous sameness of urban greenways prompts questions on generative design grammar and syntax, whether creative, critical rethinking at that level might be lacking. However the design syntax of urban greenways is not explicitly discussed thus leaving a critical gap in knowledge. This paper begins tackling the larger question by acting on the fundamental subset of it, by operationalizing the design syntax of urban greenways. This is done through mathematics-based graph studies to analyze patterns and shapes, photography based thermal, material and morphology studies, and section analyses to make imagery-derived deductions on the design syntax. Recommendation on approaches to diversify and enrich the design syntax includes a more direct reference from ecosystem science theories such for siting and planning the urban greenways at macro- to meso-scale, a mixed-method approach, combining mathematics, photography and drawings based frames for analyses at meso-, to micro-scale, and a turtle view scale for designing at meso- to micro-scale, with an emphasis on latter.}
}
@incollection{BUTTON199067,
title = {Chapter 4 - Going Up a Blind Alley: Conflating Conversation Analysis and Computational Modelling},
editor = {PAUL LUFF and NIGEL GILBERT and DAVID FROHLICH},
booktitle = {Computers and Conversation},
publisher = {Academic Press},
address = {London},
pages = {67-90},
year = {1990},
isbn = {978-0-08-050264-9},
doi = {https://doi.org/10.1016/B978-0-08-050264-9.50009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080502649500099},
author = {Graham Button},
abstract = {Publisher Summary
This chapter discusses the desirability of developing computational models of conversational phenomena, and the supportive role given to conversation analysis (CA) in the development of such models. The arguments presented in this chapter are not an attempt to restrict the range of creative resources that software designers might turn to for inspiration. In particular, it is implicitly endorsed in the attempts to develop descriptively adequate models of conversation for use in computer systems, and explicitly endorsed when it is argued that by providing a simulacrum of conversation one has naturally occurring conversation between computers and humans. The attraction of CA for people who want to develop rules of conversational organization that can be used to program computers is two-fold: (1) CA might seem to provide a ready-made package of conversational rules that they can use or adapt for their purposes; and (2) their models may be authorized by appealing to CA. However, CA is used to authorize computational models of conversation that misrepresent the details of how conversation works.}
}
@article{WOLFENGAGEN2024101185,
title = {Semantic configuration model with natural transformations},
journal = {Cognitive Systems Research},
volume = {83},
pages = {101185},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101185},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723001195},
author = {Viacheslav Wolfengagen and Larisa Ismailova and Sergey Kosikov and Igor Slieptsov and Sebastian Dohrn and Alexander Marenkov and Vladislav Zaytsev},
keywords = {Information process, Configuration, Morphing, Cognitive preference, Semantic net, Functor, Natural transformation},
abstract = {In the present work, efforts have been made to create a configuration-based approach to knowledge extraction. The notion of granularity is developed, which allows fine-tuning the expressive possibilities of the semantic network. As known, the central issues for knowledge-based systems are what’s-in-a-node and what’s-in-a-link. As shown, the answer can be obtained from the functor-as-object representation. Then the nodes are functors, and the main links are natural transformations. Such a model is applicable to represent morphing, and the object is considered as a process, which is in a harmony with current ideas on computing. It is possible to represent information channels that carry out the transformations of processes. The possibility of generating displaced concepts and the generation of families of their morphs is shown, the evolvent of stages of knowledge and properties of the process serve as parameters.}
}
@article{KORDAKI2017122,
title = {Digital card games in education: A ten year systematic review},
journal = {Computers & Education},
volume = {109},
pages = {122-161},
year = {2017},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2017.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S036013151730043X},
author = {Maria Kordaki and Anthi Gousiou},
keywords = {Applications in subject areas, Interactive learning environments, Pedagogical issues, Review, Digital card games},
abstract = {This paper presents a 10-year review study that focuses on the investigation of the use of Digital Card Games (DCGs) as learning tools in education. Specific search terms keyed into 10 large scientific electronic databases identified 50 papers referring to the use of non-commercial DCGs in education during the last decade (2003–2013). The findings revealed that the DCGs reported in the reviewed papers: (a) were used for the learning of diverse subject disciplines across all educational levels and leaning towards the school curriculum, in two ways: game-construction and game-play, (b) were mainly proposed by their designers as meaningful, familiar and appealing learning contexts, in order to motivate and engage players/students and also to promote social, rich and constructivist educational experiences while at the same time integrating modern technologies and innovative gamed-based approaches, (c) were implemented using a plethora of digital tools, (d) mainly adopted social and constructivist views of learning during their design and use, although the views were explicitly reported in only a few of these, (e) were evaluated – in more than half of the studies – with positive results in terms of: student learning, attitudes towards DCGs and enrichment of social interaction and collaboration, (f) appeared to support students to acquire essential thinking skills through DCG-play. However, despite the rich DCG-game experiences reported in the reviewed papers, some essential but under-researched topics were also specified.}
}
@article{SCHNEIDER2012475,
title = {Eye gaze reveals a fast, parallel extraction of the syntax of arithmetic formulas},
journal = {Cognition},
volume = {125},
number = {3},
pages = {475-490},
year = {2012},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2012.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0010027712001357},
author = {Elisa Schneider and Masaki Maruyama and Stanislas Dehaene and Mariano Sigman},
keywords = {Arithmetic, Gestalt, Cognitive architecture, Language, Mathematical education},
abstract = {Mathematics shares with language an essential reliance on the human capacity for recursion, permitting the generation of an infinite range of embedded expressions from a finite set of symbols. We studied the role of syntax in arithmetic thinking, a neglected component of numerical cognition, by examining eye movement sequences during the calculation of arithmetic expressions. Specifically, we investigated whether, similar to language, an expression has to be scanned sequentially while the nested syntactic structure is being computed or, alternatively, whether this structure can be extracted quickly and in parallel. Our data provide evidence for the latter: fixations sequences were stereotypically organized in clusters that reflected a fast identification of syntactic embeddings. A syntactically relevant pattern of eye movement was observed even when syntax was defined by implicit procedural rules (precedence of multiplication over addition) rather than explicit parentheses. While the total number of fixations was determined by syntax, the duration of each fixation varied with the complexity of the arithmetic operation at each step. These findings provide strong evidence for a syntactic organization for arithmetic thinking, paving the way for further comparative analysis of differences and coincidences in the instantiation of recursion in language and mathematics.}
}
@article{XIE2024,
title = {Wide human-like neural network incorporating driving styles for human-like driving intention analysis},
journal = {Journal of Intelligent Transportation Systems},
year = {2024},
issn = {1547-2450},
doi = {https://doi.org/10.1080/15472450.2024.2425304},
url = {https://www.sciencedirect.com/science/article/pii/S1547245024000471},
author = {Jiming Xie and Yan Zhang and Yaqin Qin and Ke Li and Shuai Dong and Siyu Liu and Yulan Xia},
keywords = {autonomous vehicle, decision making, driving intention, human driving vehicle, width human-like neural network},
abstract = {Enhancing the synergy between autonomous and human-driven vehicles at the societal level requires understanding drivers’ behaviors and cognitive patterns, as well as conducting human-like driving intention analysis. To achieve this goal, this study designs a novel framework for analyzing human-like driving intention. Firstly, a spectral clustering method is employed to characterize driving styles. Secondly, a misclassification cost matrix is tailored to different driving needs. Finally, inspired by the complex neural networks found in the human brain, we develop a specialized lightweight neural network, termed the Width Human-like Neural Network (WNN), aimed at realizing personalized cognition and facilitating human-like decision-making in driving intention. Experimental studies and validation based on natural driving trajectory data from Kunming, China, demonstrate that the method accurately infers internal implicit driving intention from external explicit and observable driving behaviors, achieving a prediction accuracy of 99.8%. This framework strategically allocates limited computational resources to critical areas for autonomous vehicles and exemplifies best practices for improving neural network performance in driving intention analysis tasks.}
}
@article{MARITAN2022167351,
title = {Building Structural Models of a Whole Mycoplasma Cell},
journal = {Journal of Molecular Biology},
volume = {434},
number = {2},
pages = {167351},
year = {2022},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2021.167351},
url = {https://www.sciencedirect.com/science/article/pii/S002228362100588X},
author = {Martina Maritan and Ludovic Autin and Jonathan Karr and Markus W. Covert and Arthur J. Olson and David S. Goodsell},
keywords = {whole cell modeling, computational modeling, nucleoid structure, scientific visualization, mycoplasma genitalium},
abstract = {Building structural models of entire cells has been a long-standing cross-discipline challenge for the research community, as it requires an unprecedented level of integration between multiple sources of biological data and enhanced methods for computational modeling and visualization. Here, we present the first 3D structural models of an entire Mycoplasma genitalium (MG) cell, built using the CellPACK suite of computational modeling tools. Our model recapitulates the data described in recent whole-cell system biology simulations and provides a structural representation for all MG proteins, DNA and RNA molecules, obtained by combining experimental and homology-modeled structures and lattice-based models of the genome. We establish a framework for gathering, curating and evaluating these structures, exposing current weaknesses of modeling methods and the boundaries of MG structural knowledge, and visualization methods to explore functional characteristics of the genome and proteome. We compare two approaches for data gathering, a manually-curated workflow and an automated workflow that uses homologous structures, both of which are appropriate for the analysis of mesoscale properties such as crowding and volume occupancy. Analysis of model quality provides estimates of the regularization that will be required when these models are used as starting points for atomic molecular dynamics simulations.}
}
@article{LU2025100015,
title = {Risk theory: From perception to cognition},
journal = {Risk Sciences},
volume = {1},
pages = {100015},
year = {2025},
issn = {2950-6298},
doi = {https://doi.org/10.1016/j.risk.2025.100015},
url = {https://www.sciencedirect.com/science/article/pii/S2950629825000050},
author = {Duojia Lu},
keywords = {Risk, Cognitive disparity, Value expectation, Decision making, Stakeholders},
abstract = {This paper proposes a generic risk theory. The risk theory starts with a basic observation that risk is the product of a specific human cognitive process. This cognitive process is responsible for the generation and transformation of risk under different conditions. At the core of risk theory is a generic descriptive risk model. This risk model can be used to describe most risks seen in real life with a unified underlying logic. In the risk model, the human cognitive process of risk takes into account both the target value expectation and the realistic value expectation of cognitive subjects, and considers the disparity between them in terms of human values. Hence, risk in a variety of forms represents the disparity between the ideals of people and the cognitive reality of values. The risk model is quantitative. In the risk model, all elements from risk perception to risk cognition can be constructed quantitatively in terms of formal logic and probability. This renders most questions in the risk theory computational by nature. The model represents the cognitive disparity in terms the target value expectation and the realistic value expectation of the cognitive subject. Then the risk model is able to describe the necessary and sufficient conditions for the cognitive disparity to become perception.}
}
@article{SCHWABER1993126,
title = {Computational modeling of neuronal dynamics for systems analysis: application to neurons of the cardiorespiratory NTS in the rat},
journal = {Brain Research},
volume = {604},
number = {1},
pages = {126-141},
year = {1993},
issn = {0006-8993},
doi = {https://doi.org/10.1016/0006-8993(93)90359-U},
url = {https://www.sciencedirect.com/science/article/pii/000689939390359U},
author = {J.S. Schwaber and E.B. Graves and J.F.R. Paton},
keywords = {Nucleus tractus solitarii, Systems modeling, Cardiovascular reflex, Neuronal dynamics},
abstract = {The study constructs computational models of neurons in order to examine the contribution that their response dynamics may make to functional properties at the system level. As described in the accompanying study, neurons in the cardiorespiratory nucleus tractus solitarii (NTS) of the rat were recorded in vitro. When these cells were intracellularly injected with a constant current pulse, spike discharge patterns and subthreshold voltage trajectories were observed that were time- and voltage-dependent. The accompanying manuscript describes these dynamic responses in 4 classes of putative second-order cells that appear to receive direct primary afferent input, and a previous paper described two populations of rhythmically firing interneurons, one of which is intrinsically auto-active. In the present manuscript experimental neuronal voltage response data was collected across a current injection series for the S3 neuron type described in the accompanying study and for the auto-active neuron described previously. Using this data, computational model neurons have been constructed for these two neurons by using membrane ion channels to produce and match the observed neuronal voltage behavior. The channels were those implicated in the dynamic responses observed in the companion study, and include gNafast, gKdr, gKA, gKCa, gKAHP, gKM, gCaT and gCaL. The description of channel kinetics follows the Hodgkin-Huxley form. Different neuronal sources from the literature of channel kinetics were investigated and assembled into a ‘channel kinetics library’ from which both neuron models were tuned, primarily by adjusting the maximum channel densities, g¯, and time-dependence of kinetics. Methods are described for tuning the channel kinetics library to match various physiological responses. This approach created neuron models that were able to closely replicate the observed complex voltage and spiking responses of the two very different cardiorespiratory NTS neurons. The interaction of voltage- and calcium-dependent conductances were analyzed for their functional contributions by tuning their kinetics. Specific parameters are given that account for the behavior of each model. Sensitivity analyses by perturbing KCa and KA are are shown for both neurons, and I/F curves are presented for the auto-active neuron's simulated and recorded responses. The potential systems-level functional implications resulting from the different kinetics is demonstrated by driving the S3 model neuron in simulation with the pattern of input produced by model primary baroreceptor afferents. The limitations and significance of this approach are discussed. The present study of model neurons are being extended to the larger family of neurons found in the cardiorespiratory NTS (e.g. S1, S2 and S4), are being related to the baroreceptor vagal reflex by in vivo studies, and are being used to explore systems level computation, for example by creating networks reflecting baroreceptor reflex organization. The present kinetics library in principle could be used in this way for other neuronal systems.}
}
@article{DARICI2024123327,
title = {How will I break AI? Post-Luddism in the AI age: Fuzzy MCDM synergy},
journal = {Technological Forecasting and Social Change},
volume = {202},
pages = {123327},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123327},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524001239},
author = {Sefer Darıcı and Muhammad Riaz and Gülay Demir and Zekiye Tamer Gencer and Dragan Pamucar},
keywords = {AI, Communication, Post-Luddism, Fuzzy set, DEMATEL, LMAW},
abstract = {This study proposes a fuzzy multi-criteria model to assess the risk of unemployment among professionals in the communication sector in Turkey, prompted by the rapid development and evolution of artificial intelligence (AI) technologies. The method integrates Fuzzy The Decision Making Trial and Evaluation Laboratory (F-DEMATEL) and Fuzzy Logarithm Methodology of Additive Weights (F-LMAW) procedures. Data were collected from 20 experts representing professions such as public relations, advertising, journalism, and design through a 12-question survey. In the analysis, the F-DEMATEL procedure was initially employed to determine attitudes towards AI technologies, followed by the application of the F-LMAW procedure to assess the magnitude of AI's impact on occupational groups. Findings reveal a nuanced stance: while professionals acknowledge the necessity of AI for their work, they are unwilling to accept unemployment due to more advanced AI. This newly identified structure, termed Post-Luddism, highlights concerns over technological unemployment, particularly pronounced in professions like journalism where job prospects are limited and creative thinking is paramount. In other communication fields, the intensive use of technology mitigates fears of AI harm. However, even in journalism, there exists a propensity to perceive AI as detrimental. These insights shed light on communication professionals' apprehensions and attitudes towards AI's effects. Policymakers and stakeholders can leverage this understanding to formulate strategic measures, considering the divergent perspectives among professional groups regarding AI, towards mitigating potential unemployment risks and fostering AI-adaptive strategies.}
}
@article{CHEN2024132899,
title = {A novel offshore wind power prediction model based on TCN-DANet-sparse transformer and considering spatio-temporal coupling in multiple wind farms},
journal = {Energy},
volume = {308},
pages = {132899},
year = {2024},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2024.132899},
url = {https://www.sciencedirect.com/science/article/pii/S0360544224026732},
author = {Juntao Chen and Xueying Fu and Lingli Zhang and Haoye Shen and Jibo Wu},
keywords = {Dual attention network, Temporal convolutional network, Offshore wind power prediction, Sparse transformer, Spatio-temporal coupling},
abstract = {Offshore wind power capacity is growing, leading to larger clustered farms. Accurately predicting offshore wind power capacity is crucial for power system stability; however, current studies often overlook neighbouring installations. To address this, this study presents the Temporal Convolutional Network-Dual Attention Network-Sparse Transformer (TCN-DANet-Sparse Transformer) model, which considers the spatiotemporal coupling of multiple wind farms. Before detailing our model, we review the existing prediction methods, noting their limitations in capturing interconnected adjacent wind farms. Our model integrates spatial information from nearby farms to enhance prediction reliability. Through Pearson Correlation Coefficient analysis, we explore the temporal and spatial coupling features. Using overlapping sliding windows, we partition farms into subsequences, processed with TCN-DANet for efficient spatio-temporal feature extraction. These features are then input into the Sparse Transformer to improve the computational efficiency. Validated using a dataset from Kächele et al., our model outperforms the baseline on the London Wind Farm. In spring, for Case 1, the mean square error (MSE) of the main model decreased by 43.19 % compared to that of the TCN-DANet-transformer model. Similarly, for Case 2, the MSE of the main model is reduced by 41.69 %.}
}
@incollection{DAS2025193,
title = {Chapter 15 - Systems pharmacology – principles, methods and applications},
editor = {Babak Sokouti},
booktitle = {Systems Biology and In-Depth Applications for Unlocking Diseases},
publisher = {Academic Press},
pages = {193-206},
year = {2025},
isbn = {978-0-443-22326-6},
doi = {https://doi.org/10.1016/B978-0-443-22326-6.00015-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443223266000158},
author = {Arpan Jyoti Das and Habeeb {Shaik Mohideen}},
keywords = {CADD, Computational biology, Molecular network, Omics networking, Systems biology, Systems pharmacology},
abstract = {Socializing has become much easier with the advent of scintillating discoveries and technological advancements in computer science, information technology applications, and of course, the indispensable Internet. Historical and unimaginable success has been achieved by breaking horizons in almost all the fields, but biology. Biological phenomena are so difficult to understand because of the complex cross-talks between different entities such as DNA, RNA, proteins, lipids, carbohydrates, and their relevant downstream postprocessing modifications. The dance and interplay involving these moieties as a function of a drug is called as Systems Pharmacology. The multiscale modeling and simulation approach of systems pharmacology employ computational models to simulate drug effects at various levels, from molecular interactions to organ-level responses, allowing for a more comprehensive understanding of drug action. In this chapter, we will delve into the historical landscapes, methods and principles, tools, applications, frameworks, and benefits of systems pharmacology that will give a beginner a comprehensive understanding of the field.}
}
@article{LAO2022,
title = {Analyzing Suicide Risk From Linguistic Features in Social Media: Evaluation Study},
journal = {JMIR Formative Research},
volume = {6},
number = {8},
year = {2022},
issn = {2561-326X},
doi = {https://doi.org/10.2196/35563},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X22007910},
author = {Cecilia Lao and Jo Lane and Hanna Suominen},
keywords = {evaluation study, interdisciplinary research, linguistics, machine learning, mental health, natural language processing, social media, suicide risk},
abstract = {Background
Effective suicide risk assessments and interventions are vital for suicide prevention. Although assessing such risks is best done by health care professionals, people experiencing suicidal ideation may not seek help. Hence, machine learning (ML) and computational linguistics can provide analytical tools for understanding and analyzing risks. This, therefore, facilitates suicide intervention and prevention.
Objective
This study aims to explore, using statistical analyses and ML, whether computerized language analysis could be applied to assess and better understand a person’s suicide risk on social media.
Methods
We used the University of Maryland Suicidality Dataset comprising text posts written by users (N=866) of mental health–related forums on Reddit. Each user was classified with a suicide risk rating (no, low, moderate, or severe) by either medical experts or crowdsourced annotators, denoting their estimated likelihood of dying by suicide. In language analysis, the Linguistic Inquiry and Word Count lexicon assessed sentiment, thinking styles, and part of speech, whereas readability was explored using the TextStat library. The Mann-Whitney U test identified differences between at-risk (low, moderate, and severe risk) and no-risk users. Meanwhile, the Kruskal-Wallis test and Spearman correlation coefficient were used for granular analysis between risk levels and to identify redundancy, respectively. In the ML experiments, gradient boost, random forest, and support vector machine models were trained using 10-fold cross validation. The area under the receiver operator curve and F1-score were the primary measures. Finally, permutation importance uncovered the features that contributed the most to each model’s decision-making.
Results
Statistically significant differences (P<.05) were identified between the at-risk (671/866, 77.5%) and no-risk groups (195/866, 22.5%). This was true for both the crowd- and expert-annotated samples. Overall, at-risk users had higher median values for most variables (authenticity, first-person pronouns, and negation), with a notable exception of clout, which indicated that at-risk users were less likely to engage in social posturing. A high positive correlation (ρ>0.84) was present between the part of speech variables, which implied redundancy and demonstrated the utility of aggregate features. All ML models performed similarly in their area under the curve (0.66-0.68); however, the random forest and gradient boost models were noticeably better in their F1-score (0.65 and 0.62) than the support vector machine (0.52). The features that contributed the most to the ML models were authenticity, clout, and negative emotions.
Conclusions
In summary, our statistical analyses found linguistic features associated with suicide risk, such as social posturing (eg, authenticity and clout), first-person singular pronouns, and negation. This increased our understanding of the behavioral and thought patterns of social media users and provided insights into the mechanisms behind ML models. We also demonstrated the applicative potential of ML in assisting health care professionals to assess and manage individuals experiencing suicide risk.}
}
@article{MUTHUSAMY2025112916,
title = {High-precision malware detection in android apps using quantum explainable hierarchical interaction network},
journal = {Knowledge-Based Systems},
volume = {310},
pages = {112916},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112916},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124015508},
author = {Ramnath Muthusamy and Yesubai Rubavathi Charles},
keywords = {Recommender system, Android applications, Real or fake app detection, Privacy, Feature interaction, Quantum superposition and entanglement},
abstract = {The exponential growth of Android applications has increased the prevalence of fraudulent and malicious apps, posing significant risks to user security and privacy. Existing detection methodologies often struggle with poor interpretability, scalability, and computational complexity, limiting their effectiveness. To address these challenges, this study introduces the Quantum Explainable Hierarchical Interaction Network (QEHIN), a novel framework designed to detect real and fake Android applications with superior accuracy and interpretability. QEHIN incorporates quantum computing principles such as superposition and entanglement to model high-order feature interactions effectively. Its innovative architecture includes a Quantum Embedding Layer for transforming input features into quantum states, a Quantum Hierarchical Interaction Network (QHIN) for capturing complex dependencies, a Quantum Deep Neural Network (QDNN) for enhanced feature processing, and a Quantum Cross-Hierarchical Unit (QCHU) to ensure seamless integration across hierarchical levels. This design achieves precise, transparent, and scalable detection of malicious applications, addressing the shortcomings of traditional methods. Evaluation on the Google Play Store Reviews, MobileRec, and Android-App-Recommendation datasets demonstrates the novelty and effectiveness of QEHIN. It achieves an accuracy of 98.86 %, precision of 98.78 %, recall of 98.82 %, and a kappa score of 98.54 %, significantly outperforming existing approaches.}
}
@article{DELI2021784,
title = {The thermodynamics of cognition: A mathematical treatment},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {784-793},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S200103702100012X},
author = {Eva Deli and James Peters and Zoltán Kisvárday},
keywords = {Consciousness, Free will, Mental energy, Intellect, Emotional regulation, Fermionic mind hypothesis, Carnot cycle, Landauer's principle},
abstract = {There is a general expectation that the laws of classical physics must apply to biology, particularly the neural system. The evoked cycle represents the brain's energy/information exchange with the physical environment through stimulus. Therefore, the thermodynamics of emotions might elucidate the neurological origin of intellectual evolution, and explain the psychological and health consequences of positive and negative emotional states based on their energy profiles. We utilized the Carnot cycle and Landauer's principle to analyze the energetic consequences of the brain's resting and evoked states during and after various cognitive states. Namely, positive emotional states can be represented by the reversed Carnot cycle, whereas negative emotional reactions trigger the Carnot cycle. The two conditions have contrasting energetic and entropic aftereffects with consequences for mental energy. The mathematics of the Carnot and reversed Carnot cycles, which can explain recent findings in human psychology, might be constructive in the scientific endeavor in turning psychology into hard science.}
}
@article{PANULAONTTO2019292,
title = {The AXIOM approach for probabilistic and causal modeling with expert elicited inputs},
journal = {Technological Forecasting and Social Change},
volume = {138},
pages = {292-308},
year = {2019},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0040162518305870},
author = {Juha Panula-Ontto},
keywords = {Systems modeling, Modeling techniques, Decision support, Cross-impact analysis, Belief networks, Expert elicitation},
abstract = {Expert informants can be used as the principal information source in the modeling of socio-techno-economic systems or problems to support planning, foresight and decision-making. Such modeling is theory-driven, grounded in expert judgment and understanding, and can be contrasted with data-driven modeling approaches. Several families of approaches exist to enable expert elicited systems modeling with varying input information requirements and analytical ambitions. This paper proposes a novel modeling language and computational process, which combines aspects from various other approaches in an attempt to create a flexible and practical systems modeling approach based on expert elicitation. It is intended to have high fitness in modeling of systems that lack statistical data and exhibit low quantifiability of important system characteristics. AXIOM is positioned against Bayesian networks, cross-impact analysis, structural analysis, and morphological analysis. The modeling language and computational process are illustrated with a small example model. A software implementation is also presented.}
}
@article{HERNANDEZRAMIREZ2024414,
title = {The Future End of Design Work: A Critical Overview of Managerialism, Generative AI, and the Nature of Knowledge Work, and Why Craft Remains Relevant},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {414-440},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000960},
author = {Rodrigo Hernández-Ramírez and João Batalheiro Ferreira},
keywords = {creativity, design work, generative artificial intelligence (GenAI), knowledge work, managerialism},
abstract = {This article examines the transformation of design work under the influence of managerialism and the rise of Generative Artificial Intelligence (GenAI). Drawing on John Maynard Keynes’s projections of technological unemployment and the evolving nature of work, it argues that despite advancements in automation, work has not diminished but rather devalued. Design, understood as a type of knowledge work, faces an apparent existential crisis. GenAI grows adept at mimicking the output of creative processes. The article explores how the fear of the end of design work fueled by the rise of GenAI is rooted in a misunderstanding of design work. This misunderstanding is driven by managerialism—an ideology that prioritizes efficiency and quantifiable outcomes over the intrinsic value of work. Managerialism seeks to instrumentalize and automate design, turning it into a controllable procedure to generate quantifiable creative outputs. The article argues why design work cannot be turned into a procedure and automated using GenAI. Advocates of these systems claim they enhance productivity and open new opportunities. However, evidence so far shows that flawed GenAI models produce disappointing outcomes while operating at a significant environmental cost. The article concludes by arguing for a robust theory of design—one that acknowledges the unique ontological and epistemic boundaries of design work and underscores why design cannot be reduced to a procedural output.}
}
@incollection{VALLERO2014953,
title = {Chapter 33 - Grand Challenges},
editor = {Daniel Vallero},
booktitle = {Fundamentals of Air Pollution (Fifth Edition)},
publisher = {Academic Press},
edition = {Fifth Edition},
address = {Boston},
pages = {953-961},
year = {2014},
isbn = {978-0-12-401733-7},
doi = {https://doi.org/10.1016/B978-0-12-401733-7.00033-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780124017337000335},
author = {Daniel Vallero},
keywords = {Bayesian, Biogeochemical cycles, Categorical imperative, Circle of poisons, CO, Command and control, Computational tools, Fossil fuels, Fundamentals of air pollution, Geographic information system (GIS), Geostatistics, Global greenhouse gas emissions (GHG), Grand Challenges, Immanuel Kant, Indoor air pollution, Informatics, Kriging, National Academy of Engineering, Precautionary principle, Pre-Kindergarten, Real-world exposures, Reductionist, Risk, Sustainability, Systems thinking, Transdisciplinary, Translational science},
abstract = {This chapter looks to the future of air quality and how the lessons learned in recent decades can be applied to new problems. The challenges include finding ways to prevent emerging economies from repeating the air pollution mistakes and harm that developed nations have experienced in arriving at solutions to air pollution problems. Other challenges include: global problems, such as long-range transport of pollutants, climate change; real-world-exposures (including indoor air pollution); improvements in technologies to remove difficult-to-treat pollutants; and addressing the growing number of mobile sources. This will require more systems thinking and sustainable, transdisciplinary solutions. The legacy of the current cadre of air pollution experts must be one of translational science and the enhancement of early air pollution education for the next generation.}
}
@article{TAMILVENDAN2024469,
title = {Parametric optimization in drilling of sisal–glass reinforced epoxy composites using Taguchi grey relational analysis method},
journal = {Transactions of the Canadian Society for Mechanical Engineering},
volume = {48},
number = {3},
pages = {469-476},
year = {2024},
issn = {0315-8977},
doi = {https://doi.org/10.1139/tcsme-2024-0018},
url = {https://www.sciencedirect.com/science/article/pii/S0315897724000570},
author = {D. Tamilvendan and A.R. Ravikumar and R. Thirumalai},
keywords = {Taguchi grey relational analysis, drlling, glass fiber, sisal fiber, composite},
abstract = {This research work intends to study the effect of hybridization of glass and sisal fiber, stacking sequence and tensile properties of the composite. The sisal-glass fiber hybrid composites laminates are prepared using reinforced plain woven sisal fabric (unidirectional) and plainwoven glass fabric. In this research study, 27 experiments are conducted as per L27 orthogonal array. Five process parameters are selected and three responses are considered in this work. The drilling of the composite specimen is considered and the drilling process parameters such as speed, feed rate, drill diameter, material thickness, and drill point angle are selected. The responses considered in this work are delamination factor, thrust force, and torque. Taguchi analysis is performed and the response table for means for the responses is determined, and the most influencing parameter in the drilling of the composite specimen is analyzed. The grey relational coefficients are computed and followed with the computation of the grey relational grade. The grey relational grades are calculated for determining the highest contributing parameter in the drilling of the sisal fiber and glass fiber reinforced hybrid composite specimen. The optimum drilling process parameters are ranked and the ranks presented represent the sequence of run resulting in optimum solutions.}
}
@incollection{HARNAD2005817,
title = {Chapter 36 - A GROUNDED MIND IN A ROBOTIC BODY},
editor = {Henri Cohen and Claire Lefebvre},
booktitle = {Handbook of Categorization in Cognitive Science},
publisher = {Elsevier Science Ltd},
address = {Oxford},
pages = {817-820},
year = {2005},
isbn = {978-0-08-044612-7},
doi = {https://doi.org/10.1016/B978-008044612-7/50091-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780080446127500913},
author = {STEVAN HARNAD},
abstract = {Publisher Summary
This chapter presents the important themes of embodied cognition. In the chapter, Poirier and others first point out that minds (and brains) have bodies, and that this is not only unlikely to be incidental, but also most of the things that minds can do, they do with their bodies. Pure thinking, that is cognition, seems in and of itself to be a disembodied mental activity, conducted autonomously inside our heads without any signs of sensorimotor interaction with the world of objects, organisms, states, events, and properties that most of our thoughts are about. But surely whatever pure thinking does go on in our heads occurs in the service of our present and future doings in the world, and is grounded in our past doings. Both Proulx and Hélie, and Cangelosi are concerned with how to give a cognitive system the sensorimotor capacity, which is the capacity to detect, recognize and do the kinds of things that one is able to do with the kinds of things there are in the world. In other words, it is the capacity to categorize. The shapes that objects project on one's sensory surfaces can be processed by neural networks that do what is called unsupervised learning.}
}
@article{DAI2024108354,
title = {Leveraging artificial intelligence (AI) in English as a foreign language (EFL) classes: Challenges and opportunities in the spotlight},
journal = {Computers in Human Behavior},
volume = {159},
pages = {108354},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108354},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400222X},
author = {Kun Dai and Quanguo Liu},
keywords = {Artificial intelligence (AI), AI-Powered instruments, Challenges and opportunities, English as a foreign language (EFL) classes, EFL students},
abstract = {The widespread use of Artificial Intelligence (AI) in language education contexts has motivated several scholars around the world to uncover the advantages and disadvantages of AI and AI-powered instruments in different language classrooms. Yet, as the review of earlier investigations revealed, few inquiries have been carried out to divulge the pros and cons of leveraging AI in EFL classes. To narrow this gap, using the phenomenological approach, this inquiry investigated the opportunities and challenges of implementing AI in EFL classes from the perspective of Chinese EFL students. To do so, through the criterion sampling technique, a total of 45 EFL students was recruited from different educational institutions in China. To collect the dataset, participants were asked to complete an open-ended questionnaire. For the sake of triangulation, among the 45 participants, 15 were randomly selected to engage in a follow-up interview session. With the aid of MAXQDA software (version 2023), participants’ perceptions of AI opportunities and challenges were carefully analyzed. Overall, the analysis findings uncovered that leveraging AI in EFL classes can bring numerous opportunities for EFL students, including individualized learning, timely and immediate feedback, rich educational resources, and an interactive learning atmosphere. However, as demonstrated by the analysis outcomes, implementing AI in EFL courses may also face students with a range of challenges and problems. The research outcomes would be of great help to teachers and educational leaders in mitigating the challenges of leveraging AI in language classrooms.}
}
@article{CAGNAC2023,
title = {Codes and methods improvements for safety assessment and LTO: varied approaches},
journal = {EPJ - Nuclear Sciences & Technologies},
volume = {9},
year = {2023},
issn = {2491-9292},
doi = {https://doi.org/10.1051/epjn/2023001},
url = {https://www.sciencedirect.com/science/article/pii/S2491929223000109},
author = {Albannie Cagnac and Denis Verrier and Vladislav Pištora},
abstract = {Nuclear safety has always been at the heart of the concerns of nuclear power plant operators and developers, as well as of various nuclear research organizations and regulatory authorities. Over the last decades, all these nuclear actors have developed and integrated a large number of calculation codes and other tools into their safety work. From the system approach to the local understanding of a phenomenon on a given component, from neutronics to operation optimization for long-term operation, these methods and codes have been constantly evolving since their appearance, in order to be able to integrate new plant designs and components, to improve the results of modeling physical phenomena or quantify and thus reduce the uncertainties on these results. Currently, several H2020 Euratom projects are working on the improvement of these codes and methods. This article will focus on three of these projects: CAMIVVER (Codes And Methods Improvements for VVER comprehensive safety assessment), APAL (Advanced PTS Analysis for LTO), and sCO2-4-NPP (innovative SCO2-based heat removal technology for an increased level of safety of Nuclear Power Plants) in order to illustrate our thinking on the improvement of calculation frameworks. First, we will present the work and the approach adopted with regard to the different calculation codes and methods used in each of these three projects. We will then conclude with an overall analysis of these three approaches, highlighting the difficulties and successes of these three projects, and identifying areas of work for the general improvement of the calculation codes.}
}
@article{PERIGNAT201931,
title = {STEAM in practice and research: An integrative literature review},
journal = {Thinking Skills and Creativity},
volume = {31},
pages = {31-43},
year = {2019},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1871187118302190},
author = {Elaine Perignat and Jen Katz-Buonincontro},
keywords = {STEAM education, Creativity, Arts-integration, Transdisciplinary, Interdisciplinary},
abstract = {This integrative review examines 44 published articles (empirical, descriptive, and pedagogical frameworks) on the topic of STEAM (Science, Technology, Engineering, Arts, Mathematics) education from 2007 to 2018. Despite the emergence of STEAM as a popular pedagogical approach for enhancing students’ creativity, problem-solving skills, and interest in STEM fields, the definitions and purposes of STEAM education remain ubiquitous. Therefore, the review examined descriptions of the overall purpose of STEAM education, definitions of the STEAM acronym and the ‘A’ in STEAM, creativity as a learning outcome, elements of arts education, and arts education learning outcomes. The review found a myriad of definitions of the STEAM concept in general, a variety of interpretations for the “A” in STEAM, and an overall lack of reported learning outcomes in the areas of creativity, problem-solving, and arts education. The articles also differentiate in methods for merging STEAM disciplines, described in one of five ways: transdisciplinary, interdisciplinary, multi-disciplinary, cross-disciplinary, and arts-integration. Recommendations are provided to advance both research and practice in STEAM education.}
}
@article{CUSHEN2011458,
title = {Aha! Voila! Eureka! Bilingualism and insightful problem solving},
journal = {Learning and Individual Differences},
volume = {21},
number = {4},
pages = {458-462},
year = {2011},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2011.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1041608011000215},
author = {Patrick J. Cushen and Jennifer Wiley},
keywords = {Bilingualism, Creativity, Insight, Problem solving},
abstract = {What makes a person able to solve problems creatively? One interesting factor that may contribute is experience with multiple languages from an early age. Bilingual individuals who acquire two languages by the age of 6 have been shown to demonstrate superior performance on a number of thinking tasks that require flexibility. However, bilingual advantages have yet to be identified particularly on insight problems that are used as a model of creative problem solving following initial impasse. As such, the goal of the present study was to investigate the influence of language experience on problem solving performance on a matched set of insight and non-insight problems. Results demonstrate an interaction between type of problem (insight versus non-insight) and language status.}
}
@article{BUCKNER200749,
title = {Self-projection and the brain},
journal = {Trends in Cognitive Sciences},
volume = {11},
number = {2},
pages = {49-57},
year = {2007},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2006.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S1364661306003275},
author = {Randy L. Buckner and Daniel C. Carroll},
abstract = {When thinking about the future or the upcoming actions of another person, we mentally project ourselves into that alternative situation. Accumulating data suggest that envisioning the future (prospection), remembering the past, conceiving the viewpoint of others (theory of mind) and possibly some forms of navigation reflect the workings of the same core brain network. These abilities emerge at a similar age and share a common functional anatomy that includes frontal and medial temporal systems that are traditionally associated with planning, episodic memory and default (passive) cognitive states. We speculate that these abilities, most often studied as distinct, rely on a common set of processes by which past experiences are used adaptively to imagine perspectives and events beyond those that emerge from the immediate environment.}
}
@article{AUGIER2001307,
title = {Sublime Simon: The consistent vision of economic psychology's Nobel laureate},
journal = {Journal of Economic Psychology},
volume = {22},
number = {3},
pages = {307-334},
year = {2001},
issn = {0167-4870},
doi = {https://doi.org/10.1016/S0167-4870(01)00036-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167487001000368},
author = {Mie Augier},
keywords = {Herbert Simon, Bounded rationality, Carnegie Mellon University, Economics and psychology},
abstract = {This essay contains a study of some of Herbert Simon's ideas, with particular emphasis on the role of bounded rationality in Simon's thinking and his contributions to economics and psychology. I describe Simon's visions for challenging rational choice theory, through limited rationality, and for bringing psychology into economics, putting this in perspective by describing the evolution of some of this thoughts, focusing on the continuity in his work.}
}
@article{LUCKEN202555,
title = {Leveraging participatory sense-making and public engagement with science for AI democratization},
journal = {Studies in History and Philosophy of Science},
volume = {110},
pages = {55-64},
year = {2025},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2025.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0039368125000135},
author = {Collin Lucken and Tim Elmo Feiten},
keywords = {Public engagement with science, Embodied cognition, Participatory sense-making, Artificial intelligence, Democratizing AI},
abstract = {Our paper explores new potentials for productive dialogue between public engagement with science (PEWS) and radical embodied cognitive science (RECS). We establish a strong connection between the two fields by highlighting parallels between the views they reject: the ‘deficit model’ in science communication and the ‘information processing paradigm’ in cognitive science. Furthermore, we show that the positive visions of PEWS and RECS are similarly aligned: The concept of participatory sense-making from enactive cognitive science provides an account of why active, dialogical engagement in science communication is so effective. Conversely, processes in which affected communities actively engage developments in science and technology through contribution and contestation provide an invaluable case study for RECS accounts of emergent dynamics in techno-cultural systems. After establishing the connection between PEWS and RECS, we motivate the need for what we call ‘participatory cognitive strategies’. Finally, a brief case study shows the potential for these strategies in actively involving different groups of stakeholders throughout the development of large-scale AI systems, allowing us to make a conceptual contribution to ongoing debates about the meaning of ‘democratizing AI’ in this project and in the larger AI initiative of which it is a part.}
}
@article{XIAO1995169,
title = {Three-dimensional melt flows in Czochralski oxide growth: high-resolution, massively parallel, finite element computations},
journal = {Journal of Crystal Growth},
volume = {152},
number = {3},
pages = {169-181},
year = {1995},
issn = {0022-0248},
doi = {https://doi.org/10.1016/0022-0248(95)00090-9},
url = {https://www.sciencedirect.com/science/article/pii/0022024895000909},
author = {Qiang Xiao and Jeffrey J. Derby},
abstract = {Three-dimensional, time-dependent features of melt flows which occur during the Czochralski growth of oxide crystals are analyzed using a theoretical bulk-flow model. The transition from a steady, axisymmetric flow to a time-dependent, three-dimensional state characterized by an annular wave structure is found to strongly affect the temperature distribution and heat transfer through the melt. The results are obtained using a novel, massively parallel implementation of the Galerkin finite element method which affords high spatial resolution of the computed flows.}
}
@article{SHOTTER201734,
title = {Persons as dialogical-hermeneutical-relational beings – New circumstances ‘call out’ new responses from us},
journal = {New Ideas in Psychology},
volume = {44},
pages = {34-40},
year = {2017},
note = {SI: The Person},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2016.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X1630157X},
author = {John Shotter},
keywords = {Persons, Ideals, Generalities, Particularities, Hermeneutics, Indeterminacy, Dialogicality},
abstract = {Shifting from a world of already-made-things to a world of things-continually-in-the-making changes everything. Psychology, like all other sciences, tries to proceed by analysis, by breaking down a living, unique, always developing organic whole into a set of general, already-existing, nameable elements. But as Bakhtin makes clear, in discussing how Dostoevsky portrays the inner dynamics of people worrying over how to act for the best in living their lives, such an itemization of merely observed behavioural characteristics leads to a degrading reification of a person's unfinalizability, of their still-developing nature. Below, I first examine the Cartesianism that still seems present in much of our thinking in social inquiry today. I then turn attention to the primacy of our living movements out in the world and their responsiveness to events occurring around us. While finally turning to the fact that, as living beings, what ‘goes on inside us’, is not so important as ‘what we go on inside of’. Although Dostoevsky portrays this indivisible, flowing reality, in terms of a set of discontinuous fragments —because that is the nature of our experience in everyday life — as hermeneutical-dialogical-relational beings, we have a basic capability of organizing them into unitary wholes which sit in the background to everything we think and do.}
}
@article{YIN2022109800,
title = {Deep learning-accelerated optimization algorithm for controller parameters optimization of doubly-fed induction generators},
journal = {Applied Soft Computing},
volume = {131},
pages = {109800},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109800},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622008493},
author = {Linfei Yin and Xinghui Cao and Senlin Wang},
keywords = {Deep fully connected models, Gray wolf optimizer, Adaptive differential evolution, Global search, Parameter optimization},
abstract = {In this work, a cooperative Gray wolf Optimizer with adaptive differential Evolution (GOE) is proposed for the multimodal controller parameters optimization of doubly-fed induction generators (DFIGs) based on maximum power point tracking (MPPT) strategies. Moreover, the optimization process of the GOE is accelerated by a deep fully connected model (DFCM). The GOE contains a cooperative gray wolf optimizer (GWO) and adaptive differential evolution (ADE). The cooperative GWO contains alpha, beta, delta, and omega wolves to explore and exploit optimization problems and achieves optimization tasks wider and deeper than GWO. The ADE cooperates with the cooperative GWO to solve global optimization over continuous spaces. The simulation results on seven uni-model benchmark functions show that the GOE accelerated by DFCM obtains acceptable fitness values with 39.99% lesser computation time than the symmetry adapted stochastic search (SASS) algorithm and 80.72% lesser computation time than the Lévy flights-success-history based adaptive differential evolution with constraint handling technique (COLSHADE) algorithm, which are the winners of the CEC2020 Competition on Real-World Single Objective Constrained Optimization. Furthermore, the simulation results on DFIG with MPPT strategies in three real-world cases verify that the GOE accelerated by DFCM can effectively obtain global optimization solutions for non-smooth problems with 99.51% lesser average computation time than the SASS algorithm, 99.63% less than the COLSHADE algorithm, and 89.52% less than other methods. In addition, the accelerated GOE algorithm by DFCM has the feature of faster convergence.}
}
@article{BERNABEI2023100172,
title = {Students’ use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100172},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100172},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000516},
author = {Margherita Bernabei and Silvia Colabianchi and Andrea Falegnami and Francesco Costantino},
keywords = {LLM, ChatGPT, Higher education, Essay generation},
abstract = {The accessibility of advanced Artificial Intelligence-based tools, like ChatGPT, has made Large Language Models (LLMs) readily available to students. These LLMs can generate original written content to assist students in their academic assessments. With the rapid adoption of LLMs, exemplified by the popularity of OpenAI's ChatGPT, there is a growing need to explore their application in education. Few studies examine students' use of LLMs as learning tools. This paper focuses on the application of ChatGPT in engineering higher education through an in-depth case study. It investigates whether engineering students can generate high-quality university essays with LLMs assistance, whether existing LLMs identification systems can detect essays produced with LLMs, and how students perceive the usefulness and acceptance of LLMs in learning. The research adopts a deductive/inductive approach, combining conceptualization and empirical evidence analysis. The study involves mechanical and management engineering students, who compose essays using LLMs. The essay assessment showed good results, but some recommendations emerged for teachers and students. Thirteen LLMs detectors were tested without achieving satisfactory results, suggesting to avoid LLMs ban. In addition, students were administered a questionnaire based on constructs and items that follow the technology acceptance models available in the literature. The results contribute to qualitative evidence by highlighting possible future research and educational practices.}
}
@incollection{HE2013241,
title = {5.16 - Flood Inundation Dynamics and Socioeconomic Vulnerability under Environmental Change},
editor = {Roger A. Pielke},
booktitle = {Climate Vulnerability},
publisher = {Academic Press},
address = {Oxford},
pages = {241-255},
year = {2013},
isbn = {978-0-12-384704-1},
doi = {https://doi.org/10.1016/B978-0-12-384703-4.00508-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780123847034005086},
author = {Y. He and F. Pappenberger and D. Manful and H. Cloke and P. Bates and F. Wetterhall and B. Parkes},
keywords = {Flood inundation dynamics, Two-faced flood, Model cascade, Uncertainties, Flood vulnerability, Impact studies, Flood risk, Living with floods, Harnessing floods},
abstract = {Floods are a major threat to human existence and historically have both caused the collapse of civilizations and forced the emergence of new cultures. The physical processes of flooding are complex. Increased population, climate variability, change in catchment and channel management, modified landuse and land cover, and natural change of floodplains and river channels all lead to changes in flood dynamics, and as a direct or indirect consequence, social welfare of humans. Section 5.16.1 explores the risks and benefits brought about by floods and reviews the responses of floods and floodplains to climate and landuse change. Section 5.08.2 reviews the existing modeling tools, and the top–down and bottom–up modeling frameworks that are used to assess impacts on future floods. Section 5.08.3 discusses changing flood risk and socioeconomic vulnerability based on current trends in emerging or developing countries and presents an alternative paradigm as a pathway to resilience. Section 5.08.4 concludes the chapter by stating a portfolio of integrated concepts, measures, and avant-garde thinking that would be required to sustainably manage future flood risk.}
}
@article{BERX2022107827,
title = {Identification and classification of risk factors for human-robot collaboration from a system-wide perspective},
journal = {Computers & Industrial Engineering},
volume = {163},
pages = {107827},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107827},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221007312},
author = {Nicole Berx and Wilm Decré and Ido Morag and Peter Chemweno and Liliane Pintelon},
keywords = {Human-robot collaboration, Human factors, Industry 4.0, Safety, Risk factors, Socio-technical},
abstract = {Industry 4.0 systems in general and advanced manufacturing systems such as collaborative robots, in particular, are characterized by a high level of complexity leading to new safety concerns. Safety, specifically for collaborative robots, has been mainly addressed from a technical perspective, to safeguard the physical safety of the operator. Concerns have been raised regarding less focus in Industry 4.0 literature on how other factors, such as psychosocial can produce safety-related risks for the operator in human-robot collaboration. This paper identifies and classifies the risk factors in a human-robot collaboration that have been described in research papers in the last decade. The resulting five classes constitute dimensions that will be used as preliminary building blocks for a safety evaluation framework to be developed in the next step. By evaluating the resulting classes with the underlying dimensions of contemporary socio-technical thinking, this paper demonstrates that these five classes offer a comprehensive, system-wide perspective including risk factors beyond technological considerations. Topics emerging from new risks related to the impact of working with collaborative robots, such as psychosocial, ethical, and cyber risk factors will need to be taken into account in the risk factors that are important to identify, assess and mitigate before working with collaborative robots. Operator involvement and participation, especially throughout the risk assessment and mitigation cycle are recommended as new areas of attention in human-robot collaboration. Going forward, one challenge will be the agility and adaptability of legislation to at least keep track of risk factors emerging from continuously changing technologies and to translate them into practically applicable tools for enterprises and design engineers implementing collaborative applications. Another key challenge will be the measurement of the new emerging and sometimes less technological risks.}
}
@article{SIEGELMANN2013117,
title = {Turing on Super-Turing and adaptivity},
journal = {Progress in Biophysics and Molecular Biology},
volume = {113},
number = {1},
pages = {117-126},
year = {2013},
note = {Can Biology Create a Profoundly New Mathematics and Computation?},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2013.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0079610713000278},
author = {Hava T. Siegelmann},
keywords = {Adaptive computation, Biological computation, Super-Turing computation},
abstract = {Biological processes are often compared to computation and modeled on the Universal Turing Machine. While many systems or aspects of systems can be well described in this manner, Turing computation can only compute what it has been programmed for. It has no ability to learn or adapt to new situations. Yet, adaptation, choice and learning are all hallmarks of living organisms. This suggests that there must be a different form of computation capable of this sort of calculation. It also suggests that there are current computational models of biological systems that may be fundamentally incorrect. We argue that the Super-Turing model is both capable of modeling adaptive computation, and furthermore, a possible answer to the computational model searched for by Turing himself.}
}
@article{LI2024124918,
title = {A method of dense point cloud SLAM based on improved YOLOV8 and fused with ORB-SLAM3 to cope with dynamic environments},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124918},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124918},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424017858},
author = {Yanke Li and Huabo Shen and Yaping Fu and Kai Wang},
keywords = {SLAM, VSLAM, Neural Network, Deep learning},
abstract = {With the development of society and the advancement of technology, intelligent robots have been widely used in various fields. At the same time, Simultaneous Localization and Mapping (SLAM) technology is a key technology in the research field of intelligent robots. However, in dynamic environments, achieving accurate and robust visual SLAM remains a major challenge. In this paper, we propose a method based on improved YOLOv8 fused with ORB-SLAM3 to address dense point cloud SLAM in dynamic environments. Our proposed method successfully integrates real-time object detection and image segmentation technologies of YOLOv8 into the ORB-SLAM3 framework, achieving high-precision and robust visual SLAM in dynamic environments. In the YOLOv8 framework, we use a balanced convolution method, GSConv, instead of some traditional convolution layers (Conv), which balances accuracy with computational load. Based on the GSConv convolution method, we adopt a new feature fusion module, VoVGSCSP, to replace traditional C2f feature fusion modules, thereby improving the Neck structure of YOLOv8 and achieving a lightweight network model. We compare our proposed method with ORB-SLAM3 and some computer vision algorithms on the TUM dataset. Experimental data confirms that our method outperforms existing visual SLAM algorithms in dynamic environments. In fast-moving dynamic environments, the RMSE of absolute pose estimation of our method is 96.28% lower than that of ORB-SLAM3, and the RMSE of relative pose estimation is 51.57% lower than that of ORB-SLAM3. The experimental results demonstrate that our method significantly improves the accuracy of pose estimation in dynamic environments and greatly enhances the performance compared to ORB-SLAM3.}
}
@article{FUJISHIRO2025103006,
title = {Chromatin domains in the cell: Phase separation and condensation},
journal = {Current Opinion in Structural Biology},
volume = {91},
pages = {103006},
year = {2025},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2025.103006},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X25000247},
author = {Shin Fujishiro and Masaki Sasai and Kazuhiro Maeshima},
abstract = {Negatively charged genomic DNA wraps around positively charged core histone octamers to form nucleosomes, which, along with proteins and RNAs, self-organize into chromatin within the nucleus. In eukaryotic cells, chromatin forms loops that collapse into chromatin domains and serve as functional units of the genome. Chromatin domains vary in physical properties based on gene activity and are assembled into A (euchromatin) and B (heterochromatin) compartments. Since various factors—such as chromatin-binding proteins, histone modifications, transcriptional states, depletion attraction, and cations—can significantly impact chromatin organization, the formation processes of these hierarchical structures remain unclear. No single imaging, genomics, or modeling method can provide a complete picture of the process. Beautiful models can sometimes fool our thinking. In this short review, we critically discuss the formation mechanisms of the chromatin domain in the cell from a physical point of view, including phase separation and condensation.}
}
@article{TANG2014245,
title = {On the causes of early life experience effects: Evaluating the role of mom},
journal = {Frontiers in Neuroendocrinology},
volume = {35},
number = {2},
pages = {245-251},
year = {2014},
note = {CRH/Stress in Honor of Wylie Vale},
issn = {0091-3022},
doi = {https://doi.org/10.1016/j.yfrne.2013.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S009130221300068X},
author = {Akaysha C. Tang and Bethany C. Reeb-Sutherland and Russell D. Romeo and Bruce S. McEwen},
keywords = {Maternal care, Stress, CORT, HPA, Self-regulation, Novelty, Maternal mediation, Maternal modulation, Early experience, Cognitive development},
abstract = {Early life experiences are thought to have long-lasting effects on cognitive, emotional, and social function during adulthood. Changes in neuroendocrine function, particularly the hypothalamic–pituitary–adrenal (HPA) axis, contribute to these systems-level behavioral effects. In searching for causal mechanisms underlying these early experience effects, pioneering research has demonstrated an important role for maternal care in offspring development, and this has led to two persistent ideas that permeate current research and thinking: first, environmental impact on the developing infant is mediated through maternal care behavior; second, the more care that a mother provides, the better off her offspring. While a good beginning, the reality is likely more complex. In this review, we critically examine these ideas and propose a computationally-motivated theoretical framework, and within this framework, we consider evidence supporting a hypothesis of maternal modulation. These findings may inform policy decisions in the context of child health and development.}
}
@article{BARTOLOZZI2011163,
title = {eMorph: Towards Neuromorphic Robotic Vision},
journal = {Procedia Computer Science},
volume = {7},
pages = {163-165},
year = {2011},
note = {Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911005874},
author = {Chiara Bartolozzi and Charles Clercq and Neeraj Mandloi and Francesco Rea and Giacomo Indiveri and Daniel Fasnacht and Giorgio Metta and Michael Hofstätter and Ryad Benosman},
keywords = {neuromorphic, humanoid robot, event-driven computation, vision},
abstract = {The eMorph project aims at introducing a new concept for vision in the field of humanoid robotics. The system that is currently being developed is inspired by the biology of mammalian visual systems, introducing concepts such as stimulus-driven signal acquisition and processing, together with space-variant sensor design coupled with active vision. This approach is leading to the realization of a system that goes beyond current thinking in robotic vision.}
}
@article{LIU2025113288,
title = {Knowledge-based natural answer generation via effective graph learning},
journal = {Knowledge-Based Systems},
volume = {316},
pages = {113288},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113288},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125003351},
author = {Zedong Liu and Jianxin Li and Yongle Huang and Ningning Cui and Lili Pei},
keywords = {Natural answer generation, Adaptive multi-hop retrieval, Graph-based Mamba, Prompt optimization},
abstract = {Objectives:
Natural Answer Generation (NAG) aims to generate natural and fluent answers to user questions. Existing NAG methods typically employ fixed-hop retrieval to construct knowledge graphs and utilize attention-based networks for answer generation. However, these approaches lack interpretability, struggle to filter out redundant information in the graph, and are computationally intensive.
Methods:
To address these issues, this paper introduces an innovative approach AdaptQA model. Initially, AdaptQA constructs a knowledge graph from the knowledge base (KB) using an adaptive multi-hop retrieval algorithm. Subsequently, it generates answers through the Graph-based Mamba module (GBM), effectively filtering out redundant information. Finally, the answers are optimized using a pre-trained large language model to enhance their fluency and accuracy.
Novelty:
The proposed AdaptQA model introduces a new approach to NAG by improving the completeness of the knowledge graph and optimizing question answers. This method overcomes the limitations of existing NAG techniques by reducing the complexity of model inference.
Findings:
Through extensive experiments on two benchmark datasets, HotpotQA and WikiHop, AdaptQA demonstrates superior performance, significantly outperforming existing NAG methods. Specifically, AdaptQA achieves an accuracy of 94.47% on the HotpotQA dataset and 91.38% on the WikiHop dataset.}
}
@article{PUZANTIAN2021387,
title = {Redesigning a PhD measurement course for a new era in nursing science},
journal = {Journal of Professional Nursing},
volume = {37},
number = {2},
pages = {387-390},
year = {2021},
issn = {8755-7223},
doi = {https://doi.org/10.1016/j.profnurs.2020.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S8755722320300983},
author = {Houry Puzantian and Hala Darwish},
keywords = {Measurement, Quantitative, Nursing research, PhD},
abstract = {Measurement is at the core of the research process. At the PhD level, students need to develop an in-depth understanding of measures relevant to their area of work and refine their knowledge of measurement issues. Traditionally, measurement coursework in Nursing focused on the psychometric evaluation of instruments measuring cognition and behavior. However, in the age of Big Data, precision medicine, and translational science, PhD students need to develop knowledge and skills relevant to these fields and to collaborate with experts from the different disciplines. Therefore, Nursing faculty need to recognize the state-of-the-science of nursing research and tend to a variety of measurement issues across a spectrum of operationalized concepts. Herein we present an overview of learning outcomes, instructional content and methods of delivery for a contemporary PhD-level course on measurement for Nursing Science. We also present our experience in the design, implementation, and evaluation of a novel PhD measurement course.}
}
@article{KAFUKU2019192,
title = {Application of Fuzzy Logic in Selection of Remanufacturing Technology},
journal = {Procedia Manufacturing},
volume = {33},
pages = {192-199},
year = {2019},
note = {Sustainable Manufacturing for Global Circular Economy: Proceedings of the 16th Global Conference on Sustainable Manufacturing},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2019.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S2351978919305001},
author = {John Mbogo Kafuku and Muhamad Zameri {Mat Saman} and Sha’ri Mohd Yusof},
keywords = {Remanufacturing Operations, Technology Selection, Fuzzy Logic, Technology Selection Criteria, Fuzzy Decision Tool},
abstract = {Fuzzy approach is frequently used for selection of manufacturing technology. However, the application of the fuzzy tool for choosing the appropriate remanufacturing technology is seldom applied. This study applies the fuzzy logic approach for the selection of technology in order to minimize vagueness in decision making, thereby making results more similar to experts’ thinking. Through elicitation of experts’ inputs, six cleaning technologies were evaluated and ranked appropriately, using criteria of technology cost, operating cost, and disposal effect. Moreover, the technology selection was computed through experts’ opinion using the fuzzy logic inference system. The results show that when technical function of the technology is at the low level of 20%, the technology quality is as low as 15%, and the technology flexibility is rated as low at 25%; then the technical adequacy of the assessed technology will be as low as 10%. The fuzzy approach shows that technology performance is largely impacted by criteria far beyond the technology itself, including purchasing cost, disposal cost, operating cost, and other support functions to compliment experience of experts. Despite the fact that decision makers are appropriately selecting technology, the application of the fuzzy logic tool helps to accommodate vagueness, ambiguity, and subjective views of experts. Notwithstanding the robustness of the approach, application of software to help selection of technology is more reliable and accurate, reduce time of decision, and can be accessed worldwide.}
}
@article{CHRISTENSEN2025102467,
title = {perms: Likelihood-free estimation of marginal likelihoods for binary response data in Python and R},
journal = {Journal of Computational Science},
volume = {84},
pages = {102467},
year = {2025},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102467},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324002606},
author = {Dennis Christensen and Per August Jarval Moen},
keywords = {Binary classification, Bioassay, Marginal likelihood estimation, Permutation counting},
abstract = {In Bayesian statistics, the marginal likelihood (ML) is the key ingredient needed for model comparison and model averaging. Unfortunately, estimating MLs accurately is notoriously difficult, especially for models where posterior simulation is not possible. Recently, the idea of permutation counting was introduced, which provides an estimator which can accurately estimate MLs of models for exchangeable binary responses. Such data arise in a multitude of statistical problems, including binary classification, bioassay and sensitivity testing. Permutation counting is entirely likelihood-free and works for any model from which a random sample can be generated, including nonparametric models. Here we present perms, a package implementing permutation counting. Following optimisation efforts, perms is computationally efficient and can handle large data problems. It is available as both an R package and a Python library. A broad gallery of examples illustrating its usage is provided, which includes both standard parametric binary classification and novel applications of nonparametric models, such as changepoint analysis. We also cover the details of the implementation of perms and illustrate its computational speed via a simple simulation study.}
}
@article{KONOVALOV20213323,
title = {Dissecting functional contributions of the social brain to strategic behavior},
journal = {Neuron},
volume = {109},
number = {20},
pages = {3323-3337.e5},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321005699},
author = {Arkady Konovalov and Christopher Hill and Jean Daunizeau and Christian C. Ruff},
keywords = {fMRI, TPJ, dmPFC, social, decision making, strategic},
abstract = {Summary
Social interactions routinely lead to neural activity in a “social brain network” comprising, among other regions, the temporoparietal junction (TPJ) and the dorsomedial prefrontal cortex (dmPFC). But what is the function of these areas? Are they specialized for behavior in social contexts or do they implement computations required for dealing with any reactive process, even non-living entities? Here, we use fMRI and a game paradigm separating the need for these two aspects of cognition. We find that most social-brain areas respond to both social and non-social reactivity rather than just to human opponents. However, the TPJ shows a dissociation from the dmPFC: its activity and connectivity primarily reflect context-dependent outcome processing and reactivity detection, while dmPFC engagement is linked to implementation of a behavioral strategy. Our results characterize an overarching computational property of the social brain but also suggest specialized roles for subregions of this network.}
}
@article{EBEL2024104612,
title = {Cooperative object transportation with differential-drive mobile robots: Control and experimentation},
journal = {Robotics and Autonomous Systems},
volume = {173},
pages = {104612},
year = {2024},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104612},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023002518},
author = {Henrik Ebel and Mario Rosenfelder and Peter Eberhard},
keywords = {Cooperative manipulation, Non-prehensile manipulation, Robotic networks, Distributed optimization, Non-holonomic robots, Hardware validation},
abstract = {Non-prehensile cooperative object transportation is a challenging model problem for distributed control and organization methods but also has practical applications. Therefore, it is widely studied in distributed robotics research. This paper describes and evaluates a novel transportation scheme for differential-drive mobile robots that is, to the authors’ best knowledge, the most versatile scheme of its kind successfully evaluated with real-world hardware. The proposed scheme can conceptually deal with any number of robots and arbitrary polygonal objects, including non-convex ones, without having to retune, retrain, or reconfigure any of the control parameters between different scenarios. This is achieved by splitting the task into a formation control and a formation finding task, both of which are tackled with model-based approaches using distributed optimization. Formation control and formation finding are complicated by the robots’ non-holonomic kinematic constraints. Therefore, a tailored distributed model predictive controller is used for formation control. Finding formations relies on a multibody-dynamics representation of the robots-object system to properly account for contact and non-holonomic constraints. Due to these measures, the transportation scheme achieves a very satisfactory performance and dexterity in real-world hardware experiments utilizing network communication and distributed computation.}
}
@article{STRATFORD2022115813,
title = {Exploring the potential neurotoxicity of vaping vitamin E or vitamin E acetate},
journal = {Toxicology and Applied Pharmacology},
volume = {434},
pages = {115813},
year = {2022},
issn = {0041-008X},
doi = {https://doi.org/10.1016/j.taap.2021.115813},
url = {https://www.sciencedirect.com/science/article/pii/S0041008X21004178},
author = {Kimberly Stratford and Prabha Kc and Susan Rudy and Anna-Sophie Weidner and Priscilla Callahan-Lyon and Luis G. Valerio},
keywords = {Pulmonary injury, Electronic Nicotine Delivery Systems (ENDS), Tobacco products, Electronic cigarettes, Vitamin E, Vitamin E acetate, E-Cigarette or Vaping Product Use-Associated Lung Injury (EVALI), Vaping, Neurotoxicity, Computational model},
abstract = {Serious adverse health effects have been reported with the use of vaping products, including neurologic disorders and e-cigarette or vaping product use-associated lung injury (EVALI). Vitamin E acetate, likely added as a diluent to cannabis-containing products, was linked to EVALI. Literature searches were performed on vitamin E and vitamin E acetate-associated neurotoxicity. Blood brain barrier (BBB) penetration potential of vitamin E and vitamin E acetate were evaluated using cheminformatic techniques. Review of the literature showed that the neurotoxic potential of inhalation exposures to these compounds in humans is unknown. Physico-chemical properties demonstrate these compounds are lipophilic, and molecular weights indicate vitamin E and vitamin E acetate have the potential for BBB permeability. Computational models also predict both compounds may cross the BBB via passive diffusion. Based on literature search, no experimental nonclinical studies and clinical information on the neurotoxic potential of vitamin E via inhalation. Neurotoxic effects from pyrolysis by-product, phenyl acetate, structurally analogous to vitamin E acetate, suggests vitamin E acetate has potential for central nervous system (CNS) impairment. Cheminformatic model predictions provide a theoretical basis for potential CNS permeability of these inhaled dietary ingredients suggesting prioritization to evaluate for potential hazard to the CNS.}
}
@article{ROOTESMURDY2024100987,
title = {Cortical similarities in psychiatric and mood disorders identified in federated VBM analysis via COINSTAC},
journal = {Patterns},
volume = {5},
number = {7},
pages = {100987},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100987},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924001028},
author = {Kelly Rootes-Murdy and Sandeep Panta and Ross Kelly and Javier Romero and Yann Quidé and Murray J. Cairns and Carmel Loughland and Vaughan J. Carr and Stanley V. Catts and Assen Jablensky and Melissa J. Green and Frans Henskens and Dylan Kiltschewskij and Patricia T. Michie and Bryan Mowry and Christos Pantelis and Paul E. Rasser and William R. Reay and Ulrich Schall and Rodney J. Scott and Oliver J. Watkeys and Gloria Roberts and Philip B. Mitchell and Janice M. Fullerton and Bronwyn J. Overs and Masataka Kikuchi and Ryota Hashimoto and Junya Matsumoto and Masaki Fukunaga and Perminder S. Sachdev and Henry Brodaty and Wei Wen and Jiyang Jiang and Negar Fani and Timothy D. Ely and Adriana Lorio and Jennifer S. Stevens and Kerry Ressler and Tanja Jovanovic and Sanne J.H. {van Rooij} and Lydia M. Federmann and Christiane Jockwitz and Alexander Teumer and Andreas J. Forstner and Svenja Caspers and Sven Cichon and Sergey M. Plis and Anand D. Sarwate and Vince D. Calhoun},
keywords = {transdiagnostic, federated analysis, COINSTAC, psychiatric disorders, regression, mood disorders, decentralized, gray matter, PTSD, mild cognitive impairment},
abstract = {Summary
Structural neuroimaging studies have identified a combination of shared and disorder-specific patterns of gray matter (GM) deficits across psychiatric disorders. Pooling large data allows for examination of a possible common neuroanatomical basis that may identify a certain vulnerability for mental illness. Large-scale collaborative research is already facilitated by data repositories, institutionally supported databases, and data archives. However, these data-sharing methodologies can suffer from significant barriers. Federated approaches augment these approaches by enabling access or more sophisticated, shareable and scaled-up analyses of large-scale data. We examined GM alterations using Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation, an open-source, decentralized analysis application. Through federated analysis of eight sites, we identified significant overlap in the GM patterns (n = 4,102) of individuals with schizophrenia, major depressive disorder, and autism spectrum disorder. These results show cortical and subcortical regions that may indicate a shared vulnerability to psychiatric disorders.}
}
@article{BARTELS2008381,
title = {Principled moral sentiment and the flexibility of moral judgment and decision making},
journal = {Cognition},
volume = {108},
number = {2},
pages = {381-417},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2008.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010027708000607},
author = {Daniel M. Bartels},
keywords = {Morality, Judgment, Decision making, Values, Ethics, Intuition, Emotions, Reasoning, Moral rules, Moral dilemmas},
abstract = {Three studies test eight hypotheses about (1) how judgment differs between people who ascribe greater vs. less moral relevance to choices, (2) how moral judgment is subject to task constraints that shift evaluative focus (to moral rules vs. to consequences), and (3) how differences in the propensity to rely on intuitive reactions affect judgment. In Study 1, judgments were affected by rated agreement with moral rules proscribing harm, whether the dilemma under consideration made moral rules versus consequences of choice salient, and by thinking styles (intuitive vs. deliberative). In Studies 2 and 3, participants evaluated policy decisions to knowingly do harm to a resource to mitigate greater harm or to merely allow the greater harm to happen. When evaluated in isolation, approval for decisions to harm was affected by endorsement of moral rules and by thinking style. When both choices were evaluated simultaneously, total harm – but not the do/allow distinction – influenced rated approval. These studies suggest that moral rules play an important, but context-sensitive role in moral cognition, and offer an account of when emotional reactions to perceived moral violations receive less weight than consideration of costs and benefits in moral judgment and decision making.}
}
@article{NOVIANTRI2023446,
title = {Unsteady State Temperature Distribution Inside House Based on Slope Roof},
journal = {Procedia Computer Science},
volume = {227},
pages = {446-453},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.545},
url = {https://www.sciencedirect.com/science/article/pii/S187705092301712X},
author = {Viska Noviantri and Agus Diemas Prayoga and Denny Pratama},
keywords = {unsteady state heat equation, ghost point, finite difference method, slope roof},
abstract = {The house is a building that serves as a place to gather with family and also to get comfort. The house is designed so the occupants can feel aesthetically and functionally comfortable. It will be interesting to discuss the temperature inside the house as one of the comfort factors. The study aims to analyze the temperature conditions inside the house, which are influenced by the slope of the roof. A two-dimensional unsteady state heat equation represents this temperature since the temperature distribution satisfies the heat transfer concept and changes over time. This governing equation will be approximated by the forward time center space scheme as one finite difference method and completed by the quadratic ghost point method since the house domain is an irregular shape. Van Neumann criteria are applied here to analyze the stability of the computational approach for this numerical scheme. Furthermore, these schemes are implemented in MATLAB application to quantitatively and visually display temperature dynamics. Some simulations completed these approximations to see temperature variations over time. The results show that the bigger slope causes the average temperature to be cooler. In other words, the temperature in the house will be more comfortable when the roof slope gets bigger.}
}
@article{KERREN2025,
title = {Exploring the role of dimensionality transformation in episodic memory},
journal = {Trends in Cognitive Sciences},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2025.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S136466132500021X},
author = {Casper Kerrén and Daniel Reznik and Christian F. Doeller and Benjamin J. Griffiths},
keywords = {episodic memory, dimensionality reduction and dimensionality expansion, neural oscillations, corticohippocampal connectivity, neural representations},
abstract = {Episodic memory must accomplish two adversarial goals: encoding and storing a multitude of experiences without exceeding the finite neuronal structure of the brain, and recalling memories in vivid detail. Dimensionality reduction and expansion (‘dimensionality transformation’) enable the brain to meet these demands. Reduction compresses sensory input into simplified, storable codes, while expansion reconstructs vivid details. Although these processes are essential to memory, their neural mechanisms for episodic memory remain unclear. Drawing on recent insights from cognitive psychology, systems neuroscience, and neuroanatomy, we propose two accounts of how dimensionality transformation occurs in the brain: structurally (via corticohippocampal pathways) and functionally (through neural oscillations). By examining cross-species evidence, we highlight neural mechanisms that may support episodic memory and identify crucial questions for future research.}
}
@article{DELIDDO2021102537,
title = {Let's replay the political debate: Hypervideo technology for visual sensemaking of televised election debates},
journal = {International Journal of Human-Computer Studies},
volume = {145},
pages = {102537},
year = {2021},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102537},
url = {https://www.sciencedirect.com/science/article/pii/S1071581920301397},
author = {Anna {De Liddo} and Nieves Pedreira Souto and Brian Plüss},
keywords = {Sensemaking, Public deliberation, Political election debates, Hypervideo, Advanced visual interfaces, Interactive visualisations, Deliberation within},
abstract = {Despite the widespread proliferation of social media in policy and politics, televised election debates are still a prominent form of large-scale public engagement between politicians and the electorate during election campaigns. Advanced visual interfaces can improve these important spaces of democratic engagement. In this paper, we present a user study in which a new hypervideo technology was compared with a publicly available interface for television replay. The results show that hypervideo navigation, coupled with interactive visualisations, improved sensemaking of televised political debates and promoted people's attitude to challenging personal assumptions. This finding suggests that hypervideo interfaces can play a substantial role in supporting citizens in the complex sensemaking process of informing their political choices during an election campaign, and can be used as instruments to promote critical thinking and political opinion shifting.}
}
@article{AMIROUCHE1991293,
title = {Gain in computational efficiency by vectorization in the dynamic simulation of multi-body systems},
journal = {Computers & Structures},
volume = {41},
number = {2},
pages = {293-302},
year = {1991},
issn = {0045-7949},
doi = {https://doi.org/10.1016/0045-7949(91)90432-L},
url = {https://www.sciencedirect.com/science/article/pii/004579499190432L},
author = {F.M.L. Amirouche and N.H. Shareef},
abstract = {This paper presents a new technique developed for increasing the computational efficiency of the dynamic simulation of multi-body systems, providing the computer code with the speed of execution, which is an order of magnitude ahead of the procedure outlined in S. K. Ider and F. M. L. Amirouche [J. appl. Mech.56, (2) (1989)]. This technique is useful with the finite element based algorithm for the solution of dynamical equations of motion for the constrained and unconstrained systems with flexible/rigid interconnected bodies. The implementation of the technique has totally eliminated the costly multiplications of large Boolean matrices, where intensive cpu utilization was required. The overall expensive computer time has been drastically reduced, particularly for the three-dimensional systems involving large degrees of freedom, as a result of their intricate geometry. The algorithmic procedure has been presented in a matrix form and is based on the recursive formulation using Kane's equation, strain energy, mode synthesis, finite element approach, a stable and efficient method for reducing the number of equations subsequent to the constraints resulting from closed loops and/or prescribed motions. Further enhancement in the speed of execution has been achieved by subjecting the developed code to vectorization on the vector-processing machine. A study of simple robot with flexible links has been presented comparing the execution times on the scalar machine (IBM-3081) and the vector-processor (IBM-3090) with and without vector options. Performance figures has been plotted demonstrating the large gains achieved by the technique developed.}
}
@article{SELESNICK2012115,
title = {Quantum-like logics and schizophrenia},
journal = {Journal of Applied Logic},
volume = {10},
number = {1},
pages = {115-126},
year = {2012},
note = {Special issue on Automated Specification and Verification of Web Systems},
issn = {1570-8683},
doi = {https://doi.org/10.1016/j.jal.2011.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1570868311000656},
author = {S.A. Selesnick and G.S. Owen},
keywords = {Logic, Quantum logic, Linear logic, Schizophrenia},
abstract = {Many researchers in different disciplines have independently concluded that brains are, possibly among other things, vector processing devices. In this paper we offer support for this hypothesis coming from a new perspective. Namely, we test it against some known anomalies in the processing by schizophrenic patients of certain logical tasks: they perform better at them than normal controls, despite the observation that they do not generally employ “normal” or “commonsense” logic. On the assumption that they are compelled to use the intrinsic logic of the brain instead of commonsense logic, and that this logic is linear or quantum-like, we are able to resolve these and other anomalies. Our conclusions support the idea that human brains (at least) perform intrinsic logical operations according to the dictates of a linear (or Grassmannian, or quantum-like) logic rather than “classical” or Aristotelian logic (which seems not to be intrinsic to brains, these having evolved under the pressure of different constraints). If this is the case, then commonsense logic must be acquired through experience and the construction of contexts, an ability schizophrenic patients seem to lack, and who are consequently compelled to rely on the intrinsic logic, which is quantum-like and more efficient at certain tasks. Moreover, the proclivity toward errors of von Domarus type (namely the inference that shared attributes imply identity), which seems to be endemic to human thinking and has been discussed in connection with schizophrenia, is also explained on this basis.}
}
@incollection{BURATTINI20021315,
title = {37 - Hybrid Expert Systems: An Approach to Combining Neural Computation and Rule-Based Reasoning},
editor = {Cornelius T. Leondes},
booktitle = {Expert Systems},
publisher = {Academic Press},
address = {Burlington},
pages = {1315-1354},
year = {2002},
isbn = {978-0-12-443880-4},
doi = {https://doi.org/10.1016/B978-012443880-4/50081-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780124438804500818},
author = {Ernesto Burattini and Massimo {De Gregorio} and Guglielmo Tamburrini},
abstract = {Publisher Summary
This chapter examines an approach that integrates neural computation and rule-based reasoning, or the hybrid systems. This integration is actively applied in artificial intelligence and cognitive sciences, such as linguistic theory, natural language processing, and expert systems. The opportunity of employing neural techniques in expert systems is often suggested on the ground that the learning, generalization, fault, and noise tolerance capacities of neural networks can alleviate well-known shortcomings of symbolic problem solvers, such as brittleness in front of incomplete or noisy data, no increase in performance with experience, and time-consuming knowledge acquisition. This chapter explores neurosymbolic integration for rule-based expert systems in connection with automatic data acquisition, rule processing, and explanation. At the periphery of expert systems, sensory processing by neural nets is coupled to rule-based reasoning in order to perform a data acquisition task involving the deployment of expert knowledge and heuristic problem solving. The reaction times of rule-based systems are dramatically reduced by the use of a neurally inspired, parallel inference engine. Informative user interactions with expert systems are achieved by coupling symbolic and neurally supported, pictorial explanation. The relative significance of these aspects of neurosymbolic integration is enhanced by pointing to limitations of neural techniques for automatic knowledge acquisition and robust problem solving in expert systems. These uses of neural nets may often jeopardize an expert system's reliability and reduce its transparency to the user.}
}
@incollection{CHENG202579,
title = {Chapter 5 - Sparse attention and content-based learning},
editor = {Ge Cheng},
booktitle = {ChatGPT},
publisher = {Elsevier},
pages = {79-98},
year = {2025},
isbn = {978-0-443-27436-7},
doi = {https://doi.org/10.1016/B978-0-443-27436-7.00005-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443274367000059},
author = {Ge Cheng},
keywords = {GPT-3, Sparse transformer, content-based learning, in-context learning, Bayesian inference, chain of thought, meta-learning, sparse attention, few-shot learning},
abstract = {This chapter delves into the architecture and learning strategies of GPT-3, emphasizing its Sparse Transformer design and content-based learning. GPT-3, with 175 billion parameters, introduces a hybrid attention mechanism alternating between dense and locally banded sparse attention patterns, optimizing its efficiency in handling long sequences. The chapter explores the Sparse Transformer’s ability to reduce computational complexity, enhancing GPT-3 scalability and performance across various natural language processing tasks. Additionally, it discusses metalearning and in-context learning as key strategies for task adaptation without extensive retraining. The chapter also covers Bayesian inference as a framework for understanding contextual learning and introduces the chain-of-thought approach, which enhances reasoning capabilities through step-by-step problem-solving techniques. These innovations enable GPT-3 to perform complex reasoning tasks effectively, demonstrating its advanced capabilities in natural language understanding and generation.}
}
@article{SHI2023926,
title = {Decoding Human Biology and Disease Using Single-cell Omics Technologies},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {21},
number = {5},
pages = {926-949},
year = {2023},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2023.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1672022923001043},
author = {Qiang Shi and Xueyan Chen and Zemin Zhang},
keywords = {Single-cell omics, Computational method, Cellular heterogeneity, Disease, Cancer research},
abstract = {Over the past decade, advances in single-cell omics (SCO) technologies have enabled the investigation of cellular heterogeneity at an unprecedented resolution and scale, opening a new avenue for understanding human biology and disease. In this review, we summarize the developments of sequencing-based SCO technologies and computational methods, and focus on considerable insights acquired from SCO sequencing studies to understand normal and diseased properties, with a particular emphasis on cancer research. We also discuss the technological improvements of SCO and its possible contribution to fundamental research of the human, as well as its great potential in clinical diagnoses and personalized therapies of human disease.}
}
@article{KORMAN201530,
title = {The social life of cognition},
journal = {Cognition},
volume = {135},
pages = {30-35},
year = {2015},
note = {The Changing Face of Cognition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2014.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S001002771400225X},
author = {Joanna Korman and John Voiklis and Bertram F. Malle},
keywords = {History, Social psychology, Theory of mind, Communication, Robotics, Social cognition, Computation},
abstract = {We begin by illustrating that long before the cognitive revolution, social psychology focused on topics pertaining to what is now known as social cognition: people’s subjective interpretations of social situations and the concepts and cognitive processes underlying these interpretations. We then examine two questions: whether social cognition entails characteristic concepts and cognitive processes, and how social processes might themselves shape and constrain cognition. We suggest that social cognition relies heavily on generic cognition but also on unique concepts (e.g., agent, intentionality) and unique processes (e.g., projection, imitation, joint attention). We further suggest that social processes play a prominent role in the development and unfolding of several generic cognitive processes, including learning, attention, and memory. Finally, we comment on the prospects of a recently developing approach to the study of social cognition (social neuroscience) and two potential future directions (computational social cognition and social–cognitive robotics).}
}
@article{XIE2024e34960,
title = {Enhanced nonlinear active noise control: A novel approach using brain storm optimization algorithm},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e34960},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e34960},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024109917},
author = {Jiangchun Xie and Jianmin Ma},
keywords = {Active noise control, Brain storm optimization (BSO) algorithm, Filtered-x least mean squares (FxLMS) algorithm, Nonlinear noise reduction extended Kalman Filter (EKF), Noise reduction performance, Multi-frequency noise},
abstract = {Active Noise Control (ANC) systems play a crucial role in reducing unwanted noise in various settings. Traditional ANC methods, like the Filtered-x Least Mean Squares (FxLMS) algorithm, are effective in linear noise scenarios. However, they often struggle with more nonlinear and complex noise patterns. This paper introduces a novel approach using the brain storm optimization (BSO) algorithm in nonlinear ANC systems, which represents a significant departure from conventional techniques. The BSO algorithm, inspired by human brainstorming processes, excels in addressing the complexities of nonlinear noise by incorporating principles, such as delayed evaluation, free imagination, quantity and quality, and comprehensive improvement. By combining the BSO algorithm with an Extended Kalman Filter (EKF), a new ANC system is proposed that can adapt to a wide range of noise types with improved speed and accuracy. Experimental results showcase the superior performance of the BSO algorithm, achieving an impressive noise reduction of up to 48 dB (dB) in a 500Hz sinusoidal noise scenario, with a convergence time as fast as 0.01 s, outperforming the FxLMS algorithm by a significant margin. Moreover, in complex environments with multi-frequency and random noise, the BSO algorithm consistently demonstrates better noise reduction and quicker convergence, reducing noise levels by up to 27 dB within 0.001 s. The innovative use of the BSO algorithm in ANC systems not only enhances noise reduction capabilities, especially for nonlinear and complex noise signals, but also improves convergence times, paving the way for future advancements in ANC technologies.}
}
@article{LI2024120889,
title = {Hierarchical fuzzy inference based on Bandler-Kohout subproduct},
journal = {Information Sciences},
volume = {677},
pages = {120889},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120889},
url = {https://www.sciencedirect.com/science/article/pii/S002002552400803X},
author = {Dechao Li and Zhisong Liu and Qiannan Guo},
keywords = {Fuzzy implication, Fuzzy inference, Bandler-Kohout subproduct, Hierarchical system, T-norm},
abstract = {Fuzzy inference with the Bandler-Kohout subproduct (BKS) has been successfully applied in many fields such as fuzzy control, artificial intelligence, image processing, data mining, decision-making, prediction, classification and so on. However, one has to face with the rule explosion in these applications. To deal with this problem, hierarchical fuzzy systems with the compositional rule of inference (CRI) method have been constructed by a series of low-dimensional sub fuzzy systems. And it has been proved that hierarchical fuzzy inference method can efficiently restrain the explosion of fuzzy rules. Therefore, in order to increase the computational efficiency of the fuzzy inference based on the BKS when multi-input-single-output (MISO) fuzzy rules are involved, this paper mainly constructs two hierarchical fuzzy inference methods based on the BKS in which the if-then rules are respectively interpreted by fuzzy implications and ML-implications. Moreover, the validity of the two BKS hierarchical fuzzy inferences is studied with the GMP rules. Finally, two examples are employed to illustrate the computational efficiency of our proposed BKS hierarchical inference methods.}
}
@incollection{DALE201343,
title = {Chapter Two - The Self-Organization of Human Interaction},
editor = {Brian H. Ross},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {59},
pages = {43-95},
year = {2013},
issn = {0079-7421},
doi = {https://doi.org/10.1016/B978-0-12-407187-2.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780124071872000022},
author = {Rick Dale and Riccardo Fusaroli and Nicholas D. Duran and Daniel C. Richardson},
keywords = {Alignment, Conversation, Coordination, Dynamics, Interaction, Language, Self-organization, Synergy},
abstract = {We describe a “centipede’s dilemma” that faces the sciences of human interaction. Research on human interaction has been involved in extensive theoretical debate, although the vast majority of research tends to focus on a small set of human behaviors, cognitive processes, and interactive contexts. The problem is that naturalistic human interaction must integrate all of these factors simultaneously, and grander theoretical mitigation cannot come only from focused experimental or computational agendas. We look to dynamical systems theory as a framework for thinking about how these multiple behaviors, processes, and contexts can be integrated into a broader account of human interaction. By introducing and utilizing basic concepts of self-organization and synergy, we review empirical work that shows how human interaction is flexible and adaptive and structures itself incrementally during unfolding interactive tasks, such as conversation, or more focused goal-based contexts. We end on acknowledging that dynamical systems accounts are very short on concrete models, and we briefly describe ways that theoretical frameworks could be integrated, rather than endlessly disputed, to achieve some success on the centipede’s dilemma of human interaction.}
}
@article{CRAGG1974315,
title = {Thinking about the future: A critique of the limits to growth: Edited by H. S. D. Cole, Christopher Freeman, Marie Jahoda & K. L. R. Pavitt. Chatto & Windus for Sussex University Press, London: 218 pp., £3.00, 1973},
journal = {Biological Conservation},
volume = {6},
number = {4},
pages = {315-316},
year = {1974},
issn = {0006-3207},
doi = {https://doi.org/10.1016/0006-3207(74)90014-7},
url = {https://www.sciencedirect.com/science/article/pii/0006320774900147},
author = {J.B. Cragg}
}
@article{WANG2025100834,
title = {Toward bridging the gap between machine intelligence and machine wisdom: Dilemmas and conjectures},
journal = {The Innovation},
pages = {100834},
year = {2025},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2025.100834},
url = {https://www.sciencedirect.com/science/article/pii/S2666675825000372},
author = {Rui Wang and Shixuan Liu and Changjun Fan and Guozheng Li and Jincai Huang and Zhong Liu and Gang Zhou},
abstract = {In recent years, artificial intelligence (AI) has achieved tremendous development, akin to a significant leap, similar to progressing from 1 to 100. However, a significant gap still exists between current machine intelligence and human wisdom: machine intelligence is constrained to post hoc inference based on existing data, lacking the ability for genuine exploratory innovation and possessing no prospective reasoning inherent to human wisdom. Drawing inspiration from human wisdom, this article presents conjectures for overcoming the four dilemmas faced by machine intelligence: neglect of silicon-based cognition, lack of artistry, pitfall of perfectionism, and obsession with uniformity. These conjectures aim to propel machine intelligence toward machine wisdom, achieving a great leap from 1 to i.}
}
@article{AIROLDI2024101864,
title = {The nested relationality of perceived legitimacy: Mapping taste hierarchies with granular digital traces},
journal = {Poetics},
volume = {102},
pages = {101864},
year = {2024},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2024.101864},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X24000032},
author = {Massimo Airoldi},
keywords = {Taste, Cultural hierarchies, Music classification, Youtube, Digital traces},
abstract = {The article has a double purpose. On the one hand, it contributes to theories of cultural legitimacy and classification. Based on data about consumers’ music evaluations, it shows that taste hierarchies are configured as nested and relational classificatory systems. Nested, because rank systems of symbolic value are collectively recognized, reproduced, and negotiated by consumers not only at the level of genres, but also at lower, nested levels – e.g., sub-genre, artist, single artwork; relational, because the value attributed to music by consumers is ordinarily assessed and constructed through analogies and comparisons, and partly depends on the classifier's relative position in the social space. On the other hand, this paper makes a key methodological contribution: by analyzing large amounts of YouTube data through computational methods and in combination with survey data, it illustrates how the granularity of digital traces can advance sociological research on cultural categories, meaning structures and symbolic imaginaries.}
}
@article{YANG2025105265,
title = {Harmony in diversity: Digital literacy research in a multidisciplinary landscape},
journal = {Computers & Education},
volume = {230},
pages = {105265},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105265},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000338},
author = {Feng Yang and Ruiyang Yao and Yunyue Ren and Luxuan Guo},
keywords = {Information literacy, Interdisciplinary projects, Applications in subject areas, Bibliometrics},
abstract = {The advent of the digital era has significantly heightened interest in digital literacy across multidisciplinary backgrounds and has endowed these fields with interdisciplinary and integrative characteristics. In this study, we employed VOSviewer and Bibliometrix for bibliometric and descriptive analyses of digital literacy, and we analyzed 3005 records from the Social Science Citation Index and Science Citation Index. We constructed keyword co-occurrence time networks across five distinct research areas and supplemented them with keyword co-occurrence frequencies to examine similarities and differences between research themes from diverse disciplinary perspectives. The findings of this study indicate that although various fields recognize the significance of digital literacy, different fields prioritize different aspects. As the main field of research, Education & Educational Research focus primarily on the pedagogical practices of cultivating digital literacy, whereas Communication emphasizes the cultivation of digital literacy to address challenges in information dissemination. Information Science & Library Science typically view libraries as central to digital literacy. Moreover, Computer Science research emphasizes the leveraging of technology, whereas Psychology explores the connection between digital literacy and cognitive processes. Analyzing the differences between different disciplines and drawing new ideas from them is of great significance for Education & Educational Research regarding how to deepen digital literacy education content, construct digital literacy education contexts, integrate digital literacy education resources, narrow the digital divide, and promote educational equity in the future.}
}
@article{DEMSAR2007551,
title = {Investigating visual exploration of geospatial data: An exploratory usability experiment for visual data mining},
journal = {Computers, Environment and Urban Systems},
volume = {31},
number = {5},
pages = {551-571},
year = {2007},
note = {Geospatial Analysis and Modeling},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2007.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0198971507000579},
author = {Urška Demšar},
keywords = {Exploratory geovisualisation, Visual data mining, Exploratory usability},
abstract = {This study presents a small exploratory usability experiment with the goal to observe how people visually explore geospatial data. The well-known iris dataset from pattern recognition was put into geographical context for this experiment, in order to provide the participants with a dataset with easily observable spatial and other relationships. The participants were given free hand to explore this dataset with a visual data mining system in any way they liked. The protocols collected during the experiment with the thinking-aloud method were analysed with the aim to understand what types of hypotheses the participants formed, which visualisations they used to either derive, confirm or reject their hypotheses and what exploration strategies they adopted.}
}
@article{CONRAD1991316,
journal = {Bulletin of Mathematical Biology},
volume = {53},
number = {1},
pages = {316-318},
year = {1991},
issn = {0092-8240},
doi = {https://doi.org/10.1016/S0092-8240(05)80052-7},
url = {https://www.sciencedirect.com/science/article/pii/S0092824005800527},
author = {Michael Conrad}
}
@article{FISCHLER1987257,
title = {Parallel guessing: A strategy for high-speed computation},
journal = {Pattern Recognition},
volume = {20},
number = {2},
pages = {257-263},
year = {1987},
issn = {0031-3203},
doi = {https://doi.org/10.1016/0031-3203(87)90059-8},
url = {https://www.sciencedirect.com/science/article/pii/0031320387900598},
author = {M.A. Fischler and O. Firschein},
keywords = {Parallel processing, Image analysis algorithms, Image processing, Architectures},
abstract = {Conventional approaches to speeding up image understanding computation involving conventional serial algorithms attempt to decompose these algorithms into portions that can be computed in parallel. Because many classes of algorithms do not readily decompose, one seeks some other basis for parallelism. In this paper we argue that “parallel guessing” for image analysis is a useful approach, and that several recent scene analysis algorithms are based on this concept. Problems suitable for this approach have the characteristic that either “distance” from a true solution, or the correctness of a guess, can be readily checked. We review image analysis algorithms that have a parallel guessing or randomness flavor.}
}
@article{HENNE2019157,
title = {A counterfactual explanation for the action effect in causal judgment},
journal = {Cognition},
volume = {190},
pages = {157-164},
year = {2019},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2019.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010027719301301},
author = {Paul Henne and Laura Niemi and Ángel Pinillos and Felipe {De Brigard} and Joshua Knobe},
keywords = {Action effect, Omissions, Omission effect, Causal reasoning, Counterfactual thinking, Causation by omission},
abstract = {People’s causal judgments are susceptible to the action effect, whereby they judge actions to be more causal than inactions. We offer a new explanation for this effect, the counterfactual explanation: people judge actions to be more causal than inactions because they are more inclined to consider the counterfactual alternatives to actions than to consider counterfactual alternatives to inactions. Experiment 1a conceptually replicates the original action effect for causal judgments. Experiment 1b confirms a novel prediction of the new explanation, the reverse action effect, in which people judge inactions to be more causal than actions in overdetermination cases. Experiment 2 directly compares the two effects in joint-causation and overdetermination scenarios and conceptually replicates them with new scenarios. Taken together, these studies provide support for the new counterfactual explanation for the action effect in causal judgment.}
}
@incollection{GARDNER2024153,
title = {Chapter 7 - Smart design for cultural heritage},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {153-174},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00005-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000057},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Heritage futures, Interaction, Physical computing, Smart cultural heritage, Smart heritage, Smart city, Urban technology},
abstract = {This chapter explores the evolving relationship between cultural heritage and the smart city. The role of smart technologies in a cultural heritage context is often assumed to involve the integration of sensor-based technologies and computational systems to autonomously monitor and manage sites. This chapter expands the definition of smart heritage to include urban technology projects that use sensor-based technologies and physical computing to realize situated and embodied interaction experiences that encourage citizens and visitors to share and co-create cultural heritage experiences with each other. It discusses existing and speculative urban technology projects that combine spatial design and physical computing affordances to create cultural heritage experiences that can be simultaneously attuned to both the past and the future.}
}
@article{GIORGI2024119928,
title = {Embedding parametric resonance in a 2:1 wave energy converter to get a broader bandwidth},
journal = {Renewable Energy},
volume = {222},
pages = {119928},
year = {2024},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2023.119928},
url = {https://www.sciencedirect.com/science/article/pii/S0960148123018438},
author = {Giuseppe Giorgi},
keywords = {2:1 parametric resonance, Parametric instability, Wave energy converter, Nonlinear Froude–Krylov force},
abstract = {The effort to increase the converted power is a common challenge to players in the field of wave energy conversion, both academic and industrial. In the case devices are found to be prone to parametric resonance, it typically has a negative impact on power harvesting and may jeopardize the reliability of the device. This paper makes the case that parametric resonance is not a danger that should be avoided, but rather a chance to achieve a broader system response bandwidth and ultimately increase the amount of power available at the power take-off. Since a time-varying wetted surface causes the highly nonlinear phenomenon of parametric resonance, linear models are unable to fully capture this instability. As a result, nonlinear Froude–Krylov forces are herein implemented via a computationally effective method for prismatic floaters that is compatible with both exhaustive simulation methods and real-time computing, as the whole simulations runs up to 50 times faster than real-time. A novel pendulum-based device is intentionally defined to exhibit a 2:1 ratio between heave and pitch natural frequencies, causing parametric instability. Results demonstrate that linear models predict a single zone of meaningful potential power extraction around the pitch natural frequency, as expected; however, by using the designed attitude to develop parametric instability, a second additional region develops near the heave natural period. As a result, the free response bandwidth is in fact increased, making more energy available at the power take-off axis thanks to the nonlinear instability embedded in the wave energy converter.}
}
@article{GROEGER1987295,
title = {Computation—The final metaphor? An interview with Philip Johnson-Laird},
journal = {New Ideas in Psychology},
volume = {5},
number = {2},
pages = {295-304},
year = {1987},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(87)90030-4},
url = {https://www.sciencedirect.com/science/article/pii/0732118X87900304},
author = {J.A. Groeger}
}
@article{BENARIE1992291,
title = {Air pollution modeling: P. Zannetti, Computational Mechanics Publications, Southampton, U.K. 1990, 444 pp. Price: £59.00},
journal = {Science of The Total Environment},
volume = {119},
pages = {291},
year = {1992},
issn = {0048-9697},
doi = {https://doi.org/10.1016/0048-9697(92)90273-U},
url = {https://www.sciencedirect.com/science/article/pii/004896979290273U},
author = {Michel Benarie}
}
@article{MUGHAL2020159,
title = {Goals of the national mathematics curriculum of Pakistan: educators’ perceptions and challenges toward achievement},
journal = {International Journal of Educational Management},
volume = {35},
number = {1},
pages = {159-172},
year = {2020},
issn = {0951-354X},
doi = {https://doi.org/10.1108/IJEM-04-2020-0203},
url = {https://www.sciencedirect.com/science/article/pii/S0951354X20000678},
author = {Shahid Hussain Mughal and Muhammad Mujtaba Asad and Donnie Adams},
keywords = {Mathematics, Curriculum design, Pedagogy, Content knowledge, National plan},
abstract = {Purpose
The national mathematics curriculum of Pakistan has emphasized on improving content knowledge, reasoning abilities and problem-solving skills of students about thinking, communicating and solving mathematics (national mathematics curriculum of Pakistan, 2006). Whereas, there is a need to understand the point of view of teachers about the challenges they face in achieving the goals of national mathematics curriculum. This will help leading teacher training institutions to revisit their math teacher continuous professional development (CPD) programs and facilitate school leadership in improving the quality of math education in rural schools of the province. However, the purpose of this research study is to figure out the challenges that teachers are facing while achieving the goals of the national curriculum by teaching mathematics at the primary level in educational institutes of Pakistan.
Design/methodology/approach
In this research study qualitative research approaches have been utilized, in which focus group discussions (FGDs) were used as data collection techniques. Furthermore, thematic analysis of the data led toward the development of four overarching themes such as teachers' knowledge about mathematics curriculum, challenges relating to mathematics content and pedagogy, difficulties in developing conceptual understanding and designing lesson plans to address students' diversity.
Findings
The overall findings of this research study suggested that the majority of teachers are facing difficulties in mathematics content teaching such as decimal fraction, unitary method, measurement principles, practical geometry and data handling. Moreover, teachers are also facing challenges and difficulties in developing hands-on and minds-on activities in the teaching of mathematical concepts to the students of primary level in educational institutes of Pakistan.
Practical implications
This research study will facilitate the teachers and stakeholders to address the problematic issues in the domain of content delivery of mathematics. Whereas, this study recommends educating teachers about national mathematics curriculum and to develop a CPD framework for mathematics teachers for the enhancement of their pedagogical content knowledge. The study also recommends orientating school heads about the different aspects of math curriculum so that they can mentor math teachers in achieving math curriculum goals.
Originality/value
This is the first research study of its nature, which targets and highlights the teacher's perceptions toward the achieving the goals of national mathematics curriculum of Pakistan and addressing the pedagogical challenges faced in mathematics teachers. There is a dearth of studies in mathematics education in Sindh province. The issue is of immense importance, the findings will help teachers to improve mathematics instructions at primary level.}
}
@article{REIS2024103184,
title = {Machine learning methods in physical therapy: A scoping review of applications in clinical context},
journal = {Musculoskeletal Science and Practice},
volume = {74},
pages = {103184},
year = {2024},
issn = {2468-7812},
doi = {https://doi.org/10.1016/j.msksp.2024.103184},
url = {https://www.sciencedirect.com/science/article/pii/S2468781224002790},
author = {Felipe J.J. Reis and Matheus Bartholazzi Lugão de Carvalho and Gabriela de Assis Neves and Leandro Calazans Nogueira and Ney Meziat-Filho},
keywords = {Artificial intelligence, Computational intelligence, Machine intelligence, Computer reason, Physical therapy modalities},
abstract = {Background
Machine learning (ML) efficiently processes large datasets, showing promise in enhancing clinical practice within physical therapy.
Objective
The aim of this scoping review is to provide an overview of studies using ML approaches in clinical settings of physical therapy.
Data sources
A scoping review was performed in PubMed, EMBASE, PEDro, Cochrane, Web of Science, and Scopus.
Selection criteria
We included studies utilizing ML methods. ML was defined as the utilization of computational systems to encode patterns and relationships, enabling predictions or classifications with minimal human interference.
Data extraction and data synthesis
Data were extracted regarding methods, data types, performance metrics, and model availability.
Results
Forty-two studies were included. The majority were published after 2020 (n = 25). Fourteen studies (33.3%) were in the musculoskeletal physical therapy field, nine (21.4%) in neurological, and eight (19%) in sports physical therapy. We identified 44 different ML models, with random forest being the most used. Three studies reported on model availability. We identified several clinical applications for ML-based tools, including diagnosis (n = 14), prognosis (n = 7), treatment outcomes prediction (n = 7), clinical decision support (n = 5), movement analysis (n = 4), patient monitoring (n = 3), and personalized care plan (n = 2).
Limitation
Model performance metrics, costs, model interpretability, and explainability were not reported.
Conclusion
This scope review mapped the emerging landscape of machine learning applications in physical therapy. Despite the growing interest, the field still lacks high-quality studies on validation, model availability, and acceptability to advance from research to clinical practice.}
}
@article{NOST202223,
title = {Earth for AI: A Political Ecology of Data-Driven Climate Initiatives},
journal = {Geoforum},
volume = {130},
pages = {23-34},
year = {2022},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2022.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0016718522000240},
author = {Eric Nost and Emma Colven},
keywords = {Adaptation, Artificial intelligence, Climate change, Digital geographies, Environmental data justice, Knowledge production},
abstract = {Emerging narratives around artificial intelligence (AI) and machine learning place great faith in these technologies’ ability to ameliorate threats posed by climate change. They promise the capacity to analyze vast amounts of more precise and real-time data, improving how decision-makers predict, respond, and adapt. Yet scholars in political ecology have long observed that technocentric approaches typically reduce complex human-environment relationships in ways that fail to account for social relations and power dynamics. This paper charts the emerging political economy of “climate AI” – the philanthropies, NGOs, private consultancies, and tech giants investing in data-driven climate initiatives. Mapping out two case studies, we show that environmental and climate crises are grist for tech solutions and find that many climate AI actors are interested in it for surveillance, greenwashing, and commodifying algorithms. We pay special attention to how neocolonial and racialized power structures manifest in climate AI and outline three ways for political ecologists and digital geographers to research its socio-materiality: how computational resources are environmentally embedded, how disasters become “shocks” that the AI industry capitalizes on, and how climate AI shapes material investment flows and landscapes. Highlighting how data-driven approaches to climate crises reproduce injustices already faced by marginalized communities, our analysis contributes to research on environmental data justice.}
}
@article{BLACUTT2025586,
title = {Bias toward escape responding during reinforcement learning among those with suicidal ideation},
journal = {Journal of Psychiatric Research},
volume = {181},
pages = {586-595},
year = {2025},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2024.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S0022395624007222},
author = {Miguel Blacutt and Caitlin M. O'Loughlin and Brooke A. Ammerman},
keywords = {Suicide, Avoidance, Computational, Impulsivity, Drift diffusion},
abstract = {Self-injury and suicide can be characterized by reward system dysfunction and self-reports of active efforts to escape unpleasant emotional states. Therefore, individuals with histories of suicidal ideation (SI) should exhibit a preference for active escape from unpleasant states, which exceed the effects of impulsive behavior under distress and lack of premeditation. Participants made active (Go) or passive (No-Go) choices in response to stimuli to escape or avoid an unpleasant state in a behavioral task. A drift-diffusion reinforcement learning model was used to estimate latent biases for active escape and avoidance in people with and without SI history. Bayesian logistic regression was used to examine the relationship between escape and avoid bias with SI. Escape bias predicted SI history, whereas avoidance bias did not. Escape bias remained a significant predictor of SI when controlling for negative urgency and lack of premeditation. Those with histories of SI demonstrate a decision-making bias favoring escape from aversive states. This bias remains significant after adjusting for facets of impulsivity linked to hasty decisions under distress and lack of premeditation. A heightened escape response may help clinicians to identify SI risk and develop targeted treatments to attenuate the escape bias.}
}
@article{B2021107538,
title = {A survey on genomic data by privacy-preserving techniques perspective},
journal = {Computational Biology and Chemistry},
volume = {93},
pages = {107538},
year = {2021},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2021.107538},
url = {https://www.sciencedirect.com/science/article/pii/S1476927121001055},
author = {Abinaya B. and Santhi S.},
keywords = {Data sharing, Data access and storage, Data computation, Outsourcing, Privacy-preserving techniques},
abstract = {Nowadays, the purpose of human genomics is widely emerging in health-related problems and also to achieve time and cost-efficient healthcare. Due to advancement in genomics and its research, development in privacy concerns is needed regarding querying, accessing and, storage and computation of the genomic data. While the genomic data is widely accessible, the privacy issues may emerge due to the untrusted third party (adversaries/researchers), they may reveal the information or strategy plans regarding the genome data of an individual when it is requested for research purposes. To mitigate this problem many privacy-preserving techniques are used along with cryptographic methods are briefly discussed. Furthermore, efficiency and accuracy in a secure and private genomic data computation are needed to be researched in future.}
}
@article{MOTANIETO2023103965,
title = {The Mexican Carbon Capture and Storage Platform: Construction of a boundary object for bridging the gaps between contexts, actors, and disciplines},
journal = {International Journal of Greenhouse Gas Control},
volume = {129},
pages = {103965},
year = {2023},
issn = {1750-5836},
doi = {https://doi.org/10.1016/j.ijggc.2023.103965},
url = {https://www.sciencedirect.com/science/article/pii/S1750583623001354},
author = {J. Mota-Nieto and J.A. Fernández-Reyes and P.M. García-Meneses},
keywords = {CCS/CCUS, Communication platform, Mexico, Boundary objects, Stakeholders},
abstract = {Carbon Capture and Storage (CCS) is a technology identified as a potential solution to mitigate climate change by reducing carbon emissions from large-scale emitters. If CCS is expected to be adopted globally, transparent and reliable data and information must be readily attainable to all stakeholders to support the technology choice and decision-making process. The implementation of CCS requires effective communication and collaboration strategies. Still, materials and communication platforms to inform stakeholders about the potential and contribution of CCS are predominantly accessible in English since ongoing projects are mainly located in English-speaking countries. The Mexican Carbon Capture and Storage platform (MeCCS) was developed as a digital sharing and learning space for national stakeholders to obtain and expand their knowledge about CCS technology in Spanish. It was constructed as a boundary object (BO) to bridge different communities and disciplines, facilitating communication, understanding, and cooperation. The platform includes diverse elements that combine science and art to produce dissemination materials for different audiences to help build critical thinking and inform them about CCS technology. The platform confirmed its capacity to transfer and translate knowledge one year after its launch. It also served to connect different audiences in Mexico and globally and identify further areas of research and CCS-related efforts.}
}
@article{FERNANDEZ20181,
title = {Natural deep eutectic solvents-mediated extractions: The way forward for sustainable analytical developments},
journal = {Analytica Chimica Acta},
volume = {1038},
pages = {1-10},
year = {2018},
issn = {0003-2670},
doi = {https://doi.org/10.1016/j.aca.2018.07.059},
url = {https://www.sciencedirect.com/science/article/pii/S0003267018309231},
author = {María de los Ángeles Fernández and Joana Boiteux and Magdalena Espino and Federico J.V. Gomez and María Fernanda Silva},
keywords = {Natural deep eutectic solvents, Extraction, Green analytical chemistry, Sample prep, Microextractions},
abstract = {The concept of sustainable development has impacted in analytical chemistry changing the way of thinking processes and methods. It is important for analytical chemists to consider how sample preparation can integrate the basic concepts of Green Chemistry. In this sense, the replacement of traditional organic solvents is of utmost importance. Natural Deep Eutectic Solvents (NADES) have come to light as a green alternative. In the last few years, a growing number of contributions have applied these natural solvents proving their efficiency in terms of extraction ability, analyte stabilization capacity and detection compatibility. However, the arising question that has to be answered is: the use of NADES is enough to green an extraction process? This review presents an overview of knowledge regarding sustainability of NADES-based extraction procedures, focused on reported literature within the timeframe spanning from 2011 up to date. The contributions were analyzed from a green perspective in terms of energy, time, sample and solvent consumption. Moreover, we include a critical analysis to clarify whether the use of NADES as extraction media is enough for greening an analytical methodology; strategies to make them even greener are also presented. Finally, recent trends and future perspectives on how NADES-based extraction approaches in combination with computational methodologies can contribute are discussed.}
}
@article{CORTESE2024108397,
title = {Applications of genome-scale metabolic models to the study of human diseases: A systematic review},
journal = {Computer Methods and Programs in Biomedicine},
volume = {256},
pages = {108397},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108397},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724003900},
author = {Nicola Cortese and Anna Procopio and Alessio Merola and Paolo Zaffino and Carlo Cosentino},
keywords = {Genome-scale metabolic networks, Constraint-based modeling, Systems biology, Simulation, Systematic literature review},
abstract = {Background and Objectives:
Genome-scale metabolic networks (GEMs) represent a valuable modeling and computational tool in the broad field of systems biology. Their ability to integrate constraints and high-throughput biological data enables the study of intricate metabolic aspects and processes of different cell types and conditions. The past decade has witnessed an increasing number and variety of applications of GEMs for the study of human diseases, along with a huge effort aimed at the reconstruction, integration and analysis of a high number of organisms. This paper presents a systematic review of the scientific literature, to pursue several important questions about the application of constraint-based modeling in the investigation of human diseases. Hopefully, this paper will provide a useful reference for researchers interested in the application of modeling and computational tools for the investigation of metabolic-related human diseases.
Methods:
This systematic review was conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Elsevier Scopus®, National Library of Medicine PubMed® and Clarivate Web of Science™ databases were enquired, resulting in 566 scientific articles. After applying exclusion and eligibility criteria, a total of 169 papers were selected and individually examined.
Results:
The reviewed papers offer a thorough and up-to-date picture of the latest modeling and computational approaches, based on genome-scale metabolic models, that can be leveraged for the investigation of a large variety of human diseases. The numerous studies have been categorized according to the clinical research area involved in the examined disease. Furthermore, the paper discusses the most typical approaches employed to derive clinically-relevant information using the computational models.
Conclusions:
The number of scientific papers, utilizing GEM-based approaches for the investigation of human diseases, suggests an increasing interest in these types of approaches; hopefully, the present review will represent a useful reference for scientists interested in applying computational modeling approaches to investigate the aetiopathology of human diseases; we also hope that this work will foster the development of novel applications and methods for the discovery of clinically-relevant insights on metabolic-related diseases.}
}
@article{BYLYA20172358,
title = {Modelling challenges for incremental bulk processes despite advances in simulation technology: example issues and approaches},
journal = {Procedia Engineering},
volume = {207},
pages = {2358-2363},
year = {2017},
note = {International Conference on the Technology of Plasticity, ICTP 2017, 17-22 September 2017, Cambridge, United Kingdom},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.10.1008},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817358010},
author = {O.I. Bylya and M. Ward and B. Krishnamurty and S. Tamang and R.A. Vasin},
keywords = {Flow forming, rotary forging, process modelling, simplification approaches. Introduction},
abstract = {Incremental bulk deformation processes have traditionally been difficult to simulate. This paper will argue that, despite advances in computation and software, they remain difficult to model. The main reason for this is the shortage of ideas on what is the real objective of FE modelling for such processes. Even a very detailed model and data obtained in simulation does not give answers to the main question - how to optimise the process parameters? High computational time and volume of information only aggravate the situation. All modern mathematical techniques of dimensionality reduction (such as POD/PGD) lose their power when the priorities and acceptable compromises of modelling are not clear. This paper tries to use a large volume of available experimental and modelling experience to illustrate this problem and look for possible break-through directions.}
}
@article{AI2022631,
title = {Reconsidering autistic ‘camouflaging’ as transactional impression management},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {8},
pages = {631-645},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322001061},
author = {Wei Ai and William A. Cunningham and Meng-Chuan Lai},
keywords = {autism, camouflaging, impression management, predictive coding, social alignment, wellbeing},
abstract = {Social performances pervade human interactions. Some autistic people describe their social performances as ‘camouflaging’ and engage in these performances to mitigate social challenges and survive in the neurotypical world. Here, we reconsider autistic camouflaging under the unifying framework of impression management (IM) by examining overlapping and unique motivations, neurocognitive mechanisms, and consequences. Predictive coding and Bayesian principles are synthesized into a computational model of IM that applies to autistic and neurotypical people. Throughout, we emphasize the inherently transactional, context-dependent nature of IM, the distinct computational challenges faced by autistic people, and the psychological toll that compelled IM can take. Viewing camouflaging through this lens highlights the pressing needs to change societal attitudes, destigmatize autism, refine social skills-building programs for autistic individuals, and integrate these programs with environment-focused support.}
}
@article{TALANOV2018473,
title = {Simulation of serotonin mechanisms in NEUCOGAR cognitive architecture},
journal = {Procedia Computer Science},
volume = {123},
pages = {473-478},
year = {2018},
note = {8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.01.072},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918300735},
author = {Max Talanov and Fail Gafarov and Jordi Vallverdú and Sergey Ostapenko and Marat Gazizov and Alexander Toschev and Alexey Leukhin and Salvatore Distefano},
keywords = {Serotonin, dopamine, disgust, artificial intelligence, simulation, affective computing, emotion modelling, neuromodulation},
abstract = {This work aims at demonstrating that the neuromodulatory mechanisms that control the emotional states of mammals (specifically rat’s brains) can be represented and re-implemented in a computational model processed by a machine. In particular we specifically focus on two neuro-transmitters, serotonin and dopamine, starting from their fundamental role in basic cognitive processes. In our specific implementation, we represent the simulation of the ‘disgust-like’ state based on the three dimensional neuromodulatory model of affects or emotions, according to the ‘cube of emotions’. These functional mechanisms can be transferred into an artificial cognitive system: inhibition, for example, can elicit a blocking behaviour that, depending on its intensity and duration, can push the system to a general emotional state. We have simulated 1000 milliseconds of the serotonin and dopamine systems using NEST Neural Simulation Tool with the rat brain as the model to artificially reproduce this mechanism on a computational system.}
}
@article{GOTTS2019100728,
title = {Agent-based modelling of socio-ecological systems: Models, projects and ontologies},
journal = {Ecological Complexity},
volume = {40},
pages = {100728},
year = {2019},
note = {Agent-based modelling to study resilience in socio-ecological systems},
issn = {1476-945X},
doi = {https://doi.org/10.1016/j.ecocom.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S1476945X18301272},
author = {Nicholas M. Gotts and George A.K. {van Voorn} and J. Gareth Polhill and Eline de Jong and Bruce Edmonds and Gert Jan Hofstede and Ruth Meyer},
keywords = {Socio-ecological system, Agent-based model, Complexity, Ontology},
abstract = {Socio-Ecological Systems (SESs) are the systems in which our everyday lives are embedded, so understanding them is important. The complex properties of such systems make modelling an indispensable tool for their description and analysis. Human actors play a pivotal role in SESs, but their interactions with each other and their environment are often underrepresented in SES modelling. We argue that more attention should be given to social aspects in models of SESs, but this entails additional kinds of complexity. Modelling choices need to be as transparent as possible, and to be based on analysis of the purposes and limitations of modelling. We recommend thinking in terms of modelling projects rather than single models. Such a project may involve multiple models adopting different modelling methods. We argue that agent-based models (ABMs) are an essential tool in an SES modelling project, but their expressivity, which is their major advantage, also produces problems with model transparency and validation. We propose the use of formal ontologies to make the structure and meaning of models as explicit as possible, facilitating model design, implementation, assessment, comparison and extension.}
}