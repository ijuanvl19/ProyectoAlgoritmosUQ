@article{SHYJA2023100465,
title = {Link quality and energy efficient optimal simplified cluster based routing scheme to enhance lifetime for wireless body area networks},
journal = {Nano Communication Networks},
volume = {37},
pages = {100465},
year = {2023},
issn = {1878-7789},
doi = {https://doi.org/10.1016/j.nancom.2023.100465},
url = {https://www.sciencedirect.com/science/article/pii/S1878778923000315},
author = {V. Irine Shyja and G. Ranganathan and V. Bindhu},
keywords = {WBAN, Clustering, Cluster head, Multipath routing scheme, Link quality},
abstract = {Monitoring of patient’s health in the medical industry can be enabled using wireless body area networks (WBANs), which are already used for various purposes, including assisting in human safety. It is imperative to use better power management strategies since the body sensors are small and the battery cannot hold a charge for a long time. Due to the vast amounts of information generated by medical sensors, resource-constrained networks face a significant challenge when guaranteeing the specified quality of service (QoS). Moreover, the WBAN regularly meets the primary hassle of QoS degradation because of congestion WBAN structure can easily compromise heterogeneous and complex networks. Either inappropriate data collection or using energy effectively to transmit medical data without the expense of travel and length has become an important one. To address this issue, the present research work ‘Link Quality and Energy Efficient Optimal Clustering-Multipath (LEOC-MP)’ scheme tries to explore an answer. The main goals of the LEOC-MP (Optimal Link Quality and Energy Efficient Optimal Clustering-Multipath) system are to guarantee node-to-node link quality, lengthen network life, and compute high-performing cluster heads to guarantee reliable multi path data transfer. This work was executed in three phases. First, an optimal simplified clustering technique for data collection from body sensors using an improved pelican optimization (ICO) algorithm is introduced. Next, multiple design constraints for node rank computation, energy efficiency, link quality, path loss, distance, and delay are used. Besides, an Auto-Regressive Probabilistic Neural Network (AR-PNN) is introduced to optimize those design constraints and compute the cluster head (CH) of each cluster. Multipath firing is then performed using a moderated puffer-fish optimization (MPO) algorithm that finds the closest optimal and shortest node to transmit optimal drug data. The work is simulated using an NS-3 environment, and the results are obtained. The outcome of this work is analyzed with existing methodologies, and the results prove that the present work consistently outperforms the existing methodologies.}
}
@article{ARORA2022108615,
title = {Music as a blend of spirituality, culture, and mind mollifying drug},
journal = {Applied Acoustics},
volume = {189},
pages = {108615},
year = {2022},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108615},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X2100709X},
author = {Shefali Arora and Abhinav Tyagi},
keywords = {Music, Science, Emotions, Society, Health, COVID-19 etc},
abstract = {Science inspires music more often than human imagination. Music is an integral part of all societies, including animal ones. It is behaving like an instrument for digesting information. It has been proven to help in healing the body, mind, and culture. Music can maintain and regulate emotion. It is a common thread among large social groups and is used as a tool to navigate through life. Real science and real music require a steady thinking process. It is a way of finding compatibility within a society as well as developing a link with other societies. Music plays a developmental role in a person’s identity, cultural worldview and permeates through life. In nutshell “Science explains Music and Music makes us The Human”}
}
@article{SCHAEFER2024108796,
title = {GPT-4 as a biomedical simulator},
journal = {Computers in Biology and Medicine},
volume = {178},
pages = {108796},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108796},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524008813},
author = {Moritz Schaefer and Stephan Reichl and Rob {ter Horst} and Adele M. Nicolas and Thomas Krausgruber and Francesco Piras and Peter Stepper and Christoph Bock and Matthias Samwald},
keywords = {Biomedical simulation, Large language models, GPT-4, Computational biology, Artificial intelligence},
abstract = {Background
Computational simulation of biological processes can be a valuable tool for accelerating biomedical research, but usually requires extensive domain knowledge and manual adaptation. Large language models (LLMs) such as GPT-4 have proven surprisingly successful for a wide range of tasks. This study provides proof-of-concept for the use of GPT-4 as a versatile simulator of biological systems.
Methods
We introduce SimulateGPT, a proof-of-concept for knowledge-driven simulation across levels of biological organization through structured prompting of GPT-4. We benchmarked our approach against direct GPT-4 inference in blinded qualitative evaluations by domain experts in four scenarios and in two quantitative scenarios with experimental ground truth. The qualitative scenarios included mouse experiments with known outcomes and treatment decision support in sepsis. The quantitative scenarios included prediction of gene essentiality in cancer cells and progression-free survival in cancer patients.
Results
In qualitative experiments, biomedical scientists rated SimulateGPT's predictions favorably over direct GPT-4 inference. In quantitative experiments, SimulateGPT substantially improved classification accuracy for predicting the essentiality of individual genes and increased correlation coefficients and precision in the regression task of predicting progression-free survival.
Conclusion
This proof-of-concept study suggests that LLMs may enable a new class of biomedical simulators. Such text-based simulations appear well suited for modeling and understanding complex living systems that are difficult to describe with physics-based first-principles simulations, but for which extensive knowledge is available as written text. Finally, we propose several directions for further development of LLM-based biomedical simulators, including augmentation through web search retrieval, integrated mathematical modeling, and fine-tuning on experimental data.}
}
@article{1991202,
title = {Use of computational methods in drug design},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {11},
number = {2},
pages = {202-203},
year = {1991},
issn = {0169-7439},
doi = {https://doi.org/10.1016/0169-7439(91)80072-X},
url = {https://www.sciencedirect.com/science/article/pii/016974399180072X}
}
@article{LAW2023112555,
title = {Frontopolar cortex represents complex features and decision value during choice between environments},
journal = {Cell Reports},
volume = {42},
number = {6},
pages = {112555},
year = {2023},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2023.112555},
url = {https://www.sciencedirect.com/science/article/pii/S2211124723005661},
author = {Chun-Kit Law and Nils Kolling and Chetwyn C.H. Chan and Bolton K.H. Chau},
keywords = {frontopolar cortex, ventromedial prefrontal cortex, decision making, environment choice, convolutional neural network, CNN},
abstract = {Summary
Important decisions often involve choosing between complex environments that define future item encounters. Despite its importance for adaptive behavior and distinct computational challenges, decision-making research primarily focuses on item choice, ignoring environment choice altogether. Here we contrast previously studied item choice in ventromedial prefrontal cortex with lateral frontopolar cortex (FPl) linked to environment choice. Furthermore, we propose a mechanism for how FPl decomposes and represents complex environments during decision making. Specifically, we trained a choice-optimized, brain-naive convolutional neural network (CNN) and compared predicted CNN activation with actual FPl activity. We showed that the high-dimensional FPl activity decomposes environment features to represent the complexity of an environment to make such choice possible. Moreover, FPl functionally connects with posterior cingulate cortex for guiding environment choice. Further probing FPl’s computation revealed a parallel processing mechanism in extracting multiple environment features.}
}
@article{NAWAZ2024102806,
title = {Grappling with a sea change: Tensions in expert imaginaries of marine carbon dioxide removal},
journal = {Global Environmental Change},
volume = {85},
pages = {102806},
year = {2024},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2024.102806},
url = {https://www.sciencedirect.com/science/article/pii/S0959378024000104},
author = {Sara Nawaz and Javier Lezaun},
abstract = {While research on marine carbon dioxide removal (mCDR) expands apace, significant unknowns persist regarding the risks and benefits of individual mCDR options. This paper analyses the assumptions and expectations that animate expert understandings of mCDR, with a focus on issues that are central to the responsible governance of this emerging field of climate action. Drawing upon interviews with experts involved in mCDR research projects both academic and entrepreneurial, we highlight four thematic tensions that orient their thinking but are often unstated or left implicit in scientific and technical assessments: (1) the relevance of ‘naturalness’ as a criterion of evaluation for mCDR approaches; (2) the perceived need to accelerate research and development activities via alternative paradigms of evidence-building; (3) a framing of mCDR as a form of waste management that will, in turn, generate new (and currently poorly understood) forms of environmental pollutants; and (4) a commitment to inclusive governance mixed with difficulty in identifying specific stakeholders or constituencies in mCDR interventions. Although expert consensus on these four issues is unlikely, we suggest ways of ensuring that consideration of these themes enriches debate on the responsible development of novel mCDR capabilities.}
}
@article{VADIATI2025100120,
title = {(En) coding care into digital urbanism: Vignettes of collective practices},
journal = {Digital Geography and Society},
pages = {100120},
year = {2025},
issn = {2666-3783},
doi = {https://doi.org/10.1016/j.diggeo.2025.100120},
url = {https://www.sciencedirect.com/science/article/pii/S2666378325000091},
author = {Niloufar Vadiati and Letizia Chiappini and Martin Bangratz},
keywords = {Care, Digital urbanism, Refusing, Commoning, Reappropriating},
abstract = {The tech-entrepreneurial model behind the computation of urban processes is (re) producing what has already been identified as a technocratic, solutionist, and commodifying model of urban planning. Within this model, not only is caring not a prerequisite of urban production, but decade(s)in of smartification and platformization practices shows diminishing the spaces, infrastructure, and socio-economic relations that were co-produced to generate care. Through the lens of feminist geography, care is examined as a multidimensional concept encompassing socio-spatial dynamics, power relations, and ethical urban practices. Using empirical data from three research projects, the study showcases alternative digital urbanism practices, categorized into three vignettes: refusal, commoning, and reappropriation. These categories are illustrated with cases such as grassroots food cooperatives, feminist hack-spaces, digital sovereignty initiatives, platform-based welfare experiments and civil society initiatives such as Code for Germany. By situating care within the spatial and social fabric of urban life, the paper argues for its potential as a politic, practice, and epistemology that challenges the exploitative logic of contemporary digital infrastructures. The findings reveal the embeddedness of care practices within local contexts, highlighting the dual need for trans-local networks and territorial embeddedness. This study contributes to the discourse on caring digital urbanism, advancing a feminist theorisation of everyday digital urbanism.}
}
@article{WOLFENGAGEN2016359,
title = {Migration of the Individuals},
journal = {Procedia Computer Science},
volume = {88},
pages = {359-364},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.449},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916317057},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey V. Kosikov and Irina A. Parfenova and Mikhail Yu. Ermak and Vasiliy D. Petrov and Ilya A. Nikulin and Victor A. Kholodov},
keywords = {data model, computational model, conceptual modeling, stage-by-stage cognition model, variable domains, Big Data, Thick Data},
abstract = {The individuals are modeled by the elements of variable domains. The primitive frame to detect the individual migration from domain to domain is proposed. The supporting computational model is based on a separation of individuals into actual, possible and virtual ones. As was shown, this leads to an adoption of the stage-by-stage cognition model with a pair of evolvents to capture dynamics of the domains – the 2-dimensions model. The first evolvent reflects the generation of the individuals in a domain, the beginning of and canceling out their existence in a domain. The second evolvent reflects the shifts in properties of the individuals. As awaited this unified data model will have the applications to a wide range of models in computer science and Information Technologies.}
}
@incollection{STAPLETON2014127,
title = {8.07 - Administrative Evil and Patient Health: A Critique of the Impact of Manufacturing Systems on Health Care},
editor = {Saleem Hashmi and Gilmar Ferreira Batalha and Chester J. {Van Tyne} and Bekir Yilbas},
booktitle = {Comprehensive Materials Processing},
publisher = {Elsevier},
address = {Oxford},
pages = {127-150},
year = {2014},
isbn = {978-0-08-096533-8},
doi = {https://doi.org/10.1016/B978-0-08-096532-1.00813-X},
url = {https://www.sciencedirect.com/science/article/pii/B978008096532100813X},
author = {L. Stapleton},
keywords = {AMAT, Health, Manufacturing},
abstract = {Manufacturing systems principles underpin enterprise information systems. Nowadays these principles, and the systems that accompany them, are widely applied across various sectors, including health services management systems. The question arises: To what extent are these principles appropriate for health care management applications? This chapter explores the question from a human-centered systems perspective by examining the rationalities and assumptions that underpin manufacturing systems and applying these ideas to health care contexts. Human-centered systems have a long theoretical tradition within the automation and control community stretching back at least into the 1970s. It is a particularly strong theme in manufacturing systems research. As automation and control systems are increasingly important outside the factory, many researchers are revisiting core concepts within this tradition. One particularly important sector is health care, which, in recent years, has implemented a range of AMAT (automation and machine-assisted thinking)-type solutions not the least of which are enterprise resource planning systems (ERPs). These implementations have been accompanied by highly publicized systems failures. Ethical problems have also arisen. The chapter exposes an ‘administrative evil’ that relegates the patient to the status of a subassembly, a component in an ever-more complex health care production line. Humans are dehumanized in the rationality of our health care administrative systems. The chapter concludes that health care systems projects should adopt a human-centered approach that draws on research in manufacturing, automation, and control engineering as well as other disciplines.}
}
@article{VIDENOVIK2024100616,
title = {Game-based learning approach in computer science in primary education: A systematic review},
journal = {Entertainment Computing},
volume = {48},
pages = {100616},
year = {2024},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2023.100616},
url = {https://www.sciencedirect.com/science/article/pii/S187595212300071X},
author = {Maja Videnovik and Ana {Madevska Bogdanova} and Vladimir Trajkovik},
keywords = {Educational game, Game-based learning, Computer science, Primary education},
abstract = {This paper reviews the current situation concerning the implementation of game-based learning in computer science in primary education, providing insight into current trends, identifying strengths and potential research topics. Articles published in four databases from 2017 to 2021 are included in the analysis and an in-depth analysis of 32 articles is done. Different types of games, implemented in various educational contexts, are presented in these articles. Most of them describe implemented methodology, game-based environment or are evaluating the effectiveness of the created game or the approach. The possibility of implementing a game-based approach while learning other computer science topics or measuring the effectiveness of learning by designing a game as a pedagogical strategy are some areas for future research.}
}
@article{LIU2022102936,
title = {A review of spatially-explicit GeoAI applications in Urban Geography},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {112},
pages = {102936},
year = {2022},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2022.102936},
url = {https://www.sciencedirect.com/science/article/pii/S1569843222001339},
author = {Pengyuan Liu and Filip Biljecki},
keywords = {Urban studies, Deep learning, Socio-economics, Location encoder, Graph neural network},
abstract = {Urban Geography studies forms, social fabrics, and economic structures of cities from a geographic perspective. Catalysed by the increasingly abundant spatial big data, Urban Geography seeks new models and research paradigms to explain urban phenomena and address urban issues. Recent years have witnessed significant advances in spatially-explicit geospatial artificial intelligence (GeoAI), which integrates spatial studies and AI, primarily focusing on incorporating spatial thinking and concept into deep learning models for urban studies. This paper provides an overview of techniques and applications of spatially-explicit GeoAI in Urban Geography based on 581 papers identified using a systematic review approach. We examined and screened papers in three scopes of Urban Geography (Urban Dynamics, Social Differentiation of Urban Areas, and Social Sensing) and found that although GeoAI is a trending topic in geography and the applications of deep neural network-based methods are proliferating, the development of spatially-explicit GeoAI models is still at their early phase. We identified three challenges of existing models and advised future research direction towards developing multi-scale explainable spatially-explicit GeoAI. This review paper acquaints beginners with the basics of GeoAI and state-of-the-art and serve as an inspiration to attract more research in exploring the potential of spatially-explicit GeoAI in studying the socio-economic dimension of the city and urban life.}
}
@article{GAULD2024116255,
title = {Exploring the interplay of clinical reasoning and artificial intelligence in psychiatry: Current insights and future directions},
journal = {Psychiatry Research},
volume = {342},
pages = {116255},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.116255},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124005407},
author = {Christophe Gauld and Vincent P. Martin and Hugo Bottemanne and Pierre Fourneret and Jean-Arthur Micoulaud-Franchi and Guillaume Dumas},
keywords = {Artificial intelligence, Statistical prediction, Psychiatry, Computational sciences, Explainability, Deep learning},
abstract = {For many years, it has been widely accepted in the psychiatric field that clinical practice cannot be reduced to finely tuned statistical prediction systems utilizing diverse clinical data. Clinicians are recognized for their unique and irreplaceable roles. In this brief historical overview, viewed through the lens of artificial intelligence (AI), we propose that comprehending the reasoning behind AI can enhance our understanding of clinical reasoning. Our objective is to systematically identify the factors that shape clinical reasoning in medicine, based on six factors that were historically considered beyond the reach of statistical methods: open-endedness, unanalyzed stimulus-equivalences, empty cells, theory mediation, insufficient time, and highly configured functions. Nevertheless, a pertinent consideration in the age of AI is whether these once-considered insurmountable specific factors of clinicians are now subject to scrutiny or not. Through example in AI, we demonstrate that a deeper understanding of these factors not only sheds light on clinical decision-making and its heuristic processes but also underscores the significance of collaboration between AI experts and healthcare professionals. This comparison between AI and clinical reasoning contributes to a better grasp of the current challenges AI faces in the realm of clinical medicine.}
}
@article{SAMSONOVICH2022824,
title = {Key Advanced Research Initiative: A Manifesto for the New-Generation Artificial Intelligence},
journal = {Procedia Computer Science},
volume = {213},
pages = {824-831},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.140},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922018397},
author = {Alexei V. Samsonovich and Sergey A. Shumsky and Valery E. Karpov and Artemy A. Kotov and Anton G. Kolonin},
keywords = {AGI, humanlike AI, strong AI, virtual evolution, machine learning, evolutionary computation, artificial creativity, anthropocentric AI},
abstract = {The goal here is to identify key directions for the future advanced research initiatives in Artificial Intelligence (AI) and beyond. The following areas are identified as having particular importance: (1) socially emotional, ethical, and moral AI, (2) self-developing and self-sustainable AI, and (3) human-analogous AI, inspired by the human psychology. As a result, a general concept is formulated with the intent to clarify and unify the currently popular slogans, including Artificial General Intelligence (AGI), Strong AI, Human-Level or Humanlike AI (HLAI), Brain-Inspired or Biologically Inspired Cognitive Architectures (BICA), and more. The key idea of the proposed concept is that future AI must open a new angle of view and new perspectives to humans, thereby enriching and transforming the society, helping it to solve its problems and taking the civilization to a new level. While being created by humans, for humans, and fully compatible with humans at the social level, it will not be “a human in silicon”, but rather an “alien”: intelligent, friendly, and welcome. Its principles will combine preprogrammed basic functions and its own natural ontogeny in a virtual social environment. Forms of implementation will range from virtual entities to wearable electronics and autonomous robots. The expected impact on the society will be immense and crucial for its survival.}
}
@article{WANG20221,
title = {The past and future of mapping the biomarkers of psychosis},
journal = {Current Opinion in Behavioral Sciences},
volume = {43},
pages = {1-5},
year = {2022},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2021.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352154621001261},
author = {Ling-Ling Wang and Simon SY Lui and Raymond CK Chan},
abstract = {Biomarker research has investigated the neurobiological basis for individual differences in liability to psychosis. However, few biomarkers for psychosis have been consistently found to be useful. This paper reviews several previous approaches to identify putative biomarkers of liability to psychosis, and then highlights the lessons that we have learned. We argue that limiting our research to clinical patients at the extreme of the psychosis continuum would likely obscure our knowledge as to how a minority of the general population would develop psychosis. Research on putative neurobiological origins of inter-individual differences in personality traits may be useful in mapping the biomarkers of psychosis. To identify biomarkers applicable to the general population, we advocate the transdiagnostic and psychosis continuum approach. We also advocate the use of multivariate analyses and computational modelling to tackle complex multi-modal datasets. More research should be conducted to study intra-individual variations over different ranges of timescale.}
}
@article{BRANASGARZA2012254,
title = {Cognitive effort in the Beauty Contest Game},
journal = {Journal of Economic Behavior & Organization},
volume = {83},
number = {2},
pages = {254-260},
year = {2012},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2012.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0167268112001278},
author = {Pablo Brañas-Garza and Teresa García-Muñoz and Roberto Hernán González},
keywords = {Beauty Contest Game, Raven, Cognitive Reflection Test},
abstract = {This paper analyzes cognitive effort in 6 different oneshot p-beauty games. We use both Raven and Cognitive Reflection tests to identify subjects’ abilities. We find that the Raven test does not provide any insight on Beauty Contest Game playing but CRT does: subjects with higher scores on this test are more prone to play dominant strategies. The results are confirmed when levels of reasoning instead of entries in the BCG are used.}
}
@article{KNIGHT20158,
title = {Making grammars: From computing with shapes to computing with things},
journal = {Design Studies},
volume = {41},
pages = {8-28},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000605},
author = {Terry Knight and George Stiny},
keywords = {computational model(s), design theory, perception, reflective practice, shape grammar},
abstract = {Recent interest in making and materiality spans from the humanities and social sciences to engineering, science, and design. Here, we consider making through the lens of a unique computational theory of design: shape grammars. We propose a computational theory of making based on the improvisational, perception and action approach of shape grammars and the shape algebras that support them. We modify algebras for the materials (basic elements) of shapes to define algebras for the materials of objects, or things. Then we adapt shape grammars for computing shapes to making grammars for computing things. We give examples of making grammars and their algebras. We conclude by reframing designing and making in light of our computational theory of making.}
}
@incollection{SARSANI2011231,
title = {Computers and Creativity},
editor = {Mark A. Runco and Steven R. Pritzker},
booktitle = {Encyclopedia of Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {231-240},
year = {2011},
isbn = {978-0-12-375038-9},
doi = {https://doi.org/10.1016/B978-0-12-375038-9.00041-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123750389000418},
author = {M.R. Sarsani},
keywords = {Approaches to creativity, Computer applications, Computer functions, Computers, Computers and creativity, Creativity definitions, Metaphor, Problem solving, Productivity tools},
abstract = {Computers have entered all walks of human life across the world. Computers are being used by people of all ages and in every profession, in their work as well as in their leisure. There is growing interest in the application of computer-based productivity tools to support simulation effects, higher level thinking, metacognitive processes, maintaining interest, promoting learning, developing curiosity, and fostering creativity. The Internet has brought abort a revolution in the world of information technology by providing searching facilities for exploring or seeking information from all over the world (e.g., e-learning, e-shopping, e-mail, Telnet and Usenet, audio and video conferences, etc.). Different viewpoints have been put forward to explain the concept, emphasizing different aspects of creativity. Generally, creativity has been discussed in terms of its end product, creative person, creative process, and creative press or environments. There are no substantial researches directly measuring the effect of the computer simulation technology to support either uncreative drill or creative production. Some researchers speculate that computer simulation technology may have a positive effect on creativity. However, due to a lack of empirical research, the true effect of simulation technology on creativity is still unknown and inconclusive.}
}
@incollection{TIN1994299,
title = {Baby-Sit: Towards a situation-theoretic computational environment},
editor = {Carlos Martín-Vide},
series = {North-Holland Linguistic Series: Linguistic Variations},
publisher = {Elsevier},
volume = {56},
pages = {299-308},
year = {1994},
booktitle = {Current Issues in Mathematical Linguistics},
issn = {0078-1592},
doi = {https://doi.org/10.1016/B978-0-444-81693-1.50034-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444816931500348},
author = {Erkan Tin and Varol Akman},
abstract = {Publisher Summary
This chapter provides an overview of a situation-theoretic computational environment. Situation theory was first formulated in detail by Jon Barwise and John Perry in 1983. Various versions of the theory have been applied to a number of linguistic issues, resulting in what is commonly known as situation semantics. Individuals, properties, relations, spatio-temporal locations, and situations are the basic constructs of situation theory. The world is viewed as a collection of objects, sets of objects, properties, and relations. Infons are discrete items of information and situations are first-class objects that describe parts of the real world. Information flow is made possible by a network of abstract links among high-order uniformities, viz. situation types. The chapter presents a computational approach to situation theory and its associated environment (called BABY-SIT). The environment is dubbed BABY-SIT because it is believed that presently it includes far too many provisional, make-shift design decisions. The chapter highlights that compared to existing approaches, BABY-SIT enhances the basic features of situation theory.}
}
@article{SUN2025105522,
title = {Memory-MambaNav: Enhancing object-goal navigation through integration of spatial–temporal scanning with state space models},
journal = {Image and Vision Computing},
volume = {158},
pages = {105522},
year = {2025},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2025.105522},
url = {https://www.sciencedirect.com/science/article/pii/S0262885625001106},
author = {Leyuan Sun and Yusuke Yoshiyasu},
keywords = {Embodied artificial intelligence, Robotic vision, Object-goal navigation, State space models, Spatial–temporal modeling, Reinforcement learning},
abstract = {Object-goal Navigation (ObjectNav) involves locating a specified target object using a textual command combined with semantic understanding in an unknown environment. This requires the embodied agent to have advanced spatial and temporal comprehension about environment during navigation. While earlier approaches focus on spatial modeling, they either do not utilize episodic temporal memory (e.g., keeping track of explored and unexplored spaces) or are computationally prohibitive, as long-horizon memory knowledge is resource-intensive in both storage and training. To address this issue, this paper introduces the Memory-MambaNav model, which employs multiple Mamba-based layers for refined spatial–temporal modeling. Leveraging the Mamba architecture, known for its global receptive field and linear complexity, Memory-MambaNav can efficiently extract and process memory knowledge from accumulated historical observations. To enhance spatial modeling, we introduce the Memory Spatial Difference State Space Model (MSD-SSM) to address the limitations of previous CNN and Transformer-based models in terms of receptive field and computational demand. For temporal modeling, the proposed Memory Temporal Serialization SSM (MTS-SSM) leverages Mamba’s selective scanning capabilities in a cross-temporal manner, enhancing the model’s temporal understanding and interaction with bi-temporal features. We also integrate memory-aggregated egocentric obstacle-awareness embeddings (MEOE) and memory-based fine-grained rewards into our end-to-end policy training, which improve obstacle understanding and accelerate convergence by fully utilizing memory knowledge. Our experiments on the AI2-Thor dataset confirm the benefits and superior performance of proposed Memory-MambaNav, demonstrating Mamba’s potential in ObjectNav, particularly in long-horizon trajectories. All demonstration videos referenced in this paper can be viewed on the webpage (https://sunleyuan.github.io/Memory-MambaNav).}
}
@article{DING2012264,
title = {Finding MicroRNA Targets in Plants: Current Status and Perspectives},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {10},
number = {5},
pages = {264-275},
year = {2012},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2012.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1672022912000733},
author = {Jiandong Ding and Shuigeng Zhou and Jihong Guan},
keywords = {MicroRNA, Target prediction, Degradome-seq, Integration},
abstract = {MicroRNAs (miRNAs), a class of ∼20–24nt long non-coding RNAs, have critical roles in diverse biological processes including development, proliferation, stress response, etc. With the development and availability of experimental technologies and computational approaches, the field of miRNA biology has advanced tremendously over the last decade. By sequence complementarity, miRNAs have been estimated to regulate certain mRNA transcripts. Although it was once thought to be simple and straightforward to find plant miRNA targets, this viewpoint is being challenged by genetic and biochemical studies. In this review, we summarize recent progress in plant miRNA target recognition mechanisms, principles of target prediction, and introduce current experimental and computational tools for plant miRNA target prediction. At the end, we also present our thinking on the outlook for future directions in the development of plant miRNA target finding methods.}
}
@article{FESTA2024,
title = {Incidence of circular refurbishment measures on indoor air quality and comfort conditions in two real buildings: Experimental and numerical analysis},
journal = {Energy and Built Environment},
year = {2024},
issn = {2666-1233},
doi = {https://doi.org/10.1016/j.enbenv.2024.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666123324000394},
author = {Valentino Festa and Silvia Ruggiero and Sara Riccardi and Margarita- Niki Assimakopoulos and Dimitra Papadaki},
keywords = {Energy building refurbishment, Experimental campaign, Indoor air quality, Thermal comfort, Computational fluid dynamics analysis},
abstract = {The application of Circular Economy to construction sector is a key to attain carbon neutrality, since it is responsible of 40 % of natural resource consumption. In this frame the importance of an efficient building refurbishment process throughout recycled material and renewable energy is fundamental. From an overview about building refurbishment emerges the need to investigate aspects related to Indoor Environmental Quality and the comparison between in-field measurements with output of dynamic simulation models. The present study aims to fill these two gaps by means an energy renovation of two real buildings in Greece. The work develops within the European project “Drive 0″, born to promote deep environmentally friendly retrofitting by means of circular renovation concepts. The methodological approach involves on-site monitoring of a series of parameters describing the energy, microclimate environmental and air quality, before and after the energy requalification. In addition, a numerical model developed in Building Energy Simulation program is calibrated and a Computational Fluid Dynamics is developed. From the in-field measurements emerges that, on one hand, the refurbishment of heating system shows a great improvement of indoor thermal conditions, with Total Volatile Organic Compounds concentration that sometimes exceed 3.0 mg/m3; on the other hand an integrated thermal insulation reduces infiltrations and changes the envelope behaviour, with a global energy saving of 30 % during winter and autumn periods. Another result of the study shows that a numerical model developed in Building Energy Simulation program and calibrated on energy consumption can greatly fit the local thermal comfort distribution of the occupant zone and predict the indoor air quality, if it outputs are used as input data in a Computational Fluid Dynamics study. These results can be beneficial to decision makers and designers for evaluating emitters positioning, opening design and mechanical ventilation strategies, aimed at reducing energy costs.}
}
@article{YANG2022107728,
title = {Mixed data-driven sequential three-way decision via subjective–objective dynamic fusion},
journal = {Knowledge-Based Systems},
volume = {237},
pages = {107728},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107728},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121009692},
author = {Xin Yang and Yang Chen and Hamido Fujita and Dun Liu and Tianrui Li},
keywords = {Three-way decision, Sequential three-way decision, Mixed data, subjective–objective, Dynamic fusion},
abstract = {In the context of granular computing, sequential three-way decision is a useful tool to triadic thinking, triadic computing and triadic processing from coarser to finer under multilevel and multiview granularity space. In this paper, we mainly explore a novel framework of sequential three-way decision for the fusion of mixed data from the subjective and objective dynamic perspectives. The former focuses on the decision maker’s dynamic behavior without considering the time-evolving data, and the latter emphasizes on dealing with dynamic mixed data over time by multi-stage decision-making. We firstly utilize four T-norm operators and kernel-based similarity relations to integrate different types of dynamic data. Then the subjective and objective models of sequential three-way decision are investigated based on decision thresholds, attribute importance and cost reduction. Finally, the comparative experiments are reported to verify that our proposed models can achieve the lower decision cost and the acceptable accuracy.}
}
@article{KISELEV2022e09664,
title = {Predicting verbal reasoning from virtual community membership in a sample of Russian young adults},
journal = {Heliyon},
volume = {8},
number = {6},
pages = {e09664},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e09664},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022009525},
author = {Pavel Kiselev and Valeriya Matsuta and Artem Feshchenko and Irina Bogdanovskaya and Boris Kiselev},
keywords = {Verbal reasoning, Social networking site, Virtual community, Machine learning},
abstract = {Predicting personality traits from social networking site profiles can help to assess individual differences in verbal reasoning without using long questionnaires. Inspired by earlier studies, which investigated whether abstract-thinking ability are predictable by social networking sites data, we used supervised machine learning to predict verbal-reasoning ability based on a proposed set of features extracted from virtual community membership. A large sample (N = 3,646) of Russian young adults aged 18–22 years approved access to the data from their social networking accounts and completed an online test on verbal reasoning. We experimented with binary classification machine-learning models for verbal-reasoning prediction. Prediction performance was tested on isolated control subsamples for men and women. The results of prediction on AUC-ROC metrics for control subsamples over 0.7 indicated reasonably good performance on predicting verbal-reasoning level. We also investigated the contribution of virtual community's genres to verbal reasoning level prediction for male and female participants. Theoretical interpretations of results stemming from both Vygotsky's sociocultural theory and behavioural genomics are discussed, including the implication that virtual communities make up a non-shared environment that can cause variance in verbal reasoning. We intend to conduct studies to explore the implications of the results further.}
}
@article{ELIAZ2010304,
title = {Paying for confidence: An experimental study of the demand for non-instrumental information},
journal = {Games and Economic Behavior},
volume = {70},
number = {2},
pages = {304-324},
year = {2010},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2010.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0899825610000229},
author = {Kfir Eliaz and Andrew Schotter},
abstract = {This paper presents experimental evidence that when individuals are about to make a given decision under risk, they are willing to pay for information on the likelihood that this decision is ex-post optimal, even if this information will not affect their decision. Our findings suggest that this demand for non-instrumental information is caused by what we refer to as a “confidence effect”: the desire to increase one's posterior belief by ruling out “bad news”, even when such news would have no effect on one's decision. We conduct various treatments to show that our subjects' behavior is not likely to be caused by an intrinsic preference for information, failure of backward induction or an attempt to minimize thinking costs.}
}
@article{SCHEFFLER201575,
title = {NeurOS™ and NeuroBlocks™ a neural/cognitive operating system and building blocks},
journal = {Biologically Inspired Cognitive Architectures},
volume = {11},
pages = {75-105},
year = {2015},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2014.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X14000747},
author = {Lee Scheffler},
keywords = {Cognition, Perception, Pattern recognition, Memory, Learning, Behavior},
abstract = {NeurOS is an open platform for accelerating research, development and hosting execution of intelligent applications. A NeurOS application is a directed “neural graph” of modular components connected by signal paths, similar to biological brain connectivity and functional block diagrams of neural pathways. Built-in reusable modules (NeuroBlocks) provide a wide range of general- and special-purpose capabilities: inputs/senses, outputs/effectors, processing, memory, pattern learning and recognition, visualization/instrumentation, custom module development, integrating external intelligence capabilities, and sub-graph reuse. NeurOS sub-graph assemblies address neural/cognitive functions including perception, pattern learning and recognition, working memory, imagination, prediction, context priming, attention, abstraction, classification, associational thinking and behavior. NeurOS applications are inherently portable, scalable, networkable, extensible and embeddable. NeurOS development tools provide simple intuitive graphical drag and drop application assembly from components without programming, along with testing, debugging, monitoring and visualization. Prototype NeurOS applications have begun to explore a wide range of intelligent functions in diverse areas, including aspects of pattern recognition, vision, music, reading, puzzle solving, reasoning, behavior. Building working intelligent systems using NeurOS and NeuroBlocks lets researchers and developers focus on their core functions and rapidly iterate and instrument working models, fostering both analytical and biological insight as well as usable systems.}
}
@article{KOLIBIUS2025,
title = {On the origin of memory neurons in the human hippocampus},
journal = {Trends in Cognitive Sciences},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2025.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S1364661325000312},
author = {Luca D. Kolibius and Sheena A. Josselyn and Simon Hanslmayr},
keywords = {episodic memory, hippocampus, concept neurons, Indexing Theory, single neurons, conjunctive coding, memory trace, engram},
abstract = {The hippocampus is essential for episodic memory, yet its coding mechanism remains debated. In humans, two main theories have been proposed: one suggests that concept neurons represent specific elements of an episode, while another posits a conjunctive code, where index neurons code the entire episode. Here, we integrate new findings of index neurons in humans and other animals with the concept-specific memory framework, proposing that concept neurons evolve from index neurons through overlapping memories. This process is supported by engram literature, which posits that neurons are allocated to a memory trace based on excitability and that reactivation induces excitability. By integrating these insights, we connect two historically disparate fields of neuroscience: engram research and human single neuron episodic memory research.}
}
@article{RULE2020900,
title = {The Child as Hacker},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {11},
pages = {900-915},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320301741},
author = {Joshua S. Rule and Joshua B. Tenenbaum and Steven T. Piantadosi},
keywords = {Learning and cognitive development, Language of thought, Hacking, Computational modeling, Program induction},
abstract = {The scope of human learning and development poses a radical challenge for cognitive science. We propose that developmental theories can address this challenge by adopting perspectives from computer science. Many of our best models treat learning as analogous to computer programming because symbolic programs provide the most compelling account of sophisticated mental representations. We specifically propose that children’s learning is analogous to a particular style of programming called hacking, making code better along many dimensions through an open-ended set of goals and activities. By contrast to existing theories, which depend primarily on local search and simple metrics, this view highlights the many features of good mental representations and the multiple complementary processes children use to create them.}
}
@article{FALOMIR201931,
title = {Special issue on problem-solving, creativity and spatial reasoning},
journal = {Cognitive Systems Research},
volume = {58},
pages = {31-34},
year = {2019},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S138904171930261X},
author = {Zoe Falomir and Ana-Maria Olteţeanu},
keywords = {Cognitive systems, Problem-solving, Creativity, Computational creativity, Spatial reasoning, Cognition, General artificial intelligence, Spatial cognition},
abstract = {Problem-solving, creativity and spatial reasoning are high level abilities of cognitive systems with high potential for synergies. However, they have been treated separately by different fields. This special issue presents research work on these topics, aiming to observe their interrelations in order to create theoretical approaches, methodologies and computational tools to advance work on creativity and spatial problem-solving in cognitive systems.}
}
@incollection{KAMPIS1991345,
title = {Chapter Seven - SELF-REPRODUCTION AND COMPUTATION},
editor = {GEORGE KAMPIS},
booktitle = {Self-Modifying Systems in Biology and Cognitive Science},
publisher = {Pergamon},
address = {Amsterdam},
pages = {345-403},
year = {1991},
volume = {6},
series = {IFSR International Series on Systems Science and Engineering},
isbn = {978-0-08-036979-2},
doi = {https://doi.org/10.1016/B978-0-08-036979-2.50012-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780080369792500124},
author = {GEORGE KAMPIS}
}
@article{CHERNYSHOV20151345,
title = {Information Support and Skill Evaluation of Human-Operators},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {3},
pages = {1345-1350},
year = {2015},
note = {15th IFAC Symposium onInformation Control Problems inManufacturing},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.06.273},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315005121},
author = {K.R. Chernyshov and E.Ph Jharko},
keywords = {Human-operator, Information support, Flexible simulation, Evaluation of skills, Random processes, Measures of dependence},
abstract = {The paper presents an approach to design an intelligent information support system to be used as a human-operator assistant to control large complex industrial plants. Tasks and structure of such an intelligent information support system (IISS), IISS design stages, methodology of IISS design, toolkits for IISS design are considered. A flexible simulation complex (FSC) as such an intelligent toolkit has been presented. The complex is used as a “kernel” of IISS for human-operators of a nuclear power plant. A new approach to abnormal situations with regard for the heuristic regularities of human-operator thinking process is proposed. The regularities are revealed on basis of recording the motions of the human- operator eyes over the information field of the control board and processing the experimental data obtained. For data processing, a probability theoretical approach is used based on involving the notion of consistency of measures of dependence of random variables.}
}
@article{WOZNIAK2023489,
title = {BiLSTM deep neural network model for imbalanced medical data of IoT systems},
journal = {Future Generation Computer Systems},
volume = {141},
pages = {489-499},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22004095},
author = {Marcin Woźniak and Michał Wieczorek and Jakub Siłka},
keywords = {Medical informatics, Deep learning, Multi-optimization learning, BiLSTM, IoT},
abstract = {Health informatics is one of the most developed field in recent time. Computational Intelligence is among the most influential factors that may help to improve patient oriented and secure decision support model. In this article we present a model of IoT system, which combines BiLSTM deep learning with Decision Tree model and data balancing strategy used to help in automated diagnosis support. Presented solution include experimental series of data preprocessing using well established balancing algorithms with custom parameters and modifications in order to best prepare the data for the network training. Such algorithms are ADASYN, SMOTE-Tomek, etc. The system helps to evaluate questionnaires and securely exchange documents between patient and corresponding medical team. From the level of system patient and doctors are able to see automated diagnosis provided by deep learning model. The model gives an important advance to help patients faster. Results show that proposed BiLSTM deep learning with decision tree mode detects diseases from questionnaires with accuracy above 96%, precision above 88% and recall above 96% which proves efficiency of our proposed model.}
}
@article{FAYEZ2023105905,
title = {Moringa extract reverses pilocarpine-induced hippocampal sclerosis in rats with temporal lobe epilepsy},
journal = {Journal of Functional Foods},
volume = {111},
pages = {105905},
year = {2023},
issn = {1756-4646},
doi = {https://doi.org/10.1016/j.jff.2023.105905},
url = {https://www.sciencedirect.com/science/article/pii/S1756464623005054},
author = {Shaimaa Fayez and Nourhan {Hisham Shady} and Iten M. Fawzy and Sherif A. Maher and Entesar {Ali saber} and Mahmoud Elrehany and Alaa M. Alqahtani and Esam S. Allehyani and Ahmed M. Shawky and Usama {Ramadan Abdelmohsen} and Nada M. Mostafa},
keywords = {, Moringinine A, Computational studies, Epilepsy},
abstract = {The horseradish tree “Moringa oleifera” is the most nutritious terrestrial plant around the globe. Although native to India, its fast growth and drought resistance ability enabled the plant to be cultivated worldwide. In the current study, we report on the isolation of a new phenolic methyl ester namely moringinine A (1) along with four other known compounds viz. caffeic acid (2), ferulic acid (3), 4-hydroxybenzonitrile (4), and 4-hydroxyphenyl acetic acid (5) from Moringa seeds. The later compound was first to be isolated from family Moringaceae. Compounds identification was guided by interplay of NMR and HR-ESI-MS analysis. Anti-epileptic studies conducted in vivo showed that the extract attenuates convulsions by suppressing stress–induced pro-inflammatory markers TNF-α, IL-1β, IL-6, and IFN-ɣ whereas upregulating the anti-inflammatory markers TGF-β and IL-10 in the hippocampal tissues of epileptic rats. The isolated compounds were subjected to computational studies through docking on lactate dehydrogenase A(LDH) and interleukin-6 (IL-6), where all showed binding modes and interaction energies comparable to those of the reference drug diazepam. ADME investigation revealed good pharmacokinetic and drug-likeness properties. These results show that Moringa oleifera seeds could potentially be used as adjuvant in the management of epilepsy.}
}
@article{DELIMA2024107089,
title = {Integrating artificial intelligence and wing geometric morphometry to automate mosquito classification},
journal = {Acta Tropica},
volume = {249},
pages = {107089},
year = {2024},
issn = {0001-706X},
doi = {https://doi.org/10.1016/j.actatropica.2023.107089},
url = {https://www.sciencedirect.com/science/article/pii/S0001706X23002760},
author = {Vinicio Rodrigues {de Lima} and Mauro César Cafundó {de Morais} and Karin Kirchgatter},
keywords = {Mosquito-borne diseases, Species identification, Integrative approach},
abstract = {Mosquitoes (Diptera: Culicidae) comprise over 3500 global species, primarily in tropical regions, where the females act as disease vectors. Thus, identifying medically significant species is vital. In this context, Wing Geometric Morphometry (WGM) emerges as a precise and accessible method, excelling in species differentiation through mathematical approaches. Computational technologies and Artificial Intelligence (AI) promise to overcome WGM challenges, supporting mosquito identification. AI explores computers' thinking capacity, originating in the 1950s. Machine Learning (ML) arose in the 1980s as a subfield of AI, and deep Learning (DL) characterizes ML's subcategory, featuring hierarchical data processing layers. DL relies on data volume and layer adjustments. Over the past decade, AI demonstrated potential in mosquito identification. Various studies employed optical sensors, and Convolutional Neural Networks (CNNs) for mosquito identification, achieving average accuracy rates between 84 % and 93 %. Furthermore, larval Aedes identification reached accuracy rates of 92 % to 94 % using CNNs. DL models such as ResNet50 and VGG16 achieved up to 95 % accuracy in mosquito identification. Applying CNNs to georeference mosquito photos showed promising results. AI algorithms automated landmark detection in various insects' wings with repeatability rates exceeding 90 %. Companies have developed wing landmark detection algorithms, marking significant advancements in the field. In this review, we discuss how AI and WGM are being combined to identify mosquito species, offering benefits in monitoring and controlling mosquito populations.}
}
@article{FARHAT199435,
title = {Simulation of compressible viscous flows on a variety of MPPs: computational algorithms for unstructured dynamic meshes and performance results},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {119},
number = {1},
pages = {35-60},
year = {1994},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(94)00075-1},
url = {https://www.sciencedirect.com/science/article/pii/0045782594000751},
author = {Charbel Farhat and Stéphane Lanteri},
abstract = {We report here on our effort in simulating unsteady viscous flows on the iPSC-860, the CM-5 and the KSR-1 MPPs (Massively Parallel Processors), using a Monotonic Upwind Scheme for Conservation Laws finite volume/finite element method on fully unstructured fixed and moving grids. We advocate mesh partitioning with message passing as a portable paradigm for parallel processing. We present and discuss several performance results obtained on all three MPP systems in terms of interprocessor communication costs, I/O, scability and sheer performance.}
}
@article{BYLANDER1994165,
title = {The computational complexity of propositional STRIPS planning},
journal = {Artificial Intelligence},
volume = {69},
number = {1},
pages = {165-204},
year = {1994},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(94)90081-7},
url = {https://www.sciencedirect.com/science/article/pii/0004370294900817},
author = {Tom Bylander},
abstract = {I present several computational complexity results for propositional STRIPS planning, i.e., STRIPS planning restricted to ground formulas. Different planning problems can be defined by restricting the type of formulas, placing limits on the number of pre-and postconditions, by restricting negation in pre- and postconditions, and by requiring optimal plans. For these types of restrictions, I show when planning is tractable (polynomial) and intractable (NP-hard). In general, it is PSPACE-complete to determine if a given planning instance has any solutions. Extremely severe restrictions on both the operators and the formulas are required to guarantee polynomial time or even NP-completeness. For example, when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. When definite Horn ground formulas are permitted, determining plan existence is PSPACE-complete even if operators are limited to zero preconditions and one postcondition. One of the interesting tractable problems is if each operator is restricted to positive preconditions and one postcondition (only ground literals). The blocks-world problem, slightly modified, is a subproblem of this restricted planning problem. These results in combination with previous analyses are not encouraging for domain-independent planning.}
}
@article{WEI2025104318,
title = {Probability evaluation of blade flutter in a transonic compressor with inlet distortion using SSA-DBEN model},
journal = {Journal of Fluids and Structures},
volume = {135},
pages = {104318},
year = {2025},
issn = {0889-9746},
doi = {https://doi.org/10.1016/j.jfluidstructs.2025.104318},
url = {https://www.sciencedirect.com/science/article/pii/S0889974625000532},
author = {Jingshan Wei and Zhidong Chi and Shimin Wang and Qun Zheng and Wei Yan and Bin Jiang},
keywords = {Axial compressor, Total pressure distortion, Deep belief network, Sparrow search algorithm, Flutter probability assessment},
abstract = {Inlet distortion significantly impacts the aeroelastic stability of aircraft engines, posing potential risks to their reliability and performance. Evaluating the probability of flutter in compressor blades is an effective approach to quantifying uncertain vibration characteristics and assessing blade aeroelastic stability. To improve modeling accuracy and computational efficiency in this analysis, a prediction method based on the sparrow search algorithm -deep extreme belief network (SSA-DEBN) model is proposed. The proposed method is evaluated through a case study involving the flutter probability assessment of a typical compressor rotor under inlet total pressure distortion. The results demonstrate that the aerodynamic modal damping ratio initially decreases and then increases as the wavelength of the inlet distortion decreases, reaching a minimum when the sinusoidal wave number of the distortion is two. Under inlet distortion conditions, the aerodynamic modal damping ratio of the compressor blade follows an approximate normal distribution, with a flutter reliability of 98.48 %. The primary factors influencing compressor blade flutter are rotational speed, inlet total temperature, vibration frequency, inlet total pressure, outlet static pressure, and distortion amplitude. The SSA-DEBN method has high accuracy and efficiency in the evaluation of compressor blade flutter failure mode by comparative analysis.}
}
@article{BORDY201329,
title = {Radiotherapy out-of-field dosimetry: Experimental and computational results for photons in a water tank},
journal = {Radiation Measurements},
volume = {57},
pages = {29-34},
year = {2013},
note = {Proceedings of the Workshop: Dosimetry for Second Cancer Risk Estimation EURADOS Annual Meeting Vienna 2012},
issn = {1350-4487},
doi = {https://doi.org/10.1016/j.radmeas.2013.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1350448713002710},
author = {J.M. Bordy and I. Bessieres and E. d'Agostino and C. Domingo and F. d'Errico and A. {di Fulvio} and Ž. Knežević and S. Miljanić and P. Olko and A. Ostrowsky and B. Poumarede and S. Sorel and L. Stolarczyk and D. Vermesse},
keywords = {Radiotherapy, Photon dosimetry, Out of field doses, Scatter radiation, Leakage},
abstract = {The first objective of this work was to check and select a set of four kinds of passive photon, dosimeters (two thermo-luminescence dosimeter (TLD) types, one radiophotoluminescence (RPL) dosimeter and one optically stimulated luminescence (OSL) dosimeter) together with a common measurement protocol. Dosimeters were calibrated in a reference clinical linear acccelerator beam in a water tank at a reference facility at the Laboratoire National Henri Becquerel (CEA LIST/LNE LNHB, Saclay. Radiation qualities of 6, 12 and 20 MV were used with standard calibration conditions described in IAEA TRS 398 and non-standard conditions. Profile and depth dose ion chamber measurements were also made to provide reference values. Measurements were made in a water tank into which pipes could be inserted which held dosimeters in pre-determined and reproducible positions. The water tank was built to enable investigation of doses up to 60 cm from the beam axis. A first set of experiments was carried out with the beam passing through the tank. From this first experiment, penumbra and out-of-field dose profiles including water and collimator scatter and leakage were found over three orders of magnitude. Two further sets of experiments using the same experimental arrangement with the beam outside the tank, to avoid water scatter, were designed to measure collimator scatter and leakage by closing the jaws of the collimator. Depending on the energy, typical leakage and collimator scatter represents 10–40% and 30–50% of the total out-of-field doses respectively. It was concluded that all dosimeters can be used for out-of-field photon dosimetry. All show good uniformity, good reproducibility, and can be used down to low doses expected at distances remote from the subsequent radiotherapy target volume.}
}
@incollection{KOCH2009125,
title = {Consciousness: Theoretical and Computational Neuroscience},
editor = {Larry R. Squire},
booktitle = {Encyclopedia of Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {125-130},
year = {2009},
isbn = {978-0-08-045046-9},
doi = {https://doi.org/10.1016/B978-008045046-9.00407-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080450469004071},
author = {C. Koch and G. Tononi},
abstract = {Consciousness is a puzzling, state-dependent property of certain types of complex, adaptive, and highly interconnected systems. The best example is a healthy and attentive human brain. If the brain is anesthetized, consciousness ceases. Small lesions in the midbrain and thalamus of patients can lead to a complete loss of consciousness, while destruction of circumscribed parts of the cerebral cortex of patients can eliminate very specific aspects of consciousness, such as the ability to be aware of motion or to recognize objects (e.g., faces), without a concomitant loss of consciousness in general. Given the similarity in brain structure and behavior, biologists commonly assume that at least some animals, in particular nonhuman primates, share certain aspects of consciousness with humans. Brain scientists are exploiting a number of empirical approaches that shed light on the neural basis of consciousness. At present, it is not known to what extent artificial systems, such as computers, robots, or the World Wide Web as a whole, are or can become ‘conscious.’ What is needed is a theory of consciousness that explains in quantitative terms what types of systems, with what architecture, can possess conscious states.}
}
@article{MAGRI2023105535,
title = {Scene context is predictive of unconstrained object similarity judgments},
journal = {Cognition},
volume = {239},
pages = {105535},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105535},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723001695},
author = {Caterina Magri and Eric Elmoznino and Michael F. Bonner},
keywords = {Contextual associations, Objects, Scenes, Similarity, Convolutional neural networks, Natural image statistics},
abstract = {What makes objects alike in the human mind? Computational approaches for characterizing object similarity have largely focused on the visual forms of objects or their linguistic associations. However, intuitive notions of object similarity may depend heavily on contextual reasoning—that is, objects may be grouped together in the mind if they occur in the context of similar scenes or events. Using large-scale analyses of natural scene statistics and human behavior, we found that a computational model of the associations between objects and their scene contexts is strongly predictive of how humans spontaneously group objects by similarity. Specifically, we learned contextual prototypes for a diverse set of object categories by taking the average response of a convolutional neural network (CNN) to the scene contexts in which the objects typically occurred. In behavioral experiments, we found that contextual prototypes were strongly predictive of human similarity judgments for a large set of objects and rivaled the performance of models based on CNN representations of the objects themselves or word embeddings for their names. Together, our findings reveal the remarkable degree to which the natural statistics of context predict commonsense notions of object similarity.}
}
@article{BROWN19921,
title = {Some conceptual issues in the modeling and computational analysis of the Canada-U.S. Free Trade Agreement},
journal = {The North American Journal of Economics and Finance},
volume = {3},
number = {1},
pages = {1-20},
year = {1992},
issn = {1062-9408},
doi = {https://doi.org/10.1016/1062-9408(92)90009-G},
url = {https://www.sciencedirect.com/science/article/pii/106294089290009G},
author = {Drusilla K. Brown and Robert M. Stern},
abstract = {We present an interpretive history of the development of the computational analysis of the Canada-U.S. FTA. Several important conceptual issues are identified, including: perfect competition and national product differentiation; imperfect competition and increasing returns to scale; tariff liberalization and monopolistic competition; adjustment and dynamic effects; macroeconomic effects; and other pertinent aspects of market structure and firm behavior.}
}
@article{PEZZULO2013270,
title = {Action simulation in the human brain: Twelve questions},
journal = {New Ideas in Psychology},
volume = {31},
number = {3},
pages = {270-290},
year = {2013},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2013.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X13000263},
author = {Giovanni Pezzulo and Matteo Candidi and Haris Dindo and Laura Barca},
keywords = {Action simulation, Internal model, Forward model, Motor control, Action understanding},
abstract = {Although the idea of action simulation is nowadays popular in cognitive science, neuroscience and robotics, many aspects of the simulative processes remain unclear from empirical, computational, and neural perspectives. In the first part of the article, we provide a critical review and assessment of action simulation theories advanced so far in the wider literature of embodied and motor cognition. We focus our analysis on twelve key questions, and discuss them in the context of human and (occasionally) primate studies. In the second part of the article, we describe an integrative neuro-computational account of action simulation, which links the neural substrate (as revealed in neuroimaging studies of action simulation) to the components of a computational architecture that includes internal modeling, action monitoring and inhibition mechanisms.}
}
@article{PURWANTO2019118170,
title = {Using group model building to develop a causal loop mapping of the water-energy-food security nexus in Karawang Regency, Indonesia},
journal = {Journal of Cleaner Production},
volume = {240},
pages = {118170},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.118170},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619330409},
author = {Aries Purwanto and Janez Sušnik and F.X. Suryadi and Charlotte {de Fraiture}},
keywords = {Group model building, Causal loop diagram, Water-energy-food (WEF) security, Nexus modelling},
abstract = {This paper develops a qualitative causal model of a water, energy, and food (WEF) security nexus system to be used in analysing the interlinkages among those and other sectors that influence and are influenced by each other in a local context. Local stakeholder engagement through a group model building (GMB) approach was applied in Karawang Regency, Indonesia, to develop the model with the goals of improving problem understanding, raising consensus among participants, and building acceptance and commitment regarding the subsequent development of a quantitative nexus model. After recognizing the issues regarding water, energy and food sectors in the study area and eliciting opinions about nexus interactions, the next stage was to build a conceptual framework to describe the nexus system and to develop an integrated causal loop diagram (CLD) that describes critical system (inter-)linkages. The developed Karawang WEF security (K-WEFS) model is composed of six sub-models with water, energy and food sectors as endogenous factors. In addition, population, economic and ecosystem services were considered as exogenous drivers of the system. It is expected that all the major internal and external factors and drivers are covered, including possible feedback mechanisms, and key variables will be analysed further in the system. The future achievement of WEF security targets can be based on robust evaluation and planning processes underpinned by thorough understanding of whole system dynamics and the impacts of changes in the linked sectors, even in a qualitative way. In this way, a first step towards breaking silo thinking in regional planning may be attained.}
}
@article{JOHNSON1989319,
title = {Exploiting parallelism in computational science},
journal = {Future Generation Computer Systems},
volume = {5},
number = {2},
pages = {319-337},
year = {1989},
note = {Grand Challenges to Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/0167-739X(89)90050-2},
url = {https://www.sciencedirect.com/science/article/pii/0167739X89900502},
author = {Gary M. Johnson},
abstract = {The full exploitation of numerical simulation as an independent approach to the solution of engineering and scientific problems requires computing capability far exceeding that which is presently available. In this paper, the computing requirements posed by challenging problems in several disciplines are examined and contrasted with contemporary supercomputer resources. Of the means available to help fill the gap between the demands of computational science and the performance level of present-generation supercomputer systems, parallel processing appears to have the greatest potential for near-term success. Parallel computer architectures are reviewed and categorized according to processing units, memory, and interconnection scheme. Philosophies of parallel processing are discussed. They are distinguished by the number and size of the parallel tasks which they employ. Scientific problems are examined for parallelism inherent at the physical level. Typical algorithms and their mappings onto parallel architectures are discussed. Computational examples are presented to document the performance of scientific applications on present-generation parallel processors. Projections are made concerning software developments and machine architectures.}
}
@article{MU2025109748,
title = {Adaptive model-agnostic meta-learning network for cross-machine fault diagnosis with limited samples},
journal = {Engineering Applications of Artificial Intelligence},
volume = {141},
pages = {109748},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109748},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624019079},
author = {Mingzhe Mu and Hongkai Jiang and Xin Wang and Yutong Dong},
keywords = {Fault diagnosis, Rotating machine, Adaptive model-agnostic meta-learning network, Cross-machine, Limited samples},
abstract = {Deep learning-based methods have been extensively studied in rotating machinery defect diagnosis. However, training an accurate and robust diagnostic model is still a challenge under severe domain bias and limited samples. For this reason, a new adaptive model-agnostic meta-learning (AMAML) is proposed for cross-machine fault diagnosis with limited samples. First, a novel adaptive feature encode network is built, incorporating lightweight spatial-bilateral channel attention. This enables the network to extract critical fault information in multiple dimensions adaptively within limited samples, which improves the learning efficiency of generalized diagnostic knowledge. Then, an adaptive loss computation (ALC) method is devised, which inventively realizes the interaction between loss computation and model performance. The underfitting and overfitting dilemmas under few-shot conditions are tackled by ALC. Finally, an adaptive meta-optimization strategy is proposed for dynamically adapting the update strategy of the base learner, so that the model is always optimized in the direction of strong generalizability while obtaining high performance. Six cross-machine diagnosis tasks are conducted to verify the effectiveness of AMAML. The average diagnostic accuracy of the AMAML under the 5-shot setting reached 97.42%. Experiments confirm that AMAML is superior to other prevailing methods and is potentially promising for engineering applications.}
}
@incollection{MILLER2020181,
title = {Chapter eight - Data science and the exposome},
editor = {Gary W. Miller},
booktitle = {The Exposome (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {181-209},
year = {2020},
isbn = {978-0-12-814079-6},
doi = {https://doi.org/10.1016/B978-0-12-814079-6.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128140796000080},
author = {Gary W. Miller},
keywords = {Bioinformatics, systems biology, models, computational biology, machine learning, Bayesian methods, artificial intelligence, causal inference},
abstract = {Data science is focused on extracting meaningful value from complex datasets. Exposome-related data are certainly complex with information coming from a myriad of sources. The huge amounts of data must be organized in some manner that allows appropriate interpretations and associations to be drawn. It is unlikely that unsupervised approaches will allow for causal associations to be made, but with proper study design and appropriate statistical and computational models, it should be possible to derive meaningful connections between complex exposures and specific health outcomes. The complex types of data will undoubtedly require sophistical mathematical approaches, including bioinformatics, computational, machine learning, and systems biology-based techniques. This chapter reviews some of the possible strategies that can be used to keep track of the diverse and massive datasets that will result from exposome research.}
}
@article{PITTAPANTAZI2007301,
title = {Secondary school students’ levels of understanding in computing exponents},
journal = {The Journal of Mathematical Behavior},
volume = {26},
number = {4},
pages = {301-311},
year = {2007},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2007.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0732312307000508},
author = {Demetra Pitta-Pantazi and Constantinos Christou and Theodossios Zachariades},
keywords = {Exponents, Prototype, Conceptual change},
abstract = {The aim of this study is to describe and analyze students’ levels of understanding of exponents within the context of procedural and conceptual learning via the conceptual change and prototypes’ theory. The study was conducted with 202 secondary school students with the use of a questionnaire and semi-structured interviews. The results suggest that three levels of understanding can be identified. At the first level students’ interpretation of exponents is based upon exponents that symbolize natural numbers. At Level 2, students’ knowledge acquisition process is a process of enrichment of the existing conceptual structures. Students at this level are able to compute exponents with negative numbers by extending the application of prototype examples. Finally, at Level 3 students not only extend the prototype examples but also reorganize their thinking in order to compute and compare exponents with roots, a concept which is quite different from the concept of exponents with natural numbers.}
}
@article{GHAVAM2021128776,
title = {The life cycle environmental impacts of a novel sustainable ammonia production process from food waste and brown water},
journal = {Journal of Cleaner Production},
volume = {320},
pages = {128776},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.128776},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621029747},
author = {Seyedehhoma Ghavam and Caroline M. Taylor and Peter Styring},
keywords = {Green ammonia, Waste utilization, Carbon capture and sequestration, Carbon capture and utilization, Greenhouse gas emissions, Life cycle assessment},
abstract = {To replace existing high impact ammonia production technologies, a new sustainability-driven waste-based technology producing green ammonia with and without urea was devised using life cycle thinking and sustainable design principles, targeting efficiency, carbon emissions, water, and power use competitiveness. We have used life cycle assessment to determine whether cradle-to-gate, multiple configurations of the core waste-based processes integrating several carbon capture/utilization options can compete environmentally with other available ammonia technologies. Our waste-to-ammonia processes reduce potential impacts from abiotic depletion, human toxicity, and greenhouse gas (GHG) emissions relative to fossil-based and renewable technologies. Among the assessed technologies, coupling dark fermentation with anaerobic digestion and capturing CO2 for sequestration or later use is most efficient for GHGs, water, and energy, consuming 27% less energy and reducing GHGs by 98% compared to conventional ammonia. Water use is 38% lower than water electrolysis and GHGs are 94% below municipal waste incineration routes per kg NH3. Additionally, displacing conventional, high impact urea by integrating urea production from process CO2 decreases life cycle environmental impacts significantly despite increased energy demand. On a fertilizer-N basis, the ammonia + urea configuration without dark fermentation performs best on all categories included. Methane and ammonia leakage cause nearly all life cycle impacts, indicating that failing to prevent leakage undermines the effectiveness of new technologies such as these. Our results show that a green ammonia/ammonia + urea process family as designed here can reduce waste and prevent the release of additional CO2 from ammonia production while avoiding fossil-based alternatives and decreasing emissions from biogenic waste sources.}
}
@article{LIEVENS2021128,
title = {A service design perspective on the stakeholder engagement journey during B2B innovation: Challenges and future research agenda},
journal = {Industrial Marketing Management},
volume = {95},
pages = {128-141},
year = {2021},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2021.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0019850121000791},
author = {Annouk Lievens and Vera Blažević},
keywords = {Stakeholder engagement, B2B innovation process, Stakeholder engagement journey, Innovation networks, Service design},
abstract = {Innovation in business-to-business (B2B) contexts deals with highly dynamic, complex, and heterogeneous constellations of stakeholders with a diversity of goals, motives, and capabilities that further challenge successful management of B2B innovation processes and outcomes. Complex challenges, such as sustainability and digitization trends, push these B2B firms to embrace new innovation methods that help them manage disruptive change. Service design thinking has emerged as an innovation management practice emphasizing a human-centered innovation process of user interactions, creativity, and learning mindsets. In this article, we aim to evaluate the challenges and develop a research agenda on how service design can effectively enable stakeholders' engagement during the B2B innovation process. We argue that to advance service design opportunities for stakeholder engagement, we need to address the unique complexities and challenges of stakeholder engagement during innovation from a systemic and dynamic process perspective. From a systemic perspective, we zoom in on the building blocks of stakeholder engagement and address multi-level stakeholder engagement platforms (i.e., innovation networks). From a dynamic process perspective, we treat stakeholder engagement as an emerging process and zoom in on the temporal and relational connections and hybrid orchestration to allow for both structural and emerging stakeholder engagement during innovation. We develop a stakeholder engagement journey in which we integrate service and innovation stages and propose how service design activities can support and facilitate the aforementioned challenges and complexities. Finally, we identify concrete research questions and, accordingly, develop a research agenda for future research on stakeholder engagement in B2B innovation trajectories.}
}
@article{CRILLY2021333,
title = {The Evolution of “Co-evolution” (Part II): The Biological Analogy, Different Kinds of Co-evolution, and Proposals for Conceptual Expansion},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {7},
number = {3},
pages = {333-355},
year = {2021},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2021.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2405872621000927},
author = {Nathan Crilly},
keywords = {Design process, Design thinking, Creativity, Biological analogy, Interdisciplinarity},
abstract = {Descriptions of problem-solution “co-evolution” either explicitly or implicitly draw an analogy between processes of design and processes of biological evolution. Analogies of this kind are common in research because of their potential to assist in explanation and discovery. However, reviewing the design literature reveals that the discussion of design co-evolution has become disconnected from the biological analogy on which it is founded, and from which other disciplines draw. Here, I explore the function of the co-evolution analogy, provide an illustrative example from biology, and explore the varieties of co-evolution to which design might be compared. By doing so, I propose two possible directions for expanding the design co-evolution concept: (i) examining what co-evolves in addition to, or instead of, problems and solutions, and (ii) examining the different levels at which co-evolution occurs. Both of these proposals are illustrated with a variant of the design co-evolution diagram.}
}
@article{HOIFODT2015,
title = {Predictors of Response to Web-Based Cognitive Behavioral Therapy With High-Intensity Face-to-Face Therapist Guidance for Depression: A Bayesian Analysis},
journal = {Journal of Medical Internet Research},
volume = {17},
number = {9},
year = {2015},
issn = {1438-8871},
doi = {https://doi.org/10.2196/jmir.4351},
url = {https://www.sciencedirect.com/science/article/pii/S1438887115002137},
author = {Ragnhild Sørensen Høifødt and Matthias Mittner and Kjersti Lillevoll and Susanne Kvam Katla and Nils Kolstrup and Martin Eisemann and Oddgeir Friborg and Knut Waterloo},
keywords = {treatment outcome, computer-assisted therapy, cognitive behavior therapy, depression, primary health care, Bayesian analysis},
abstract = {Background
Several studies have demonstrated the effect of guided Internet-based cognitive behavioral therapy (ICBT) for depression. However, ICBT is not suitable for all depressed patients and there is a considerable level of nonresponse. Research on predictors and moderators of outcome in ICBT is inconclusive.
Objective
This paper explored predictors of response to an intervention combining the Web-based program MoodGYM and face-to-face therapist guidance in a sample of primary care patients with mild to moderate depressive symptoms.
Methods
Participants (N=106) aged between 18 and 65 years were recruited from primary care and randomly allocated to a treatment condition or to a delayed treatment condition. The intervention included the Norwegian version of the MoodGYM program, face-to-face guidance from a psychologist, and reminder emails. In this paper, data from the treatment phase of the 2 groups was merged to increase the sample size (n=82). Outcome was improvement in depressive symptoms during treatment as assessed with the Beck Depression Inventory-II (BDI-II). Predictors included demographic variables, severity variables (eg, number of depressive episodes and pretreatment depression and anxiety severity), cognitive variables (eg, dysfunctional thinking), module completion, and treatment expectancy and motivation. Using Bayesian analysis, predictors of response were explored with a latent-class approach and by analyzing whether predictors affected the slope of response.
Results
A 2-class model distinguished well between responders (74%, 61/82) and nonresponders (26%, 21/82). Our results indicate that having had more depressive episodes, being married or cohabiting, and scoring higher on a measure of life satisfaction had high odds for positively affecting the probability of response. Higher levels of dysfunctional thinking had high odds for a negative effect on the probability of responding. Prediction of the slope of response yielded largely similar results. Bayes factors indicated substantial evidence that being married or cohabiting predicted a more positive treatment response. The effects of life satisfaction and number of depressive episodes were more uncertain. There was substantial evidence that several variables were unrelated to treatment response, including gender, age, and pretreatment symptoms of depression and anxiety.
Conclusions
Treatment response to ICBT with face-to-face guidance may be comparable across varying levels of depressive severity and irrespective of the presence and severity of comorbid anxiety. Being married or cohabiting, reporting higher life satisfaction, and having had more depressive episodes may predict a more favorable response, whereas higher levels of dysfunctional thinking may be a predictor of poorer response. More studies exploring predictors and moderators of Internet-based treatments are needed to inform for whom this treatment is most effective.
Trial Registration
Australian New Zealand Clinical Trials Registry number: ACTRN12610000257066; https://www.anzctr.org.au/trial_view.aspx?id=335255 (Archived by WebCite at http://www.webcitation.org/6GR48iZH4).}
}
@article{PAILLARD2025101182,
title = {GREEN: A lightweight architecture using learnable wavelets and Riemannian geometry for biomarker exploration with EEG signals},
journal = {Patterns},
volume = {6},
number = {3},
pages = {101182},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101182},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925000303},
author = {Joseph Paillard and Jörg F. Hipp and Denis A. Engemann},
keywords = {electroencephalography, EEG, biomarkers, deep learning, wavelets, Riemannian geometry, brain-computer interface, BCI},
abstract = {Summary
Spectral analysis using wavelets is widely used for identifying biomarkers in EEG signals. Recently, Riemannian geometry has provided an effective mathematical framework for predicting biomedical outcomes from multichannel electroencephalography (EEG) recordings while showing concord with neuroscientific domain knowledge. However, these methods rely on handcrafted rules and sequential optimization. In contrast, deep learning (DL) offers end-to-end trainable models achieving state-of-the-art performance on various prediction tasks but lacks interpretability and interoperability with established neuroscience concepts. We introduce Gabor Riemann EEGNet (GREEN), a lightweight neural network that integrates wavelet transforms and Riemannian geometry for processing raw EEG data. Benchmarking on six prediction tasks across four datasets with over 5,000 participants, GREEN outperformed non-deep state-of-the-art models and performed favorably against large DL models while using orders-of-magnitude fewer parameters. Computational experiments showed that GREEN facilitates learning sparse representations without compromising performance. By integrating domain knowledge, GREEN combines a desirable complexity-performance trade-off with interpretable representations.}
}
@article{RANGANATHAN201958,
title = {Emotion Mining in Social Media Data},
journal = {Procedia Computer Science},
volume = {159},
pages = {58-66},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.160},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919313389},
author = {Jaishree Ranganathan and Angelina Tzacheva},
keywords = {Data Mining, Emotion, Microblog, Sentiment Analysis, Twitter},
abstract = {Emotions are known to influence the perception of human beings along with their memory, thinking and imagination. Human perception is important in today’s world in a wide range of factors including but not limited to business, education, art, and music. Microblogging and Social networking sites like Twitter, Facebook are challenging sources of information that allow people to share their feelings and thoughts on a daily basis. In this paper we propose an approach to automatically detect emotions on Twitter messages that explores characteristics of the tweets and the writer’s emotion using Support Vector Machine LibLinear model and achieve 98% accuracy. Emotion mining gained attraction in the field of computer science due to the vast variety of systems that can be developed and promising applications like remote health care system, customer care services, smart phones that react based on users’s emotion, vehicles that sense emotion of the driver. These emotions help understand the current state of user. In order to perform suitable actions or provide suggestions on how user’s can enhance their feeling for a better healthy life-style we use actionable recommendations. In this work we extract action rules with respect to the user emotions that help provide suggestions for user’s.}
}
@article{XIAO1996292,
title = {On the effects of ampoule tilting during vertical Bridgman growth: three-dimensional computations via a massively parallel, finite element method},
journal = {Journal of Crystal Growth},
volume = {167},
number = {1},
pages = {292-304},
year = {1996},
issn = {0022-0248},
doi = {https://doi.org/10.1016/0022-0248(96)00231-X},
url = {https://www.sciencedirect.com/science/article/pii/002202489600231X},
author = {Qiang Xiao and Satheesh Kuppurao and Andrew Yeckel and Jeffrey J. Derby},
abstract = {Three-dimensional convection and asymmetric radial segregation, caused by ampoule tilting during the vertical Bridgman growth, are analyzed using a novel, massively parallel, finite element model. The growth of cadmium telluride with a dilute dopant is considered and found to be surprisingly sensitive to the amount of tilt - as little as one degree of misalignment of the ampoule axis from the gravitational vector produces a significant three-dimensional flow and a concomitant skewing of the dopant distribution along the surface of the growing solid. This indicates the need for precise ampoule axis alignment to ensure process reproducibility. Analysis of the dopant distribution along the solid-liquid interface of the tilted system reveals a surface region more uniform in dopant concentration than any corresponding region of the interface of the perfectly aligned system. For systems in which low radial segregation is very important, growth with an intentional axis offset may be beneficial.}
}
@article{SALCEANU2014837,
title = {The Influence of Computer Games on Children's Development. Exploratory Study on the Attitudes of Parents},
journal = {Procedia - Social and Behavioral Sciences},
volume = {149},
pages = {837-841},
year = {2014},
note = {LUMEN 2014 - From Theory to Inquiry in Social Sciences, Iasi, Romania, 10-12 April 2014},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.08.323},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814050368},
author = {Claudia Sălceanu},
keywords = {Computer games, influence on children, positive and negative effects of computer games, parents’ attitudes;},
abstract = {The current study aims to investigate the attitudes of parents (N=1087) regarding the influence of computer games on their children's development in the following aspects: time they spend at the computer to play, types of favourite games, ways of child supervision, benefits and disadvantages of computer games. The results of the research show: 30.47% of children may access the computer anytime they want; the computer is mostly used for games (36.28%); 42.87% of parents supervise their children's activities at the computer only when they have spare time; 50% of parents allow their children to spend 1-2hours at computer games every day, while 28.54% allow 3-4hours (and more) of computer games every day. The biggest benefits of computer games, according to parents, are thinking development (9.60%), observation capacity (8.27%), and creativity (8.01%). The biggest disadvantages of computer games are the lack of physical movement (13.37%), sight disorders (13.15%) and agitation (8.58%). Parents recognize that games can have powerful effects on children, and should therefore set limits on the amount and content of games their children play. In this way, we can realize the potential benefits while minimizing the potential harms.}
}
@article{MAHMUD20233933,
title = {Detection of Different Stages of Alzheimer’s Disease Using CNN Classifier},
journal = {Computers, Materials and Continua},
volume = {76},
number = {3},
pages = {3933-3948},
year = {2023},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.039020},
url = {https://www.sciencedirect.com/science/article/pii/S1546221823000450},
author = {S M Hasan Mahmud and Md Mamun Ali and Mohammad Fahim Shahriar and Fahad Ahmed Al-Zahrani and Kawsar Ahmed and Dip Nandi and Francis M. Bui},
keywords = {Alzheimer’s disease, early detection, convolutional neural network, data augmentation, random oversampling, machine learning},
abstract = {Alzheimer’s disease (AD) is a neurodevelopmental impairment that results in a person’s behavior, thinking, and memory loss. The most common symptoms of AD are losing memory and early aging. In addition to these, there are several serious impacts of AD. However, the impact of AD can be mitigated by early-stage detection though it cannot be cured permanently. Early-stage detection is the most challenging task for controlling and mitigating the impact of AD. The study proposes a predictive model to detect AD in the initial phase based on machine learning and a deep learning approach to address the issue. To build a predictive model, open-source data was collected where five stages of images of AD were available as Cognitive Normal (CN), Early Mild Cognitive Impairment (EMCI), Mild Cognitive Impairment (MCI), Late Mild Cognitive Impairment (LMCI), and AD. Every stage of AD is considered as a class, and then the dataset was divided into three parts binary class, three class, and five class. In this research, we applied different preprocessing steps with augmentation techniques to efficiently identify AD. It integrates a random oversampling technique to handle the imbalance problem from target classes, mitigating the model overfitting and biases. Then three machine learning classifiers, such as random forest (RF), K-Nearest neighbor (KNN), and support vector machine (SVM), and two deep learning methods, such as convolutional neuronal network (CNN) and artificial neural network (ANN) were applied on these datasets. After analyzing the performance of the used models and the datasets, it is found that CNN with binary class outperformed 88.20% accuracy. The result of the study indicates that the model is highly potential to detect AD in the initial phase.}
}
@article{KISAALITA201658,
title = {Perspectives on context, design teams and diffusion of technological innovations in low-resource settings: A practical approach based on sub-Saharan African projects},
journal = {Technology in Society},
volume = {46},
pages = {58-62},
year = {2016},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2016.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X16300495},
author = {William S. Kisaalita},
keywords = {Technological innovations, Sustainable development, Developing countries, Design teams, Poverty alleviation, Food and energy security},
abstract = {A human-centered design approach for creating science/engineering-driven solutions or innovations, referred to as “connect-the-dots,” is presented. Dots symbolize the best questions and the connections reveal the best order in which these questions should be answered. In this approach, the number of customer or user behavioral changes are critically analyzed, revealing the overall context in which the solution or innovation will operate; especially to undergraduate students creating solutions to problems from settings that are less familiar, from cultural, economic, and geopolitical viewpoints. Solutions or innovations that result in minimal user behavior changes are preferred. Additional benefits include better incorporation of systems theory thinking, ease with which team multidisciplinarity and diversity can be identified, and seamlessly integrating design and research.}
}
@article{CAI2024118870,
title = {An efficient Meta-VSW method for ship behaviors recognition and application},
journal = {Ocean Engineering},
volume = {311},
pages = {118870},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.118870},
url = {https://www.sciencedirect.com/science/article/pii/S002980182402208X},
author = {Zhiyuan Cai and Qidong Fan and Lecheng Li and Long Yu and Congbo Li},
keywords = {Ship behavior recognition, Unsupervised algorithm, Massive unknown data, Meta-trajectory, Operational efficiency, Fuel consumption},
abstract = {Ship behaviors refer to the operational process such as sailing, entering into port/departure, etc., which indicate by their position, speed, and so on. The collected big data normally have been treated by unsupervised Machine Learning methods. However, the process is time consuming and lacks consideration of time continuity. From the unknown data to recognize and recur the ship behaviors is still a complex problem. Hence, this study proposes a universal Meta-trajectory Variable Sliding Window (Meta-VSW) method to provide an efficient and high-fidelity solution. In this method, the ship data were connected into the smallest units by the meta-trajectory coding, and combines with variable sliding windows to achieve fast, continuous and accurate recognition of ship behaviors. Taking an inland-water ship and a marine transport ship as examples, the validity of the method was fulfilled and compared with two commonly used algorithms, Affinity Propagation (AP) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN). It has the fastest computational speed and can effectively classify the behaviors of massive unknown data from different ships. And it has good performance in capturing behavior boundaries, with the recognition accuracy up to 0.9. Then, the method was applied to analyze the operational effectively and fuel consumption.}
}
@article{GAN2021101212,
title = {Translating novel HPC techniques into efficient geoscience solutions},
journal = {Journal of Computational Science},
volume = {52},
pages = {101212},
year = {2021},
note = {Case Studies in Translational Computer Science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101212},
url = {https://www.sciencedirect.com/science/article/pii/S1877750320305135},
author = {Lin Gan and Haohuan Fu and Guangwen Yang},
keywords = {Computational geoscience application, Numerical simulation, High performance computing, Translational computer science},
abstract = {Computational geoscience is an established field for better understanding and protecting our planet. It covers a wide range of different fields that are closely related to Earth systems. As a popular research area that largely relies on high performance computing, the efficient translation of novel techniques from computer science to practical geoscience solutions has emerged as an important and challenging problem. Based on a series of efforts in conducting interdisciplinary research in computer science and geoscience, this paper summarizes the measures we have taken and the lessons we have learned to successfully translate selected computational laboratory innovations into practical solutions.}
}
@incollection{KAMESWARI202581,
title = {Chapter 4 - Future trends and research challenges in digital twins},
editor = {Sailesh Iyer and Anand Nayyar and Anand Paul and Mohd Naved},
booktitle = {Digital Twins for Smart Cities and Villages},
publisher = {Elsevier},
pages = {81-101},
year = {2025},
isbn = {978-0-443-28884-5},
doi = {https://doi.org/10.1016/B978-0-443-28884-5.00004-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044328884500004X},
author = {Y. Lalitha Kameswari and B. {Omkar Lakshmi Jagan} and Thayyaba Khatoon Mohammed and Shady H.E. {Abdel Aleem}},
keywords = {Artificial intelligence, Digital twins, Integration, Internet of Things, Machine learning, Urban planning},
abstract = {With applications ranging from manufacturing and healthcare to urban planning and energy, digital twin technology has become a ground-breaking idea. In order to provide light on the potential breakthroughs and obstacles that lie ahead, this study examines future trends and research challenges in the field of digital twins. Several significant themes are anticipated to influence the development of digital twins as they continue to change. Digital twins will be better able to learn from complex situations in real time because to the combination of artificial intelligence (AI) and machine learning (ML). Digital twins will be given the ability to foresee, improve, and react to dynamic changes as a result of this AI-driven evolution, which will ultimately result in more effective and resilient systems. Another important development is the idea of federated digital twins, in which various interconnected digital twin instances work together to represent a larger, interconnected system. By integrating the strengths of several digital twins, this method makes it easier to model and analyze very complex and interconnected systems, such as smart cities or multimodal transportation networks. It is also projected that digital twins would spread into the Internet of Things (IoT) space. A closer connection between the real and virtual worlds will be made possible by the seamless integration of sensors, actuators, and data streams with digital twin platforms. This pattern will open the door to fresh perspectives and opportunities for improvement. To fully realize the potential of digital twins, a number of scientific challenges must be overcome. As the integration of real-time data from physical systems raises worries about unauthorized access and potential vulnerabilities, data privacy and security continue to be of the utmost importance. Additionally, sophisticated methods for data assimilation, model validation, and uncertainty quantification are needed to create accurate and trustworthy digital twin models. Another urgent issue is interoperability. The creation of standardized interfaces and protocols is essential to facilitate seamless integration and data sharing as digital twins proliferate across many sectors and domains. Furthermore, novel approaches to distributed computing and high-performance simulation are necessary to meet the scalability and computational requirements of large-scale digital twin ecosystems. In-depth analysis of these trends and problems is provided in this chapter, along with suggestions for future research areas and solutions. The field of digital twins is set for a paradigm-shifting impact on how we build, function, and interact with the physical world by tackling these issues and exploiting new trends.}
}
@article{ZALL2024101285,
title = {Towards emotion-aware intelligent agents by utilizing knowledge graphs of experiences},
journal = {Cognitive Systems Research},
volume = {88},
pages = {101285},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101285},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724000792},
author = {Raziyeh Zall and Mohammad Reza Kangavari},
keywords = {Affective computing, Intelligent agent, Cognitive architecture, Appraisal theory, Emotional mental state},
abstract = {Because of the increasing presence of intelligent agents in various aspects of human social life, social skills play a vital role in ensuring these systems exhibit acceptable and realistic behavior in social communication. The importance of emotional intelligence in social capabilities is noteworthy, so incorporating emotions into the behaviors of intelligent agents is essential. Therefore, some computational models of emotions have been presented to develop intelligent agents that exhibit emotional human-like behaviors. However, most current computational models of emotions neglect the dynamic learning of the affective meaning of events based on agents’ experiences. Such models evaluate the events in the environment according to emotional aspects without considering the context of the situations. Also, these models capture the emotional states of agents by using predefined rules determined according to psychological theories. Therefore, they disregard the data-driven methods that can obtain the relationships between appraisal variables and emotions based on natural human data with fewer assumptions on the nature of such relationships. To address these issues, we proposed a novel and unified affective-cognitive framework (EIAEC) to facilitate the development of emotion-aware intelligent agents. EIAEC uses appraisal theories to acquire the emotional states of the agent in various situations. This paper contains four main contributions: 1- We have designed an efficient episodic memory that uses events and their conditional contexts to store and retrieve knowledge and experiences. This memory facilitates emotional expressions and decision-making adapted to the situations of the agent. 2- A novel method has been proposed that learns context-dependent affective values associated with events by using the agent’s experiences in various contexts. Subsequently, we acquired appraisal variables using the elements and related meta-data in episodic memory. 3- We have proposed a new data-driven method that maps appraisal variables to emotional states. 4- Moreover, a method has been developed to update the activation values regarding actions by using the emotional states of the agent. This method models the influence of emotions on the agent’s decision-making. Finally, we simulate a driving scenarios in our proposed framework to manifest the generated emotions in different situations and conditions. Moreover, we show how the proposed method learns the affective meaning of events and actions used in appraisal computing.}
}
@article{TEIXEIRADUARTE2022112513,
title = {Review on layout optimization strategies of offshore parks for wave energy converters},
journal = {Renewable and Sustainable Energy Reviews},
volume = {163},
pages = {112513},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2022.112513},
url = {https://www.sciencedirect.com/science/article/pii/S1364032122004178},
author = {Felipe Teixeira-Duarte and Daniel Clemente and Gianmaria Giannini and Paulo Rosa-Santos and Francisco Taveira-Pinto},
keywords = {Computational intelligence techniques, Wave energy, Renewable energy, Layout optimization, Offshore parks, Energy parks, WEC arrays},
abstract = {Layout optimization of wave energy offshore parks is a challenging task, as it encompasses various design objectives and constraints attributed to the complex hydrodynamic interactions. The wave energy converter (WEC) park performance is affected by local environment and device characteristics. To solve this challenge, advanced numerical algorithms, including artificial intelligence, have been applied to a wide range of case studies. Nevertheless, this process remains incomplete, which keeps it as a pertinent research topic in the field of WEC development. The present paper provides an overview of the current state and research trends of offshore WEC park layout optimization. To analyze the state-of-the-art, the paper targets the last decades’ research on this topic, summarizing the studies, addressing the optimization objective and the employed methods and separating them according to the corresponding technique. The review showed that the results strongly depend on the methodologies applied. Furthermore, a preferential use of computational intelligence techniques has been observed in recent years.}
}
@article{SHIBATA2021436,
title = {Sensitivity – Local index to control chaoticity or gradient globally –},
journal = {Neural Networks},
volume = {143},
pages = {436-451},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021002471},
author = {Katsunari Shibata and Takuya Ejima and Yuki Tokumaru and Toshitaka Matsuki},
keywords = {Sensitivity, Sensitivity adjustment learning (SAL), Edge of chaos, Recurrent neural network (RNN), Deep feedforward neural network (DFNN), Vanishing gradient problem},
abstract = {Here, we introduce a fully local index named “sensitivity” for each neuron to control chaoticity or gradient globally in a neural network (NN). We also propose a learning method to adjust it named “sensitivity adjustment learning (SAL)”. The index is the gradient magnitude of its output with respect to its inputs. By adjusting its time average to 1.0 in each neuron, information transmission in the neuron changes to be moderate without shrinking or expanding for both forward and backward computations. That results in moderate information transmission through a layer of neurons when the weights and inputs are random. Therefore, SAL can control the chaoticity of the network dynamics in a recurrent NN (RNN). It can also solve the vanishing gradient problem in error backpropagation (BP) learning in a deep feedforward NN or an RNN. We demonstrate that when applying SAL to an RNN with small and random initial weights, log-sensitivity, which is the logarithm of RMS (root mean square) sensitivity over all the neurons, is equivalent to the maximum Lyapunov exponent until it reaches 0.0. We also show that SAL works with BP or BPTT (BP through time) to avoid the vanishing gradient problem in a 300-layer NN or an RNN that learns a problem with a lag of 300 steps between the first input and the output. Compared with manually fine-tuning the spectral radius of the weight matrix before learning, SAL’s continuous nonlinear learning nature prevents loss of sensitivities during learning, resulting in a significant improvement in learning performance.}
}
@article{BENTON2023105626,
title = {Associative learning or Bayesian inference? Revisiting backwards blocking reasoning in adults},
journal = {Cognition},
volume = {241},
pages = {105626},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105626},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723002603},
author = {Deon T. Benton and David H. Rakison},
keywords = {Causal reasoning, Causal mechanisms, Computational models, Analytical models, Associative learning, Bayesian inference},
abstract = {Causal reasoning is a fundamental cognitive ability that enables humans to learn about the complex interactions in the world around them. However, the cognitive mechanisms that underpin causal reasoning are not well understood. For instance, there is debate over whether Bayesian inference or associative learning best captures causal reasoning in human adults. The two experiments and computational models reported here were designed to examine whether adults engage in one form of causal inference called backwards blocking reasoning, whether the presence of potential distractors affects performance, and how adults' ratings align with the predictions of different computational models. The results revealed that adults engaged in backwards blocking reasoning regardless of whether distractor objects are present and that their causal judgements supported the predictions of a Bayesian model but not the predictions of two different associative learning models. Implications of these results are discussed.}
}
@article{ROBINSON2021,
title = {Development of the Organonitrogen Biodegradation Database: Teaching Bioinformatics and Collaborative Skills to Undergraduates during a Pandemic},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2351},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000745},
author = {Serina L. Robinson and Troy Biernath and Caleb Rosenthal and Dean Young and Lawrence P. Wackett and Betsy M. Martinez-Vaz},
abstract = {Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology.
ABSTRACT
Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology. The work presented here describes a fully online, collaborative research experience created to allow undergraduate students to learn those skills. The research experience was focused on the development and implementation of the Organonitrogen Biodegradation Database (ONDB, z.umn.edu/ondb). The ONDB was developed to catalog information about the cost, chemical properties, and biodegradation potential of commonly used organonitrogen compounds. A cross-institutional team of undergraduate researchers worked in collaboration with two faculty members and a postdoctoral fellow to develop the database. Students carried out extensive online literature searches and used a biodegradation prediction website to research and represent the microbial catabolism of different organonitrogen compounds. Participants employed computational tools such as R, Shiny, and flexdashboard to construct the database pages and interactive web interface for the ONDB. Worksheets and forms were created to encourage other students and researchers to gather information about organonitrogen compounds and expand the database. Student progress was evaluated through biweekly project meetings, presentations, and a final reflection. The ONDB undergraduate research experience provided a platform for students to learn bioinformatics skills while simultaneously developing a teaching and research tool for others.}
}
@article{BARFAR2019173,
title = {Cognitive and affective responses to political disinformation in Facebook},
journal = {Computers in Human Behavior},
volume = {101},
pages = {173-179},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219302699},
author = {Arash Barfar},
keywords = {Political disinformation, Polarization, Echo chamber, Text analysis, Social media, Facebook},
abstract = {The epidemic of political disinformation in social media has in part triggered the transition to the post-truth era in which emotional and ideological appeals are more influential in shaping public opinion than objective facts. In this study we examined the cognitive and affective responses that political disinformation prompted in Facebook, as the most popular social media platform. Through text analysis of user comments corpora on nearly 2,100 political posts from popular sources in Facebook, we found that compared to true news, political disinformation received significantly less analytic responses from Facebook followers. While the results indicated greater anxiety in responses to true news, responses to political disinformation were filled with greater anger and incivility. We also found similar (low) levels of cognitive thinking in responses to extreme conservative and extreme liberal disinformation. Contrary to prior research findings, our results indicated that responses to extreme liberal disinformation in Facebook were filled with greater anger and incivility. This suggests that the incivility and outrage in online political discourses should not be attributed to a specific political party without considering the concurrent political events.}
}
@article{HAMDI2019772,
title = {Fuzzy Approach for Locating Sensors in Industrial Internet of Things},
journal = {Procedia Computer Science},
volume = {160},
pages = {772-777},
year = {2019},
note = {The 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919317120},
author = {Sarah El Hamdi and Mustapha Oudani and Abdellah Abouabdellah and Anass Sebbar},
keywords = {I2oT, Architecture, Fuzzy Theory},
abstract = {Nowadays, in this era of a data driven thinking and reflection, data mining and data analysis are keys to any business survival in a competitive conjectural market. The internet of things is an emerging technology that manages to create a path for the new generation of industrial production system. This advanced technology is requirement to the proliferation of Smart factories, it represents the best tool to help this new concept of plants to organize themselves and optimize the available resources and their consumption. The purpose of this paper is two-pronged; a proposal for an architectural framework of the industrial internet of things, and a mathematical formulation based on fuzzy logic to determine the ideal location of sensors at the shop floor taking into consideration several restrictions.}
}
@article{LI2025102888,
title = {From assistance to reliance: Development and validation of the large language model dependence scale},
journal = {International Journal of Information Management},
volume = {83},
pages = {102888},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102888},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225000209},
author = {Zewei Li and Zheng Zhang and Mingwei Wang and Qi Wu},
keywords = {Factor model of LLMs dependence, Large language models, Functional dependence, Existential dependence, Alleviating interventions},
abstract = {With the rapid advancement of large language models (LLMs), the phenomenon of LLMs dependence has emerged and garnered significant attention. However, previous scales have been insufficient to measure the extent of individuals' dependence on LLMs. The current study aims to utilize the human-computer trust model and addiction theory to develop and validate the LLMs dependence scale (LDS) and to report its psychometric properties. An exploratory structural investigation of LLMs dependence was conducted with a sample of 421 LLMs users (Sample 1), which included items analysis, exploratory factor analysis, and network analysis. Additionally, a formal test was performed with a separate sample of 1030 LLMs users (Sample 2), with the data undergoing structural validation through confirmatory factor analysis, validity testing, and reliability testing. To mitigate the potential negative impacts of LLMs dependence, we employed the NodeIdentifyR algorithm for computational simulation interventions to identify critical intervention nodes within the LLMs dependence network. The results indicated that the LDS (18 items) exhibited a bifactor structure of functional dependence and existential dependence. The confirmatory factor model demonstrated a good fit and the LDS also showed good criterion-related validity. Subsequent simulated results of alleviating interventions suggested that users' existential dependence was primarily driven by their dependence on LLMs to handle tedious and boring tasks, while functional dependence was more influenced by users' belief in the omnipotence of LLMs. In summary, the factor structure of the LDS is clear, and its reliability and validity indices meet psychometric standards, making it an effective tool for measuring LLMs dependence.}
}
@article{VALLVERDU20146,
title = {What are Simulations? An Epistemological Approach},
journal = {Procedia Technology},
volume = {13},
pages = {6-15},
year = {2014},
note = {SLACTIONS 2013: Research conference on virtual worlds – Learning with simulations},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2014.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212017314000139},
author = {Jordi Vallverdú},
keywords = {model, computer, simulation, epistemology, representation},
abstract = {Contemporary sciences use a wide and diverse range of computational simulations, including in the areas of aeronautics, chemistry, bioinformatics, social sciences, AI, the physics of elementary particles and most other scientific fields. A simulation is a mathematical model that describes or creates computationally a system process. Simulations are our best cognitive representation of complex reality, that is, our deepest conception of what reality is. In this paper we defend that a simulation is equivalent epistemologically and ontologically with all other types of cognitive models of elements of reality. Therefore, simulations cannot be considered secondary nor weak instruments to approach to the reality analysis.}
}
@incollection{LEVY1989243,
title = {A Computational Approach to Hippocampal Function},
editor = {Robert D. Hawkins and Gordon H. Bower},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {23},
pages = {243-305},
year = {1989},
booktitle = {Computational Models of Learning in Simple Neural Systems},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(08)60113-9},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108601139},
author = {William B Levy},
abstract = {Publisher Summary
This chapter describes the early, formative stages of a theory of hippocampal function. This theory has been stimulated by the psychological observations indicating a role for the hippocampus in short-term working memory and spatial behavior and develops mainly through the consideration of computational issues. These computational issues are related to the psychological viewpoint through physiological and anatomical observations. The hippocampus participates in the prediction of future representations based on past and present representations. All three classes of representations are derived from a multiplicity of sensory modalities, such as auditory, visual, and olfactory signals from neo- and piriform cortices. This fusion of sensory modalities requires recoding because of computational complexity problems. The CA1 region of the hippocampus is postulated to be a prediction-generating layer or tier. This region produces a prediction based on its input from hippocampal region CA3. The combined hippocampal dentate gyrus/CA3 (DG/CA3) system is postulated to be a preprocessor serving the CA1 prediction layer. The computational complexity problems arise from the combinatorial explosion of possible representations resulting when the hippocampus and supporting limbic structures mix representations from multiple sensory modalities.}
}
@article{BALMER2024105411,
title = {Design Space Exploration and Explanation via Conditional Variational Autoencoders in Meta-Model-Based Conceptual Design of Pedestrian Bridges},
journal = {Automation in Construction},
volume = {163},
pages = {105411},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105411},
url = {https://www.sciencedirect.com/science/article/pii/S092658052400147X},
author = {Vera Balmer and Sophia V. Kuhn and Rafael Bischof and Luis Salamanca and Walter Kaufmann and Fernando Perez-Cruz and Michael A. Kraus},
keywords = {Computational design, Design space exploration, Generative AI, Conditional Variational Autoencoder, Explainable AI, Pedestrian bridge},
abstract = {Today, engineers rely on conventional iterative (often manual) techniques for conceptual design. Emerging parametric models facilitate design space exploration based on quantifiable performance metrics, yet remain time-consuming and computationally expensive, leaving room for improvement. This paper provides a design exploration and explanation framework to augment the designer via a Conditional Variational Autoencoder (CVAE), which serves as a forward performance predictor as well as an inverse design generator conditioned on a set of performance requests. Hence, the CVAE overcomes the limitations of traditional iterative techniques by learning a differentiable mapping for a highly nonlinear design space, thus enabling sensitivity analysis. These methods allow for informing designers about (i) relations of the model between features and performances and (ii) structural improvements under user-defined objectives. The framework is tested on a case-study and proves its potential to serve as a future co-pilot for conceptual design studies of diverse civil structures and beyond.}
}
@article{WANG19951,
title = {Peripheral dynamics of the Cl + CH4 → HCl + CH3 reaction. A classical trajectory computation},
journal = {Chemical Physics},
volume = {197},
number = {1},
pages = {1-17},
year = {1995},
issn = {0301-0104},
doi = {https://doi.org/10.1016/0301-0104(95)00134-A},
url = {https://www.sciencedirect.com/science/article/pii/030101049500134A},
author = {Xuebin Wang and M. Ben-Nun and R.D. Levine},
abstract = {The Cl + CH4 → HCl + CH3 reaction is expected to provide a prototype of a peripheral mechanism. This proposal is examined via a classical trajectory computation using a number of model potentials in which the degrees of freedom which do not take part in the net reaction are, or are not, frozen. The models include a full six-atom potential. The essential features of the dynamics are not sensitive to the level of detail with which the CH3 is described, showing that the intramolecular dynamics of the radical do not significantly affect the dynamics of the reactive event. The reaction is found to proceed by two distinct mechanisms: for trajectories with a large impact parameter, a very short lived complex is formed and dissociates to a rotationally cold HCl product, scattered into the forward direction. At smaller impact parameters, the reaction proceeds via a direct mechanism with a rotationally hot HCl which is scattered backward. The computed angular distribution is in agreement with the experiment, which detects HCl in the j = 1, 3 states and suggests that higher rotational states of HCl, which were not probed in the experiment, will also be scattered backward. The role of the initial vibrational excitation of CH4 is discussed.}
}
@article{RITCHIE2012649,
title = {Styles for philosophers of science},
journal = {Studies in History and Philosophy of Science Part A},
volume = {43},
number = {4},
pages = {649-656},
year = {2012},
note = {Part Special Issue: Styles of Thinking},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2012.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0039368112000490},
author = {Jack Ritchie},
keywords = {Ian Hacking, Styles of Thinking, Realism, Self-authentication},
abstract = {In this paper I discuss the bearing of Hacking’s ideas about Scientific Styles on traditional debates in the philosophy of science concerning rationality and realism. I argue that a kind of deflationary position with regard to realism debates is a natural consequence of Hacking’s claim that styles are self-authenticating. I then go on to argue, using an example of van Fraassen’s, that Hacking should allow a methodological role for realism debates and hence they are not idle, as he has claimed, although their resolution may not be important.}
}
@incollection{KRAWCZYK2018101,
title = {Chapter 5 - Reasoning Origins: Human Development During Childhood},
editor = {Daniel C. Krawczyk},
booktitle = {Reasoning},
publisher = {Academic Press},
pages = {101-129},
year = {2018},
isbn = {978-0-12-809285-9},
doi = {https://doi.org/10.1016/B978-0-12-809285-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092859000053},
author = {Daniel C. Krawczyk},
keywords = {Analogies, Causal reasoning, Decision making, Development, Developmental stages, Moral reasoning, Relational reasoning},
abstract = {The developmental process is remarkably dynamic. The process is both a biological one and an environmental one with both factors frequently contributing to the output of increasingly sophisticated and abstract reasoning behavior. Children begin with a process of cortical thickening as large numbers of synaptic connections are formed. From age three onward, the cortex undergoes a tuning process as some synaptic connections strengthen and others weaken. The net result of this process is a decrease in cortical volume from age 5 through 20. Children's thinking is guided by a variety of factors. The context of a problem becomes a significant factor in determining how children will reason and developmental reasoning studies require sensitivity toward making the experimental stimuli understandable and interesting to the child. Children exhibit some competencies in causal reasoning and learning from a very young age. Children show increasing reasoning abilities as they develop. Skills such as relational and analogical reasoning grow during the elementary school years and are supported by increases in cognitive control and decreases in impulsivity. The child becomes less concrete in how he or she views and interacts with the world. This increasing abstraction ability encompasses semantic knowledge, deduction, and moral thinking.}
}
@incollection{WILLIAMS2020341,
title = {Chapter 17 - Begin with the human: Designing for safety and trustworthiness in cyber-physical systems},
editor = {William F. Lawless and Ranjeev Mittu and Donald A. Sofge},
booktitle = {Human-Machine Shared Contexts},
publisher = {Academic Press},
pages = {341-357},
year = {2020},
isbn = {978-0-12-820543-3},
doi = {https://doi.org/10.1016/B978-0-12-820543-3.00017-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128205433000171},
author = {Elizabeth T. Williams and Ehsan Nabavi and Genevieve Bell and Caitlin M. Bentley and Katherine A. Daniell and Noel Derwort and Zac Hatfield-Dodds and Kobi Leins and Amy K. McLennan},
keywords = {Trust, Safety, Autonomy, Agency, Assurance, Metrics, Interfaces, Human-machine interaction, Cyber-physical systems},
abstract = {Control systems are designed and built to manage and regulate the behavior of other systems. The use of artificial intelligence (AI) in control systems has simultaneously created new opportunities and new challenges in how we create, manage, and govern cyber-physical systems. In this paper, we discuss the challenge of defining and developing a model for contemplating how these systems will potentially learn, evolve, and act without human intervention. We present an analytical framework for thinking about trust and safety in these systems—both key factors for shared context in human-machine teams—and demonstrate its application using an example from history.}
}
@article{CHANDRA2018306,
title = {New narratives of development work? Making sense of social entrepreneurs’ development narratives across time and economies},
journal = {World Development},
volume = {107},
pages = {306-326},
year = {2018},
issn = {0305-750X},
doi = {https://doi.org/10.1016/j.worlddev.2018.02.033},
url = {https://www.sciencedirect.com/science/article/pii/S0305750X18300780},
author = {Yanto Chandra},
keywords = {Development narrative, Development, Social enterprise, Social entrepreneur, Computational linguistics},
abstract = {This article views social entrepreneurship as a relatively new model for achieving sustainable development. It also identifies development narratives that social entrepreneurs (SEs) construct to represent and promote their work as an important research gap in development studies. Drawing on the development and narratology literature, and employing computational linguistics (CL) techniques, this article compares the development narratives of 1076 Ashoka SEs across two periods (2009–2013 and 1994–1998) and two economies (developing and developed). CL analyses reveal important themes that characterize the identity, framing and orientations of development SEs across time and economies. The findings demonstrate how SE development narratives i) tend to be more pragmatic and solution-centric, and contain less political ideology than conventional development narratives, ii) combine extant development ideas and models but reframe them in new ways to address contemporary, complex development challenges, and iii) reflect a ‘bottom-up’ approach that encourages local ownership and collaborations with various social and economic sectors to achieve development goals. Overall, this study identifies the increasing importance of SEs in the development industry and reveals new aspects of SEs—their latent political framing, collective-utilitarian identities, and topical areas—that require further research via development narratives.}
}
@article{ALBALAWI201712033,
title = {Distributed Economic MPC with Safety-Based Constraints for Nonlinear Systems**Financial support from the National Science Foundation and the Department of Energy is gratefully acknowledged.},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {12033-12040},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.2098},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317327581},
author = {Fahad Albalawi and Helen Durand and Panagiotis D. Christofides},
keywords = {Process safety, distributed model predictive control, computation time},
abstract = {Promoting process safety of chemical processes while operating them in an economically-optimal manner is a matter of great importance. In Albalawi et al. (2016), a safety-based economic model predictive control methodology (safety-EMPC) was developed to operate nonlinear processes in an economically-optimal manner while maintaining process safety and closed-loop stability. However, the safety-EMPC control strategy was developed with a centralized economic model predictive control (EMPC) structure; thus, computation time limitations within a sampling period may reduce the effectiveness of such a controller design for promoting process safety. Alternatively, we develop in this work sequential and iterative safety-based distributed EMPC schemes (safety-DEMPC) that may overcome the computation time limitations of the centralized safety-EMPC while maintaining similar closed-loop performance. Using a catalytic reactor example, the two proposed safety-DEMPC schemes were demonstrated to achieve similar closed-loop performance to the centralized safety-EMPC while reducing the on-line computation time requirements compared to the centralized safety-EMPC.}
}
@incollection{TANQUE202113,
title = {Chapter 2 - Knowledge Representation and Reasoning in AI-Based Solutions and IoT Applications},
editor = {Gurjit Kaur and Pradeep Tomar and Marcus Tanque},
booktitle = {Artificial Intelligence to Solve Pervasive Internet of Things Issues},
publisher = {Academic Press},
pages = {13-49},
year = {2021},
isbn = {978-0-12-818576-6},
doi = {https://doi.org/10.1016/B978-0-12-818576-6.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128185766000022},
author = {Marcus Tanque},
keywords = {Artificial intelligence, machine learning, intelligent machine, artificial neural networks, cognitive science, deep learning, artificial general networks, knowledge representation, and reasoning, cognitive informatics, Internet of Things},
abstract = {Artificial intelligence (AI)-based solutions, knowledge representation and reasoning, and the Internet of Things applications have transformed how researchers and practitioners view the analytical and computational capabilities. The disruptive evolution of these technologies has encouraged researchers and practitioners to develop integrated AI-based analytical solutions needed for solving pervasive issues affecting computational applications. The capabilities include AI, knowledge Representation and Reasoning and Internet of Things. Such capabilities are designed to support AI-based solutions, knowledge representation and reasoning, and the Internet of Things (IoT) applications. These technology trends involve relevant computational areas, that is, intelligent devices, sensors, autonomous vehicles, robotics, virtual reality, augmented intelligence, and others. The study addresses and validates solutions on how researchers can solve issues that affect AI, knowledge representation and reasoning, and IoT applications.}
}
@article{GALLISTEL199243,
title = {Preverbal and verbal counting and computation},
journal = {Cognition},
volume = {44},
number = {1},
pages = {43-74},
year = {1992},
note = {Numerical Cognition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(92)90050-R},
url = {https://www.sciencedirect.com/science/article/pii/001002779290050R},
author = {C.R. Gallistel and Rochel Gelman},
abstract = {We describe the preverbal system of counting and arithmetic reasoning revealed by experiments on numerical representations in animals. In this system, numerosities are represented by magnitudes, which are rapidly by inaccurately generated by the Meck and Church (1983) preverbal counting mechanism. We suggest the following. (1) The preverbal counting mechanisms is the source of the implicit principles that guide the acquisition of verbal counting. (2) The preverbal system of arithmetic computation provides the framework for the assimilation of the verbal system. (3) Learning to count involves, in part, learning a mapping from the preverbal numerical magnitudes to the verbal and written number symbols and the inverse mappings from these symbols to the preverbal magnitudes. (4) Subitizings is the use of the preverbal counting process and the mapping from the resulting magnitudes to number words in order to generate rapidly the number words for small numerosities. (5) The retrieval of the number facts, which plays a central role in verbal computation, is mediated via the inverse mappings from verbal and written numbers to the preverbal magnitudes and the use of these magnitudes to find the appropriate cells in tabular arrangements of the answers. (6) This model of the fact retrieval process accounts for the salient features of the reaction time differences and error patterns revealed by expriments on mental arithmetic. (7) The application of verbal and written computational algorithms goes on in parallel with, and is to some extent guided by, preverbal computations, both in the child and in the adult.}
}
@article{JAHANIFAR2024103132,
title = {Mitosis detection, fast and slow: Robust and efficient detection of mitotic figures},
journal = {Medical Image Analysis},
volume = {94},
pages = {103132},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103132},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524000574},
author = {Mostafa Jahanifar and Adam Shephard and Neda Zamanitajeddin and Simon Graham and Shan E. Ahmed Raza and Fayyaz Minhas and Nasir Rajpoot},
keywords = {Mitosis, Detection, Segmentation, Breast cancer, MIDOG, TUPAC, Computational pathology, Deep learning},
abstract = {Counting of mitotic figures is a fundamental step in grading and prognostication of several cancers. However, manual mitosis counting is tedious and time-consuming. In addition, variation in the appearance of mitotic figures causes a high degree of discordance among pathologists. With advances in deep learning models, several automatic mitosis detection algorithms have been proposed but they are sensitive to domain shift often seen in histology images. We propose a robust and efficient two-stage mitosis detection framework, which comprises mitosis candidate segmentation (Detecting Fast) and candidate refinement (Detecting Slow) stages. The proposed candidate segmentation model, termed EUNet, is fast and accurate due to its architectural design. EUNet can precisely segment candidates at a lower resolution to considerably speed up candidate detection. Candidates are then refined using a deeper classifier network, EfficientNet-B7, in the second stage. We make sure both stages are robust against domain shift by incorporating domain generalization methods. We demonstrate state-of-the-art performance and generalizability of the proposed model on the three largest publicly available mitosis datasets, winning the two mitosis domain generalization challenge contests (MIDOG21 and MIDOG22). Finally, we showcase the utility of the proposed algorithm by processing the TCGA breast cancer cohort (1,124 whole-slide images) to generate and release a repository of more than 620K potential mitotic figures (not exhaustively validated).}
}
@article{SAKEEF2025100146,
title = {Detecting cognitive engagement in online course forums: A review of frameworks and methodologies},
journal = {Natural Language Processing Journal},
volume = {11},
pages = {100146},
year = {2025},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2025.100146},
url = {https://www.sciencedirect.com/science/article/pii/S2949719125000226},
author = {Nazmus Sakeef and M. Ali Akber Dewan and Fuhua Lin and Dharamjit Parmar},
keywords = {Online learning, Cognitive engagement detection, ICAP, CoI, KCSA, Course forum analysis},
abstract = {A key aspect of online learning in higher education involves the utilization of course discussion forums. Assessing the quality of posts, such as cognitive engagement, within online course discussion forums, and determining students’ interest and participation is challenging yet beneficial. This research investigates existing literature on identifying the cognitive engagement of online learners through the analysis of course discussion forums. Essentially, this review examines three educational frameworks - Van Der Meijden’s Knowledge Construction in Synchronous and Asynchronous Discussion Posts (KCSA), Community of Inquiry (CoI), and Interactive, Constructive, Active, and Passive (ICAP), which have been widely used for students’ cognitive engagement detection analyzing their posts in course discussion forums. This study also examines the natural language processing and deep learning approaches employed and integrated with the above three educational frameworks in the existing literature concerning the detection of cognitive engagement in the context of online learning. The article provides recommendations for enhancing instructional design and fostering student engagement by leveraging cognitive engagement detection. This research underscores the significance of automating the identification of cognitive engagement in online learning and puts forth suggestions for future research directions.}
}
@article{MEHRYAR2024109812,
title = {AI and climate resilience governance},
journal = {iScience},
volume = {27},
number = {6},
pages = {109812},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.109812},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224010344},
author = {Sara Mehryar and Vahid Yazdanpanah and Jeffrey Tong},
keywords = {Natural sciences, Earth sciences, Environmental science, Environmental policy, Social sciences},
abstract = {Summary
While artificial intelligence (AI) offers promising solutions to address climate change impacts, it also raises many application limitations and challenges. A risk governance perspective is used to analyze the role of AI in supporting decision-making for climate adaptation, spanning risk assessment, policy analysis, and implementation. This comprehensive review combines expert insights and systematic literature review. The study’s findings indicate a large emphasis on applying AI to climate “risk assessments,” particularly regarding hazard and exposure assessment, but a lack of innovative approaches and tools to evaluate resilience and vulnerability as well as prioritization and implementation process, all of which involve subjective, qualitative, and context-specific elements. Additionally, the study points out challenges such as difficulty of simulating complex long-term changes, and evolving policies and human behavior, reliance on data quality and computational resources, and the need for improved interpretability of results as areas requiring further development.}
}
@incollection{VARGHESE202275,
title = {Chapter 4 - Principles in action},
editor = {George Varghese and Jun Xu},
booktitle = {Network Algorithmics (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {75-107},
year = {2022},
isbn = {978-0-12-809927-8},
doi = {https://doi.org/10.1016/B978-0-12-809927-8.00009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128099278000099},
author = {George Varghese and Jun Xu},
keywords = {Buffer validation, Dijkstra's algorithm, virtual circuit, transport protocols},
abstract = {Part 2 of the book begins a detailed look at specific network bottlenecks such as data copying and control transfer. While the principles are used in these later chapters, the focus of these later chapters is on the specific bottleneck being examined. Given that network algorithmics is as much a way of thinking as it is a set of techniques, it seems useful to round out Part 1 by seeing the principles in action on small, self contained, but nontrivial network problems. Thus this chapter provides examples of applying the principles in solving specific networking problems. The examples are drawn from real problems, and some of the solutions are used in real products. Unlike subsequent chapters, this chapter is not a collection of new material followed by a set of exercises. Instead, this chapter can be thought of as an extended set of exercises. In Section 4.1 to Section 4.15, 15 problems are motivated and described. Each problem is followed by a hint that suggests specific principles, which is then followed by a solution sketch. There are also a few exercises after each solution. In classes and seminars on the topic of this chapter, the audience enjoyed inventing solutions by themselves (after a few hints were provided), rather than directly seeing the final solutions.}
}
@article{LIN2022104649,
title = {Towards a cross-level understanding of Bayesian inference in the brain},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {137},
pages = {104649},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104649},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422001385},
author = {Chin-Hsuan Sophie Lin and Marta I. Garrido},
keywords = {Probabilistic inference, Bayesian decision theory, Uncertainty, Sampling, Variational approximation, Neural codes, Marr’s level of analysis},
abstract = {Perception emerges from unconscious probabilistic inference, which guides behaviour in our ubiquitously uncertain environment. Bayesian decision theory is a prominent computational model that describes how people make rational decisions using noisy and ambiguous sensory observations. However, critical questions have been raised about the validity of the Bayesian framework in explaining the mental process of inference. Firstly, some natural behaviours deviate from Bayesian optimum. Secondly, the neural mechanisms that support Bayesian computations in the brain are yet to be understood. Taking Marr’s cross level approach, we review the recent progress made in addressing these challenges. We first review studies that combined behavioural paradigms and modelling approaches to explain both optimal and suboptimal behaviours. Next, we evaluate the theoretical advances and the current evidence for ecologically feasible algorithms and neural implementations in the brain, which may enable probabilistic inference. We argue that this cross-level approach is necessary for the worthwhile pursuit to uncover mechanistic accounts of human behaviour.}
}
@article{THIEDE201536,
title = {Can teachers accurately predict student performance?},
journal = {Teaching and Teacher Education},
volume = {49},
pages = {36-44},
year = {2015},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2015.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X1500013X},
author = {Keith W. Thiede and Jonathan L. Brendefur and Richard D. Osguthorpe and Michele B. Carney and Amanda Bremner and Sam Strother and Steven Oswalt and Jennifer L. Snow and John Sutton and Dan Jesse},
keywords = {Teacher judgment, Judgment accuracy, Mathematics achievement},
abstract = {In two studies, we examined the effect of professional development to improve mathematics instruction on the accuracy of teachers' monitoring of student learning. Study 1 was conducted with 36 teachers participating in three years of professional development. Judgment accuracy was influenced by the fidelity with which what was learned in the professional development. Study 2 was conducted with 64 teachers from 8 schools, which were randomly assigned to receive professional development or serve as a control. Judgment accuracy was greater for teachers receiving professional development than for teachers who did not and teachers were better to predict students' computational skills.}
}
@article{GAO2023106199,
title = {Letter to the Editor on a shallow water wave equation in Results Phys. 43, 106048 (2022) and its generalization},
journal = {Results in Physics},
volume = {44},
pages = {106199},
year = {2023},
issn = {2211-3797},
doi = {https://doi.org/10.1016/j.rinp.2022.106199},
url = {https://www.sciencedirect.com/science/article/pii/S2211379722008208},
author = {Xin-Yi Gao and Yong-Jiang Guo and Wen-Rui Shan},
keywords = {Generalized shallow water wave equation, Similarity reductions, Symbolic computation},
abstract = {Results Phys. 43, 106048 (2022) has amusingly retrieved some solitonic and other analytic solutions for a shallow water wave equation presented there. In this Letter, we suggest that such an equation be moreover studied in line with Results Phys. 43, 106048 (2022). Employing symbolic computation, for a generalization of that equation, with respect to the displacement and velocity of the water, we construct a family of the similarity reductions, to a known ordinary differential equation. Our results depend on the gravitational force and wave height.}
}
@article{HE2023112111,
title = {Predicting thermodynamic stability of magnesium alloys in machine learning},
journal = {Computational Materials Science},
volume = {223},
pages = {112111},
year = {2023},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2023.112111},
url = {https://www.sciencedirect.com/science/article/pii/S0927025623001052},
author = {Xi He and Jinde Liu and Chen Yang and Gang Jiang},
keywords = {Machine learning, DFT, Thermodynamic stability, Magnesium alloy},
abstract = {Density functional theory (DFT) have been widely used to screen thermodynamically stable material; however, its high computational cost limits its use. In this paper, we explore the use of DFT data from high-throughput calculations to create faster machine learning (ML) models that can be used to screen thermodynamically stable magnesium alloy materials. Our methods work by utilizing the kernel ridge regression (KRR) algorithm, as well as Deep Potential Molecular Dynamics (DeePMD) to train ML models for predicting the formation energy of magnesium alloys. The accuracy, stability, and generalization ability of the ML models created under both methods are evaluated in detail. Meanwhile, we have conducted in-depth comparative analysis of the two methods, which concluded that the accuracy of DeePMD model performs better and time efficiency of KRR model has more advantages. The results show that the best performing DeePMD model and KRR model achieve the RMSE of 0.43 meV/atom and 6.80 meV/atom, indicating that our methods provide a reliable idea for obtaining the formation energy of magnesium alloys.}
}
@incollection{GOMILA201219,
title = {3 - The Relevance of Language for Thought: A Continuum of Possibilities},
editor = {Antoni Gomila},
booktitle = {Verbal Minds},
publisher = {Elsevier},
address = {London},
pages = {19-33},
year = {2012},
isbn = {978-0-12-385200-7},
doi = {https://doi.org/10.1016/B978-0-12-385200-7.00003-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123852007000035},
author = {Antoni Gomila},
keywords = {Cognitive restructuring, linguistic relativism, Whorf, Vygotsky, thinking for speaking, modular interphase, social scaffolding, categorical effect, perceptual similarity},
abstract = {Publisher Summary
This chapter directs the influence and relevance of language on thoughts. Though there has been no outlined domain on how exactly language effects cognitive architecture, the chapter critically studies five most relevant positions that have attracted defenders, critics since twentieth century to contemporary proposals. It discuses relativism, cognitive restructuring, thinking for speaking, language as modular interface, and language as social scaffolding. Linguistic relativism finds its roots in Romanticism as a reaction to the supremacist attitudes of the “Enlightment thinkers,” who were in the business of establishing hierarchies of languages. Cognitive system, being linguistic, acquires a supplementary system of cognitive representation and processing, which transforms the basic capabilities of system and gives rise to new possibilities. Since language is an interface between the modules it attempts to concede to some cognitive impact without challenging the general cognitive architecture of modules of thought as a successful representational vehicle. Lastly, human minds are socially and culturally constituted minds and therefore linguistic symbols (like other kinds of symbols and other social tools in general) allow the individual to externally discharge cognitive processes through language.}
}
@article{BIBI2025115199,
title = {Dopant-free hole transport materials for perovskite solar cells and donor molecules for organic solar cells},
journal = {Computational and Theoretical Chemistry},
volume = {1248},
pages = {115199},
year = {2025},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2025.115199},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X25001355},
author = {Zeeshana Bibi and Javed Iqbal and Ali Raza Ayub and Amna Ayub and Sehrish Gul},
keywords = {DFT, Perovskite solar cell, Hole transporting material, Organic solar cells},
abstract = {This work aimed to create new Ullazine derivatives as hole-transporting materials (HTMs) for perovskite solar cells (PSCs) and donor materials for organic solar cells (OSCs). The newly devised compounds (UM1-UM6) exhibit much smaller energy band gaps and a broader λmax than the UMR because of their strong electron-attracting groups. While UMR has a bandgap of 3.37 eV, the produced molecules ranged from 1.45 to 2.08 eV. The λmax of UM1-UM6 in DCM are 376–460 nm, while the λmax value of UMR is 408 nm. The reference UMR has a λh value of 0.008164 eV, whereas the computationally computed λh values of the UM1-UM6 created molecules range from 0.003777 to 0.008791 eV. Reason being, the acceptor moieties of these compounds make hole transit easier. Furthermore, after all of the newly created molecules were scaled with a PC61BM acceptor, the Voc values were comparable to or higher than the reference, suggesting that these molecules are in a good position to increase efficiency. In terms of PCE (6.27 to 12.33 %), the newly created compounds (UM1-UM6) perform better than the reference compound (PCE = 7.80 %). The newly designed compounds (UM1-UM6) have the potential to be used as noble HTMs in the development of more advanced perovskite solar cells (PSCs) and donor molecules for organic solar cells (OSCs) in the future.}
}
@article{XUE2024108224,
title = {Interaction dynamics of social support expressions predict future support-seeking behaviors in online support groups},
journal = {Computers in Human Behavior},
volume = {156},
pages = {108224},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108224},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400092X},
author = {Haoning Xue and Wang Liao and Jingwen Zhang},
keywords = {Compensation, Computational methods, Interaction dynamics, Online support groups, Reciprocity, Support-seeking},
abstract = {Maintaining the sustainability of online support groups (OSGs) presents a significant challenge. Integrating the literature on interaction dynamics and supportive communication, this study investigated how interaction dynamics in supportive communication foster long-term support-seeking behaviors that are crucial to sustaining continuous support exchanges in OSGs. Using a large-scale dataset of 48,868 posts and 468,243 comments over ten years from an OSG, this study examined how reciprocity and compensation of emotional and informational support, signaled by emotional expressions and analytical expressions, predicted a poster's future support-seeking behaviors in the OSG. Results showed that a poster's future support-seeking behaviors were positively associated with receiving (a) reciprocity of analytical expressions and (b) compensation of negative emotional expressions with positive emotional expressions in their past posts. However, reciprocity of negative emotional expressions was negatively associated with a poster's future support-seeking behaviors. This study emphasizes social support as an ongoing interactive process and its importance in motivating support-seeking behaviors and fostering a thriving OSG.}
}
@incollection{LOEWER20012166,
title = {Cognitive Science: Philosophical Aspects},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2166-2171},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/01026-3},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767010263},
author = {B. Loewer},
abstract = {Three questions have dominated the philosophy of mind in the analytic tradition since Descartes. They are: what are thoughts and thinking? How can the mind represent the world? What is consciousness? Most contemporary analytic philosophers attempt to answer these questions within a broadly materialistic framework since they think that there is overwhelming reason to believe that human beings are biological organisms entirely composed of ordinary matter. Recently the central questions in the philosophy of mind have been given some new twists and partial answers by developments within cognitive science. This article reviews some of the main ideas in cognitive science and its impact on these issues in the philosophy of mind.}
}
@article{JAGER2021133,
title = {Using agent-based modelling to explore behavioural dynamics affecting our climate},
journal = {Current Opinion in Psychology},
volume = {42},
pages = {133-139},
year = {2021},
note = {Psychology of Climate Change (2021)},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2021.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X21000968},
author = {Wander Jager},
keywords = {Agent based modelling, Social complexity, Computational social science, Social simulation, Artificial societies, Environmental behaviour, Climate, Psychology},
abstract = {This article introduces the methodology of agent-based modelling (ABM), explains how it contributes to understanding the dynamics of climate-relevant behaviour and discusses the challenges to implementing behavioural theory in ABMs. Next, an overview will be given on recent advances in environmentally relevant ABMs. The conclusions address the future of the ABM tool in the context of environmentally relevant behaviour in research and education.}
}
@article{XIE2015262,
title = {Evolutionary sampling: A novel way of machine learning within a probabilistic framework},
journal = {Information Sciences},
volume = {299},
pages = {262-282},
year = {2015},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2014.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0020025514011384},
author = {Zhenping Xie and Jun Sun and Vasile Palade and Shitong Wang and Yuan Liu},
keywords = {Evolutionary sampling, Support sample model, Monte Carlo Markov chain, Rejection sampling, Online learning, Particle swarm optimization},
abstract = {In many traditional machine learning methods, sampling is only a process of acquiring training data. However, some studies (on sequential Markov chains and particle filters) have demonstrated that sampling can be used for solving some intractable optimization problems in classical learning methods. Along this line of thinking, the relationships between sampling and learning are theoretically exploited in this paper, wherein the key feature of the sampling process is selecting representative samples from original data that can be modeled by a probability distribution. In theory, acquiring reliable samples is not an easy task for an arbitrary probability distribution. Motivated by approaches in evolutionary computation, rejection sampling and function approximation, a novel sampling strategy, called the evolutionary sampling, is proposed in this paper, and a machine learning method, called the evolutionary sampling approach (ESA), is put forward afterwards. Within ESA, a computing model, called the support sample model (SSM), is presented as well and is used to approximate an original density function. Accordingly, a concrete implementation of an evolutionary sampling approach (ESA) is proposed to seek the optimal model parameters of the SSM. Benefiting from the combination of rejection sampling and evolutionary searching, the ESA can theoretically converge to the optimal solution by minimizing the total variation distance, and can do this with high computational efficiency. Moreover, the normalized factor of a density function can be automatically estimated with high precision within the ESA. As a result, the ESA may be suitable for machine learning problems that could be transformed into density function approximation problems within a probabilistic framework. In addition, derived from the rejection sampling strategy, the ESA can also have online learning abilities required by large-scale data stream processing tasks. Theoretical analyses and application studies are carried out in this paper, and the results demonstrate that the ESA, as a novel way of machine learning, has several prominent merits aspired by past researches in machine learning.}
}
@article{WEISSLER19991061,
title = {A Perspective on Standardizing the Predictive Power of Noninvasive Cardiovascular Tests by Likelihood Ratio Computation: 1. Mathematical Principles},
journal = {Mayo Clinic Proceedings},
volume = {74},
number = {11},
pages = {1061-1071},
year = {1999},
issn = {0025-6196},
doi = {https://doi.org/10.4065/74.11.1061},
url = {https://www.sciencedirect.com/science/article/pii/S0025619611650933},
author = {Arnold M. Weissler},
abstract = {The current practice of reporting positive and negative predictive value (PV), sensitivity (Se), and specificity (Sp) as measures of the power of noninvasive cardiovascular tests has significant limitations. A test result's PV and its comparison with other test results are highly dependent on the pretest disease prevalence at which it is determined; the citation of sensitivity and specificity provides no succinct or explicit quantitation of the rule-in and rule-out power of a test. This article presents a rationale for the use of an alternative standard for expressing predictive power in the form of positive and negative likelihood ratios, (+)LR and (-)LR. The likelihood ratios are composite expressions of test power, which incorporate the Se and Sp and their respective complements [(1 - Se) and (1 - Sp)], thus yielding single unambiguous measures of positive and negative predictive power. The likelihood ratios are calculated as follows: (+)LR = Se(l- Sp) and (-)LR = Sp/(I- Se). On analysis of the predictive value equations, the likelihood ratios equal the quotients of the posttest predictive value odds to the pretest prevalence odds for disease and no disease, respectively, as follows: (+)LR = (+)PVOd/POD and (-)LR = (-)PVOn/PON, where (+)PVO d is positive predictive value odds for disease, POD is prevalence odds for disease, (-)PVOn is negative predictive value odds for no disease, and PON is prevalence odds for no disease. Thus, the likelihood ratios are measures of the odds advantage in posttest probability of disease or no disease relative to pretest probability, independent of disease prevalence in the tested population. The quotients of the (+)LR or the (-)LR among test results studied in a common population are direct expressions of their relative predictive power in that population, The likelihood ratio principle is applicable to the evaluation of the predictive power of multiple tests performed in a common population and to estimating predictive power at multiple test thresholds.}
}
@article{BERZ1990473,
title = {Computational aspects of optics design and simulation: COSY INFINITY},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {298},
number = {1},
pages = {473-479},
year = {1990},
issn = {0168-9002},
doi = {https://doi.org/10.1016/0168-9002(90)90649-Q},
url = {https://www.sciencedirect.com/science/article/pii/016890029090649Q},
author = {Martin Berz},
abstract = {The new differential algebraic (DA) techniques allow very efficient treatment and understanding of nonlinear motion in optical systems as well as circular accelerators. To utilize these techniques in their most general way, a powerful software environment is essential. A language with structure elements similar to Pascal was developed. It has object oriented features to allow for a direct utilization of the elementary operations of the DA package. The compiler of the language is written in Fortran 77 to guarantee wide portability. The language was used to write a very general beam optics code, COSY INFINITY. At its lowest level, it allows the computation of the maps of standard beam line elements including fringe fields and system parameters to arbitrary order. The power of the DA approach coupled with an adequate language environment reveals itself in the very limited length of COSY INFINITY of only a few hundred lines. Grouping of elements as well as structures for optimization and study are readily available through the features of the language. Because of the openness of the approach, it offers a lot of power for more advanced purposes. For example, it is very easy to construct new particle optical elements. There are also many ways to efficiently manipulate and analyze the maps.}
}
@incollection{CUMMINS20171,
title = {Chapter 1 - The Agile Enterprise},
editor = {Fred A. Cummins},
booktitle = {Building the Agile Enterprise (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {1-34},
year = {2017},
series = {The MK/OMG Press},
isbn = {978-0-12-805160-3},
doi = {https://doi.org/10.1016/B978-0-12-805160-3.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128051603000016},
author = {Fred A. Cummins},
keywords = {Agile enterprise, Business impact of technology, Capability-based architecture, Business collaboration management, Value delivery management, Value delivery modeling language},
abstract = {This chapter begins with an introduction to the agile enterprise concept and provides a somewhat historical perspective on the evolution of information technology and its impact on business operations and management. It then introduces three new ways of thinking that are key to today's agile enterprise and are referenced in the subtitle of this book: (1) capability-based architecture, (2) business collaboration management (BCM), and (3) value delivery management (VDM). Finally, the impact of VDM is discussed related to the management of major business changes, along with some critical success factors for the journey to agility.}
}
@article{HICKS2007233,
title = {Lean information management: Understanding and eliminating waste},
journal = {International Journal of Information Management},
volume = {27},
number = {4},
pages = {233-249},
year = {2007},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2006.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0268401206001435},
author = {B.J. Hicks},
keywords = {Information management, SMEs, Waste, Information systems infrastructure, Strategy, Process improvement},
abstract = {This paper deals with the development of a new approach for supporting the improvement of information management and the overall information systems infrastructure. In particular, the paper discusses the application of lean thinking to information management; where information management can be considered to involve adding value to information by virtue of how it is organised, visualised and represented; and enabling information (value) to flow to the end-user (customer) through the processes of exchange, sharing and collaboration. The potential benefits of lean thinking are discussed and the fundamental barriers for its application to information management are highlighted. These include the need to characterise the nature of waste and establish the five principles of; value, value streams, flow, pull and continuous improvement in the context of information management. It follows that the core contribution of this paper is the development of an understanding of these critical elements and the creation of a conceptual framework for a set of lean principles within the context of information management. This framework offers a unique and arguably generic approach for supporting the retrospective improvement of information management systems and the overall information systems infrastructure.}
}
@article{ADAMS201731,
title = {Patternlets — A teaching tool for introducing students to parallel design patterns},
journal = {Journal of Parallel and Distributed Computing},
volume = {105},
pages = {31-41},
year = {2017},
note = {Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S074373151730014X},
author = {Joel C. Adams},
keywords = {Design patterns, Education, MPI, Multiprocessing, Multithreading, OpenMP, Parallel, Patternlets, Teaching, Threads},
abstract = {Thanks to the ubiquity of multicore processors, today’s CS students must be introduced to parallel computing or they will be ill prepared as modern software developers. Professional developers of parallel software think in terms of parallel design patterns, which are markedly different from traditional (sequential) design patterns. It follows that the more we can teach students to think in terms of parallel patterns, the more their thinking will resemble that of parallel software professionals. In this paper, we present patternlets—minimalist, scalable, syntactically correct programs, each designed to introduce students to a particular parallel design pattern. The collection currently includes 44 patternlets (16 MPI, 17 OpenMP, 9 Pthreads, and 2 heterogeneous), of which we present a representative sample. We also present data that indicate the use of patternlets to introduce parallelism in CS2 produced a modest improvement in student understanding of parallel concepts.}
}
@article{EVANS2008100,
title = {When can we say ‘if’?},
journal = {Cognition},
volume = {108},
number = {1},
pages = {100-116},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2008.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010027708000310},
author = {Jonathan St.B.T. Evans and Helen Neilens and Simon J. Handley and David E. Over},
keywords = {Conditionals, Reasoning, Decision making, Language comprehension},
abstract = {In this study, we focus on the conditions which permit people to assert a conditional statement of the form ‘if p then q’ with conversational relevance. In a broadly decision-theoretic approach, also drawing on hypothetical thinking theory [Evans, J. St. B. T. (2007). Hypothetical thinking: Dual processes in reasoning and judgement. Hove, UK: Psychology Press.], we predicted that conditional tips and promises would appear more useful and persuasive and be more likely to encourage an action p when (a) the conditional link from p to q was stronger, (b) the cost of the action p was lower and (c) the benefit of the consequence q was higher. Similarly, we predicted that conditional warnings and threats would be seen as more useful and persuasive and more likely to discourage an action p when (a) the conditional link from p to q was stronger, (b) the benefit of the action p was lower and (c) the cost of the consequence q was higher. All predictions were strongly confirmed, suggesting that such conditionals may best be asserted when they are of high relevance to the goals of the listener.}
}
@article{TAKAMA20151263,
title = {NFC-based Tangible User Interface for Information Curation and Its Application to Analogy Game},
journal = {Procedia Computer Science},
volume = {60},
pages = {1263-1270},
year = {2015},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.192},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915023194},
author = {Yasufumi Takama and Tomohiro Ito and Hiroshi Ishikawa},
keywords = {Tangible user interface (TUI), Near field communication (NFC), Smartphone, Information curation, Analogy game},
abstract = {This paper applies a Tangible User Interface (TUI) for information curation using Near Field Communication (NFC) to an analogy game. The increase in text data is more remarkable in current IT society. Although those are usually accessed with using Graphical User Interface (GUI), users except experienced computer users have difficulty in reading and organizing data with GUI. In particular, information curation such as grouping related data / information and finding relationship among them is difficult. In order to solve this problem, an interface that can access text data intuitively is expected. We are developing a TUI based on NFC, by which a user can move and group text data in a similar manner when handling paper documents. As one of the promising applications of the proposed TUI, this paper focuses on creative thinking support, for which touching externalized thought by hand is expected to be effective. An experiment is conducted, in which test participants did an analogy game with using the proposed TUI. The experimental result shows experience of using the TUI affects the participants’ self-evaluation about idea creation.}
}
@incollection{KAKKAR2025215,
title = {Chapter 11 - A neuroinspired journey: Tracing the evolution and objectives of neuromorphic systems},
editor = {Harish Garg and Jyotir {Moy Chatterjee} and R. Sujatha and Shatrughan Modi},
booktitle = {Primer to Neuromorphic Computing},
publisher = {Academic Press},
pages = {215-238},
year = {2025},
isbn = {978-0-443-21480-6},
doi = {https://doi.org/10.1016/B978-0-443-21480-6.00009-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443214806000092},
author = {Mohit Kumar Kakkar},
keywords = {Neuromorphic computing, Von Neumann Model, Neural network architecture, Artificial neural networks, Neuromorphic framework},
abstract = {A subfield of computing known as “neuromorphic computing” (NC) develops cutting-edge and effective computing platforms by drawing inspiration from the anatomy and physiology of the human brain. The potential for energy savings offered by NC is one of its primary benefits. Neuromorphic systems aim to replicate the brain's remarkable energy efficiency by utilizing specialized hardware designs and algorithms that optimize computation and minimize data movement to reduce power consumption. This work presents a thorough investigation of the development and goals of neuromorphic frameworks, taking motivation from the complicated functions of the human mind. It investigates the motives and driving forces behind the pursuit of NC, such as the search for highly parallel and energy-efficient computing architectures. In addition, this work has discussed the thematic areas and benchmarks for progress in NC as well. This chapter serves as a guide through the neuroinspired journey of neuromorphic systems, revealing insight into their past, present, and future.}
}