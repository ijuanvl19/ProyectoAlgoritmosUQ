@article{PFOTENHAUER201638,
title = {Architecting complex international science, technology and innovation partnerships (CISTIPs): A study of four global MIT collaborations},
journal = {Technological Forecasting and Social Change},
volume = {104},
pages = {38-56},
year = {2016},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2015.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0040162515004102},
author = {Sebastian M. Pfotenhauer and Danielle Wood and Dan Roos and Dava Newman},
keywords = {Innovation policy, Research collaboration, Regional development, University partnerships, System architecture, Policy design, MIT, International partnerships},
abstract = {Complex international partnerships have emerged as a policy instrument of choice for many governments to build domestic capacity in science, technology and innovation with the help of foreign partners. At present, these flagship initiatives tend to be primarily practitioner-driven with limited systematic understanding of available design options and trade-offs. Here, we present an analysis of four such partnerships from the university sector between the Massachusetts Institute of Technology (MIT) and governments in the UK, Portugal, Abu Dhabi, and Singapore. Using a system architecture approach in conjunctions with in-depth case studies and elements of interpretive policy analysis, we map how in each country distinct capacity-building goals, activities, and political and institutional contexts translate into different partnership architectures: a bilateral hub-&-spokes architecture (UK), a consortium architecture (Portugal), an institution-building architecture (Abu Dhabi), and a functional expansion architecture (Singapore). Despite these differences in emergent macro-architectures, we show that each partnership draws on an identical, limited set of ‘forms’ that can by organized around four architectural views (education, research, innovation & entrepreneurship, institution-building) and four levels of interaction between partners (people, programs/projects, objects, organization/process). Based on our analysis, we derive a design matrix that can help guide the development future partnerships through a systematic understanding of available design choices. Our research underscores the utility and flexibility of complex international partnerships as systemic policy instruments. It suggests a greater role for global research universities in capacity-building and international development, and emphasizes the potential of targeted cross-border funding. Our research also demonstrates the analytic power of system architecture for policy analysis and design. We argue that architectural thinking provides a useful stepping stone for STS-type interpretive policy analysis into national innovation initiatives in different political cultures, as well as more custom-tailored approaches to program evaluation.}
}
@article{NOROOZI201279,
title = {Argumentation-Based Computer Supported Collaborative Learning (ABCSCL): A synthesis of 15 years of research},
journal = {Educational Research Review},
volume = {7},
number = {2},
pages = {79-106},
year = {2012},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2011.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X11000522},
author = {Omid Noroozi and Armin Weinberger and Harm J.A. Biemans and Martin Mulder and Mohammad Chizari},
keywords = {Argumentation, Argumentative knowledge construction, Collaborative argumentation, Computer-Supported Collaborative Learning, Argumentation-Based Computer Supported Collaborative Learning},
abstract = {Learning to argue is an essential objective in education; and online environments have been found to support the sharing, constructing, and representing of arguments in multiple formats for what has been termed Argumentation-Based Computer Supported Collaborative Learning (ABCSCL). The purpose of this review is to give an overview of research in the field of ABCSCL and to synthesize the findings. For this review, 108 publications (89 empirical studies and 19 conceptual papers) on ABCSCL research dating from 1995 through 2011 were studied to highlight the foci of the past 15 years. Building on Biggs’ (2003) model, the ABCSCL publications were systematically categorized with respect to student prerequisites, learning environment, processes, and outcomes. Based on the quantitative and qualitative findings, this paper concludes that ABCSCL environments should be designed in a systematic way that takes the variety of specific conditions for learning into account. It also offers suggestions for educational practice and future research.}
}
@incollection{TAIEF2025582,
title = {1.44 - The Application of Machine Learning for Green Hydrogen Production},
editor = {Professor Abdul Ghani Olabi},
booktitle = {Comprehensive Green Materials (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {582-593},
year = {2025},
isbn = {978-0-443-15739-4},
doi = {https://doi.org/10.1016/B978-0-443-15738-7.00030-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157387000301},
author = {Wafa Taief and Amani Al-Othman and Muhammad Tawalbeh},
keywords = {Green hydrogen, Hydrogen production, Machine learning, Optimization algorithms., Water electrolysis},
abstract = {It is no secret that the amount of pollution that fossil fuels cause in the environment when burned. When searching for alternative solutions, it is noted that hydrogen is an attractive option because of its many advantages that are included in this work. Hydrogen can be produced by different methods. In this work, there is a comprehensive review of the hydrogen production methods divided according to the sources, either renewable or nonrenewable, and the type of energy used based on both single and combined forms. In this work, there is a general view of the machine learning algorithms and models and the categories that they belong to, as well as their application in green hydrogen production. This work is very useful for the readers to organize their ideas about hydrogen production methods and machine learning and its applications to produce green hydrogen, so after reading this work, they can know their specific interests and search for details about it.}
}
@article{DELIMA2023100590,
title = {Managing the plot structure of character-based interactive narratives in games},
journal = {Entertainment Computing},
volume = {47},
pages = {100590},
year = {2023},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2023.100590},
url = {https://www.sciencedirect.com/science/article/pii/S1875952123000459},
author = {Edirlei Soares {de Lima} and Bruno Feijó and Antonio L. Furtado},
keywords = {Interactive storytelling, Narrative generation, Drama management, Plot structure, Automated planning},
abstract = {The use of narrative generation methods in games is a complex challenge that involves multiple problems of plot-based processes integrated with character-based methods. Examples of these problems are the high computational complexity of many story generation algorithms, the difficulties associated with the generation of interactive narratives that are compelling and emotionally impactful, the complex interactions among characters, and the need for tools and methods to support story writers in the process of creating and managing the narrative structure of interactive stories. In this work, we present and evaluate a new approach to generate and manage the plot structure of character-based interactive narratives in games, which combines multi-agent planning with a drama management strategy based on narrative structures. The proposed method is supported by an authoring tool that allows authors to create and test interactive narratives using graphical interfaces and intuitive diagrams. The results of our study suggest the effectiveness of our approach in generating interactive narratives for highly interactive game environments. In addition, a user study of the proposed authoring tool indicates that it can successfully support the development of character-based interactive narratives without requiring programming knowledge.}
}
@article{LATIF2023726,
title = {Design and Development a Virtual Planetarium Learning Media Using Augmented Reality},
journal = {Procedia Computer Science},
volume = {227},
pages = {726-733},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.577},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923017441},
author = {Jazlyn Jan Keyla Latif and Augustinus Adrian Triputra and Michael Awarsa Kesuma and Fairuz Iqbal Maulana},
keywords = {Augmented Reality, Planetarium, Virtual, Virtual Planetarium, Application},
abstract = {The solar system has always been a mystery to many. If not for the advanced technologies, most humans would not have the opportunity to gain knowledge about the planets. Although Earth is a part of the solar system, the solar system is simply too dangerous and expensive for humans to explore casually. Humans do not interact with the Sun or planets actively. This is especially concerning for children who often require visual aids in studying. An Augmented Reality (AR) based application can solve that problem. Through Virtual Planetarium, children may interact with the Sun or the planets and gain information. This will help aid children's guardians in studying the solar system. The application is made by Systems Development Life Cycle (SDLC) method. Through the making of this application, it is expected that children will have a better understanding of the solar system.}
}
@article{BURGESS2011427,
title = {On system rollback and totalized fields: An algebraic approach to system change},
journal = {The Journal of Logic and Algebraic Programming},
volume = {80},
number = {8},
pages = {427-443},
year = {2011},
issn = {1567-8326},
doi = {https://doi.org/10.1016/j.jlap.2011.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1567832611000488},
author = {Mark Burgess and Alva Couch},
abstract = {In system operations the term rollback is often used to imply that arbitrary changes can be reversed i.e. ‘rolled back’ from an erroneous state to a previously known acceptable state. We show that this assumption is flawed and discuss error-correction schemes based on absolute rather than relative change. Insight may be gained by relating change management to the theory of computation. To this end, we reformulate previously-defined ‘convergent change operators’ of Burgess into the language of groups and rings. We show that, in this form, the problem of rollback from a convergent operation becomes equivalent to that of ‘division by zero’ in computation. Hence, we discuss how recent work by Bergstra and Tucker on zero-totalized fields helps to clear up long-standing confusion about the options for ‘rollback’ in change management.}
}
@article{HIEBERT1992439,
title = {Chapter 3 Reflection and communication: Cognitive considerations in school mathematics reform},
journal = {International Journal of Educational Research},
volume = {17},
number = {5},
pages = {439-456},
year = {1992},
issn = {0883-0355},
doi = {https://doi.org/10.1016/S0883-0355(05)80004-7},
url = {https://www.sciencedirect.com/science/article/pii/S0883035505800047},
author = {James Hiebert},
abstract = {The mathematics education reform efforts in the United States are shaped partially by our understanding of how students learn mathematics. Two traditions in psychology influence our current thinking most forcefully — cognitive psychology with its emphasis on individual mental operations and social cognition with its emphasis on context and group interaction. Reflection and communication, as cognitive processes and as representatives of these respective traditions, are used to establish the cognitive-based rationale for the reform and to analyze the nature of recommended changes. Issues addressed include the interdependence of reflection and communication and the way in which these processes can be used to analyze aspects of the school mathematics program, such as the way textbooks ordinarily treat written symbols. Although the theoretical arguments for reflection and communication are being increasingly well-articulated, the empirical data that address the claims are comparatively sparse. Future research efforts should aim to test theoretical claims for reflection and communication and to increase our understanding of the relationships between these cognitive processes and learning mathematics.}
}
@article{NEUMAN2014650,
title = {Personality from a cognitive-biological perspective},
journal = {Physics of Life Reviews},
volume = {11},
number = {4},
pages = {650-686},
year = {2014},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2014.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1571064514001584},
author = {Yair Neuman},
keywords = {Personality, Threat, Trust, Distrust, Psychology, Interdisciplinarity},
abstract = {The term “personality” is used to describe a distinctive and relatively stable set of mental traits that aim to explain the organism's behavior. The concept of personality that emerged in human psychology has been also applied to the study of non-human organisms from birds to horses. In this paper, I critically review the concept of personality from an interdisciplinary perspective, and point to some ideas that may be used for developing a cognitive-biological theory of personality. Integrating theories and research findings from various fields such as cognitive ethnology, clinical psychology, and neuroscience, I argue that the common denominator of various personality theories are neural systems of threat/trust management and their emotional, cognitive, and behavioral dimensions. In this context, personality may be also conceived as a meta-heuristics both human and non-human organisms apply to model and predict the behavior of others. The paper concludes by suggesting a minimal computational model of personality that may guide future research.}
}
@article{PAI201872,
title = {Assessing mobile health applications with twitter analytics},
journal = {International Journal of Medical Informatics},
volume = {113},
pages = {72-84},
year = {2018},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2018.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S1386505618301199},
author = {Rajesh R. Pai and Sreejith Alathur},
keywords = {Mobile health, Sentiment analysis, Twitter analytics, Causal loop diagram, Technology adoption model},
abstract = {Introduction
Advancement in the field of information technology and rise in the use of Internet has changed the lives of people by enabling various services online. In recent times, healthcare sector which faces its service delivery challenges started promoting and using mobile health applications with the intention of cutting down the cost making it accessible and affordable to the people.
Objectives
The objective of the study is to perform sentiment analysis using the Twitter data which measures the perception and use of various mobile health applications among the citizens.
Methods
The methodology followed in this research is qualitative with the data extracted from a social networking site “Twitter” through a tool RStudio. This tool with the help of Twitter Application Programming Interface requested one thousand tweets each for four different phrases of mobile health applications (apps) such as “fitness app”, “diabetes app”, “meditation app”, and “cancer app”. Depending on the tweets, sentiment analysis was carried out, and its polarity and emotions were measured.
Results
Except for cancer app there exists a positive polarity towards the fitness, diabetes, and meditation apps among the users. Following a system thinking approach for our results, this paper also explains the causal relationships between the accessibility and acceptability of mobile health applications which helps the healthcare facility and the application developers in understanding and analyzing the dynamics involved the adopting a new system or modifying an existing one.}
}
@article{SCHIFFMAN20041079,
title = {Mainstream economics, heterodoxy and academic exclusion: a review essay},
journal = {European Journal of Political Economy},
volume = {20},
number = {4},
pages = {1079-1095},
year = {2004},
issn = {0176-2680},
doi = {https://doi.org/10.1016/j.ejpoleco.2004.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0176268004000643},
author = {Daniel A. Schiffman},
keywords = {Academic exclusion, Pluralism, Economics education, Historical specificity, Heterodoxy},
abstract = {Does the mainstream of economic thinking and analysis tend systematically to exclude ideas and approaches that could enrich the field, and, as a consequence, have important questions and issues been shunted aside for nonobjective reasons? Two recent volumes by heterodox economists that address these questions are Geoffrey Hodgson's How Economics Forgot History: The Problem of Historical Specificity in Social Science, and Steve Keen's Debunking Economics: The Naked Emperor of the Social Sciences. I evaluate their claims of academic exclusion and assess the current state of (selective) pluralism within mainstream economics.}
}
@article{SPROULE2002412,
title = {Fuzzy pharmacology: theory and applications},
journal = {Trends in Pharmacological Sciences},
volume = {23},
number = {9},
pages = {412-417},
year = {2002},
issn = {0165-6147},
doi = {https://doi.org/10.1016/S0165-6147(02)02055-2},
url = {https://www.sciencedirect.com/science/article/pii/S0165614702020552},
author = {Beth A. Sproule and Claudio A. Naranjo and I.Burhan Türksen},
keywords = {fuzzy logic, pharmacodynamics, fuzzy sets, modelling, predictions, pharmacokinetics},
abstract = {Fuzzy pharmacology is a term coined to represent the application of fuzzy logic and fuzzy set theory to pharmacological problems. Fuzzy logic is the science of reasoning, thinking and inference that recognizes and uses the real world phenomenon that everything is a matter of degree. It is an extension of binary logic that is able to deal with complex systems because it does not require crisp definitions and distinctions for the system components. In pharmacology, fuzzy modeling has been used for the mechanical control of drug delivery in surgical settings, and work has begun evaluating its use in other pharmacokinetic and pharmacodynamic applications. Fuzzy pharmacology is an emerging field that, based on these initial explorations, warrants further investigation.}
}
@article{MAO2024101988,
title = {A survey on semantic processing techniques},
journal = {Information Fusion},
volume = {101},
pages = {101988},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101988},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523003044},
author = {Rui Mao and Kai He and Xulang Zhang and Guanyi Chen and Jinjie Ni and Zonglin Yang and Erik Cambria},
keywords = {Semantic processing, Word sense disambiguation, Anaphora resolution, Named entity recognition, Concept extraction, Subjectivity detection},
abstract = {Semantic processing is a fundamental research domain in computational linguistics. In the era of powerful pre-trained language models and large language models, the advancement of research in this domain appears to be decelerating. However, the study of semantics is multi-dimensional in linguistics. The research depth and breadth of computational semantic processing can be largely improved with new technologies. In this survey, we analyzed five semantic processing tasks, e.g., word sense disambiguation, anaphora resolution, named entity recognition, concept extraction, and subjectivity detection. We study relevant theoretical research in these fields, advanced methods, and downstream applications. We connect the surveyed tasks with downstream applications because this may inspire future scholars to fuse these low-level semantic processing tasks with high-level natural language processing tasks. The review of theoretical research may also inspire new tasks and technologies in the semantic processing domain. Finally, we compare the different semantic processing techniques and summarize their technical trends, application trends, and future directions.}
}
@article{TERZIEVA2024106,
title = {Trends, Challenges, Opportunities, and Innovations in STEM Education},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {3},
pages = {106-111},
year = {2024},
note = {22nd IFAC Conference on Technology, Culture and International Stability TECIS 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.07.134},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324002179},
author = {Valentina Terzieva and Elena Paunova-Hubenova and Savina Slavcheva},
keywords = {STEM education, STEM teaching approaches, STEM challenges, innovative teaching methods},
abstract = {STEM education aims to prepare students for their future jobs, providing authentic tasks and problems to solve. Usually, approaches to teaching STEM subjects are based on a constructivist learning theory that accentuates active, practical, and interactive learning approaches. Nowadays, the implementation of STEM education faces several logistical and pedagogical challenges, which can impact the effectiveness of STEM education programs. The conditions for applying information technologies in STEM education in Bulgarian schools and universities are presented. The paper proposes a conceptual model of the innovative STEM educational system, which includes personalization and optimization of the applied teaching methods.}
}
@article{STOJANOVIC2021107270,
title = {Application of distance learning in mathematics through adaptive neuro-fuzzy learning method},
journal = {Computers & Electrical Engineering},
volume = {93},
pages = {107270},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107270},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621002536},
author = {Jelena Stojanović and Dalibor Petkovic and Ibrahim M Alarifi and Yan Cao and Nebojsa Denic and Jelena Ilic and Hamid Assilzadeh and Sead Resic and Biljana Petkovic and Afrasyab Khan and Milosav Milickovic},
keywords = {Pupils, E-learning, Distance learning, Moodle, Computational intelligent},
abstract = {The main aim of the study is analyzing of pupils’ knowledge in mathematics by adaptive neuro fuzzy inference system (ANFIS) after implementation of distance learning application or e-learning (electronic learning). Since a large number of faculties and other institutions are increasingly using e-learning, it can be stated that for this purpose the Modular object-oriented dynamic learning environment (Moodle) learning management system (LMS) is mostly used. This paper deals with the analysis of distance learning and the application of Moodle LMS in higher education institutions, taking into account the impact of such education on the quality of teaching and the acquisition of knowledge by students, and the methods teachers use in Serbia. The ANFIS is used to determine which factors are the most important for pupils’ performance in mathematics. The results show that the main influence on the pupils’ performance is their prior knowledge. The prior knowledge is more effective when it is combined with education software in the lectures of mathematics in elementary school. In secondary school, the prior knowledge is more effective if it is combined with motivation for learning mathematics.}
}
@article{SCHAFER2020100360,
title = {Lenstool-HPC: A High Performance Computing based mass modelling tool for cluster-scale gravitational lenses},
journal = {Astronomy and Computing},
volume = {30},
pages = {100360},
year = {2020},
issn = {2213-1337},
doi = {https://doi.org/10.1016/j.ascom.2019.100360},
url = {https://www.sciencedirect.com/science/article/pii/S2213133719301349},
author = {C. Schäfer and G. Fourestey and J.-P. Kneib},
keywords = {Gravitational lensing software, High performance computing algorithms, Applied computing: astronomy, Galaxies: clusters, Galaxies: halos, Lenstool},
abstract = {With the upcoming generation of telescopes, cluster scale strong gravitational lenses will act as an increasingly relevant probe of cosmology and dark matter. The better resolved data produced by current and future facilities requires faster and more efficient lens modelling software. Consequently, we present Lenstool-HPC, a strong gravitational lens modelling and map generation tool based on High Performance Computing (HPC) techniques and the renowned Lenstool software. We also showcase the HPC concepts needed for astronomers to increase computation speed through massively parallel execution on supercomputers. Lenstool-HPC was developed using lens modelling algorithms with high amounts of parallelism. Each algorithm was implemented as a highly optimised CPU, GPU and Hybrid CPU–GPU version. The software was deployed and tested on the Piz Daint cluster of the Swiss National Supercomputing Centre (CSCS). Lenstool-HPC perfectly parallel lens map generation and derivative computation achieves a factor 30 speed-up using only 1 GPU compared to Lenstool. Lenstool-HPC hybrid Lens-model fit generation tested at Hubble Space Telescope precision is scalable up to 200 CPU–GPU nodes and is faster than Lenstool using only 4 CPU–GPU nodes.}
}
@article{PREM2024100075,
title = {Principles of digital humanism: A critical post-humanist view},
journal = {Journal of Responsible Technology},
volume = {17},
pages = {100075},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100075},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000015},
author = {Erich Prem},
keywords = {Digital humanism, Principles, Computer ethics, AI ethics, Digital sovereignty, Humanism},
abstract = {Digital humanism emerges from serious concerns about the way in which digitisation develops, its impact on society and on humans. While its motivation is clear and broadly accepted, it is still an emerging field that does not yet have a universally accepted definition. Also, it is not always clear how to differentiate digital humanism from other similar endeavours. In this article, we critically investigate the notion of digital humanism and present its main principles as shared by its key proponents. These principles include the quest for human dignity and the ideal of a better society based on core values of the Enlightenment. The paper concludes that digital humanism is to be treated as a technical endeavour to shape digital technologies and use them for digital innovation, a political endeavour investigating power shifts triggered by digital technology, and, at the same time, as a philosophical endeavour including the quest to delineate its scope and to draw boundaries for the digital. Methodologically, digital humanism is an interdisciplinary effort to debate a broad range of digitisation shortfalls in their totality, from privacy infringements to power shifts, from human alienation to disownment. While it overlaps with a range of established fields and other movements, digital humanism reflects a new academic, engineering, and societal awareness of the challenges of digital technologies.}
}
@article{ARIFOVIC20071971,
title = {Call market book information and efficiency},
journal = {Journal of Economic Dynamics and Control},
volume = {31},
number = {6},
pages = {1971-2000},
year = {2007},
note = {Tenth Workshop on Economic Heterogeneous Interacting Agents},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2007.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0165188907000073},
author = {Jasmina Arifovic and John Ledyard},
keywords = {Computer testbeds, Call markets, Learning, Experiments with human subjects, Closed book, Market design},
abstract = {What are the consequences of making bids and offers in the book available to traders in a call market? This is a problem in market design. We employ a computational mechanism design methodology to attack this problem and find that allocative efficiencies are higher in a closed book design. We validate our computational approach by running a series of tests with human subjects in exactly the same environments.}
}
@article{CHO2025101169,
title = {How age and culture influence cognition: A lifespan developmental perspective},
journal = {Developmental Review},
volume = {75},
pages = {101169},
year = {2025},
issn = {0273-2297},
doi = {https://doi.org/10.1016/j.dr.2024.101169},
url = {https://www.sciencedirect.com/science/article/pii/S0273229724000534},
author = {Isu Cho and Angela Gutchess},
keywords = {Cognitive Aging, Culture, Cognition, Culture and Cognition, Children, Lifespan perspective},
abstract = {It has long been assumed that cognitive aging is a universal phenomenon. However, increasing evidence substantiates the importance of individual differences in cognitive aging. How do experiential factors related to culture shape developmental trajectories of cognition? We propose a new model examining how age and culture influence cognitive processes, building on past models and expanding upon them to incorporate a lifespan developmental perspective. The current model posits that how age and culture interact to influence cognition depends on (a) the extent to which the cognitive task relies on top-down or bottom-up processes, and (b) for more top-down processes, the level of cognitive resources required to perform the task. To assess the validity of the model, we review literature not only from adulthood but also childhood, making this the first model to adopt a lifespan perspective in the study of culture and cognition. The current work advances understanding of cognitive aging by delineating the combined effects of biological aging processes, assumed to apply across cultures, and culture-dependent experiential aging processes, which reflect unique cultural experiences throughout one’s lifespan. This approach enables understanding of comprehensive potential mechanisms that underlie the influence of culture on cognitive development across life stages.}
}
@article{ELZANFALY201579,
title = {[I3] Imitation, Iteration and Improvisation: Embodied interaction in making and learning},
journal = {Design Studies},
volume = {41},
pages = {79-109},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X1500071X},
author = {Dina El-Zanfaly},
keywords = {computational making, design education, design technology, interaction design, reflective practice},
abstract = {I introduce in this paper a new learning and making process that fosters a new ability to make things through the body's direct, iterative engagement with materials, tools, machines and objects. Tested in a variety of educational settings, this method, which I call ‘I3’ for its three-layer operation of ‘Imitation, Iteration and Improvisation’, allows learners to develop their sensory experiences to improvise and create on their own. I introduce case studies in order to test I3. I challenge the separation of design and construction often reinforced by the use of digital fabrication. I show that learning to make and learning from making emerge together through a situated and embodied interaction among the learner, the materials, the tools and the object in-the-making.}
}
@article{ZHENG2025,
title = {Machine Memory Intelligence: Inspired by Human Memory Mechanisms},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925000293},
author = {Qinghua Zheng and Huan Liu and Xiaoqing Zhang and Caixia Yan and Xiangyong Cao and Tieliang Gong and Yong-Jin Liu and Bin Shi and Zhen Peng and Xiaocen Fan and Ying Cai and Jun Liu},
keywords = {Machine memory intelligence, Neural mechanism, Associative representation, Continual learning, Collaborative reasoning},
abstract = {Large models, exemplified by ChatGPT, have reached the pinnacle of contemporary artificial intelligence (AI). However, they are plagued by three inherent drawbacks: excessive training data and computing power consumption, susceptibility to catastrophic forgetting, and a deficiency in logical reasoning capabilities within black-box models. To address these challenges, we draw insights from human memory mechanisms to introduce “machine memory,” which we define as a storage structure formed by encoding external information into a machine-representable and computable format. Centered on machine memory, we propose the brand-new machine memory intelligence (M2I) framework, which encompasses representation, learning, and reasoning modules and loops. We explore the key issues and recent advances in the four core aspects of M2I, including neural mechanisms, associative representation, continual learning, and collaborative reasoning within machine memory. M2I aims to liberate machine intelligence from the confines of data-centric neural networks and fundamentally break through the limitations of existing large models, driving a qualitative leap from weak to strong AI.}
}
@article{PALHARESDEMELO200121,
title = {Recommendation for fertilizer application for soils via qualitative reasoning},
journal = {Agricultural Systems},
volume = {67},
number = {1},
pages = {21-30},
year = {2001},
issn = {0308-521X},
doi = {https://doi.org/10.1016/S0308-521X(00)00044-5},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X00000445},
author = {L.A.M. {Palhares de Melo} and D.J. Bertioli and E.V.M. Cajueiro and R.C. Bastos},
keywords = {Fertilizer application, Qualitative reasoning, Approximate reasoning},
abstract = {In Brazil, liming and fertilization are essential practices in agriculture due to the soils being acidic and poor in nutrients. Distinct decision tables that serve as support for recommendation of fertilizer application are used, but one of their features is that they are based on a strictly quantitative analysis of input variables. This sometimes causes dificulties in their use when calculating the output (recommended fertilizer application). This work presents a model for the use and interpretation of decision tables for fertilizer application. It is based on a qualitative characterization for the rules and input variables used. The results have shown that this approach gives feasible results which more accurately reflect human thinking about the decision table.}
}
@article{FORTINI2023107058,
title = {An experimental and numerical study of the solid particle erosion damage in an industrial cement large-sized fan},
journal = {Engineering Failure Analysis},
volume = {146},
pages = {107058},
year = {2023},
issn = {1350-6307},
doi = {https://doi.org/10.1016/j.engfailanal.2023.107058},
url = {https://www.sciencedirect.com/science/article/pii/S1350630723000122},
author = {Annalisa Fortini and Alessio Suman and Nicola Zanini},
keywords = {Wear damage, Hardfacing, Centrifugal fan, Computational fluid dynamics, Solid particle erosion, Metallographic analysis},
abstract = {The present paper addresses the wear failure analysis of a large-sized centrifugal fan operating in a cement clinker grinding plant. Within cement production, the calcination at middle and high-temperature values (from 120 °C to 400 °C depending on the process parameters) of the raw material requires such a process fan, which also ensures the draft and feed of the flue gases and combustion air needed for the operation of the main equipment of the cement factory. To detect and analyze the impact conditions within the heavy-duty fan, Computational Fluid Dynamics (CFD) analyses were performed. The analysis of the numerical results shows that the relevant fan surfaces are affected by different impact velocities and angles, generating non-uniform erosion patterns similar to the on-field detections. Besides, the obtained comprehensive description of the flow and contaminants behaviors through the entire flow path enables setting up the subsequent experimental investigation. The erosive wear behavior of a Fe-Cr-C hardfacing cast iron and wear-resistant steel was tested through a test rig constructed for the purpose of being in accordance with the ASTM G76 standard. The test bench was adapted to manage the raw meal powder used in the cement factory to reproduce the actual operating conditions. The results show a greater capability of Fe-Cr-C hardfacing cast iron to face the erosion phenomenon in terms of lower values of material loss over the exposure time. These findings, coupled with the metallographic analysis to detect the erosion mechanisms (ductile and/or brittle), help a better prediction of the fan operating life. The investigation showed the reliability of the numerical/experimental coupled approach in assessing the actual erosion magnitude and the influence of the impact angle on the erosion phenomena. This coupled approach gains a further understanding of the proper design of manufacturing and maintenance activities, covering several project steps from material selections to the scheduled and overhaul operations. A reliable operating-life prediction allows manufacturers and operators to obtain production and economic goals.}
}
@article{ZHANG2022101922,
title = {Multiple-symbol noncoherent learning detection of coded QAM signals in IEEE 802.15.3 Wireless Multi-media Networks},
journal = {Physical Communication},
volume = {55},
pages = {101922},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2022.101922},
url = {https://www.sciencedirect.com/science/article/pii/S1874490722001999},
author = {Gaoyuan Zhang and Congfang Ma and Kai Chen and Yongen Li and Haiqiong Li and Congzheng Han},
keywords = {Wireless Multi-media Networks, Noncoherent detection, Deep learning, Uniform quantization},
abstract = {We consider the noncoherent deep learning problem for coded signal detection under the phase noncoherent channels for remote home healthcare applications with high data rate. In particular, a multiple-symbol noncoherent learning detection (MNLD) scheme based on neural networks is proposed for low-density parity-check (LDPC) coded noncoherent quadrature amplitude modulation (QAM) signals in IEEE 802.15.3 Wireless Multi-media Networks. Our derivation shows that extensive operations for the first kind zero-order modified Bessel function is unavoidable for the implementation of the optimal bit log-likelihood ratio (LLR) for decoding in traditional multiple-symbol detection (MSD) scheme. The perfect estimation of the channel state information (CSI), i.e., a priori information about the variance of the additive white Gaussian noise (AWGN), is also required for the receiver. This is clearly not computationally practical for Wireless Multi-media Networks. Consequently, we developed an improved approach based on feed-forward neural networks to accurately calculate the bit LLR. Furthermore, to decrease the generation size of training set and thus increase the training speed of the proposed neural networks, we uniformly quantize the continuous carrier phase offset (CPO), which is random and unknown, into discrete status. Our simulation results verify the learning efficiency of this simplified training-set generation configuration. The decoding convergence is successfully accelerated and much performance gain is finally achieved when compared with traditional decoding using the perfect bit LLR. This is clearly critical for high reliable transmission of home healthcare information.}
}
@article{RAN2024102578,
title = {Spatiotemporal characteristics and influencing factors of airport service quality in China},
journal = {Journal of Air Transport Management},
volume = {117},
pages = {102578},
year = {2024},
issn = {0969-6997},
doi = {https://doi.org/10.1016/j.jairtraman.2024.102578},
url = {https://www.sciencedirect.com/science/article/pii/S0969699724000437},
author = {Xinyue Ran and Lingling Li and Ruiling Han},
keywords = {Airport, Aviation complaint, Service quality, Influencing factors, Spatiotemporal differentiation characteristic},
abstract = {Airport service quality (ASQ) is essential for determining the quality of ground civil aviation services. In this study, ASQ was assessed using the monthly airport aviation complaint data from 2015 to 2019 of 196 airports in mainland China (except for airports in Hong Kong, Macao, and Taiwan, which are not included in the statistics). First, we constructed a seasonal index of aviation complaints to evaluate and compare the overall temporal characteristics of ASQ in China. Second, the spatial distribution pattern of ASQ in China was determined using the aviation complaint concentration index and hot spot analysis model. Finally, the major influencing factors and categories of ASQ in China were analyzed considering spatiotemporal dimensions using the correspondence analysis method. The results revealed that there were clear seasonal differences among ASQ in China, with a high–low–low–high distribution during all four seasons. The regional agglomeration trend of airport aviation complaints was obvious, and the spatial difference in ASQ was large. Northern and western China performed better than southern China. Spatiotemporal and influencing factors of ASQ were the most strongly correlated factors in each quarter and region. The predominant source of aviation complaints across all types of airports is related to fundamental services, with check-in services identified as the most impactful category affecting ASQ. This study, based on 60 months of statistical data, offers a comprehensive evaluation of ASQ throughout the entire airport network in mainland China, from the perspective of aviation complaints. Additionally, a systematic ASQ evaluation method and research system encompassing time, space, and elements were established. This framework not only stimulates the improvement and enhancement of ASQ but also provides a theoretical foundation for differentially enhancing ASQ in regional airports. Overall, our results contribute to breaking through the qualitative research thinking system in ASQ research from a theoretical perspective, paving the way for exploring broader research in enhancing the quality of ground civil aviation services.}
}
@incollection{AGGARWAL2022135,
title = {Chapter 5 - Models for improving fresh produce chains},
editor = {Wojciech J. Florkowski and Nigel H. Banks and Robert L. Shewfelt and Stanley E. Prussia},
booktitle = {Postharvest Handling (Fourth Edition)},
publisher = {Academic Press},
edition = {Fourth Edition},
address = {San Diego},
pages = {135-164},
year = {2022},
isbn = {978-0-12-822845-6},
doi = {https://doi.org/10.1016/B978-0-12-822845-6.00005-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128228456000051},
author = {Deepak Aggarwal and Stanley E. Prussia},
keywords = {Soft systems, modeling, simulation, postharvest quality simulator, supply chain game, soft systems methodologies},
abstract = {Fresh produce passes through various links of refrigerated or nonrefrigerated value chains from the farmer’s plot to the consumer’s plate. Extensive research since the 1960s has focused on deciphering the ideal postharvest handling conditions to maximize product shelf life for different produce species. However, ideal conditions are seldom met in real-life value chains as the produce travels from field to sorting area, packaging, loading, transportation, unloading, retail display, and the consumer’s car. Further, retail and food service managers often are not provided information about previous handling that affects the remaining shelf life at their link of a value chain. The primary goal is to provide fresh produce with desirable qualities such as firmness, color, ripeness, rupture strength, and taste to the consumers. Postharvest value chains require assimilation of systems thinking, systems dynamics, and physiology of the fresh produce. These can be woven together using modeling and simulation games. Various types of models such as mental models, conceptual models, soft systems, and others can be applied. The underlying equations for the models are the value chain dynamics and the physiological changes in produce at varying storage conditions. The models can then be provided to the intended user as a simple spreadsheet model or as visually appealing games or videos, with the simulations running in the background. The models predicting postharvest quality changes could help decision makers alter shipment destinations and storage conditions so that fresh produce arrives with the desired consumer characteristics. Playing simulation games can be an entertaining method for everyone interested in fresh fruits and vegetables to experience the challenges and satisfactions of learning the consequences of decisions they make while playing the role of a manager at each link in a selected chain. Developing a model requires understanding about the interactions within a system and its surroundings. When developing models, information gaps often are found that require research to learn how a system works. Learning continues as users of the model gain experience without the costs or risks of changing real-life situations. Using soft systems methodology to study fresh fruit and vegetable value chains would include developing models of their activities, interconnections, flows of information, and political and social environments. This could improve our understanding of how chains could function as if they were systems. Other types of models would result from using the critical systems practice methodology as a guide for learning the technical, managerial, and social changes necessary to increase per capita consumption, reduce losses and waste, and improve profits for family farms and other global issues related to postharvest handling of fresh produce. Multiplayer simulation games would help managers and leaders learn how to improve entire fresh fruit and vegetable chains.}
}
@article{FARAHI2021100326,
title = {A simulation–optimization approach for measuring emergency department resilience in times of crisis},
journal = {Operations Research for Health Care},
volume = {31},
pages = {100326},
year = {2021},
issn = {2211-6923},
doi = {https://doi.org/10.1016/j.orhc.2021.100326},
url = {https://www.sciencedirect.com/science/article/pii/S2211692321000424},
author = {Sorour Farahi and Khodakaram Salimifard},
keywords = {Crisis, Healthcare responsiveness, Resilience, Simulation–optimization},
abstract = {Crisis occurrence in the healthcare context is, for different reasons, a phenomenon that happens abundantly. The priority of the healthcare system during a crisis is to provide quality care and superior services to the injured people. However, given the usually extreme severity of the crisis that results in a significant number of injured people, proper and timely responsiveness of healthcare systems is a challenging issue This study proposes a novel framework using a hybrid simulation–optimization approach to measure the healthcare responsiveness in crisis to address this real-world problem. This paper closely connects operations research techniques to critical systems thinking notions to evaluate the behavior of a system in the face of crisis. Since all arriving casualties to the hospital are first taken to the emergency department (ED), the ED in a case study is used to illustrate the performance of the presented approach. We designed seven crisis scenarios and one scenario of the ED system in a normal situation and modeled them using discrete-event simulation (DES). Patients’ interarrival times act as the driver of workload experienced in ED during crisis scenarios of varying severity. For crisis simulation scenarios that are unable to cope with the severity of the crisis, we developed an optimization model in an optimization tool to determine the optimal configuration of resources. The optimal configuration can improve healthcare resilience. The results show that an interarrival time of 13.8 min is the maximum threshold, below which feasible solutions could not be found, and the ED system is likely to collapse.}
}
@article{GE2025100537,
title = {Dissociable ventral and dorsal sensorimotor functional circuits linking the hypomanic personality traits to aggression via behavioral inhibition system},
journal = {International Journal of Clinical and Health Psychology},
volume = {25},
number = {1},
pages = {100537},
year = {2025},
issn = {1697-2600},
doi = {https://doi.org/10.1016/j.ijchp.2024.100537},
url = {https://www.sciencedirect.com/science/article/pii/S1697260024001029},
author = {Wei Ge and Yuanyuan Gao and Xiang Li and Jinlian Wang and Hohjin Im and Wenwei Zhu and Guang Zhao and Ying Hu and Pinchun Wang and Xia Wu and Qiong Yao and Xin Niu and Xiongying Chen and Qiang Wang},
keywords = {Hypomanic personality traits, Aggression, Sensorimotor cortex, IS-RSA, BIS},
abstract = {Hypomanic personality traits (HPT) are susceptibility markers for psychiatric disorders, particularly bipolar disorder, and are strongly associated with aggressive behaviors. However, the neuropsychological mechanisms underlying this association remain unclear. This study utilized psychometric network analysis and Inter-Subject Representation Similarity Analysis (IS-RSA) to explore the neuropsychological circuits that link HPT to aggression in a large non-clinical population. Psychometric network analysis (n = 716) identified two key nodes: the Behavioral Inhibition System (BIS) and mood volatility, a core dimension of HPT. We observed a positive correlation between mood volatility and aggression, with BIS serving as a mediating factor. Task-based functional imaging (n = 53) further revealed a double dissociation between the dorsal (dSMC) and ventral (vSMC) sensorimotor cortices to HPT, specifically during the processing of reward magnitude and delay in a delayed reward paradigm. Functional patterns within these regions mediated the relationship between individual differences in mood volatility and aggression, with BIS acting as a mediator through parallel pathways. Resting-state functional imaging (n = 505) replicated this functional segregation and revealed distinct integrative patterns: the dSMC was functionally connected to the frontoparietal network (FPN) and the vSMC to the sensorimotor network (SMN). These circuits collectively mediated the associations among mood volatility, aggression, and BIS. These findings highlight the critical role of sensorimotor circuits and BIS in understanding the neuropsychological pathways linking HPT-related mood volatility to aggression.}
}
@article{FURIA2007164,
title = {Automated compositional proofs for real-time systems},
journal = {Theoretical Computer Science},
volume = {376},
number = {3},
pages = {164-184},
year = {2007},
note = {Fundamental Aspects of Software Engineering},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2007.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0304397507000643},
author = {Carlo A. Furia and Matteo Rossi and Dino Mandrioli and Angelo Morzenti},
keywords = {Formal verification, Modular systems, Real-time, Compositionality, Rely/guarantee},
abstract = {We present a framework for formally proving that the composition of the behaviors of the different parts of a complex, real-time system ensures a desired global specification of the overall system. The framework is based on a simple compositional rely/guarantee circular inference rule, plus a methodology concerning the integration of the different parts into a whole system. The reference specification language is the TRIO metric linear temporal logic. The novelty of our approach with respect to existing compositional frameworks–most of which do not deal explicitly with real-time requirements–consists mainly in its generality and abstraction from any assumptions about the underlying computational model and from any semantic characterizations of the temporal logic language used in the specification. Moreover, the framework deals equally well with continuous and discrete time. It is supported by a tool, implemented on top of the proof-checker PVS, to perform deduction-based verification through theorem-proving of modular real-time axiom systems. As an example of application, we show the verification of a real-time version of the old-fashioned but still relevant “benchmark” of the dining philosophers problem.}
}
@article{NERSESSIAN2009178,
title = {Hybrid analogies in conceptual innovation in science},
journal = {Cognitive Systems Research},
volume = {10},
number = {3},
pages = {178-188},
year = {2009},
note = {Special Issue on Analogies - Integrating Cognitive Abilities},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S1389041709000035},
author = {Nancy J. Nersessian and Sanjay Chandrasekharan},
keywords = {Conceptual innovation, Hybrid analogies, Simulation, Visual reasoning, Engineering sciences},
abstract = {Analogies are ubiquitous in science, both in theory and experiments. Based on an ethnographic study of a research lab in neural engineering, we focus on a case of conceptual innovation where the cross-breeding of two types of analogies led to a breakthrough. In vivo phenomena were recreated in two analogical forms: one, as an in vitro physical model, and the other, as a computational model of the first physical model. The computational model also embodied constraints drawn from the neuroscience and engineering literature. Cross connections and linkages were then made between these two analogical models, over time, to solve problems. We describe how the development of the intermediary, hybrid computational model led to a conceptual innovation, and subsequent engineering innovations. Using this case study, we highlight some of the peculiar features of such hybrid analogies that are now used widely in the sciences and engineering sciences, and the significant questions they raise for current theories of analogy.}
}
@article{KOPONEN202557,
title = {Sales managers' perceptions of interpersonal communication competence in leading AI-integrated sales teams},
journal = {Industrial Marketing Management},
volume = {124},
pages = {57-72},
year = {2025},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2024.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0019850124001846},
author = {Jonna Koponen and Saara Julkunen and Anne Laajalahti and Marianna Turunen and Brian Spitzberg},
keywords = {Artificial intelligence (AI), Interpersonal communication competence, Management},
abstract = {Adoption of artificial intelligence (AI) is no longer the issue for most professional organizations—the question is how to integrate it into the functions and organizational processes. Considering the current integration of AI in work processes, the requirements for sales managers' interpersonal communication competence (ICC) are likely to be modified. However, research on sales management competencies is surprisingly scarce. This longitudinal case study investigates sales managers' perceptions of their ICC needs in leading AI-integrated sales teams in the financial sector. During the years 2019–2024, 35 expert interviews with sales managers were collected from one of Scandinavia's largest financial groups. The findings indicate that AI system integration brought benefits, concerns and communication challenges to sales managers' job content. The main components related to sales managers' ICC in leading AI-integrated sales teams encompass both traditional competencies (motivation, knowledge, communication skills, and adaptability) but also include contextual AI factors and a concern for ethical reflectivity. A component model of managerial interpersonal communication competence in AI-integrated teams (MICCAIT) is produced and its implications are examined. Given the greater reliance on technology, sales managers may increasingly need to place greater emphasis on their empathy and people-oriented skills for the human employees remaining in the workplace.}
}
@article{FOSTER2021101214,
title = {Translating the grid: How a translational approach shaped the development of grid computing},
journal = {Journal of Computational Science},
volume = {52},
pages = {101214},
year = {2021},
note = {Case Studies in Translational Computer Science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101214},
url = {https://www.sciencedirect.com/science/article/pii/S187775032030510X},
author = {Ian Foster and Carl Kesselman},
keywords = {Translational computer science, Grid computing},
abstract = {A growing gap between progress in biological knowledge and improved health outcomes inspired the new discipline of translational medicine, in which the application of new knowledge is an explicit part of a research plan. Abramson and Parashar argue that a similar gap between complex computational technologies and ever-more-challenging applications demands an analogous discipline of translational computer science, in which the deliberate movement of research results into large-scale practice becomes a central research focus rather than an afterthought. We revisit from this perspective the development and application of grid computing from the mid-1990s onwards, and find that a translational framing is useful for understanding the technology’s development and impact. We discuss how the development of grid computing infrastructure, and the Globus Toolkit, in particular, benefited from a translational approach. We identify lessons learned that can be applied to other translational computer science initiatives.}
}
@article{LENNON2022104608,
title = {Young children's social and independent behavior during play with a coding app: Digital game features matter in a 1:1 child to tablet setting},
journal = {Computers & Education},
volume = {190},
pages = {104608},
year = {2022},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2022.104608},
url = {https://www.sciencedirect.com/science/article/pii/S0360131522001798},
author = {Maya Lennon and Sarah Pila and Rachel Flynn and Ellen A. Wartella},
keywords = {Applications in coding, Cooperative/collaborative learning, Games, early years education},
abstract = {The overarching aim of this study was to explore young children's (N = 25, Mage = 5.16 years) play with two coding games (Daisy the Dinosaur and Kodable) in a 1:1 child to tablet setting. We had three research questions focused on children's game play: 1) How does the structure of each game influence children's play? 2) Do children play more or less independently depending on the game they play? 3) Do children who play the games more independently learn more coding skills? Three researchers coded more than 6 h of video data showing children's play with digital coding games. Findings include, that the type of game did influence the different ways that children behaved while playing. However, during both games, children had the same amount of independent play. Children who played more independently during Daisy the Dinosaur learned more coding skills. This may be because these children were focusing more on the game than their peers as we did not find a similar effect for the game Kodable. We discuss the ways that children play structured vs. open structured (i.e., sandbox) digital games with a particular focus on how game play may influence learning. As opportunities for individual device ownership in classrooms increase, future work should continue to explore how game features influence learning.}
}
@article{SUZUKI2008511,
title = {Research and development of fusion grid infrastructure based on atomic energy grid infrastructure (AEGIS)},
journal = {Fusion Engineering and Design},
volume = {83},
number = {2},
pages = {511-515},
year = {2008},
note = {Proceedings of the 6th IAEA Technical Meeting on Control, Data Acquisition, and Remote Participation for Fusion Research},
issn = {0920-3796},
doi = {https://doi.org/10.1016/j.fusengdes.2007.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S092037960700498X},
author = {Y. Suzuki and K. Nakajima and N. Kushida and C. Kino and T. Aoyagi and N. Nakajima and K. Iba and N. Hayashi and T. Ozeki and T. Totsuka and H. Nakanishi and Y. Nagayama},
keywords = {Grid, AEGIS, JT-60, LHD, LABCOM},
abstract = {In collaboration with the Naka Fusion Institute of Japan Atomic Energy Agency (NFI/JAEA) and the National Institute for Fusion Science of National Institute of Natural Science (NIFS/NINS), Center for Computational Science and E-systems of Japan Atomic Energy Agency (CCSE/JAEA) aims at establishing an integrated framework for experiments and analyses in nuclear fusion research based on the atomic energy grid infrastructure (AEGIS). AEGIS has been being developed by CCSE/JAEA aiming at providing the infrastructure that enables atomic energy researchers in remote locations to carry out R&D efficiently and collaboratively through the Internet. Toward establishing the integrated framework, we have been applying AEGIS to pre-existing three systems: experiment system, remote data acquisition system, and integrated analysis system. For the experiment system, the secure remote experiment system with JT-60 has been successfully accomplished. For the remote data acquisition system, it will be possible to equivalently operate experimental data obtained from LHD data acquisition and management system (LABCOM system) and JT-60 Data System. The integrated analysis system has been extended to the system executable in heterogeneous computers among institutes.}
}
@article{ABDALLA2025101310,
title = {Understanding ChatGPT adoption for data analytics learning: A UTAUT perspective among social science students in Oman},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101310},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101310},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000373},
author = {Suliman Zakaria Suliman Abdalla},
keywords = {Generative artificial intelligence, ChatGPT, UTAUT model, Data analytics learning, Social sciences, Higher education},
abstract = {Generative artificial intelligence tools, particularly ChatGPT, have shown the potential to reshape education by providing personalized, efficient, and accessible learning experiences across various academic disciplines. Despite concerns about academic integrity and AI-driven misconduct, its potential to revolutionize how students engage with and master complex subjects is undeniable. This study explores the key factors that influence social science students' adoption of ChatGPT as a transformative tool to enhance their learning of data analytics. Using a descriptive quantitative research design, data were collected from a sample of 413 Omani students. The study utilizes the Unified Theory of Acceptance and Use of Technology (UTAUT) as a guiding theoretical framework. Through ordinal logistic regression analysis, the study identifies performance expectancy, facilitating conditions, social influence, self-efficacy, and effort expectancy as significant predictors of students' decisions to adopt ChatGPT for their learning needs. Descriptive findings reveal that students highly value ChatGPT's capability to simplify complex data analytics concepts and assist in selecting appropriate analytical methods. This demonstrates its effectiveness in enhancing conceptual understanding. However, the tool received lower ratings for tasks such as data pre-processing and cleaning, suggesting some limitations in its effectiveness in these aspects of data analytics learning. The study's findings highlight ChatGPT's substantial potential to enhance academic performance in data analytics and provide practical recommendations for students, instructors and institutions. The focus is on strategically integrating AI technologies to optimize instructional effectiveness and foster deeper student engagement with data analytics curricula.}
}
@article{SINGH2024,
title = {Unlocking microbial reservoirs for antimicrobial peptides and beyond},
journal = {Trends in Plant Science},
year = {2024},
issn = {1360-1385},
doi = {https://doi.org/10.1016/j.tplants.2024.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S1360138524003145},
author = {Akanksha Singh and Shivam Chauhan and Prabodh Kumar Trivedi},
keywords = {antimicrobial peptides, global microbiome, machine learning, peptide based biologicals},
abstract = {Recently, Santos-Júnior et al. utilized a machine learning approach to identify nearly a million novel antimicrobial peptides (AMPs) from the global microbiome. Here we explore the untapped potential of plant- and soil-associated microbiomes as a source of novel peptides, highlighting their promising applications in advancing agricultural innovation and sustainability.}
}
@article{VANDECRUYS2021107,
title = {Mental distress through the prism of predictive processing theory},
journal = {Current Opinion in Psychology},
volume = {41},
pages = {107-112},
year = {2021},
note = {Psychopathology},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2021.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X21001056},
author = {Sander {Van de Cruys} and Pieter {Van Dessel}},
keywords = {Predictive processing, Mental distress, Psychopathology, Emotion, Depression, Anxiety, Active inference, Addiction, Learning, Psychotherapy, Computational psychiatry},
abstract = {Summary
We review the predictive processing theory’s take on goals and affect, to shed new light on mental distress and how it develops into psychopathology such as in affective and motivational disorders. This analysis recovers many of the classical factors known to be important in those disorders, like uncertainty and control, but integrates them in a mechanistic model of adaptive and maladaptive cognition and behavior. We derive implications for treatment that have so far remained underexposed in existing predictive processing accounts of mental disorder, specifically with regard to the model-dependent construction of value, the importance of model validation (evidence), and the introduction and learning of new, adaptive beliefs that relieve suffering.}
}
@article{ZHANG202581,
title = {Utilizing neuroimaging visualization technology to enhance standardized neurosurgical training for Traditional Chinese Medicine residents: A neuroanatomical education study},
journal = {Brain Hemorrhages},
volume = {6},
number = {2},
pages = {81-85},
year = {2025},
issn = {2589-238X},
doi = {https://doi.org/10.1016/j.hest.2024.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2589238X24000640},
author = {Rongjun Zhang and Zhigang Gong and Wenbing Jiang and Zhaofeng Su},
keywords = {Neuroimaging visualization, Traditional Chinese Medicine, Neurosurgical training, Neuroanatomy, DSI Studio, Clinical Education, Meridians, Neural fiber tracts},
abstract = {Objective
This study aims to address the difficulties encountered by Traditional Chinese Medicine (TCM) students in learning neuroanatomy during clinical training by utilizing neuroimaging visualization technology.
Methods
81 students were divided into a control group (40 students) and an observation group (41 students). The control group followed traditional teaching methods as prescribed by the curriculum, while the observation group received additional training with the neuroimaging visualization software DSI Studio. This included whole-brain neural fiber reconstruction and cortical spinal tract evaluation in the context of stroke. Upon completion of the training, both groups were assessed on neuroanatomical theory, case analysis, neurological examination, and clinical skills. The teaching effectiveness was compared based on assessment results and feedback from questionnaires administered to the observation group.
Results
The observation group significantly outperformed the control group in theoretical knowledge, case analysis, and physical examination (P < 0.05). Over 90 % of students in the observation group reported via questionnaire that the integration of neuroimaging visualization technology significantly enhanced their understanding of neuroanatomy and clinical reasoning skills.
Conclusion
The clinical teaching approach augmented with neuroimaging visualization technology significantly improves the standardized training outcomes for TCM neurosurgical residents.}
}
@incollection{MACHINMASTROMATTEO2025569,
title = {Information Literacy and the Information Science Curriculum},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {569-578},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00191-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895001917},
author = {Juan D. Machin-Mastromatteo and César Saavedra-Alamillas and Alejandro Villegas-Muro},
keywords = {Advocacy, Critical competences, Curricular implementation, Curriculum, Curriculum methodologies, Digital literacy, Information literacy, Information literacy programs, Library and information science, Media literacy, Professional education and training, Social implications, Teaching and learning methodologies, Workplace implications},
abstract = {This entry provides a background to information literacy education in the library and information science (LIS) curriculum by presenting a summary of the elements and characteristics that information literacy courses should include. These are divided into six categories: (1) curricular implementation and general challenges; (2) topics the curriculum must include; (3) inclusion of education-related topics; (4) integration of other literacies; (5) methodologies for the information literacy curriculum; and (6) workplace and social implications. Then, it includes a brief and non-exhaustive review of 41 LIS programs, including courses on information literacy and related subjects. Finally, we offer some brief considerations for the future perspectives of this topic.}
}
@article{KELLEY2011228,
title = {Theoretical explorations of cognitive robotics using developmental psychology},
journal = {New Ideas in Psychology},
volume = {29},
number = {3},
pages = {228-234},
year = {2011},
note = {Special Issue: Cognitive Robotics and Reevaluation of Piaget Concept of Egocentrism},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2009.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X0900035X},
author = {Troy D. Kelley and Daniel N. Cassenti},
keywords = {Development, Robotics, Cognition, Cognitive modeling},
abstract = {How can cognitive robotics inform developmental psychology researchers and what can developmental psychology tell us about creating robots? More importantly, how can cognitive robotics and developmental psychology nourish each other to become a symbiotic relationship for future research? We address the theoretical underpinnings of developmental change using a cognitive architecture implemented on a robotic system and how our theories of knowledge representation relate to critical periods of infant development. Next, we will show how descriptive theories of cognitive development, specifically Zelazo's Levels of Consciousness (LOC; Zelazo, 2000, Zelazo, 2004, Zelazo and Jacques, 1996), can be mapped onto a computational cognitive architecture (ACT-R; Anderson & Lebiere, 1998). Following our discussion of Zelazo's theory, we will apply the ACT-R architecture specifically to the problem of object permanence. Finally, we will address how cognitive robotics can serve as a computational proving ground of developmental psychology for future research.}
}
@incollection{FOTOPOULOS2022241,
title = {Chapter 8 - The edge-cloud continuum in wearable sensing for respiratory analysis},
editor = {Rui Pedro Paiva and Paulo de Carvalho and Vassilis Kilintzis},
booktitle = {Wearable Sensing and Intelligent Data Analysis for Respiratory Management},
publisher = {Academic Press},
pages = {241-271},
year = {2022},
isbn = {978-0-12-823447-1},
doi = {https://doi.org/10.1016/B978-0-12-823447-1.00002-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128234471000026},
author = {Anaxagoras Fotopoulos and Pantelis Z. Lappas and Alexis Melitsiotis},
keywords = {Artificial intelligence, Edge computing, Internet of Medical Things, Multisource fusion, P4 health care},
abstract = {Edge computing is seen as a set of remotely available computer system resources that drive the computing power at the source of data to improve energy efficiency and security, as well as decrease latency. Although the computation capability of biomedical wearables has increased extremely during the past decade, it is still challenging to perform sophisticated artificial intelligence (AI) algorithms in a resource-constrained environment for energy-efficiency and (near) real-time processing, along the edge-cloud continuum. The aim of this chapter is twofold. The first is to outline the role of edge computing on the Internet of Medical Things, in which wearable technologies are used as the sensory equipment for respiratory analysis, at the transition of patient monitoring from hospital to home. The second is to discuss the potential of explainable AI in the P4 health-care context for respiratory analysis, by highlighting computational intelligence and multisource fusion approaches to achieve continuous monitoring of respiratory analysis.}
}
@article{LUO2020151,
title = {Three-way decision with incomplete information based on similarity and satisfiability},
journal = {International Journal of Approximate Reasoning},
volume = {120},
pages = {151-183},
year = {2020},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2020.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X19303421},
author = {Junfang Luo and Mengjun Hu and Keyun Qin},
keywords = {Three-way decision, Rough set, Incomplete information, Similarity, Satisfiability, Fuzzy logic},
abstract = {Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a brief review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using α-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using α-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.}
}
@article{GATI2021298,
title = {Differentially private data fusion and deep learning Framework for Cyber–Physical–Social Systems: State-of-the-art and perspectives},
journal = {Information Fusion},
volume = {76},
pages = {298-314},
year = {2021},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521000890},
author = {Nicholaus J. Gati and Laurence T. Yang and Jun Feng and Xin Nie and Zhian Ren and Samwel K. Tarus},
keywords = {Differential privacy, Deep computation, Data fusion, CPSS},
abstract = {The modern technological advancement influences the growth of the cyber–physical system and cyber–social system to a more advanced computing system cyber–physical–social system (CPSS). Therefore, CPSS leads the data science revolution by promoting tri-space information resource from a single space. The establishment of CPSSs increases the related privacy concerns. To provide privacy on CPSSs data, various privacy-preserving schemes have been introduced in the recent past. However, technological advancement in CPSSs requires the modifications of previous techniques to suit its dynamics. Meanwhile, differential privacy has emerged as an effective method to safeguard CPSSs data privacy. To completely comprehend the state-of-the-art developments and learn the field’s research directions, this article provides a comprehensive review of differentially private data fusion and deep learning in CPSSs. Additionally, we present a novel differentially private data fusion and deep learning Framework for Cyber–Physical–Social Systems , and various future research directions for CPSSs.}
}
@article{CAMELODAZA2024101760,
title = {Parameter estimation in single-phase transformers via the generalized normal distribution optimizer while considering voltage and current measurements},
journal = {Results in Engineering},
volume = {21},
pages = {101760},
year = {2024},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2024.101760},
url = {https://www.sciencedirect.com/science/article/pii/S2590123024000136},
author = {Juan David Camelo-Daza and Diego Noel Betancourt-Alonso and Oscar Danilo Montoya and Ernesto Gómez-Vargas},
keywords = {Nonlinear optimization, Metaheuristic optimization algorithms, Generalized normal distribution optimizer, Parameter estimation, Single-phase transformers, Mean square error minimization, Voltage and current measurements},
abstract = {This research addresses, from a perspective of metaheuristic optimization, the problem regarding parametric estimation in single-phase transformers while considering voltage and current measures at the terminals of the transformer and weighing linear loads. Transformer parametric estimation is modeled as a nonlinear problem in order to minimize the mean square error between the calculated voltage and current variables and the measurements taken. The nonlinearities are associated with Kirchhoff's first and second laws applied to the equivalent electrical circuit of the single-phase transformer. The nonlinear optimization problem is solved by applying a metaheuristic optimization algorithm known as the generalized normal distribution optimizer (GNDO), which uses evolution rules that allow exploring and exploiting the solution space via the classical probability function based on normal distributions. Numerical results in three test transformers of 20, 45, and 112.5 kVA demonstrate the effectiveness and robustness of the proposed GNDO approach when compared to other optimizers reported in the literature, such as the crow search algorithm, the coyote optimization algorithm, and the exact solution of the nonlinear optimization model using the fmincon solver of the MATLAB software. All numerical simulations confirm the potential of the GNDO approach to deal with complex optimization problems in engineering and science with promising results and low computational effort.}
}
@article{REINHOLD2025122653,
title = {Perspectives: The license to fail – Steps towards an adaptive paradigm for forest management in times of unprecedented uncertainty},
journal = {Forest Ecology and Management},
volume = {585},
pages = {122653},
year = {2025},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2025.122653},
url = {https://www.sciencedirect.com/science/article/pii/S0378112725001616},
author = {Simon Reinhold and Olef Koch and Andreas Schweiger and Roderich {von Detten}},
keywords = {Forest management, Uncertainty, Resilience, Adaptive management, Experimental framework},
abstract = {This article offers a new perspective on possible consequences of looking at uncertainty in forest ecosystem management as something irreducible. Management strategies suggested by forest science are often focused on minimizing uncertainty by using predictive or probabilistic models and risk management via diversification in order to enable the achievement of relatively rigid targets or desired ecosystem conditions. These approaches, however, do not fully capture the complex, dynamic nature of forest ecosystems and the challenges ecosystem managers face as societal needs and the world’s climate are changing in an unprecedented manner. The fact that a good proportion of future events is unpredictable and that forest ecosystem management has to find ways to act upon this uncertainty precisely because it is irreducible is often overlooked. The conceptual background for this publication was drawn from considerations on uncertainty and entrepreneurial action in both forest sciences and economics. Building on that, we argue that the understanding of forests as complex and adaptive socio-ecological systems has to be better represented in systematic and hierarchical structures. Central to sector-wide innovation and adaptation is a new management paradigm: A better understanding of ecosystem dynamics in real-time and a substitution of approaches that are designed to plan or steer ecosystems with experimental proceedings via trial and error. Therefore, we propose a theoretical workflow that bolsters the decisions of individual forest managers with the results of a landscape-wide experimental network. By promoting a culture of “not-knowing”, bottom-up exchange between hierarchical levels and continuous learning and experimentation, institutions can encourage individual forest managers to learn from their own management process and thus improve the way they navigate the complexities of ecosystem management in an uncertain future.}
}
@article{SANZ2021103070,
title = {The entropic tongue: Disorganization of natural language under LSD},
journal = {Consciousness and Cognition},
volume = {87},
pages = {103070},
year = {2021},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2020.103070},
url = {https://www.sciencedirect.com/science/article/pii/S1053810020305377},
author = {Camila Sanz and Carla Pallavicini and Facundo Carrillo and Federico Zamberlan and Mariano Sigman and Natalia Mota and Mauro Copelli and Sidarta Ribeiro and David Nutt and Robin Carhart-Harris and Enzo Tagliazucchi},
keywords = {LSD, Psychedelics, Natural language, Entropy, Psychosis},
abstract = {Serotonergic psychedelics have been suggested to mirror certain aspects of psychosis, and, more generally, elicit a state of consciousness underpinned by increased entropy of on-going neural activity. We investigated the hypothesis that language produced under the effects of lysergic acid diethylamide (LSD) should exhibit increased entropy and reduced semantic coherence. Computational analysis of interviews conducted at two different time points after 75 μg of intravenous LSD verified this prediction. Non-semantic analysis of speech organization revealed increased verbosity and a reduced lexicon, changes that are more similar to those observed during manic psychoses than in schizophrenia, which was confirmed by direct comparison with reference samples. Importantly, features related to language organization allowed machine learning classifiers to identify speech under LSD with accuracy comparable to that obtained by examining semantic content. These results constitute a quantitative and objective characterization of disorganized natural speech as a landmark feature of the psychedelic state.}
}
@incollection{SAAVEDRAALAMILLAS2025623,
title = {Library Instruction and Research Training in the Context of Artificial Intelligence},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {623-629},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00122-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032395689500122X},
author = {César Saavedra-Alamillas and Josmel Pacheco-Mendoza and Erik M. Ortiz-Díaz and Youness {El Hamzaoui} and Marc A. Astbury},
keywords = {Academic production., Artificial intelligence, Embedded librarian, Information literacy, Liaison librarian, Librarian, Library instruction, Research, Researcher training, Scientific communication},
abstract = {The librarian has played a crucial role throughout history, evolving from a guardian of humanity׳s collective memory to guiding the use of collections and, in recent years, a trainer in the use of information and emerging digital technologies. Currently, the librarian is an active collaborator who understands scientific communication processes and the mechanisms for improving high-impact academic production.}
}
@article{CHIRIMUUTA201934,
title = {Synthesis of contraries: Hughlings Jackson on sensory-motor representation in the brain},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {75},
pages = {34-44},
year = {2019},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2019.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S1369848618300359},
author = {M. Chirimuuta},
abstract = {This paper examines the concept of representation in the brain which occurs in the writings of the neurologist John Hughlings Jackson (1835–1911). Jackson was immersed in Victorian physiological psychology, a hybrid of British associationism and a reflex theory of the operation of the nervous system. Furthermore, Jackson was deeply influenced by Herbert Spencer, and I argue that Spencer's progressivist evolutionary ideas are in tension with the more mechanistic approach of the reflex theory. I also discuss Jackson's legacy in the 20th century and the longstanding debate about localisation of function in the brain.}
}
@article{WANG2025101231,
title = {Dimensionality and dynamics for next-generation artificial neural networks},
journal = {Patterns},
pages = {101231},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101231},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925000790},
author = {Ge Wang and Feng-Lei Fan},
keywords = {Artificial intelligence, AI, artificial neural network, deep learning, Transformer, dimensionality expansion, feedback loop},
abstract = {Summary
The recent awarding of the Nobel Prize in Physics to Geoffrey E. Hinton and John J. Hopfield highlights their profound impact on artificial neural networks. In this perspective, we explore how their foundational insights can drive the advancement of next-generation artificial intelligence (AI) models. We propose expanding beyond conventional architectures by introducing dimensionality through intra-layer links and dynamics via feedback loops. Network height and additional dimensions, alongside traditional width and depth, enhance learning capabilities, while entangled loops across scales induce emergent behaviors akin to phase transitions in physics. We discuss how these principles extend beyond transformers, fostering a new paradigm of intelligence inspired by physics-driven models and biological cognition mechanisms.}
}
@article{ESCAMILLA2021102697,
title = {Interaction designers’ perceptions of using motion-based full-body features},
journal = {International Journal of Human-Computer Studies},
volume = {155},
pages = {102697},
year = {2021},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2021.102697},
url = {https://www.sciencedirect.com/science/article/pii/S1071581921001154},
author = {Antonio Escamilla and Javier Melenchón and Carlos Monzo and Jose Antonio Morán},
keywords = {Motion-based feature extraction, Full-body interaction, Interaction designers' perception, Designer-interpretable feature},
abstract = {Movement-based full-body interactions are increasingly being used in the design of interactive spaces, computer-mediated environments, and virtual user experiences due to the development and availability of diverse sensing technologies. In this context, the role of interaction designers is to find systematic and predictable relationships between bodily actions and the corresponding responses from technology. Sensor-based interaction design relies on sensor data analysis and higher-level feature extraction to improve detection capabilities. However, understanding human movement to inform the design of motion-based interactions is not straightforward if the detection capabilities of interaction technologies are unknown. We aim at understanding the problems and opportunities that practitioners—regardless of their technical background—perceive in using different motion-based full-body features. To achieve this, we conducted four separate focus groups with experienced practitioners, with and without technical backgrounds. We used a framework for the analysis of focus group data in information systems research to identify content areas and draw conclusions. Our findings suggest that most interaction designers, regardless of their technical background, consider motion-based feature extraction to be challenging and time-consuming. However, participants acknowledge they might use designer-interpretable features as a potential tool to foster user behavior exploration. Understanding how practitioners link sensor-based interaction design with feature extraction technology is relevant to design computational tools and reduce the technical effort required from designers to characterize the user’s movement.}
}
@article{WU2024103772,
title = {Fuser: An enhanced multimodal fusion framework with congruent reinforced perceptron for hateful memes detection},
journal = {Information Processing & Management},
volume = {61},
number = {4},
pages = {103772},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103772},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001328},
author = {Fan Wu and Bin Gao and Xiaoou Pan and Linlin Li and Yujiao Ma and Shutian Liu and Zhengjun Liu},
keywords = {Hateful memes detection, Multimodal fusion, Congruent reinforced perceptron, Main semantic, Auxiliary context},
abstract = {As a multimodal form of hate speech on social media, hateful memes are more aggressive and cryptic threats to the real life of humans. Automatic detection of hateful memes is crucial, but the images and texts in most memes are only weakly consistent or even irrelevant. Although existing works have achieved the initial goal of detecting hateful memes with pre-trained models, they are limited to monolithic inference methods while ignoring the semantic differences between multimodal representations. To strengthen the comprehension and reasoning of the hidden meaning behind the memes by combining real-world knowledge, we propose an enhanced multimodal fusion framework with congruent reinforced perceptron for hateful memes detection. Inspired by the human cognitive mechanism, we first divide the extracted multisource representations into main semantics and auxiliary contexts based on their strength and relevance, and then precode them into lightly correlated embeddings with unified spatial dimensions via a novel prefix uniform layer, respectively. To jointly learn the intrinsic correlation between primary and secondary semantics, a congruent reinforced perceptron with brain-like perceptual integration is designed to seamlessly fuse multimodal representations in a shared latent space while maintaining the feature integrity in the sub-fusion space, thereby implicitly reasoning about the subtle metaphors behind the memes. Extensive experiments on four benchmark datasets fully demonstrate the effectiveness and superiority of our architecture compared with previous state-of-the-art methods.}
}
@article{MORAVEC2023147,
title = {Global trends in disruptive technological change: social and policy implications for education},
journal = {On the Horizon},
volume = {31},
number = {34},
pages = {147-173},
year = {2023},
issn = {1074-8121},
doi = {https://doi.org/10.1108/OTH-02-2023-0007},
url = {https://www.sciencedirect.com/science/article/pii/S1074812123000325},
author = {John W. Moravec and María Cristina Martínez-Bravo},
keywords = {Literature review, Meta-analysis, Technology, Education policy, Disruptive technology, Global trends},
abstract = {Purpose
The purpose of this study is to identify global trends in disruptive technological change and map the social and policy implications, particularly as they relate to the educational ecosystem and main stakeholders across all levels of education.
Design/methodology/approach
The authors conducted a two-stage meta-analysis of 1,155 scholarly, peer-reviewed articles. The investigation involves a systematized literature review for data identification and collation adhering to defined selection criteria, and a network analysis to scrutinize data, consolidate information and unveil correlations and patterns from the literature review to produce a set of recommendations.
Findings
The study unveiled educational trends related to disruptive technologies and delineated four principal clusters representing how these technologies are transforming the education ecosystem. Additionally, a series of transversal aspects that reveal a societal vulnerability toward future prospects in the realms of ethics, sustainability, resilience, security, and policy were identified.
Practical implications
The findings spotlight an enlarging chasm between industry (and society at large) and conventional education, where many transformations triggered by disruptive technologies remain absent from teaching and learning systems. The study further offers recommendations and envisions potential scenarios, urging stakeholders to respond based on their positions concerning disruptive technologies.
Originality/value
Expanding from the meta-analysis of pertinent literature, this paper offers four collections of curated resources, four mini case studies and four scenarios for policymakers and local communities to consider, enabling them to plot courses for their optimal futures.}
}
@article{NEINHUIS2017394,
title = {Innovations from the “ivory tower”: Wilhelm Barthlott and the paradigm shift in surface science},
journal = {Beilstein Journal of Nanotechnology},
volume = {8},
pages = {394-402},
year = {2017},
issn = {2190-4286},
doi = {https://doi.org/10.3762/bjnano.8.41},
url = {https://www.sciencedirect.com/science/article/pii/S2190428617000363},
author = {Christoph Neinhuis},
keywords = {Wilhelm Barthlott, 70th birthday, self-cleaning surfaces, lotus-effect},
abstract = {This article is mainly about borders that have tremendous influence on our daily life, although many of them exist and act mostly unrecognized. In this article the first objective will be to address more generally the relation between university and society or industry, borders within universities, borders in thinking and the huge amount of misunderstandings and losses resulting from these obvious or hidden borders. In the second part and in more detail, the article will highlight the impact of the research conducted by Wilhelm Barthlott throughout his scientific career during which not only one border was removed, shifted or became more penetrable. Among the various fields of interest not mentioned here (e.g., systematics of Cactaceae, diversity and evolution of epiphytes, the unique natural history of isolated rocky outcrops called inselbergs, or the global distribution of biodiversity), plant surfaces and especially the tremendous diversity of minute structures on leaves, fruits, seeds and other parts of plants represent a common thread through 40 years of scientific career of Wilhelm Barthlott. Based on research that was regarded already old-fashioned in the 1970s and 1980s, systematic botany, results and knowledge were accumulated that, some 20 years later, initiated a fundamental turnover in how surfaces were recognized not only in biology, but even more evident in materials science.}
}
@article{DOERR2000431,
title = {How Can I Find a Pattern in this Random Data?: The Convergence of Multiplicative and Probabilistic Reasoning},
journal = {The Journal of Mathematical Behavior},
volume = {18},
number = {4},
pages = {431-454},
year = {2000},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(00)00023-7},
url = {https://www.sciencedirect.com/science/article/pii/S0732312300000237},
author = {Helen M Doerr},
abstract = {This classroom-based research study examines the thinking of pre-calculus students about multiplicative growth and decay within a probabilistic context, thus bringing together two research strands in mathematics education: students' understanding of exponential functions and students' reasoning about random events. Using a multi-stage approach to model development, a curriculum unit was designed to elicit students' creation of a model or system that could be used to describe and explain the behavior of an experienced, probabilistic system. The evidence suggests that while the students made sense of the underlying multiplicative structure of the problem situation, many students experienced a conflict between the concept of a pattern and the concept of randomness. Students encountered difficulty in reconciling the deterministic nature of a closed-form analytic solution with the non-deterministic nature of a sequence of random events. These results suggest that there is a need for students to gain experience with non-deterministic models using contexts that provide meaningful empirical data.}
}
@article{HOOD2012181,
title = {Systems Approaches to Biology and Disease Enable Translational Systems Medicine},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {10},
number = {4},
pages = {181-185},
year = {2012},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2012.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S1672022912000526},
author = {Leroy Hood and Qiang Tian},
keywords = {Systems biology, P4 medicine, Family genome sequencing, Targeted proteomics, Single-cell analysis},
abstract = {The development and application of systems strategies to biology and disease are transforming medical research and clinical practice in an unprecedented rate. In the foreseeable future, clinicians, medical researchers, and ultimately the consumers and patients will be increasingly equipped with a deluge of personal health information, e.g., whole genome sequences, molecular profiling of diseased tissues, and periodic multi-analyte blood testing of biomarker panels for disease and wellness. The convergence of these practices will enable accurate prediction of disease susceptibility and early diagnosis for actionable preventive schema and personalized treatment regimes tailored to each individual. It will also entail proactive participation from all major stakeholders in the health care system. We are at the dawn of predictive, preventive, personalized, and participatory (P4) medicine, the fully implementation of which requires marrying basic and clinical researches through advanced systems thinking and the employment of high-throughput technologies in genomics, proteomics, nanofluidics, single-cell analysis, and computation strategies in a highly-orchestrated discipline we termed translational systems medicine.}
}
@article{RAMESH2021375,
title = {Activation energy process in hybrid CNTs and induced magnetic slip flow with heat source/sink},
journal = {Chinese Journal of Physics},
volume = {73},
pages = {375-390},
year = {2021},
issn = {0577-9073},
doi = {https://doi.org/10.1016/j.cjph.2021.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0577907321001696},
author = {G.K. Ramesh and J.K. Madhukesh},
keywords = {Carbon nanotubes, Slip flow, Induce magnetic flux, Activation energy, Chemical reaction},
abstract = {Effect of induced magnetic field is critical as a result of much controlled and focused on liquid flow is wanted in numerous modern and clinical procedures for example electromagnetic casting, drug delivery and cooling of nuclear reactors. Hence this investigation explains the behaviour of hybrid carbon nanotubes (CNTs) flow through slipped surface with induced magnetic field. Accumulation of SWCNTs (single wall) and MWCNTs (multi wall) nanomaterial with water base liquid is considered. Thermal performance is analyzed with regular heat source/sink effect. Chemical reaction and activation energy impacts are incorporated in mass equation. Solution of the similarity equations are obtained by adopting RKF45 method. Influence of flow variables are illustrated through graphs and computational values of drag force, Nusselt number and Sherwood number are presented in tables. It is noted that activation energy enhance the concentration field whereas opposite behaviour for reaction rate. Also induce magnetic field boosted with the larger values of magnetic Prandtl number. Furthermore it is observed that hybrid CNTs nanomaterial having higher rate of heating/cooling compare to singular CNTs nanomaterial.}
}
@article{VANRINSVELD201717,
title = {Mental arithmetic in the bilingual brain: Language matters},
journal = {Neuropsychologia},
volume = {101},
pages = {17-29},
year = {2017},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2017.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0028393217301756},
author = {Amandine {Van Rinsveld} and Laurence Dricot and Mathieu Guillaume and Bruno Rossion and Christine Schiltz},
keywords = {Mathematics, Neuroimaging, Bilingualism, Numerical cognition, Arithmetics},
abstract = {How do bilinguals solve arithmetic problems in each of their languages? We investigated this question by exploring the neural substrates of mental arithmetic in bilinguals. Critically, our population was composed of a homogeneous group of adults who were fluent in both of their instruction languages (i.e., German as first instruction language and French as second instruction language). Twenty bilinguals were scanned with fMRI (3T) while performing mental arithmetic. Both simple and complex problems were presented to disentangle memory retrieval occuring in very simple problems from arithmetic computation occuring in more complex problems. In simple additions, the left temporal regions were more activated in German than in French, whereas no brain regions showed additional activity in the reverse constrast. Complex additions revealed the reverse pattern, since the activations of regions for French surpassed the same computations in German and the extra regions were located predominantly in occipital regions. Our results thus highlight that highly proficient bilinguals rely on differential activation patterns to solve simple and complex additions in each of their languages, suggesting different solving procedures. The present study confirms the critical role of language in arithmetic problem solving and provides novel insights into how highly proficient bilinguals solve arithmetic problems.}
}
@article{JU2017180,
title = {Single image haze removal based on the improved atmospheric scattering model},
journal = {Neurocomputing},
volume = {260},
pages = {180-191},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.04.034},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217307051},
author = {Mingye Ju and Zhenfei Gu and Dengyin Zhang},
keywords = {Improved atmospheric scattering model, Linear model, Gaussian–Laplacian pyramid, Image haze removal, Haze aware density feature},
abstract = {In this paper, we propose an improved atmospheric scattering model (IASM) to overcome the inherent limitation of the traditional atmospheric scattering model. Based on the IASM, a fast single image dehazing algorithm is also presented. In this algorithm, by constructing a linear model between the transmission and the haze aware density feature, the transmission map can be directly estimated through a linear operation on three components: luminance, saturation and gradient. Combining the sky-relevant feature and the proposed guided energy model (GEM), we can accurately estimate the atmospheric light and scene incident light, and can further restore the scene albedo via the IASM. Finally, an accelerating framework (AF) based on the Gaussian–Laplacian pyramid is proposed to increase the computational speed. Experimental results demonstrate that the proposed algorithm outperforms most of the prevalent algorithms in terms of visual effect and computational efficiency. Besides, it is also capable of processing various types of degraded images in addition to hazy images.}
}
@article{WANG2025100880,
title = {Application of gamification based virtual robots in urban landscape Design: Interaction and entertainment experience in the design process},
journal = {Entertainment Computing},
volume = {52},
pages = {100880},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100880},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002489},
author = {Wenling Wang},
keywords = {Gamification elements, Virtual robot, Urban landscape design, Design interaction, Entertainment experience},
abstract = {The traditional design process lacks fun and participation, so new elements need to be introduced to enhance the attraction and creativity of the design. The goal of the research is to design an urban landscape design method based on gamified elements and virtual robots to increase the interactivity and entertainment experience in the design process, and to explore its impact on the design results. This paper proposes an urban landscape design framework based on gamified elements and virtual robots, which includes multiple stages in the design process, each of which introduces different gamified tasks and interactions of virtual robots. Designers can gain new design ideas and inspiration by completing tasks and interacting with virtual robots. The study evaluated the effects of design methods using gamification elements and virtual robots on the design process and design results. The results show that this approach effectively increases the engagement and enjoyment of the design process, while also promoting innovation and sustainability of the design results. The urban landscape design method based on gamification elements and virtual robots has broad application prospects, which can bring more creativity and fun to urban landscape design.}
}
@article{ANTONIDES2022101010,
title = {A learning trajectory for enumerating permutations: Applying and elaborating a theory of levels of abstraction},
journal = {The Journal of Mathematical Behavior},
volume = {68},
pages = {101010},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.101010},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000785},
author = {Joseph Antonides and Michael T. Battista},
keywords = {Permutations, Learning trajectories, Abstraction, Combinatorics, Teaching experiment, Concreteness fading},
abstract = {Permutations are fundamental to combinatorics and other areas of mathematics, and it is important that students develop efficient and conceptually supported ways of mentally constructing, listing, and enumerating them. To date, there is still much to learn about how students reason about enumerating permutations, and how instruction can support students’ conceptual development. We address this gap in the research literature by carefully tracing the evolution of two preservice middle school teachers’ permutation enumeration strategies and conceptualizations, which led to the formulation of levels of sophistication for combinatorial reasoning. These levels are explained by applying and extending a constructivist theory of levels of abstraction. Additionally, we outline an instructional approach that was instrumental in facilitating student learning. Together, the proposed levels and linked instructional approach constitute an initial learning trajectory for permutations that we believe could be useful for understanding and supporting post-secondary non-STEM students’ meaningful conceptualizations and enumerations of permutations.}
}
@article{ZHU2024106594,
title = {Distilling mathematical reasoning capabilities into Small Language Models},
journal = {Neural Networks},
volume = {179},
pages = {106594},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106594},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024005185},
author = {Xunyu Zhu and Jian Li and Yong Liu and Can Ma and Weiping Wang},
keywords = {Large language models, Knowledge Distillation, Mathematical reasoning, Chain-of-Thought, Program-of-Thought},
abstract = {This work addresses the challenge of democratizing advanced Large Language Models (LLMs) by compressing their mathematical reasoning capabilities into sub-billion parameter Small Language Models (SLMs) without compromising performance. We introduce Equation-of-Thought Distillation (EoTD), a novel technique that encapsulates the reasoning process into equation-based representations to construct an EoTD dataset for fine-tuning SLMs. Additionally, we propose the Ensemble Thoughts Distillation (ETD) framework to enhance the reasoning performance of SLMs. This involves creating a reasoning dataset with multiple thought processes, including Chain-of-Thought (CoT), Program-of-Thought (PoT), and Equation-of-Thought (EoT), and using it for fine-tuning. Our experimental performance demonstrates that EoTD significantly boosts the reasoning abilities of SLMs, while ETD enables these models to achieve state-of-the-art reasoning performance.}
}
@article{MEMARIAN2023100022,
title = {ChatGPT in education: Methods, potentials, and limitations},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {1},
number = {2},
pages = {100022},
year = {2023},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100022},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000221},
author = {Bahar Memarian and Tenzin Doleck},
keywords = {ChatGPT, Large language models, Education, Artificial intelligence, Machine learning, Data science, Pedagogy},
abstract = {ChatGPT has been under the scrutiny of public opinion including in education. Yet, less work has been done to analyze studies conducted on ChatGPT in educational contexts. This review paper examines where ChatGPT is employed in educational literature and areas of potential, challenges, and future work. A total of 63 publications were included in this review using the general framework of open and axial coding. We coded and summarized the methods, and reported potentials, limitations, and future work of each study. Thematic analysis of reviewed studies revealed that most extant studies in the education literature explore ChatGPT through a commentary and non-empirical lens. The potentials of ChatGPT include but are not limited to the development of personalized and complex learning, specific teaching and learning activities, assessments, asynchronous communication, feedback, accuracy in research, personas, and task delegation and cognitive offload. Several areas of challenge that ChatGPT is or will be facing in education are also shared. Examples include but are not limited to plagiarism deception, misuse or lack of learning, accountability, and privacy. There are both concerns and optimism about the use of ChatGPT in education, yet the most pressing need is to ensure student learning and academic integrity are not sacrificed. Our review provides a summary of studies conducted on ChatGPT in education literature. We further provide a comprehensive and unique discussion on future considerations for ChatGPT in education.}
}
@article{UCAN2022104878,
title = {Advice hierarchies among finite automata},
journal = {Information and Computation},
volume = {288},
pages = {104878},
year = {2022},
note = {Special Issue: Selected Papers of the 14th International Conference on Language and Automata Theory and Applications, LATA 2020},
issn = {0890-5401},
doi = {https://doi.org/10.1016/j.ic.2022.104878},
url = {https://www.sciencedirect.com/science/article/pii/S0890540122000207},
author = {Ahmet Bilal Uçan and A.C. Cem Say},
keywords = {Formal languages, Automata theory, Advised computation},
abstract = {We examine the effects of supplying increasing amounts of trusted advice to a finite automaton. Previous work has shown that allowing such automata with a single advice tape to make a single pass over their input renders them unable to recognize the palindromes language, whereas both two-way machines reading advice from a single tape and one-way machines with multiple advice tapes can recognize all languages with exponentially bounded amounts of advice. We study several architectural variants and demonstrate the existence of language hierarchies based on increased advice length, runtime (measured in terms of the number of allowed left-to-right passes on the input), and number of advice tapes. We also prove some lower bounds for recognizing certain concrete languages.}
}
@article{ROUGIER2009155,
title = {Implicit and explicit representations},
journal = {Neural Networks},
volume = {22},
number = {2},
pages = {155-160},
year = {2009},
note = {What it Means to Communicate},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2009.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608009000112},
author = {Nicolas P. Rougier},
keywords = {Computational neuroscience, Representation, Symbol, Embodied cognition},
abstract = {During the past decades, the symbol grounding problem, as has been identified by Harnard [Harnard, S. (1990). The symbol grounding problem. Physica D: Nonlinear Phenomena, 42, 335–346], became a prominent problem in the cognitive science society. The idea that a symbol is much more than a mere meaningless token that can be processed through some algorithm, sheds new light on higher brain functions such as language and cognition. We present in this article a computational framework that may help in our understanding of the nature of grounded representations. Two models are briefly introduced that aim at emphasizing the difference we make between implicit and explicit representations.}
}
@article{ISMAEEL2019599,
title = {Drawing the operating mechanisms of green building rating systems},
journal = {Journal of Cleaner Production},
volume = {213},
pages = {599-609},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.12.115},
url = {https://www.sciencedirect.com/science/article/pii/S095965261833823X},
author = {Walaa S.E. Ismaeel},
keywords = {Green certification, Greenmarket, LEED, Performance measurement and verification, Sustainable building guidelines, Green building rating systems},
abstract = {Abstract:
Green Building Rating and Certification systems (GBRSs) were developed to provide guidelines and benchmarking criteria for conducting sustainable building processes. Yet, they lack a ‘know how’ defining their role and value-contribution, which may eventually limit their role and affect their credibility and application in the decision-making process. Subsequently, this study presents its research hypothesis assuming two mechanisms and four scopes of operation; the rating mechanism operates using the guidelines and measurement metrics while the certification mechanism operates using the verification and certification metrics. The research has adopted an integrated qualitative and quantitative approach where the development of the four interrelated scopes of operation has been traced through literature, and an assigned score weighting has been used to compare them according to different GBRSs- and more specifically for the Leadership in Energy and Environmental Design (LEED) credits. The results present an integrated application framework (IAF) with a particular focus to energy and materials' credits and based on the system's targets as well as credits' intent and interrelations. The proposed framework applies system thinking to the level of individual practices as well as the entire building process. This is followed by two case-study validations and amendments to reflect dominance, temporal precedence and iterative action of some scopes along different project phases. It indicates how the difference in building type and context may alter opportunities for scoring potentials in addition to means of supporting important decisions such as setting building reuse and CWM plans as well as specifying and procuring sustainable materials. The result provides a consistent mean to manage and document building activities and finally report buildings' performance. This shall prove very useful for researchers, practitioners and system developers. Finally, the study provides insights for developing the LEED system as well as different GBRSs using the IAF; this may take the form of a more interactive decision support tool, software management application or a better user friendly system interface.}
}
@incollection{MADIAJAGAN2019245,
title = {Chapter 15 - Parallel Machine Learning and Deep Learning Approaches for Bioinformatics},
editor = {Arun Kumar Sangaiah},
booktitle = {Deep Learning and Parallel Computing Environment for Bioengineering Systems},
publisher = {Academic Press},
pages = {245-255},
year = {2019},
isbn = {978-0-12-816718-2},
doi = {https://doi.org/10.1016/B978-0-12-816718-2.00022-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128167182000221},
author = {M. Madiajagan and S. Sridhar Raj},
keywords = {Machine learning, Deep Learning, Parallel processing, Bioinformatics, Parallel deep neural networks},
abstract = {Deep learning uses multiple layers of artificial neurons for classification and pattern recognition. The biggest drawbacks of deep learning algorithms have been the high computation cost, inter-processor communication bottlenecks and parameters training time. Hence, incorporating parallel computing into deep learning decreases the computation time of complex deep learning algorithms. This chapter presents how parallelization is applied over many processors which are loosely coupled. Up to 4096 processes are scaled linearly with higher accuracy and zero loss percentage. This capacity of huge scaling helps in training billions of training examples in just a few hours. Various applications of Hessian-free parallelization mechanism on bioinformatics applications are in gene therapy, drug development, antibiotic resistance research, waste cleanup, climate change studies, bioweapon creation, improving nutritional quality and veterinary science.}
}
@article{SIYAL20252637,
title = {Adaptive Attribute-Based Honey Encryption: A Novel Solution for Cloud Data Security},
journal = {Computers, Materials and Continua},
volume = {82},
number = {2},
pages = {2637-2664},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.058717},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825001614},
author = {Reshma Siyal and Muhammad Asim and Long Jun and Mohammed Elaffendi and Sundas Iftikhar and Rana Alnashwan and Samia Allaoua Chelloug},
keywords = {Cybersecurity, data security, cloud storage, hadoop encryption and decryption, privacy protection, attribute-based honey encryption},
abstract = {A basic procedure for transforming readable data into encoded forms is encryption, which ensures security when the right decryption keys are used. Hadoop is susceptible to possible cyber-attacks because it lacks built-in security measures, even though it can effectively handle and store enormous datasets using the Hadoop Distributed File System (HDFS). The increasing number of data breaches emphasizes how urgently creative encryption techniques are needed in cloud-based big data settings. This paper presents Adaptive Attribute-Based Honey Encryption (AABHE), a state-of-the-art technique that combines honey encryption with Ciphertext-Policy Attribute-Based Encryption (CP-ABE) to provide improved data security. Even if intercepted, AABHE makes sure that sensitive data cannot be accessed by unauthorized parties. With a focus on protecting huge files in HDFS, the suggested approach achieves 98% security robustness and 95% encryption efficiency, outperforming other encryption methods including Ciphertext-Policy Attribute-Based Encryption (CP-ABE), Key-Policy Attribute-Based Encryption (KB-ABE), and Advanced Encryption Standard combined with Attribute-Based Encryption (AES+ABE). By fixing Hadoop’s security flaws, AABHE fortifies its protections against data breaches and enhances Hadoop’s dependability as a platform for processing and storing massive amounts of data.}
}
@article{LEVINSON2002155,
title = {Returning the tables: language affects spatial reasoning},
journal = {Cognition},
volume = {84},
number = {2},
pages = {155-188},
year = {2002},
issn = {0010-0277},
doi = {https://doi.org/10.1016/S0010-0277(02)00045-8},
url = {https://www.sciencedirect.com/science/article/pii/S0010027702000458},
author = {Stephen C Levinson and Sotaro Kita and Daniel B.M Haun and Björn H Rasch},
keywords = {Language, Spatial reasoning, Linguistic relativity},
abstract = {Li and Gleitman (Turning the tables: language and spatial reasoning. Cognition, in press) seek to undermine a large-scale cross-cultural comparison of spatial language and cognition which claims to have demonstrated that language and conceptual coding in the spatial domain covary (see, for example, Space in language and cognition: explorations in linguistic diversity. Cambridge: Cambridge University Press, in press; Language 74 (1998) 557): the most plausible interpretation is that different languages induce distinct conceptual codings. Arguing against this, Li and Gleitman attempt to show that in an American student population they can obtain any of the relevant conceptual codings just by varying spatial cues, holding language constant. They then argue that our findings are better interpreted in terms of ecologically-induced distinct cognitive styles reflected in language. Linguistic coding, they argue, has no causal effects on non-linguistic thinking – it simply reflects antecedently existing conceptual distinctions. We here show that Li and Gleitman did not make a crucial distinction between frames of spatial reference relevant to our line of research. We report a series of experiments designed to show that they have, as a consequence, misinterpreted the results of their own experiments, which are in fact in line with our hypothesis. Their attempts to reinterpret the large cross-cultural study, and to enlist support from animal and infant studies, fail for the same reasons. We further try to discern exactly what theory drives their presumption that language can have no cognitive efficacy, and conclude that their position is undermined by a wide range of considerations.}
}
@incollection{SHEN20231,
title = {Interdisciplinary science learning},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {1-9},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.13030-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305130301},
author = {Ji Shen and Changzhao Wang},
keywords = {Cross-disciplinary learning, Integrated learning, Interdisciplinary science learning, Interdisciplinary understanding, Interdisciplinary practices, Knowledge integration, Multidisciplinary learning, STEM education, STEAM education},
abstract = {This article presents a conceptual review of studies and programs related to interdisciplinary science learning in different boundary-crossing scenarios including within sciences, across STEM, and with non-STEM fields. Specific examples are also included to illuminate the four core interdisciplinary practices, namely, translation, transfer, integration, and transformation, that cut across these interdisciplinary learning contexts. The article also discusses challenges for interdisciplinary science learning and strategies proposed to address these challenges. More empirical studies are called to test the effectiveness of these strategies to facilitate and assess interdisciplinary science learning in different domains and contexts.}
}
@incollection{CLEEREMANS20012584,
title = {Conscious and Unconscious Processes in Cognition},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2584-2589},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/03560-9},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767035609},
author = {A. Cleeremans},
abstract = {Characterizing the relationships between conscious and unconscious processes is one of the most important and long-standing goals of cognitive psychology. Renewed interest in the nature of consciousness—long considered not to be scientifically explorable—as well as the increasingly widespread availability of functional brain-imaging techniques, now offer the possibility of detailed exploration of the neural, behavioral, and computational correlates of conscious and unconscious cognition. This article reviews some of the relevant experimental work, highlights the methodological challenges involved in establishing the extent to which cognition can occur unconsciously, and situates ongoing debates in the theoretical context provided by current thinking about consciousness.}
}
@article{MARCHAND1995179,
title = {Policy analysis as a tool for habitat restoration: A case study of a Danube river floodplain, Hungary},
journal = {Water Science and Technology},
volume = {31},
number = {8},
pages = {179-186},
year = {1995},
note = {Integrated Water Resources Management},
issn = {0273-1223},
doi = {https://doi.org/10.1016/0273-1223(95)00399-8},
url = {https://www.sciencedirect.com/science/article/pii/0273122395003998},
author = {M. Marchand* and E.C.L. Marteijn** and P. Bakonyi***},
keywords = {Floodplain rehabilitation, Danube, policy analysis, water quality modelling},
abstract = {This paper will elaborate a policy analysis approach especially designed for habitat restoration. It will be illustrated by a case study example of a floodplain area along the Danube river, Hungary. The case study used hydrodynamic and water quality models and expertise from a range of disciplines. This made it possible to unravel the complex relations between the environment and human interventions. Crucial was the participation of local experts in the design and screening of measures, as well as the feedback from local interest groups at several occasions during the project. This resulted in the formulation of rehabilitation ideas, most of which have hitherto not been discussed. The combination of creative thinking with practical possibilities and limitations has been worked out in a cyclic process from which three different alternatives emerged. These have been analyzed for their feasibility with regard to the goals to be achieved, their costs and their impacts on other interests.}
}
@article{OSCARIDO2023539,
title = {The impact of competitive FPS video games on human's decision-making skills},
journal = {Procedia Computer Science},
volume = {216},
pages = {539-546},
year = {2023},
note = {7th International Conference on Computer Science and Computational Intelligence 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.167},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922022451},
author = {Juan Oscarido and Zulfikar Airlangga Siswanto and Devin Akwila Maleke and Alexander Agung Santoso Gunawan},
keywords = {decision making, comparison strategy, video games, cognitive skill, influence-of-games, game-based learning},
abstract = {The problem we face today is that many people think that playing games only has a negative impact on a person's brain and behavior. but the fact is that playing games has a positive impact in many ways. The aim of this document is to prove whether video games can really influence human behavior on their decision-making skills. We will test 22 respondents directly who are teenagers and adults around 17 - 25 years old, and we will score them after they have finished playing games with the genre that we decided. The results proved that competitive First-person shooter (FPS) games increase human ability to make decisions quickly and correctly. Many of our participants agree that after playing competitive FPS games, they feel a positive impact on their cognitive skills. Our participants said that they can quickly compare the impact of the decisions they make and choose exactly which is the best course of action.}
}
@article{HAN2014106,
title = {Toward an understanding of the impact of production pressure on safety performance in construction operations},
journal = {Accident Analysis & Prevention},
volume = {68},
pages = {106-116},
year = {2014},
note = {Systems thinking in workplace safety and health},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2013.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0001457513004041},
author = {SangUk Han and Farzaneh Saba and SangHyun Lee and Yasser Mohamed and Feniosky Peña-Mora},
keywords = {Safety, Systems thinking, Accident prevention, Simulation, Causal loop analysis},
abstract = {It is not unusual to observe that actual schedule and quality performances are different from planned performances (e.g., schedule delay and rework) during a construction project. Such differences often result in production pressure (e.g., being pressed to work faster). Previous studies demonstrated that such production pressure negatively affects safety performance. However, the process by which production pressure influences safety performance, and to what extent, has not been fully investigated. As a result, the impact of production pressure has not been incorporated much into safety management in practice. In an effort to address this issue, this paper examines how production pressure relates to safety performance over time by identifying their feedback processes. A conceptual causal loop diagram is created to identify the relationship between schedule and quality performances (e.g., schedule delays and rework) and the components related to a safety program (e.g., workers’ perceptions of safety, safety training, safety supervision, and crew size). A case study is then experimentally undertaken to investigate this relationship with accident occurrence with the use of data collected from a construction site; the case study is used to build a System Dynamics (SD) model. The SD model, then, is validated through inequality statistics analysis. Sensitivity analysis and statistical screening techniques further permit an evaluation of the impact of the managerial components on accident occurrence. The results of the case study indicate that schedule delays and rework are the critical factors affecting accident occurrence for the monitored project.}
}
@article{SINGH2023103044,
title = {A survey of mobility-aware Multi-access Edge Computing: Challenges, use cases and future directions},
journal = {Ad Hoc Networks},
volume = {140},
pages = {103044},
year = {2023},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2022.103044},
url = {https://www.sciencedirect.com/science/article/pii/S1570870522002165},
author = {Ramesh Singh and Radhika Sukapuram and Suchetana Chakraborty},
keywords = {Mobility, Multi-access Edge Computing, Task offloading, Service migration, Content caching, Resource allocation},
abstract = {Many mobile and pervasive applications avail cloud services to reduce overheads in on-device computation. The performance of these services depends on the available bandwidth of the underlying network, the physical proximity of the cloud server and the end devices, the volume of data, the computational capacity of the server, and, importantly, the mobility of the devices hosting the applications. Edge computing promises to provide better performance by bringing services (e.g., a video streaming service) from the cloud to servers near the user. It also enables partial or full offloading of the computation (tasks) and storage functionalities from the User Equipment (UE) to the edge of the network. This saves power and benefits from relatively more powerful devices at the edge. Multi-access Edge Computing (MEC), which supports wireless and wired access technologies, has gained significant research interest. When UEs move, services must continue to operate, tasks may need to be offloaded again, and states related to tasks and services may need to be migrated. In this paper, we focus on four functional components (task/service offloading, resource allocation, content/task caching, and service/task migration) of MEC. We survey the challenges to these and their solutions in the context of UE mobility. Mobility creates challenges during offloading resource-intensive tasks as the user may move while the task is being offloaded. Some of the other challenges are how to jointly allocate computing and communication resources, minimize service down time during migration, and share the backhaul network if the same MEC host must continue to be used. Some key research areas include intelligent task offloading and service migration algorithms, exploiting group mobility to improve task migration time, studying the interplay of MEC parameters such as capabilities of the target MEC host, etc. In addition, predicting the mobile trajectory through intelligent methods and implementations with datasets from real-world scenarios are required. We compare this paper on 11 parameters (service migration, task offloading, resource allocation, content caching, mobility, use cases, architecture, computing paradigm, mobility model, system model, virtualization/Software Defined Networks) with 31 other survey papers from 2018 to April 2022 in MEC and related domains. We discuss the Edge Computing paradigm, the system architecture and model descriptions, and use cases. We briefly explain the relevant challenges and future directions in emerging domains, such as the Internet of drones and Digital twins. We also discuss future research directions in task/service migration, offloading, resource management, distributed computing, reliability, and Quality of Service, all related to mobility in MEC.}
}
@article{JACOB2020102142,
title = {Neural correlates of rumination in major depressive disorder: A brain network analysis},
journal = {NeuroImage: Clinical},
volume = {25},
pages = {102142},
year = {2020},
issn = {2213-1582},
doi = {https://doi.org/10.1016/j.nicl.2019.102142},
url = {https://www.sciencedirect.com/science/article/pii/S2213158219304887},
author = {Yael Jacob and Laurel S Morris and Kuang-Han Huang and Molly Schneider and Sarah Rutter and Gaurav Verma and James W Murrough and Priti Balchandani},
keywords = {Default mode network, Depression, Entropy, Graph Theory, High-field MRI, Precuneus},
abstract = {Patients with major depressive disorder (MDD) exhibit higher levels of rumination, i.e., repetitive thinking patterns and exaggerated focus on negative states. Rumination is known to be associated with the cortical midline structures / default mode network (DMN) region activity, although the brain network topological organization underlying rumination remains unclear. Implementing a graph theoretical analysis based on ultra-high field 7-Tesla functional MRI data, we tested whether whole brain network connectivity hierarchies during resting state are associated with rumination in a dimensional manner across 20 patients with MDD and 20 healthy controls. Applying this data-driven approach we found a significant correlation between rumination tendency and connectivity strength degree of the right precuneus, a key node of the DMN. In order to interrogate this region further, we then applied the Dependency Network Analysis (DEPNA), a recently developed method used to quantify the connectivity influence of network nodes. This revealed that rumination was associated with lower connectivity influence of the left medial orbito-frontal cortex (MOFC) cortex on the right precuneus. Lastly, we used an information theory entropy measure that quantifies the cohesion of a network's correlation matrix. We show that subjects with higher rumination scores exhibit higher entropy levels within the DMN i.e. decreased overall connectivity within the DMN. These results emphasize the general DMN involvement during self-reflective processing related to maladaptive rumination in MDD. This work specifically highlights the impact of the MOFC on the precuneus, which might serve as a target for clinical neuromodulation treatment.}
}
@article{LAWLER1996241,
title = {Thinkable models},
journal = {The Journal of Mathematical Behavior},
volume = {15},
number = {3},
pages = {241-259},
year = {1996},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(96)90004-8},
url = {https://www.sciencedirect.com/science/article/pii/S0732312396900048},
author = {Robert W. Lawler},
abstract = {A primary objective of technical education should be the development of thinkable models in the minds of students. Thinkable models are representations of things and processes simple enough that people can use them in thought experiments. The organization of cognitive structures for technical domains can be imagined to be a network of appropriately connected thinkable models. Artificial intelligence (AI), as the science of representations, has focused in the main on languagelike representations. If we can enrich our vision of representations to include a greater variety of ways of thinking that are useful to people, we may hope to broaden access to scientific ideas. To pursue these notions in some detail, a taxonomy of models is developed and the issue of how representations relate to human modes of perception and action is raised. The notions are explored first through contrasting of several approaches to the Pythagorean Theorem.}
}
@article{WANG2023107152,
title = {scASGC: An adaptive simplified graph convolution model for clustering single-cell RNA-seq data},
journal = {Computers in Biology and Medicine},
volume = {163},
pages = {107152},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107152},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523006170},
author = {Shudong Wang and Yu Zhang and Yulin Zhang and Wenhao Wu and Lan Ye and YunYin Li and Jionglong Su and Shanchen Pang},
keywords = {ScRNA-seq, Clustering, Bioinformatics, Graph convolution, Computational biology, Machine learning},
abstract = {Single-cell RNA sequencing (scRNA-seq) is now a successful technique for identifying cellular heterogeneity, revealing novel cell subpopulations, and forecasting developmental trajectories. A crucial component of the processing of scRNA-seq data is the precise identification of cell subpopulations. Although many unsupervised clustering methods have been developed to cluster cell subpopulations, the performance of these methods is vulnerable to dropouts and high dimensionality. In addition, most existing methods are time-consuming and fail to adequately account for potential associations between cells. In the manuscript, we present an unsupervised clustering method based on an adaptive simplified graph convolution model called scASGC. The proposed method builds plausible cell graphs, aggregates neighbor information using a simplified graph convolution model, and adaptively determines the most optimal number of convolution layers for various graphs. Experiments on 12 public datasets show that scASGC outperforms both classical and state-of-the-art clustering methods. In addition, in a study of mouse intestinal muscle containing 15,983 cells, we identified distinct marker genes based on the clustering results of scASGC. The source code of scASGC is available at https://github.com/ZzzOctopus/scASGC.}
}
@article{RABELLOMESTRE2025101775,
title = {Creative Learning - A Configurative Review of Features and Practices},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101775},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101775},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000240},
author = {André Rabello-Mestre and Ingunn Johanne Ness and Vlad Petre Glăveanu},
keywords = {creative learning, creativity, learning, creativity theory, creative pedagogies, teaching for creativity},
abstract = {The idea that learning and creativity are interrelated has experienced a renaissance in the last 20 years. Fashionable and suggestive, the concept of "creative learning" has found traction in educational policy and in progressive classrooms across the globe. This configurative review explores how the concept of creative learning has been understood and put into practice across 112 education studies since 2010. Specifically, the review addresses two questions: First, what are the constitutive features and actions that characterize creative learning? Second, what are the overarching themes that can be identified in the literature? The study reports on the findings of an extensive thematic analysis, which indicated four general approaches to creative learning: namely (1) creative agency over learning, (2) affective and embodied pathways, (3) relational ecologies, and (4) learning by doing and making. The review concludes with a discussion of each of these themes, deriving from them a set of practical recommendations and a revised definition of creative learning.}
}
@incollection{PUHLMANN202517,
title = {The Concept Benign by Design},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {17-29},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00065-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044315742400065X},
author = {Neele Puhlmann and Klaus Kümmerer},
keywords = {BbD, Biodegradation, Compound, Environment, Lifecycle, Persistence, Pharmaceuticals, Product, Rules-of-Thumb, SSbD},
abstract = {Benign by Design (BbD) aims to conserve material resources and the environment effectively by considering the end-of-life stage of chemicals/materials/products already at the early design phase. This chapter focusses on designing chemicals/pharmaceuticals for full mineralization after their introduction into the environment at the end of their life. Exemplified are BbD principles, biodegradable compounds, (re)design approaches, and testing strategies. An important principle is, e.g., that biodegradability depends on the ambient conditions, which change along compounds’ lifecycle. This exemplification will encourage BbD’s application. Bringing BbD into practice dependents on available test methods and knowledge. Interdisciplinary collaboration and training are key.}
}
@incollection{GORI2018122,
title = {Chapter 3 - Linear Threshold Machines},
editor = {Marco Gori},
booktitle = {Machine Learning},
publisher = {Morgan Kaufmann},
pages = {122-184},
year = {2018},
isbn = {978-0-08-100659-7},
doi = {https://doi.org/10.1016/B978-0-08-100659-7.00003-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780081006597000038},
author = {Marco Gori},
keywords = {Linear machines, Least mean square, Linear-threshold machines, Normal equations, Ridge regression, Linear separability, Predicate order, Gradient descent, Perceptron algorithm, Terminal attractors},
abstract = {One of the simplest ways of modeling the interactions of intelligent agents with the environment is to expose them to a collection of supervised pairs (example, target). This chapter is about the learning mechanisms that arise from the assumption of dealing with linear and linear-threshold machines. In most cases, the covered topics nicely intercept different disciplines, and are of remarkable importance to better grasp many approaches to machine learning. The chapter covers classic topics, like normal equations and ridge regression, as well as representational issues in pattern recognition that are connected with the notion of predicate order. Linear-threshold machines are described along with related computational geometry issues, and the view that arises from Bayesian decision. Classic gradient learning algorithms, including the stochastic version, are described in the continuum setting, as well as the Rosenblatt perceptron algorithm. Finally, some complexity issues are covered in both the discrete and continuous setting of computation.}
}
@article{ZHIHUI2024108706,
title = {Temperature measurement at turbine outlet achieved by a sensing net and infrared thermometry method},
journal = {International Journal of Thermal Sciences},
volume = {196},
pages = {108706},
year = {2024},
issn = {1290-0729},
doi = {https://doi.org/10.1016/j.ijthermalsci.2023.108706},
url = {https://www.sciencedirect.com/science/article/pii/S1290072923005677},
author = {Wang Zhihui and Ma Chaochen and Ji Nian},
keywords = {infrared thermometry, Temperature sensing net (TSN), Turbine outlet temperature, Conjugate heat transfer (CHT), Turbine adiabatic efficiency},
abstract = {The measurement of turbine outlet temperature is challenging because of an intense swirl and high speed at this position. However, accurate measurement of the turbine outlet temperature is fundamental for characterizing the turbine performance. The paper proposed an infrared thermometry method based on the temperature sensing net (TSN) to measure the temperature distribution at the turbine outlet. First, this article describes the design and operation of the measurement procedure through infrared technology to accomplish this difficult task. Then, the temperature and velocity distribution at the turbine outlet and the adiabatic efficiency of the turbine are obtained using the CFD (Computational Fluid Dynamics) method to verify the feasibility of the proposed scheme. And the CHT (Conjugate Heat Transfer) simulation results for the TSN show that the incoming flow mass rate has a great influence on TSN temperature. In contrast, the influence of the incoming flow temperature gradient on it is almost negligible. Moreover, the fluid flow behavior and static temperature distribution around the temperature-sensing wire (TSW) at different Mach numbers are analyzed, and the heat transfer mechanism between the TSW and the fluid is revealed. The results show that the temperature of the TSN is lower than that of the incoming flow, but the distribution law is similar. The main factor affecting the temperature difference between the TSW and the fluid is the incoming flow velocity.}
}
@incollection{DU202457,
title = {Chapter 3 - Data, machine learning, first-principles, and hybrid models in the petrochemical industry},
editor = {Masoud Soroush and Richard {D Braatz}},
booktitle = {Artificial Intelligence in Manufacturing},
publisher = {Academic Press},
pages = {57-96},
year = {2024},
isbn = {978-0-323-99135-3},
doi = {https://doi.org/10.1016/B978-0-323-99135-3.00011-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323991353000117},
author = {Di Du and Johannes Pieter Schmal},
keywords = {Data, Data types, Data-driven models, First-principles models, Hybrid models, Machine learning},
abstract = {With the increase in computational power, memory, data storage, and data availability models have become more abundant and powerful, leading to many process improvements and benefits in the petrochemical industry. In this chapter, we will first discuss the data types based on dimensions. We then discuss different machine-learning approaches and other data-driven approaches with applications in the petrochemical industry. First-principles and hybrid modeling approaches are also discussed and compared with machine-learning approaches.}
}
@article{AVINERI2012512,
title = {On the use and potential of behavioural economics from the perspective of transport and climate change},
journal = {Journal of Transport Geography},
volume = {24},
pages = {512-521},
year = {2012},
note = {Special Section on Theoretical Perspectives on Climate Change Mitigation in Transport},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2012.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0966692312000646},
author = {Erel Avineri},
keywords = {Behavioural economics, Travel behaviour, Nudge},
abstract = {It can be argued that the main thinking in transport planning and policy making stem from neoclassical economics in which individuals are largely assumed to make rational, consistent, and efficient choices, and apply cognitive processes of decision making that maximise their economic utility. Research in behavioural sciences indicates that individuals’ choices in a wide range of contexts deviate from the predictions of the rational man paradigm inspired the research agenda in the field of travel behaviour. New concepts and practices of government aim to apply some behavioural economics insights in the design of behavioural change initiatives and measures, an approach recently advocated in the US and the UK. This paper provides a brief review on the use and potential of behavioural economics from the perspective of transport and climate change, in two main contexts: travel demand modelling and design of behaviour change measures. The discussion of limitations and knowledge gaps associated with the implementation of behavioural economics to a travel behaviour context might contribute to the debate and help in defining research agenda in this area.}
}
@article{HUANG2011183,
title = {On the intrinsic inevitability of cancer: From foetal to fatal attraction},
journal = {Seminars in Cancer Biology},
volume = {21},
number = {3},
pages = {183-199},
year = {2011},
note = {Why Systems Biology and Cancer?},
issn = {1044-579X},
doi = {https://doi.org/10.1016/j.semcancer.2011.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S1044579X11000320},
author = {Sui Huang},
keywords = {Tumorigenesis, Tumour progression, Epigenetic landscape, Gene regulatory network, Attractor, State space, Somatic mutation, Oncogene},
abstract = {The cracks in the paradigm of oncogenic mutations and somatic evolution as driving force of tumorigenesis, lucidly exposed by the dynamic heterogeneity of “cancer stem cells” or the diffuse results of cancer genome sequencing projects, indicate the need for a more encompassing theory of cancer that reaches beyond the current proximate explanations based on individual genetic pathways. One such integrative concept, derived from first principles of the dynamics of gene regulatory networks, is that cancerous cell states are attractor states, just like normal cell types are. Here we extend the concept of cancer attractors to illuminate a more profound property of cancer initiation: its inherent inevitability in the light of metazoan evolution. Using Waddington's Epigenetic Landscape as a conceptual aid, for which we present a mathematical and evolutionary foundation, we propose that cancer is intrinsically linked to ontogenesis and phylogenesis. This explanatory rather than enumerating review uses a formal argumentation structure that is atypical in modern experimental biology but may hopefully offer a new coherent perspective to reconcile many conflicts between new findings and the old thinking in the categories of linear oncogenic pathways.}
}
@article{JIANG2024100078,
title = {Human-AI interaction research agenda: A user-centered perspective},
journal = {Data and Information Management},
volume = {8},
number = {4},
pages = {100078},
year = {2024},
issn = {2543-9251},
doi = {https://doi.org/10.1016/j.dim.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2543925124000147},
author = {Tingting Jiang and Zhumo Sun and Shiting Fu and Yan Lv},
keywords = {Human-AI interaction, Human-AI collaboration, Human-AI competition, Human-AI conflict, Human-AI symbiosis},
abstract = {The rapid growth of artificial intelligence (AI) has given rise to the field of Human-AI Interaction (HAII). This study meticulously reviewed the research themes, theoretical foundations, and methodological frameworks of the HAII field, aiming to construct a comprehensive overview of this field and provide robust support for future investigations. HAII research themes include human-AI collaboration, competition, conflict, and symbiosis. Theories drawn from communication, psychology, and sociology support these studies, while the employed methods include both self-reporting and observational approaches commonly utilized in user studies. It is suggested that future research should broaden its focus to encompass diverse user groups, AI roles, and tasks. Moreover, it is necessary to develop multi-disciplinary theories and integrate multi-level research methods to support the sustained development of the field. This study not only furnishes indispensable theoretical and practical insights for forthcoming research endeavors but also catalyzes the realization of a future distinguished by seamless interaction between humans and AI.}
}
@article{WANG2023458,
title = {The Hutong neighbourhood grammar: A procedural modelling approach to unravel the rationale of historical Beijing urban structure},
journal = {Frontiers of Architectural Research},
volume = {12},
number = {3},
pages = {458-476},
year = {2023},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095263523000031},
author = {Yuyang Wang and Andrew Crompton and Asterios Agkathidis},
keywords = {Urban morphology, Siheyuan, Hutong neighbourhood, Procedural modelling, Shape grammar},
abstract = {Hutong neighbourhoods, composed of Chinese courtyard dwellings (Siheyuan), are historically and socially significant urban spaces that embody the traditional Chinese way of life and philosophy. As part of the national heritage, there is an increasing research interest in Hutong neighbourhoods, many of which are facing oblivion. This study presents a formal grammar for Hutong neighbourhood generation. This research investigates traditional principles of urban planning of ancient Beijing, based on examples on the historical map Qianlong Jingcheng Quantu, to derive the lost design rules. These rules are used to build up a procedural modelling framework, which reveals the development of Beijing's urban structure from the Yuan (1271–1368) to the Qing (1644–1911) dynasty. Our findings present a grammar incorporated into the procedural modelling framework to parametrically generate Hutong neighbourhoods, which replicates the morphological characteristics of historic cases. It contributes to the understanding of the generation of Hutong neighbourhoods. In support of heritage sustainability, this grammar can be implemented in a computational environment by visual scripting that enables the generation of new instances of Hutong neighbourhoods, both real and virtual.}
}
@article{CORDASCO201815,
title = {Distributed MASON: A scalable distributed multi-agent simulation environment},
journal = {Simulation Modelling Practice and Theory},
volume = {89},
pages = {15-34},
year = {2018},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2018.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X18301230},
author = {Gennaro Cordasco and Vittorio Scarano and Carmine Spagnuolo},
keywords = {Agent-based simulation, Parallel computing, Distributed computing, Scalable computational science, Cloud computing},
abstract = {Computational Social Science (CSS) involves interdisciplinary fields and exploits computational methods, such as social network analysis as well as computer simulation with the goal of better understanding social phenomena. Agent-Based Models (ABMs) represent an effective research tool for CSS and consist of a class of models, which, aim to emulate or predict complex phenomena through a set of simple rules (i.e., independent actions, interactions and adaptation), performed by multiple agents. The efficiency and scalability of ABMs systems are typically obtained distributing the overall computation on several machines, which interact with each other in order to simulate a specific model. Unfortunately, the design of a distributed simulation model is particularly challenging, especially for domain experts who sporadically are computer scientists and are not used to developing parallel code. D-MASON framework is a distributed version of the MASON library for designing and executing ABMs in a distributed environment ensuring scalability and easiness. D-MASON enable the developer to exploit the computing power of distributed environment in a transparent manner; the developer has to do simple incremental modifications to existing MASON models, without re-designing them. This paper presents several novel features and architectural improvements introduced in the D-MASON framework: an improved space partitioning strategy, a distributed 3D field, a distributed network field, a decentralized communication layer, a novel memory consistency mechanism and the integration to cloud environments. Full documentation, additional tutorials, and other material can be found at https://github.com/isislab-unisa/dmason where the framework can be downloaded.}
}
@article{CLEGG201856,
title = {Analysis of a train-operating company's customer service system during disruptions: Conceptual requirements for gamifying frontline staff development},
journal = {Journal of Rail Transport Planning & Management},
volume = {8},
number = {1},
pages = {56-77},
year = {2018},
issn = {2210-9706},
doi = {https://doi.org/10.1016/j.jrtpm.2017.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2210970617300495},
author = {Ben Clegg and Richard Orme and Chris Owen and Pavel Albores},
keywords = {Customer service systems, Gamification, Systems thinking, Mitigate-Plan-React-Recovery (MPRR) framework, Disruption management, Frontline staff training},
abstract = {This paper provides an account of an action research study into the systemic success factors which help frontline staff react to and recover from a rail service disruption. This study focuses on the effective use of information during a disruption to improve customer service, as this is a priority area for train-operating companies (TOCs) in Great Britain. A novel type of systems thinking, known as Process-Oriented Holonic (PrOH) Modelling, has been used to investigate and model the ‘Passenger Information During Disruption’ (PIDD) system. This paper presents conceptual requirements for a gamified learning environment; it describes ‘what’, ‘how’ and ‘when’ these systemic success factors could be gamified using a popular disruption management reference framework known as the Mitigate, Prepare, React and Recover (MPRR) framework. This paper will interest managers of and researchers into customer service system disruptions, as well as those wishing to develop new gamified learning environments to improve customer service systems.}
}
@article{FATTAHI2020107755,
title = {Stochastic optimization of disruption-driven supply chain network design with a new resilience metric},
journal = {International Journal of Production Economics},
volume = {230},
pages = {107755},
year = {2020},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2020.107755},
url = {https://www.sciencedirect.com/science/article/pii/S0925527320301407},
author = {Mohammad Fattahi and Kannan Govindan and Reza Maihami},
keywords = {Resilience metrics, Supply chain network design, Stochastic programming, Conic mixed-integer program},
abstract = {The supply chain (SC) ability to return quickly and effectively to its initial condition or even a more desirable state after a disruption is critically important, and is defined as SC resilience. Nevertheless, it has not been sufficiently quantified in the related literature. This study provides a new metric to quantify the SC resilience by using the stochastic programming. Our metric measures the expected value of the SC's cost increase due to a possible disruption event during its recovery period. Based on this measure, we propose a two-stage stochastic program for the supply chain network design under disruption events that optimizes location, allocation, inventory and order-size decisions. The stochastic program is formulated using quadratic conic optimization, and the sample average approximation (SAA) method is employed to handle the large number of disruption scenarios. A comprehensive computational study is carried out to highlight the applicability of the presented metric, the computational tractability of the stochastic program, and the performance of the SAA. Several key managerial and practical insights are gained based on the computational results. This new metric captures the time and cost of the SC's recovery after disruption events contrast to most of previous studies and main impacts of these two aspects on design decisions are highlighted. Further, it is shown computationally that the increase of SC's capacity is not a suitable strategy for designing resilient SCs in some business environments.}
}
@incollection{AHAMED2017465,
title = {Chapter 29 - The Architecture of a Mind-Machine},
editor = {Syed V. Ahamed},
booktitle = {Evolution of Knowledge Science},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {465-479},
year = {2017},
isbn = {978-0-12-805478-9},
doi = {https://doi.org/10.1016/B978-0-12-805478-9.00029-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128054789000297},
author = {Syed V. Ahamed},
keywords = {Mind, Knowledge, Machines, Technology, Human Needs, Knowledge Windows, Perceptual Spaces},
abstract = {Chapter Summary
In this chapter, we take bold step and propose the unthinkable: The genesis of a Customizable Mind-Machine. Thought that stems from the mind is deeply seated in a biological framework of neurons. The biological origin lies in the marvel of evolution over the eons and refined ever so fast, faster than in the prior centuries. Three (a, b, and c), triadic objects are ceaselessly at work. At a personal level (a) mind, knowledge, and machines have been intertwined like inspiration, words, and language since the dawn of the human evolution and more recently, (b) technology, manufacturing, and economics have formed a hub of progress, (c) wealth, global marketing, and insatiable needs of humans and civilization. These triadic cycles of nine essential objects of human existence are spinning quicker and quicker every year. The Internet offers the mind no choice but to leap and soar over history and over the globe. Alternatively, human mind can sink deeper and deeper into ignorance and oblivion. More recently, the Artificial Intelligence at work in the Internet had challenged the natural intelligence at the cognizance level in the mind to find its way to breakthroughs and innovations. We integrate functions of the mind with the processing of knowledge in the hardware of machines by freely traversing the neural, mental, physical, psychological, social, knowledge, and computational spaces. The laws of neural biology and mind, laws of knowledge and social sciences, and finally the laws of physics and mechanics in each of the spaces are unique and executed by distinctive processors for each space. Much as mind rules over matter, the triad of mind, space, and time creates a human-space that rules over the Relativistic-space of matter, space, and time.}
}
@article{DIMAGGIO2025S297,
title = {486. Simulating Thought Disorder: Fine-Tuning Llama-2 for Synthetic Speech in Schizophrenia},
journal = {Biological Psychiatry},
volume = {97},
number = {9, Supplement },
pages = {S297-S298},
year = {2025},
note = {Abstract Supplement},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2025.02.724},
url = {https://www.sciencedirect.com/science/article/pii/S0006322325008224},
author = {Anthony DiMaggio and Gleb Melshin and Lena Palaniyappan and Alban Voppel}
}
@article{WEIGL20231,
title = {Modelling learning for a better safety culture within an organization using a virtual safety coach: Reducing the risk of postpartum depression via improved communication with parents},
journal = {Cognitive Systems Research},
volume = {80},
pages = {1-36},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723000153},
author = {Linn-Marie Weigl and Fakhra Jabeen and Jan Treur and H. Rob Taal and Peter H.M.P. Roelofsma},
keywords = {Shared mental models, virtual AI Coach in healthcare, Fathers/psychology, Depressive disorders/complications, Postpartum depression},
abstract = {This paper describes an extension of a safety culture within hospital organizations providing more transparency and acknowledgement of all actors, and in particular the parents. It contributes a model architecture to support a hospital to develop such an extended safety culture. It is illustrated for prevention of postpartum depression. Postpartum depression is a commonly known consequence of childbirth for both mothers and fathers. In this research, we computationally analyze the risk factors and lack of support received by fathers. Therefore, we use shared mental models to model the effects of poor and additional communication by healthcare practitioners to mitigate the development of postpartum depression in both the mother and the father. Both individual mental models and shared mental models are considered in the design of the computational model. The paper illustrates the benefits of simple support in terms of communication during childbirth, which has lasting effects, even outside the hospital. For the impact of additional communication, a Virtual Safety Coach is designed that intervenes when necessary to provide support, i.e., when a health care practitioner doesn’t. Moreover, organizational learning is also modelled to improve the mental models of both the Safety Coach and the Health Care Practitioner.}
}
@incollection{CARSTON2006559,
title = {Language of Thought},
editor = {Keith Brown},
booktitle = {Encyclopedia of Language & Linguistics (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {559-561},
year = {2006},
isbn = {978-0-08-044854-1},
doi = {https://doi.org/10.1016/B0-08-044854-2/04780-5},
url = {https://www.sciencedirect.com/science/article/pii/B0080448542047805},
author = {R. Carston},
keywords = {biosemantics, computational theory of mind, connectionism, intentional realism, intentionality, Mentalese, methodological solipsism, productivity (of thought), propositional attitude, psychosemantics, representational theory of mind, syntactic structure, systematicity (of thought)},
abstract = {Two key aspects of human public languages are syntax and semantics, where syntax concerns the combinatorial structure of linguistic expressions and semantics refers to their content or meaning. So, the claim that humans have a language of thought, defended in particular by Jerry Fodor, amounts to the view that thoughts are representational (semantic) and thought processes are computational, that is, they involve transformations of symbolic structures on the basis of their formal (syntactic) properties. The fact that thought, like language, exhibits ‘productivity’ and ‘systematicity’ argues for a system of mental representation that has language-like structure.}
}
@article{WAHYUNINGSIH2024349,
title = {Comparison of Effectiveness of Logistic Regression, Naive Bayes, and Random Forest Algorithms in Predicting Student Arguments},
journal = {Procedia Computer Science},
volume = {234},
pages = {349-356},
year = {2024},
note = {Seventh Information Systems International Conference (ISICO 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924003715},
author = {Tri Wahyuningsih and Danny Manongga and Irwan Sembiring and Sutarto Wijono},
keywords = {Comparison Algorithm, Logistic Regression, Naive Bayes, Random Forest, Student Arguments},
abstract = {Currently, in the process of assessing and giving feedback on students' argumentative writing, educators have to spend a considerable amount of time reading and analyzing each essay individually. This can be a complicated and time-consuming process, especially if the number of students to be assessed is quite large. The problem of this research is to find the most effective algorithm in providing accurate and reliable predictions in the context of evaluation and feedback of students' argumentation. This study compares three algorithms (logistic regression, Naive Bayes, and Random Forest) to predict student argumentation using essays from grades 6-12. Logistic regression performed best with 94.34% accuracy, followed by random forest with 91.98% accuracy, and Naive Bayes with 88.93% accuracy. The study optimized preprocessing and selected algorithms for an automated guidance model. It is the first stage of a three-part study for developing automated guidance models. Data came from Kaggle, and the study aims to improve the accuracy of automated guidance models for student argumentation.}
}
@article{DEBRUIJN2022101666,
title = {The perils and pitfalls of explainable AI: Strategies for explaining algorithmic decision-making},
journal = {Government Information Quarterly},
volume = {39},
number = {2},
pages = {101666},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101666},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21001027},
author = {Hans {de Bruijn} and Martijn Warnier and Marijn Janssen},
keywords = {Artificial intelligence, XAI, Algorithms, Computational intelligence, Data-driven decision, Socio-tech, Transparency, Accountability, Trust, E-government},
abstract = {Governments look at explainable artificial intelligence's (XAI) potential to tackle the criticisms of the opaqueness of algorithmic decision-making with AI. Although XAI is appealing as a solution for automated decisions, the wicked nature of the challenges governments face complicates the use of XAI. Wickedness means that the facts that define a problem are ambiguous and that there is no consensus on the normative criteria for solving this problem. In such a situation, the use of algorithms can result in distrust. Whereas there is much research advancing XAI technology, the focus of this paper is on strategies for explainability. Three illustrative cases are used to show that explainable, data-driven decisions are often not perceived as objective by the public. The context might raise strong incentives to contest and distrust the explanation of AI, and as a consequence, fierce resistance from society is encountered. To overcome the inherent problems of XAI, decisions-specific strategies are proposed to lead to societal acceptance of AI-based decisions. We suggest strategies to embrace explainable decisions and processes, co-create decisions with societal actors, move away from an instrumental to an institutional approach, use competing and value-sensitive algorithms, and mobilize the tacit knowledge of professionals}
}
@article{PAULIUK2022130997,
title = {Co-design of digital transformation and sustainable development strategies - What socio-metabolic and industrial ecology research can contribute},
journal = {Journal of Cleaner Production},
volume = {343},
pages = {130997},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.130997},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622006321},
author = {Stefan Pauliuk and Maximilian Koslowski and Kavya Madhu and Simon Schulte and Sebastian Kilchert},
keywords = {Sustainable development, Digital transformation, Systems thinking, Research agenda, Technology scale-up, Development constraints},
abstract = {Sustainable development and digital transformation profoundly re-shape industrial societies but have been studied largely independently. In light of pressing global environmental and social challenges, both transformations need to be well aligned with each other to achieve multiple objectives such as listed under the UN Sustainable Development goals (SDGs). Quantitative research on interlinkages, energy and material implications, and co-dependencies between the different digital transformation (DT) and sustainable development (SD) strategies is emerging and has so far focused on estimating the overall potential and on life cycle assessment (LCA). To frame the problem systematically, we developed a hierarchy of system levels for studying society's material and energy use, including the four levels: product/process, process cluster, life cycle/material cycle, and economy-wide. We mapped major DT strategies and the SDGs to the hierarchy and found a wide gap in system coverage: While most DT strategies focus on the product, process and process cluster levels, the SDGs predominantly target the economy-wide level. Socio-metabolic and industrial ecology research is needed to inform decision makers on how the two transformations can be aligned to reach overarching societal goals, such as the SDGs, expanding on and moving beyond LCA. Future research needs to assess combinations of multiple DT and SD strategies. It needs to study how DT can help decouple human wellbeing from negative environmental and social impacts. Research needs to focus on the strategies’ deployment potential, infrastructure needs, impacts on material cycles, and potential to transform both service demand and industrial production.}
}
@article{NAPIER2014331,
title = {Insight into the numerical challenges of implementing 2-dimensional SOA models in atmospheric chemical transport models},
journal = {Atmospheric Environment},
volume = {96},
pages = {331-344},
year = {2014},
issn = {1352-2310},
doi = {https://doi.org/10.1016/j.atmosenv.2014.07.048},
url = {https://www.sciencedirect.com/science/article/pii/S1352231014005780},
author = {W.J. Napier and J.J. Ensberg and J.H. Seinfeld},
keywords = {Secondary organic aerosol, 2-Dimensional SOA model, Chemical transport model, Probability distribution, Computational efficiency},
abstract = {The new generation of secondary organic aerosol (SOA) models that represent gas- and particle-phase chemistry and thermodynamic partitioning using discrete two-dimensional grids (e.g. SOM, 2D-VBS) cannot be efficiently implemented into three-dimensional atmospheric chemical transport models (CTMs) due to the large number of bins (tracers) required. In this study, we introduce a novel mathematical framework, termed the Oxidation State/Volatility Moment Method, that is designed to address these computational burdens so as to allow the new generation of SOA models to be implemented into CTMs. This is accomplished by mapping the two-dimensional grids onto probability distributions that conserve carbon and oxygen mass. Assessment of the Moment Method strengths (speed, carbon and oxygen conservation) and weaknesses (numerical drift) provide valuable insight that can guide future development of SOA modules for atmospheric CTMs.}
}
@article{GOLDIN1998137,
title = {Representational systems, learning, and problem solving in mathematics},
journal = {The Journal of Mathematical Behavior},
volume = {17},
number = {2},
pages = {137-165},
year = {1998},
note = {Representations and the Psychology of Mathematics Education: Part II},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0364-0213(99)80056-1},
url = {https://www.sciencedirect.com/science/article/pii/S0364021399800561},
author = {Gerald A. Goldin},
abstract = {This article explores aspects of a unified psychological model for mathematical learning and problem solving, based on several different types of representational systems and their stages of development. The goal is to arrive at a scientifically adequate theoretical framework, complex enough to account for diverse empirical results but sufficiently simple to be accessible and useful in mathematics education practice. Some perspectives on representational systems are discussed, and components of the model are described in relation to these ideas—including constructs related to imagistic thinking, heuristics and strategies, affect, and the fundamental role of ambiguity.}
}
@incollection{BUCHANAN2014183,
title = {Chapter Seven - Edge Replacement and Minimality as Models of Causal Inference in Children},
editor = {Janette B. Benson},
series = {Advances in Child Development and Behavior},
publisher = {JAI},
volume = {46},
pages = {183-213},
year = {2014},
issn = {0065-2407},
doi = {https://doi.org/10.1016/B978-0-12-800285-8.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128002858000078},
author = {David W. Buchanan and David M. Sobel},
keywords = {Causal reasoning, Causal graphical models, Edge replacement, Cognitive Development, Computational Models},
abstract = {Recently, much research has focused on causal graphical models (CGMs) as a computational-level description of how children represent cause and effect. While this research program has shown promise, there are aspects of causal reasoning that CGMs have difficulty accommodating. We propose a new formalism that amends CGMs. This edge replacement grammar formalizes one existing and one novel theoretical commitment. The existing idea is that children are determinists, in the sense that they believe that apparent randomness comes from hidden complexity, rather than inherent nondeterminism in the world. The new idea is that children think of causation as a branching process: causal relations grow not directly from the cause, but from existing relations between the cause and other effects. We have shown elsewhere that these two commitments together, when formalized, can explain and quantitatively fit the otherwise puzzling effect of nonindependence observed in the adult causal reasoning literature. We then test the qualitative predictions of this new formalism on children in a series of three experiments.}
}
@article{SCHOLTE201894,
title = {Toward a systems theatre: Proposal for a program of non-trivial modeling},
journal = {Futures},
volume = {103},
pages = {94-105},
year = {2018},
note = {Futures of Society: The Interactions Revolution},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2018.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0016328717302033},
author = {Tom Scholte},
keywords = {Augusto Boal, Theatre of the Oppressed, Theatre for Living, Systems theory, Cybernetics, Konstantin Stanislavski, Soft Systems Methodology, System Dynamics, Critical systems heurstics, Enactive Management},
abstract = {This paper makes the case for, and calls for participants in, an interdisciplinary research program exploring the development of theatrical methods of social system modeling. It combines argumentation that synthesizes concepts from the theatre and the system sciences with results from a pilot application of some of the modeling methods discussed. Theatrical methods of modeling facilitate surprising insights regarding the impacts of emotion and other non-trivial factors on system behaviour that are difficult to address in purely computational and diagrammatic forms of modeling. While a theoretical relationship between systems approaches and the theatrical techniques discussed has been articulated elsewhere, this paper is the first to propose a more fulsome exploration of the potentialities of this relationship for systems praxis.}
}
@article{VALERY201844,
title = {A collaborative CPU–GPU approach for principal component analysis on mobile heterogeneous platforms},
journal = {Journal of Parallel and Distributed Computing},
volume = {120},
pages = {44-61},
year = {2018},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2018.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0743731518303411},
author = {Olivier Valery and Pangfeng Liu and Jan-Jan Wu},
keywords = {OpenCL, GPGPU, Mobile computing, Heterogeneous system, PCA, Energy efficient, Acceleration, Data analysis, Machine learning},
abstract = {The advent of the modern GPU architecture has enabled computers to use General Purpose GPU capabilities (GPGPU) to tackle large scale problem at a low computational cost. This technological innovation is also available on mobile devices, addressing one of the primary problems with recent devices: the power envelope. Unfortunately, recent mobile GPUs suffer from a lack of accuracy that can prevent them from running any large scale data analysis tasks, such as principal component analysis (Shlens, 0000) (PCA). The goal of our work is to address this limitation by combining the high precision available on a CPU with the power efficiency of a mobile GPU. In this paper, we exploit the shared memory architecture of mobile devices in order to enhance the CPU–GPU collaboration and speed up PCA computation without sacrificing precision. Experimental results suggest that such an approach drastically reduces the power consumption of the mobile device while accelerating the overall workload. More generally, we claim that this approach can be extended to accelerate other vectorized computations on mobile devices while still maintaining numerical accuracy.}
}