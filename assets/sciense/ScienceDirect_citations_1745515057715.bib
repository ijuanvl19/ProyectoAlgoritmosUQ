@article{ROOS2020112975,
title = {Online conferences – Towards a new (virtual) reality},
journal = {Computational and Theoretical Chemistry},
volume = {1189},
pages = {112975},
year = {2020},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2020.112975},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X20302759},
author = {Goedele Roos and Julianna Oláh and Rebecca Ingle and Rika Kobayashi and Milica Feldt},
keywords = {Virtual conference, Virtual Winter School on Computational Chemistry, Hybrid online/in-person conference},
abstract = {The recent article: Nature 579, 327–328 (2020), ending with the phrase: “You can’t just suddenly make a conference be online.”, has motivated us to write about the practicalities and philosophy of running online events, drawing on our extensive experience running an annual online computational chemistry conference. Our goals for this online conference series have always been: (1) Availability; (2) Community building and (3) Supporting young scientists. In this article, we highlight the motivations behind our initiative, how this has influenced the organisation of our online meeting, and discuss the benefits as well as the drawbacks of virtual meetings. Virtual conferences may not fully replace in-person meetings, but they are rapidly becoming an accepted alternative format. We discuss the hybrid online/in-person conference format as a future possibility that may offer an opportunity to reduce the environmental impact and accessibility barriers associate with in-person meetings without comprising networking and community-building opportunities.}
}
@article{MANLEY201427,
title = {A framework for simulating large-scale complex urban traffic dynamics through hybrid agent-based modelling},
journal = {Computers, Environment and Urban Systems},
volume = {44},
pages = {27-36},
year = {2014},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2013.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0198971513001129},
author = {Ed Manley and Tao Cheng and Alan Penn and Andy Emmonds},
keywords = {Agent-based simulation, Urban complexity, Human cognition, Collective phenomena, Traffic flow, Hybrid simulation},
abstract = {Urban road traffic dynamics are the product of the behaviours and interactions of thousands, often millions of individuals. Traditionally, models of these phenomena have incorporated simplistic representations of individual behaviour, ensuring the maximisation of simulation scale under given computational constraints. Yet, by simplifying representations of behaviour, the overall predictive capability of the model inevitably reduces. In this work a hybrid agent-based modelling framework is introduced that aims to balance the demands of behavioural realism and computational capacity, integrating a descriptive representation of driver behaviour with a simplified, collective model of traffic flow. The hybridisation of these approaches within an agent-based modelling framework yields a representation of urban traffic flow that is driven by individual behaviour, yet, in reducing the computational intensity of simulated physical interaction, enables the scalable expansion to large numbers of agents. A real-world proof-of-concept case study is presented, demonstrating the application of this approach, and showing the gains in computational efficiency made in utilising this approach against traditional agent-based approaches. The paper concludes in addressing how this model might be extended, and exploring the role hybrid agent-based modelling approaches may hold in the simulation of other complex urban phenomena.}
}
@article{LU2024112309,
title = {The physical information LSTM surrogate model for establishing a digital twin model of reciprocating air compressors},
journal = {Applied Soft Computing},
volume = {167},
pages = {112309},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112309},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624010834},
author = {Yingkang Lu and Yanfei Li and Gaocai Fu and Yu Jiang and Yuzhe Huang and Jiaxing Zhu and Buyun Sheng},
keywords = {Reciprocating air compressors, Digital twin, Surrogate model, Pressure prediction, Long short-term memory neural network},
abstract = {Reciprocating air compressors play a crucial role in industrial production processes. However, due to the complex structure and long operating time of reciprocating air compressors, real-time monitoring to grasp the operating status of reciprocating air compressors has become particularly important. Digital twin is a technology that can reflect the behavior of physical entities in real time, accurately predicting and evaluating the operation status of reciprocating air compressors. However, the establishment of a digital twin model for reciprocating air compressors requires a significant amount of computational resources, which can result in the inability to meet the requirements of real-time performance evaluation. To overcome this limitation, this paper proposes a method for constructing a digital twin model of reciprocating air compressors based on a surrogate model. The surrogate model is constructed based on a long short-term memory neural network with physical information(PILSTM). This model can accurately describe the changes in cylinder pressure by combining physical information. According to the characteristics of cylinder pressure changes, regularization formulas are added to ensure the smoothness of the predicted pressure. The experimental results show that the digital twin model based on the surrogate model has high prediction accuracy and real-time performance. Therefore, this model provides a new method for monitoring the operating status of reciprocating air compressors.}
}
@article{NORTHOFF2025106139,
title = {Bridging the gap of brain and experience – Converging Neurophenomenology with Spatiotemporal Neuroscience},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {173},
pages = {106139},
year = {2025},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2025.106139},
url = {https://www.sciencedirect.com/science/article/pii/S0149763425001393},
author = {Georg Northoff and Bianca Ventura},
keywords = {Neurophenomenology, Temporo-spatial dynamics, Self, Meditation, Depression},
abstract = {Neuroscience faces the challenge of connecting brain and mind, with the mind manifesting in first-person experience while the brain’s neural activity can only be investigated in third-person perspective. To connect neural and mental states, Neurophenomenology provides a methodological toolkit for systematically linking first-person subjective experience with third-person objective observations of the brain’s neural activity. However, beyond providing a systematic methodological strategy (‘disciplined circularity’), it leaves open how neural activity and subjective experience are related among themselves, independent of our methodological strategy. The recently introduced Spatiotemporal Neuroscience suggests that neural activity and subjective experience share a commonly underlying feature as their “common currency”, notably analogous spatiotemporal dynamics. Can Spatiotemporal Neuroscience inform Neurophenomenology to allow for a deeper and more substantiative connection of first-person experience and third-person neural activity? The goal of our paper is to show how Spatiotemporal Neuroscience and Neurophenomenology can be converged and integrated with each other to gain better understanding of the brain-mind connection. We describe their convergence on theoretical grounds which, subsequently, is illustrated by empirical examples like self, meditation, and depression. In conclusion, we propose that the integration of Neurophenomenology and Spatiotemporal Neuroscience can provide complementary insights, enrich both fields, allows for deeper understanding of brain-mind connection, and opens the door for developing novel methodological approaches in their empirical investigation.}
}
@article{BARBOSA2025100864,
title = {An interchangeable editor to create generic and adaptable decision trees for versatile applications and game development scenarios},
journal = {Entertainment Computing},
volume = {52},
pages = {100864},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100864},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002325},
author = {Rafael Garcia Barbosa and Maria Andréia Formico Rodrigues},
keywords = {Decision tree editor, Standard interchange format, Interoperability and adaptability, Personalized learning, Game engine integration, Game development scenarios},
abstract = {This paper introduces a novel software tool developed to serve as an editor for the manual construction of decision trees, characterized by their generic nature, flexibility, and adaptability across a wide range of applications and game development scenarios. The editor enables straightforward definition and modification of decision tree elements and data, dynamically updating to meet changing needs and contexts. A key feature of this tool is its capability to export decision trees in a standardized interchange format, enhancing interoperability by allowing seamless integration with other computational platforms, including game engines. We demonstrate the utility and versatility of our editor with three distinct and comprehensive use cases, highlighting its potential as a significant contribution to interactive technology. The tool facilitates the development of decision trees, enhancing informed decision-making and strategic planning, and supports personalized learning to improve engagement and outcomes.}
}
@article{XU2021104922,
title = {Brain decoding in multiple languages: Can cross-language brain decoding work?},
journal = {Brain and Language},
volume = {215},
pages = {104922},
year = {2021},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2021.104922},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X2100016X},
author = {Min Xu and Duo Li and Ping Li},
keywords = {Cross-language brain decoding, Neural representation, Multivariate pattern analysis, Computational modeling, Multilingualism},
abstract = {The approach of cross-language brain decoding is to use models of brain decoding from one language to decode stimuli of another language. It has the potential to provide new insights into how our brain represents multiple languages. While it is possible to decode semantic information across different languages from neuroimaging data, the approach’s overall success remains to be tested and depends on a number of factors such as cross-language similarity, age of acquisition/proficiency levels, and depth of language processing. We expect to see continued progress in this domain, from a traditional focus on words and concrete concepts toward the use of naturalistic experimental tasks involving higher-level language processing (e.g., discourse processing). The approach can also be applied to understand how cross-modal, cross-cultural, and other nonlinguistic factors may influence neural representations of different languages. This article provides an overview of cross-language brain decoding with suggestions for future research directions.}
}
@article{PICCININI2004811,
title = {Functionalism, computationalism, and mental states},
journal = {Studies in History and Philosophy of Science Part A},
volume = {35},
number = {4},
pages = {811-833},
year = {2004},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2004.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0039368104000883},
author = {Gualtiero Piccinini},
keywords = {Functionalism, Computationalism, Computational functionalism, Mental states, Computational theory of mind, Functional analysis},
abstract = {Some philosophers have conflated functionalism and computationalism. I reconstruct how this came about and uncover two assumptions that made the conflation possible. They are the assumptions that (i) psychological functional analyses are computational descriptions and (ii) everything may be described as performing computations. I argue that, if we want to improve our understanding of both the metaphysics of mental states and the functional relations between them, we should reject these assumptions.}
}
@article{SATPUTE2024109583,
title = {Exploring large language models for microstructure evolution in materials},
journal = {Materials Today Communications},
volume = {40},
pages = {109583},
year = {2024},
issn = {2352-4928},
doi = {https://doi.org/10.1016/j.mtcomm.2024.109583},
url = {https://www.sciencedirect.com/science/article/pii/S2352492824015642},
author = {Prathamesh Satpute and Saurabh Tiwari and Maneet Gupta and Supriyo Ghosh},
keywords = {Large language models, Materials science, Phase-field models, Microstructure evolution, Partial differential equations},
abstract = {There is a significant potential for coding skills to transition fully to natural language in the future. In this context, large language models (LLMs) have shown impressive natural language processing abilities to generate sophisticated computer code for research tasks in various domains. We report the first study on the applicability of LLMs to perform computer experiments on microstructure pattern formation in model materials. In particular, we exploit LLM’s ability to generate code for solving various types of phase-field-based partial differential equations (PDEs) that integrate additional physics to model material microstructures. The results indicate that LLMs have a remarkable capacity to generate multi-physics code and can effectively deal with materials microstructure problems up to a certain complexity. However, for complex multi-physics coupled PDEs for which a detailed understanding of the problem is required, LLMs fail to perform the task efficiently, since much more detailed instructions with many iterations of the same query are required to generate the desired output. Nonetheless, at their current stage of development and potential future advancements, LLMs offer a promising outlook for accelerating materials education and research by supporting beginners and experts in their physics-based methodology. We hope this paper will spur further interest to leverage LLMs as a supporting tool in the integrated computational materials engineering (ICME) approach to materials modeling and design.}
}
@article{MARUFA20241182,
title = {Educating Middle Adolescent through Social Media: The Impact of Early Marriage on Achieving High Education},
journal = {Procedia Computer Science},
volume = {245},
pages = {1182-1191},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.348},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031569},
author = {Riza Izzati Ma'rufa and Yudhistya Ayu Kusumawati and Asri Radhitanti},
keywords = {Social Media Campaign, Early Marriege, Quality Education, Women},
abstract = {Malang has become the city that reached the highest rate of early marriage in the Province of East Java. Many data had stated that Malang remained on the first rank for two years straight which is 2021 until 2022. This issue became the main cause of students dropping out of school and hampered in achieving higher education. Some of the factors that cause early marriage to remain unresolved are society's distorted perception of early marriage. Due to this issue, this study aimed to observe how (research output) can reduce the rate of early marriage especially in Malang. To acknowledge the problem, this study uses literature review and qualitative methods for data processing. Sources of this literature review are extracted from various journals that come from trusted sources. Based on the research results, it can be sensed that the influence of early marriage has a negative impact on educational attainment of adolescents especially on women. Due to high number of early marriages in Malang and the impact on educational attainment of female adolescents, this research resulting in social media campaign to educate adolescents about how early marriage impacts quality education. Therefore, it is hoped that this Instagram Platform Based Campaign will help to spread awareness among adolescents about how early marriage impacts their education and life goals.}
}
@article{HAO201630,
title = {Reflection enhances creativity: Beneficial effects of idea evaluation on idea generation},
journal = {Brain and Cognition},
volume = {103},
pages = {30-37},
year = {2016},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2016.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278262616300057},
author = {Ning Hao and Yixuan Ku and Meigui Liu and Yi Hu and Mark Bodner and Roland H. Grabner and Andreas Fink},
keywords = {Idea evaluation, Idea generation, Creativity, Alpha, EEG},
abstract = {The present study aimed to explore the neural correlates underlying the effects of idea evaluation on idea generation in creative thinking. Participants were required to generate original uses of conventional objects (alternative uses task) during EEG recording. A reflection task (mentally evaluating the generated ideas) or a distraction task (object characteristics task) was inserted into the course of idea generation. Behavioral results revealed that participants generated ideas with higher originality after evaluating the generated ideas than after performing the distraction task. The EEG results revealed that idea evaluation was accompanied with upper alpha (10–13Hz) synchronization, most prominent at frontal cortical sites. Moreover, upper alpha activity in frontal cortices during idea generation was enhanced after idea evaluation. These findings indicate that idea evaluation may elicit a state of heightened internal attention or top-down activity that facilitates efficient retrieval and integration of internal memory representations.}
}
@article{ISOLAN2024111786,
title = {Monte Carlo analysis of dosimetric issues in space exploration},
journal = {Radiation Physics and Chemistry},
volume = {221},
pages = {111786},
year = {2024},
issn = {0969-806X},
doi = {https://doi.org/10.1016/j.radphyschem.2024.111786},
url = {https://www.sciencedirect.com/science/article/pii/S0969806X24002780},
author = {Lorenzo Isolan and Valentina Sumini and Marco Sumini},
keywords = {Space habitat, MCNP6, Unstructured mesh, Topology optimization, Radiation protection},
abstract = {The Radiation protection is of paramount importance in the planning of human exploration activities in space. The related risks must be considered with respect to two aspects: devising a proper shielding and providing answers to the requirement of an effective dosimetry evaluation in astronaut's activities. Both aspects have been considered using the Monte Carlo (MC) code MCNP 6.2 as the reference tool. As case study an application devised for the National Aeronautics and Space Administration (NASA) Artemis program has been chosen. The project aims to establish a sustainable human presence on the Moon, envisioning the realization of an outpost that will serve as a steppingstone for space exploration endeavors. A Class III shelter, in situ resource utilization (ISRU) built habitat for the Moon, has been designed through computational methods and topology optimization techniques, and analyzed in terms of radiation shielding performances and the strictly related structural behavior. The outpost must be able to withstand temperature variations, micrometeorite impacts, and the absence of a substantial atmosphere. Any solution studied to respect the constraints must devise robust and innovative materials and techniques to create habitats that have as goal the shielding from the Galactic Cosmic Rays (GCR) and from the solar flares to provide a safe and habitable environment at the time scales scheduled for the missions. Moreover, the outpost design must incorporate strategies for extracting and utilizing local resources. Overcoming such challenges will pave the way for the establishment of a sustainable human presence on the Moon and serve as a crucial leap for future space exploration missions.}
}
@article{KUGURAKOVA2015112,
title = {Anthropomorphic Artificial Social Agent with Simulated Emotions and its Implementation},
journal = {Procedia Computer Science},
volume = {71},
pages = {112-118},
year = {2015},
note = {6th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2015, 6-8 November Lyon, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.12.217},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915036789},
author = {Vlada Kugurakova and Maxim Talanov and Nadir Manakhov and Denis Ivanov},
keywords = {intelligent agents, visualization, emotional artificial intelligence, neuromodulators, visual speech synthesis, expressive and controllable speech synthesis},
abstract = {In this paper we describe an emotional human-machine interface as an anthropomorphic social agent able to exhibit simulated emotions and react to emotional stimuli. We propose a neurobiologically inspired agent implementation that is based on mechanics of chemical and physiological processes within human brain. Implementation of model features simulation of neuromodulators such as dopamine, serotonin, and noradrenaline. Demonstration of emotions is achieved via combining aforementioned neuromodulators in different proportions. The Lovheim cube of emotions is used for this purpose. Topic of “uncanny valley” phenomenon and its effect on human-machine interactions is also mentioned. In conclusion of this paper we have proposed realistic computation model allowing us to visualize agents mimics in sync with his speech, and have made a working prototype of aforementioned model.}
}
@article{POGGIO1981258,
title = {Marr's computational approach to vision},
journal = {Trends in Neurosciences},
volume = {4},
pages = {258-262},
year = {1981},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(81)90081-3},
url = {https://www.sciencedirect.com/science/article/pii/0166223681900813},
author = {T. Poggio},
abstract = {In the last 7 years a new computational approach has led to promising advances in our understanding of visual perception. The foundations of the approach, its overall framework and its first solid results are largely due to the work of a single man, David Marr at MIT. Now, after his death in Boston on 17 November, 1980, research in vision will never be the same.}
}
@incollection{DORST200723,
title = {2 - Spanning oriented subspaces},
editor = {Leo Dorst and Daniel Fontijne and Stephen Mann},
booktitle = {Geometric Algebra for Computer Science},
publisher = {Morgan Kaufmann},
address = {Burlington},
pages = {23-64},
year = {2007},
series = {The Morgan Kaufmann Series in Computer Graphics},
isbn = {978-0-12-369465-2},
doi = {https://doi.org/10.1016/B978-012369465-2/50005-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780123694652500050},
author = {Leo Dorst and Daniel Fontijne and Stephen Mann},
abstract = {Publisher Summary
This chapter shows that a vector space is much more than merely a space of vectors, and that it is straightforward and useful to extend it computationally. The crucial idea here is to make the subspaces of vector space explicit elements of computation. To build the algebra of subspaces, the familiar lines and planes are revisited through the origin. This chapter investigates their geometrical properties carefully and formalizes those by the aid of a new algebraic outer product, which algebraically builds subspaces from vectors. The structure it produces is considered for the Grassmann space of subspaces of a vector space Rn, and defines many terms to describe its features. Throughout this chapter, it considers a real n-dimensional vector space Rn, but has no need for a metric; additionally, it only treats its homogeneous subspaces (i.e., subspaces containing the origin). The chapter starts with an n-dimensional vector space. However, the definition of a vector space in linear algebra is more general than what is needed in this book, being defined over arbitrary fields of scalars. To develop thinking about subspaces, the homogeneous subspaces of a 3-D space are considered.}
}
@article{DENG2023104944,
title = {A VR-based BCI interactive system for UAV swarm control},
journal = {Biomedical Signal Processing and Control},
volume = {85},
pages = {104944},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.104944},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423003774},
author = {Tao Deng and Zhen Huo and Lihua Zhang and Zhiyan Dong and Lan Niu and Xiaoyang Kang and Xiuwei Huang},
keywords = {Brain-computer interface (BCI), Swarm control, Steady state visual evoked potential (SSVEP), Electroencephalogram (EEG), Unmanned Aerial Vehicle (UAV), Quadcopter, Virtual Reality (VR)},
abstract = {The traditional Unmanned Aerial Vehicle (UAV) swarm control mainly adopts the ground station method, which is too fixed, and the interaction is difficult to meet the high dynamic task requirements. There is an urgent need for new interaction methods to integrate the advantages of human thinking in dealing with uncertain problems. Nevertheless, brain-computer interface(BCI) technology is directly controlled by thoughts, one of the most promising next-generation human–computer interaction technologies. Therefore, in this study, we innovatively applied the BCI system based on Virtual Reality (VR) to the group UAV and realized a novel and intelligent group control method, which proposes new ideas and paradigms for the control of swarm UAVs in the future. Specifically, this study takes a quadcopter as an example. A modular and extensible multi-quadcopter system was created, and then a visual stimulation 3D VR scene system with a digital twin function was established. On this basis, the BCI system based on the Stable state visual evoked potential (SSVEP) paradigm was adopted for the swarm control of the quadcopter. The experimental results show that the formation control of multi-quadcopter is successfully realized by the subjects using the proposed VR-based BCI interactive system, with an accuracy rate of 90% and a good performance in information transmission rate. In addition, the immersive VR twin system established one-to-one for EEG signal acquisition allows subjects to have a better experience.}
}
@article{OFOSUAMPONG2024100127,
title = {Artificial intelligence research: A review on dominant themes, methods, frameworks and future research directions},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100127},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100127},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000136},
author = {Kingsley Ofosu-Ampong},
keywords = {Artificial intelligence, Classification, Literature review, Technological issues, Research agenda},
abstract = {This article presents an analysis of artificial intelligence (AI) in information systems and innovation-related journals to determine the current issues and stock of knowledge in AI literature, research methodology, frameworks, level of analysis and conceptual approaches. By doing this, the article aims to identify research gaps that can guide future investigations. A total of 85 peer-reviewed articles from 2020 to 2023 were used in the analysis. The findings show that extant literature is skewed towards the prevalence of technological issues and highlights the relatively lower focus on other themes, such as contextual knowledge co-creation issues, conceptualisation, and application domains. While there have been increasing technological issues with artificial intelligence, the three identified areas of security concern are data security, model security and network security. Furthermore, the review found that contemporary AI, which continually drives the boundaries of computational capabilities to tackle increasingly intricate decision-making challenges, distinguishes itself from earlier iterations in two primary aspects that significantly affect organisational learning in dealing with AI's potential: autonomy and learnability. This study contributes to AI research by providing insights into current issues, research methodology, level of analysis and conceptual approaches, and AI framework to help identify research gaps for future investigations.}
}
@article{MAFTEI2022107032,
title = {Using fake news as means of cyber-bullying: The link with compulsive internet use and online moral disengagement},
journal = {Computers in Human Behavior},
volume = {127},
pages = {107032},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.107032},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221003551},
author = {Alexandra Maftei and Andrei-Corneliu Holman and Ioan-Alex Merlici},
keywords = {Fake news, Online moral disengagement, Cyberbullying, Compulsive internet use},
abstract = {Online moral disengagement and cyberbullying can enhance fake news spreading. We explored the links between these variables and compulsive Internet use in a sample of 509 teenagers and adults aged 11 to 67. We investigated the effect of compulsive Internet use on cyberbullying through fake news creation and/or distribution, both direct and via moral disengagement, and the related differences between adults and teenagers. The indirect effect of compulsive Internet use on cyberbullying through moral disengagement was significant in adolescents, but not in adults. As assumed, teenagers scored significantly higher than adults on all the primary variables. Contrary to our expectations, no significant gender differences emerged, regardless of participants' age, in terms of compulsive Internet use, moral disengagement, nor cyberbullying. The results emphasize the importance of relevant online education programs designed to engage both teenagers and adults in critical thinking that might help in the fake news detection process, especially during the COVID-19 pandemic.}
}
@article{RODRIGUEZ2024,
title = {Leveraging Generative AI Tools to Support the Development of Digital Solutions in Health Care Research: Case Study},
journal = {JMIR Human Factors},
volume = {11},
year = {2024},
issn = {2292-9495},
doi = {https://doi.org/10.2196/52885},
url = {https://www.sciencedirect.com/science/article/pii/S2292949524000245},
author = {Danissa V Rodriguez and Katharine Lawrence and Javier Gonzalez and Beatrix Brandfield-Harvey and Lynn Xu and Sumaiya Tasneem and Defne L Levine and Devin Mann},
keywords = {digital health, GenAI, generative, artificial intelligence, ChatGPT, software engineering, mHealth, mobile health, app, apps, application, applications, diabetes, diabetic, diabetes prevention, digital prescription, software, engagement, behaviour change, behavior change, developer, developers, LLM, LLMs, language model, language models, NLP, natural language processing},
abstract = {Background
Generative artificial intelligence has the potential to revolutionize health technology product development by improving coding quality, efficiency, documentation, quality assessment and review, and troubleshooting.
Objective
This paper explores the application of a commercially available generative artificial intelligence tool (ChatGPT) to the development of a digital health behavior change intervention designed to support patient engagement in a commercial digital diabetes prevention program.
Methods
We examined the capacity, advantages, and limitations of ChatGPT to support digital product idea conceptualization, intervention content development, and the software engineering process, including software requirement generation, software design, and code production. In total, 11 evaluators, each with at least 10 years of experience in fields of study ranging from medicine and implementation science to computer science, participated in the output review process (ChatGPT vs human-generated output). All had familiarity or prior exposure to the original personalized automatic messaging system intervention. The evaluators rated the ChatGPT-produced outputs in terms of understandability, usability, novelty, relevance, completeness, and efficiency.
Results
Most metrics received positive scores. We identified that ChatGPT can (1) support developers to achieve high-quality products faster and (2) facilitate nontechnical communication and system understanding between technical and nontechnical team members around the development goal of rapid and easy-to-build computational solutions for medical technologies.
Conclusions
ChatGPT can serve as a usable facilitator for researchers engaging in the software development life cycle, from product conceptualization to feature identification and user story development to code generation.
Trial Registration
ClinicalTrials.gov NCT04049500; https://clinicaltrials.gov/ct2/show/NCT04049500}
}
@incollection{SEDIG2005239,
title = {17 A descriptive framework for designing interaction for visual abstractions},
editor = {Grant Malcolm},
series = {Studies in Multidisciplinarity},
publisher = {Elsevier},
volume = {2},
pages = {239-254},
year = {2005},
booktitle = {Multidisciplinary Approaches to Visual Representations and Interpretations},
issn = {1571-0831},
doi = {https://doi.org/10.1016/S1571-0831(04)80045-5},
url = {https://www.sciencedirect.com/science/article/pii/S1571083104800455},
author = {K. Sedig and J. Morey},
abstract = {This chapter propses a descriptive framework for categorisation and characterisation of the different forms of interaction with visual abstractions (VAs). Abstract visual representations play an important role in assisting human reasoning, thinking, and understanding processes. There are different forms of designing interaction with these representations. The goal of this chapter is to provide a descriptive framework to guide the designers and evaluators of cognitive tools to determine the appropriate forms of interaction that can facilitate the understanding of abstract concepts, patterns, structures and processes. The framework is described and substantiated using a number of VAs that represent and communicate mathematical ideas.}
}
@article{SUCHANTKE2020439,
title = {Space sustainability in Martian orbits — First insights in a technical and regulatory analysis},
journal = {Journal of Space Safety Engineering},
volume = {7},
number = {3},
pages = {439-446},
year = {2020},
note = {Space Debris: The State of Art},
issn = {2468-8967},
doi = {https://doi.org/10.1016/j.jsse.2020.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2468896720300677},
author = {Isabell Suchantke and Francesca Letizia and Vitali Braun and Holger Krag},
abstract = {Hazards from the outer space environment either natural (space weather and asteroids) or artificial (space debris and the growing number of satellites launched to orbit) pose a rising risk to space flight activities. The awareness for space sustainability and space safety has seen a continuous increase in recent years and does not stop at the Earth's sphere of influence. The first spacefaring nations start thinking about sustainability in cislunar space and the Martian environment. This work deals with the issue of space debris in Martian orbits in the light of planetary protection. A Mars Sustainability Framework has been developed. This includes a study on the orbital and regulatory environment of Mars, long-term propagation of orbits of artificial objects and the two natural moons, and the analysis of objects evolution and first approaches for collision probability computation. With this work, the issue of space debris beyond Earth orbit is analysed at an early stage.}
}
@article{FAN2020248,
title = {From Brain Science to Artificial Intelligence},
journal = {Engineering},
volume = {6},
number = {3},
pages = {248-252},
year = {2020},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095809920300035},
author = {Jingtao Fan and Lu Fang and Jiamin Wu and Yuchen Guo and Qionghai Dai},
keywords = {Artificial intelligence, Brain science},
abstract = {Reviewing the history of the development of artificial intelligence (AI) clearly reveals that brain science has resulted in breakthroughs in AI, such as deep learning. At present, although the developmental trend in AI and its applications has surpassed expectations, an insurmountable gap remains between AI and human intelligence. It is urgent to establish a bridge between brain science and AI research, including a link from brain science to AI, and a connection from knowing the brain to simulating the brain. The first steps toward this goal are to explore the secrets of brain science by studying new brain-imaging technology; to establish a dynamic connection diagram of the brain; and to integrate neuroscience experiments with theory, models, and statistics. Based on these steps, a new generation of AI theory and methods can be studied, and a subversive model and working mode from machine perception and learning to machine thinking and decision-making can be established. This article discusses the opportunities and challenges of adapting brain science to AI.}
}
@article{SHAHIM2021102345,
title = {Security of the digital transformation},
journal = {Computers & Security},
volume = {108},
pages = {102345},
year = {2021},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102345},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821001693},
author = {Abbas Shahim},
keywords = {Digital transformation, Digital security, Information security, Digital disruption, IT auditing},
abstract = {In the early days of computation the focus was mainly on designing, developing, maintaining, and administering infrastructures and information systems housed in data centers. To this extend, security was traditionally organized around the basic technical components (e.g. data center facilities). The point was that an associated security activity was mostly separated from a business context and in general executed by the technical staff. Security was not fully understood by other audiences because the computer terminologies were frequently used. When security elements (e.g. logical access protocols used for identification, authentication, authorization) became part of the financial statement audit, its context became clearer, and it was conducted for external auditors. However, the presented outcome of the work was not completely interpretable for these practitioners as again, it was mainly reported in Information Technology (IT) jargon, and was not linked with the financial statement either. With the emergence the Sarbanes–Oxley Act (SOX) and the fundamental role of IT in relation hereto, the context of security suddenly changed to a great extent. The audience extended as compliance, including security, became the dominating item on the agenda of many C-levels (e.g. CFOs).}
}
@article{XUE2025129449,
title = {Lightweight visual backbone network with enhanced comprehensive strength through context-aware dual attention mechanism},
journal = {Neurocomputing},
volume = {624},
pages = {129449},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129449},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225001213},
author = {Jianxin Xue and Yaohua Hu and Sicheng Hua and Minyu Chen and Ling-I Wu and Xi Chang and Guoqiang Li},
keywords = {Deep learning, Attention mechanism, Backbone network, Computer vision},
abstract = {Recent studies have increasingly concentrated on integrating visual neural networks into edge devices, especially for robots and drones that require effective real-time decision-making and autonomous path planning. Achieving this necessitates lightweight visual networks with robust overall performance. In this study, we adopt a small-scale architecture based on convolutional neural networks (CNNs) and propose a Context-Aware Decoupled Fully Connected (CADFC) attention mechanism to enhance the performance of existing CNN-based visual networks. The core concept of the CADFC attention mechanism is to incorporate both remote and local contexts, enabling the network to capture local features and their relevant remote features. Moreover, we design a novel bottleneck that integrates CADFC attention with depthwise convolution. This design thinking is to accumulate focused regions, learning from depthwise convolution, alongside their surrounding features based on CADFC attention. Experimental results demonstrate that CADFC MobileNet outperforms the recent SOTA network GhostNetV2, achieving a top-1 accuracy of 76.8% with 15% fewer parameters, surpassing GhostNetV2’s 75.3% accuracy by 1.5%, even in resource-constrained environments.}
}
@article{DUFVA201917,
title = {Grasping the future of the digital society},
journal = {Futures},
volume = {107},
pages = {17-28},
year = {2019},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2018.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0016328717302252},
author = {Tomi Dufva and Mikko Dufva},
keywords = {Digitalisation, Digital society, Experiential foresight, Craft education, Art education, Artistic research, Embodied learning, Critical theory},
abstract = {Society is increasingly digitalised and connected, with computers and algorithms mediating much of people’s daily activity in one way or another. The degree of digitalisation and its consequences are challenging to understand because most people lack first-hand experience of what digitalisation actually feels like. Digitalisation is abstract and difficult to grasp, which leads to a detached sense of the digital surroundings. In this paper, we argue that in order to grasp the nature and future of a digitalised society, an embodied understanding of digitalisation is needed. Such an understanding should utilise ways of knowing other than rational thinking, challenge existing narratives and move from preparing for the future to exploring novelty. We focus on the importance of a broader understanding of digitalisation within the field of education and discuss how a more diverse view is essential to empower people to take part in a digitalised society. We use the concept of ‘digi-grasping’ to analyse awareness and involvement in the digital world. By digi-grasping we mean active sense-making and existing in a world that consists of both a digital and a physical world. We argue that through ‘grasping’ the digital world it is possible to create an ethical and aesthetic attachment to society. Digi-grasping can empower people to understand and question the choices and motivations behind current digital structures and create new structures. It is thus an important approach to shaping the futures of digital society. We illustrate the concept with examples representing different modes of being and doing at the interface of the digital and physical.}
}
@article{MITTAL2023105092,
title = {The method of harmonic balance for the Giesekus model under oscillatory shear},
journal = {Journal of Non-Newtonian Fluid Mechanics},
volume = {321},
pages = {105092},
year = {2023},
issn = {0377-0257},
doi = {https://doi.org/10.1016/j.jnnfm.2023.105092},
url = {https://www.sciencedirect.com/science/article/pii/S0377025723001040},
author = {Shivangi Mittal and Yogesh M. Joshi and Sachin Shanbhag},
keywords = {LAOS, Spectral method, Fourier series, Numerical method},
abstract = {The method of harmonic balance (HB) is a spectrally accurate method used to obtain periodic steady state solutions to dynamical systems subjected to periodic perturbations. We adapt HB to solve for the stress response of the Giesekus model under large amplitude oscillatory shear (LAOS) deformation. HB transforms the system of differential equations to a set of nonlinear algebraic equations in the Fourier coefficients. Convergence studies find that the difference between the HB and true solutions decays exponentially with the number of harmonics (H) included in the ansatz as e−mH. The decay coefficient m decreases with increasing strain amplitude, and exhibits a “U” shaped dependence on applied frequency. The computational cost of HB increases slightly faster than linearly with H. The net result of rapid convergence and modest increase in computational cost with increasing H implies that HB outperforms the conventional method of using numerical integration to solve differential constitutive equations under oscillatory shear. Numerical experiments find that HB is simultaneously about three orders of magnitude cheaper, and several orders of magnitude more accurate than numerical integration. Thus, it offers a compelling value proposition for parameter estimation or model selection.}
}
@article{ALHARRASI201958,
title = {Evidence for the involvement of a GABAergic mechanism in the effectiveness of natural and synthetically modified incensole derivatives in neuropharmacological disorders: A computational and pharmacological approach},
journal = {Phytochemistry},
volume = {163},
pages = {58-74},
year = {2019},
issn = {0031-9422},
doi = {https://doi.org/10.1016/j.phytochem.2019.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0031942218308239},
author = {Ahmed Al-Harrasi and Ajmal Khan and Najeeb Ur Rehman and Sulaiman Al-Shidhani and Nasiara Karim and Imran Khan and Sobia Ahsan Halim and Ahmed Al-Rawahi and Javid Hussain and Rene Csuk},
keywords = {Incensole, Incensone, Incensfuran, Antidepressant, Anxiolytic, Anticonvulsant, Homology modelling, Molecular docking, ADMET prediction},
abstract = {In the course of our continuing exploration for novel bioactive lead compounds (s) from the species Boswellia, we have recently reported incensole derivatives isolated from Boswellia papyrifera Hochst. Given the known antidepressant-like effects of incensole and incensole acetate, we herein present that the low dose intraperitoneal administration of incensole derivatives, namely, incensfuran and incensone, showed significant antidepressant-like effects in the forced swim test (FST) and tail suspension test (TST). Furthermore, these compounds were evaluated for their anxiolytic potential in the elevated plus maze (EPM) and light dark box (LDB) tests and anticonvulsant effects in pentylenetetrazole (PTZ)-induced seizure tests. In the EPM test, administration of these compounds led to dose-dependent increases in open arm entries and in the time spent in EPM open arms. Similar results were obtained in the LDB test, wherein compounds these caused significant increases in the number of transitions between lit and dark compartments and the time spent in the lit compartment. The anxiolytic-like effects in the EPM were not reversed by pretreatment with flumazenil, whereas PTZ and bicuculline (BIC) completely abolished the anxiolytic effects, showing the involvement of the non-benzodiazepine binding sites of GABAA receptors. All four compounds induced significantly elevated brain GABA levels, indicating the involvement of a GABAergic mechanism. Additionally, molecular docking was conducted to elucidate the mode of action for the anxiolytic and anticonvulsant effects of these derivatives. Moreover, these compounds also possess drug-like properties and excellent ADMET profiles.}
}
@incollection{MOITRA198793,
title = {Parallel Algorithms for Some Computational Problems},
editor = {Marshall C. Yovits},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {26},
pages = {93-153},
year = {1987},
booktitle = {Advances in Computers},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(08)60006-6},
url = {https://www.sciencedirect.com/science/article/pii/S0065245808600066},
author = {Abha Moitra and S. {Sitharama Iyengar}},
abstract = {Publisher Summary
The chapter presents a survey of parallel algorithms for finding the connected and biconnected components of a graph. The chapter classifies the various parallel algorithms for finding the connected components of undirected graphs according to two major criteria: the basic technique employed and the format of the input. The basic techniques used in these algorithms are breadth-first search, transitive closure, and vertex collapse. The most common form of input is adjacency matrix. The chapter presents several parallel minimum spanning tree algorithms for different types of parallel computational models. A minimum spanning tree of a weighted, connected, and undirected graph is defined as a set of edges of the graph that connects all vertices and whose total edge weight is minimum. The chapter discusses various other parallel graph algorithms for shortest path, maximum matching, planarity testing, and maximal independent set. It describes parallel algorithms for various nongraph-theoretic problems like arithmetic expression and polynomial evaluation, string matching, tree balancing, and alpha-beta search.}
}
@article{LIU2023100050,
title = {Literature review of digital twin technologies for civil infrastructure},
journal = {Journal of Infrastructure Intelligence and Resilience},
volume = {2},
number = {3},
pages = {100050},
year = {2023},
issn = {2772-9915},
doi = {https://doi.org/10.1016/j.iintel.2023.100050},
url = {https://www.sciencedirect.com/science/article/pii/S2772991523000257},
author = {Cheng Liu and Peining Zhang and Xuebing Xu},
keywords = {Digital Twin, Civil Infrastructure, Bridges, High-speed Railway},
abstract = {Currently, there are numerous drawbacks associated with infrastructure health monitoring and management, such as inefficiency, subpar real-time functionality, demanding data requirements, and high cost. Digital twin (DT), a hybrid of a computational simulation and an actual physical system, has been proposed to overcome these challenges and become increasingly popular for modeling civil infrastructure systems. This literature review summarized different methods to build digital twins in civil infrastructure. In addition, this review also introduced the current progress of digital twins in different infrastructure sectors, including smart cities and urban spaces, transport systems, and energy systems, along with detailed examples of their various applications. Finally, the current challenges in digital twin technologies for civil infrastructure are also highlighted.}
}
@article{SANGA2025104241,
title = {Stories, simulations and narratives: Collaboratively exploring food security and agricultural innovation in sub-Saharan Africa},
journal = {Agricultural Systems},
volume = {224},
pages = {104241},
year = {2025},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2024.104241},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X24003913},
author = {Udita Sanga and Maja Schlüter},
keywords = {Food security, Narratives, Storytelling, Sub-Saharan Africa, Agent-based models},
abstract = {CONTEXT
Food insecurity remains a global challenge, with differing narratives shaping interventions in sub-Saharan Africa. The “crisis narrative,” favored by aid agencies, links insecurity to production issues, advocating agricultural innovations. Meanwhile, the “chronic poverty narrative,” reflected in African policy, ties insecurity to farmer poverty, emphasizing livelihood and economic solutions. Narrative subjectivity can lead to uncritical privileging of certain understandings and solutions, necessitating a critical exploration of contexts, causes, and solutions to food insecurity in the region. Our research addresses the need to understand and illustrate the complex problem of food insecurity in the region.
OBJECTIVE
This study employs a mixed-method approach, combining collaborative storytelling, model exploration, and scenario analysis, to investigate food security, agricultural innovation, and climate adaptation in Mali, West Africa.
METHODS
We developed a three-stage methodology represented as a story arc: beginning (exposition and problem statement), development (action), and completion (solution), providing a cohesive narrative framework. The arc unfolds with the story exposition introducing characters, plot, and problem statement. The story development includes participant-led model simulations and modeler-led scenario analysis. The story completion integrates insights from model simulations and scenario analysis to develop the collective understanding of the narratives surrounding food (in)security.
RESULTS AND CONCLUSIONS
This study generates several insights that highlight the inherent complexities within agricultural innovation systems that emerge from the non-linear dynamic interaction of actors operating across scales that contribute to food insecurity. We redirect the focus of narratives of causes (and subsequent solutions) of food insecurity from solely climate-driven production losses and poverty to the complex interplay of climate, agroecology, innovation networks, risk perception, innovation beliefs, desires, and knowledge transmission. A shared narrative emerges, characterizing food security as a complex adaptive system influenced by factors such as climate-induced production variability, agroecological heterogeneity, network structures and climate risk perception. The study underscores the methodological value of collaborative storytelling and model simulation to enable a structured and reflective exploration of these complex systems. By transforming participants into co-creators of knowledge, this methodology fosters systems thinking, turning abstract systemic relationships into tangible, actionable insights.
SIGNIFICANCE
Our study demonstrates the need to critically reevaluate the role of narratives in shaping agricultural innovation systems and their capacity to transform food systems toward enhanced sustainability and food security. Our participatory and systems-driven approach offers a pathway to more adaptive and effective interventions in the face of complex, dynamic challenges.}
}
@incollection{ADDIS2025501,
title = {Memory and imagination},
editor = {Jordan Henry Grafman},
booktitle = {Encyclopedia of the Human Brain (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {501-513},
year = {2025},
isbn = {978-0-12-820481-8},
doi = {https://doi.org/10.1016/B978-0-12-820480-1.00135-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204801001352},
author = {Donna Rose Addis},
keywords = {Associative, Autobiographical memory, Default mode network, Episodic memory, Frontoparietal control network, Future thinking, Hippocampus, Imagination, Medial prefrontal cortex, Prospection, Relational processing, Schema, Simulation},
abstract = {The human brain has a remarkable capacity to not only remember events from the past but to construct a variety of imagined experiences, ranging from hypothetical and counterfactual past events, to future events and entirely fictional episodes. Both remembering and imagining is underpinned by the brain's simulation system: default mode network. I describe the theoretical beginnings of this relatively new topic in contemporary neuroscience, as well as neuroimaging investigations of autobiographical memory and prospective imagination that together provide evidence of a single “simulation system” supported primarily by core functions of the default mode network: associating elements, associative schematic processes, and buffering the emergent simulation.}
}
@article{JIN202520,
title = {Methods and reliability study of moral education assessment in universities: A machine learning-based approach},
journal = {Alexandria Engineering Journal},
volume = {125},
pages = {20-28},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2025.03.095},
url = {https://www.sciencedirect.com/science/article/pii/S111001682500403X},
author = {Ting Jin},
keywords = {Reliability study, Moral education, Machine learning, Policy analysis, Statistical analysis},
abstract = {The research aims to assess the effectiveness of machine learning (ML) techniques in evaluating moral education programs at university institutions. The objective is to employ data-driven methodologies to enhance ethical assessment frameworks through improved objectivity, scalability, and consistency. This analysis utilizes Principal Component Analysis (PCA) alongside the k-Nearest Neighbor (k-NN) method, Support Vector Regression (SVR), and Artificial Neural Networks (ANN) to study student performance indices, enabling the prediction of ethical reasoning capabilities for standardized evaluation. The study demonstrates how machine learning efficiently assesses student moral education performance by leveraging PCA to identify patterns and using ML models to make accurate predictions. Findings reveal a strong correlation between subject proficiency in mathematics, reading, and writing and moral reasoning abilities, highlighting the role of academic competencies in ethical decision-making. Additionally, gender-based analysis indicates that female students tend to achieve better results in moral skills assessments than their male counterparts. Among the models tested, SVR exhibits the highest predictive accuracy, whereas k-NN returns the widest prediction errors. The study recommends the deployment of AI-based moral assessment systems in universities to ensure consistent and objective evaluation processes for policy development.}
}
@article{SHIEH1993421,
title = {Massively parallel computational methods for finite element analysis of transient structural responses},
journal = {Computing Systems in Engineering},
volume = {4},
number = {4},
pages = {421-433},
year = {1993},
note = {Parallel Computational Methods for Large-Scale Structural Analysis and Design},
issn = {0956-0521},
doi = {https://doi.org/10.1016/0956-0521(93)90011-K},
url = {https://www.sciencedirect.com/science/article/pii/095605219390011K},
author = {R.C. Shieh},
abstract = {With the emphasis on the finitely damped system (e.g. control structure interaction) case, two fully implicit and two semi-implicit sets of finite element method-based numerical algorithms are formulated for transient response analysis of space frame and truss structures in a massively parallel processing (MPP) environment. All algorithm sets use an implicit force calculation/vector equation of motion assembly procedure. The semi-implicit algorithms are based on the explicit central difference (CD) and the fourth-order Runge-Kutta (RK4) schemes, respectively, in conjunction with the use of mass lumping techniques so that solution of the recurrence equations for unknown displacements is reduced to a trivial diagonal matrix inversion operation. The fully implicit algorithm sets are based on the Newmark Beta (NB) and CD schemes, respectively, in conjunction with use of the (iterative) preconditioned conjugate gradient (PCG) method for solving the linear algebraic recurrence equations. The semi-implicit algorithm sets are fully implemented and assessed on an MPP CM-2 computer. A preliminary assessment of the fully implicit sets of algorithms is made on a Sun Workstation. These numerical study results show that the newly formulated MPP algorithms are, to a varying degree, superefficient (or potentially superefficient) on the CM-2 compared with, and even highly competitive against, the conventional sequential algorithms on an advanced serial computer.}
}
@article{ZHANG20162579,
title = {Efficient vehicles path planning algorithm based on taxi GPS big data},
journal = {Optik},
volume = {127},
number = {5},
pages = {2579-2585},
year = {2016},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2015.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0030402615019075},
author = {Jindong Zhang and Weibin Meng and QiangQiang Liu and Haofeng Jiang and Yujie Feng and Gang Wang},
keywords = {Taxi GPS trajectory, Big data, Driving stratagem, Map matching, Optimal path},
abstract = {The driving thinking of taxi drivers is always hidden in a large amount of taxis GPS data. An efficient driving stratagem derived from taxi drivers is provided for private car drivers. The five million pieces of taxis GPS data in Nanjing, China are analyzed: firstly, the data preprocessing is conducted for the reduction measuring error of GPS data with the expurgation of the static point, the drifting point, and the relatively independent point; then, the road intersections through the regional extreme points are found to restore map with the following three algorithms: the path selection algorithm based on probability, the improved Prim path selection algorithm, and the improved Prim path selection algorithm based on probability; at last, the SPFA (Shortest Path Faster Algorithm) is applied to the measurement of the road map gained from the previous three algorithms for optimal path planning with 40 pairs of starting points and termination points, and making a comparison of the road length among three methods. Through the experimental comparison, the third method namely the improved Prim path selection algorithm based on probability which proved to be more optimal than others two methods produces an efficient driving route more accurately.}
}
@article{RUSSELL2018114,
title = {Leveraging complexity for ecosystemic innovation},
journal = {Technological Forecasting and Social Change},
volume = {136},
pages = {114-131},
year = {2018},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2017.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0040162517316475},
author = {Martha G. Russell and Nataliya V. Smorodinskaya},
keywords = {Business network, Collaboration, Complexity, Innovation ecosystem, Innovation cluster, Global economy, Non-linearity},
abstract = {This paper looks at innovation ecosystems through the lens of complexity science, considering them as open non-linear entities that are characterized by changing multi-faceted motivations of networked actors, high receptivity to feedback, and persistent structural transformations. In the context of the growing organizational complexity of economies, driven by their adaptation to high uncertainty, and the central role of collaboration, we differentiate the innovation capacity of various types of business networks by the complexity of their internal interactions, thus identifying the place of innovation ecosystems in the world of business networks, as well as the place of innovation clusters among other innovation ecosystems. We observe how innovation ecosystems have been viewed in four different research streams: management literature; the inter-firm and business network stream of economic and sociological literature; the innovation policy and competitiveness agenda in economic literature; and the dichotomy of localized and economy-wide innovation ecosystems in policy studies (in economic literature, evolutionary geography, and regional research). We then describe generic properties of innovation ecosystems in terms of complexity science, viewing them as complex adaptive systems, paying special attention to the complexity of innovation clusters. We compare complexity thinking of modern economies, deriving from their emerging ecosystem design, with traditional thinking conceived for industrial era, drawing insights for a better transition to innovation-led growth. We conclude with a summary of key findings, practical and policy implications and recommendations for further study.}
}
@article{BOGGS19831,
title = {The integration of structure determination by computation, electron diffraction and microwave spectroscopy},
journal = {Journal of Molecular Structure},
volume = {97},
pages = {1-16},
year = {1983},
note = {Determination of Molecular Structure by Microwave Spectroscopy and Electron Diffraction},
issn = {0022-2860},
doi = {https://doi.org/10.1016/0022-2860(83)90171-0},
url = {https://www.sciencedirect.com/science/article/pii/0022286083901710},
author = {James E. Boggs},
abstract = {The history of the interaction between experimental structure determinations by microwave spectroscopy and by gas phase electron diffraction is briefly reviewed in terms of three eras: (1) competition and antagonism, (2) comparison and correction, and (3) integration of analysis. A similar progression is noted for the relation between experimental and theoretical methods for studying molecular structure, with the present time straddling ages (2) and (3). Examples are given from a variety of studies involving various degrees of methodological interaction. The true integration of experimental and computational structural studies is still in its infancy with the primary illustrations involving the evaluation of theoretical structural offset values from experimental evidence, the transfer of theoretically determined parameters into the fitting of experimental data, and the current development of methods for utilizing vibrational information obtained from the combined analysis of computed theoretical and experimental infrared data in the further analysis of experimental diffraction and microwave information.}
}
@article{KHEDMATIMORASAE2024219,
title = {Advancing the discourse: A next-generation value chain-based taxonomy for circular economy key performance indicators},
journal = {Sustainable Production and Consumption},
volume = {48},
pages = {219-234},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2024.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S2352550924001428},
author = {Esmaeil Khedmati-Morasae and Markus Zils and Peter Hopkinson and Ryan Nolan and Fiona Charnley and Okechukwu Okorie and Halid Abu-Bakar},
keywords = {Circular economy, Key performance indicators, Taxonomy, Value chain, Systemic},
abstract = {The growth of interest in circular economy (CE) has been accompanied by different approaches to measurement of CE outcomes and impacts, leading to a wide portfolio of indicators with varying degrees of overlap, inconsistency, and convergence. The aim of this paper is to propose a unifying framework for CE indicators, as the next generation of CE taxonomies. We first undertake a scoping review of 59 review papers on CE indicators using manual and computational methods (i.e., topic modelling) to inform the taxonomy structure and content. As a result, we report on 11 clusters of approaches that have been attentive to different dimensions of CE (e.g. horizontal value chain, vertical scale of operation (macro, meso, micro), impact category (economic, biophysical, social), material vs product focus, etc.). Highlighting the strengths and weakness of these approaches, we identify gaps in dimensions related to horizontal and vertical scales of measurement, and propose an agnostic, integrative framework that builds on the scientific foundations of previous research, within a more systemic and comprehensive taxonomy. This taxonomy could be used as a guiding framework or heuristic for regulators, both nationally and internationally, and for practitioners to undertake a comprehensive measurement and assessment of CE related interventions and initiatives at scale.}
}
@article{LAL2023100791,
title = {IOT-based cyber security identification model through machine learning technique},
journal = {Measurement: Sensors},
volume = {27},
pages = {100791},
year = {2023},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100791},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423001277},
author = {Bechoo Lal and S. Ravichandran and R. Kavin and N. {Anil Kumar} and Dibyahash Bordoloi and R. {Ganesh Kumar}},
keywords = {Cyber security, Machine learning algorithms, Security, Repositories, Meta-classifier methods, Internet of things},
abstract = {Manual vulnerability evaluation tools produce erroneous data and lead to difficult analytical thinking. Such security concerns are exacerbated by the variety, imperfection, and redundancies of modern security repositories. These problems were common traits of producers and public vulnerability disclosures, which make it more difficult to identify security flaws through direct analysis through the Internet of Things (IoT). Recent breakthroughs in Machine Learning (ML) methods promise new solutions to each of these infamous diversification and asymmetric information problems throughout the constantly increasing vulnerability reporting databases. Due to their varied methodologies, those procedures themselves display varying levels of performance. The authors provide a method for cognitive cybersecurity that enhances human cognitive capacity in two ways. To create trustworthy data sets, initially reconcile competing vulnerability reports and then pre-process advanced embedded indicators. This proposed methodology's full potential has yet to be fulfilled, both in terms of its execution and its significance for security evaluation in application software. The study shows that the recommended mental security methodology works better when addressing the above inadequacies and the constraints of variation among cybersecurity alert mechanisms. Intriguing trade-offs are presented by the experimental analysis of our program, in particular the ensemble method that detects tendencies of computational security defects on data sources.}
}
@article{FITZPATRICK2020101942,
title = {The relation between academic abilities and performance in realistic word problems},
journal = {Learning and Individual Differences},
volume = {83-84},
pages = {101942},
year = {2020},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2020.101942},
url = {https://www.sciencedirect.com/science/article/pii/S1041608020301229},
author = {Cheryll L. Fitzpatrick and Darcy Hallett and Kyle R. Morrissey and Nadine R. Yıldız and Rutanya Wynes and Felix Ayesu},
keywords = {Word problems, Academic abilities, Educational psychology, Math cognition},
abstract = {The research on realistic word problems investigates how children (and even adults) largely fail to incorporate real-world knowledge into mathematical word problems. Because of this, most research in this area focuses on improving realistic thinking. However, very little research has explored what other abilities might predict which children actually do take real-world information into account, and what this might imply about the nature of realistic responding. We tested whether general academic abilities, such as verbal skill, reading comprehension, and math calculation skill, previously shown to be related to standard word problem performance, are related to realistic responses, and whether realistic responding is related to standard word problem solving. In our sample of sixth-grade students, only reading comprehension was independently predictive of solving realistic word problems. Performance on realistic word problems, however, was independently predictive of solving standard word problems. As such, realistic word problems may reflect problem solving ability independent of general academic ability, and therefore may be an ability worth fostering.}
}
@article{MCINTOSH1988213,
title = {A computational tutor for architectural design},
journal = {Computers, Environment and Urban Systems},
volume = {12},
number = {4},
pages = {213-219},
year = {1988},
issn = {0198-9715},
doi = {https://doi.org/10.1016/0198-9715(88)90028-2},
url = {https://www.sciencedirect.com/science/article/pii/0198971588900282},
author = {Patricia G. McIntosh},
abstract = {The conceptual basis for a computational design tutoring environment whose purpose is to aid student designers in the search for design solutions is presented. Problems that students experience in the course of their design education are presented. These problems are related to previous work in the development of computable representations of designs. A specification for a computational learning environment for design students is outlined.}
}
@article{OLMEDO2015115,
title = {Quantitative characterization of chaordic tourist destination},
journal = {Tourism Management},
volume = {47},
pages = {115-126},
year = {2015},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2014.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0261517714001812},
author = {Elena Olmedo and Ruth Mateos},
keywords = {Complexity, Chaos, Chaordic system, Tourism Arrivals},
abstract = {This paper highlights the new horizons opening with the applications of concepts from the application of the complexity science to tourism data, which are traditionally treated from an intradisciplinar point of view. From this new point of view, tourism is considered as a complex adaptive system. Complexity theory is rooted in the hard sciences, and social sciences have adopted it in recent times. Going a step further, we introduce the concept of chaordic system in tourism. This new thinking has appeared in the social sciences as a response to the current need to cope with contradictions and inconsistencies, adapting evolution without losing essence. We propose considering tourism as a chaordic system and analyzing the resulting managerial consequences. We propose the use of a set of measures to quantify a system as chaordic. Finally, we empirically analyze tourist arrivals to Majorca (Spain) to verify the existence of a chaordic system.}
}
@article{KELLER2006357,
title = {A practical view of ‘druggability’},
journal = {Current Opinion in Chemical Biology},
volume = {10},
number = {4},
pages = {357-361},
year = {2006},
note = {Next-generation therapeutics},
issn = {1367-5931},
doi = {https://doi.org/10.1016/j.cbpa.2006.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S1367593106000834},
author = {Thomas H Keller and Arkadius Pichota and Zheng Yin},
abstract = {The introduction of Lipinski's ‘Rule of Five’ has initiated a profound shift in the thinking paradigm of medicinal chemists. Understanding the difference between biologically active small molecules and drugs became a priority in the drug discovery process, and the importance of addressing pharmacokinetic properties early during lead optimization is a clear result. These concepts of ‘drug-likeness’ and ‘druggability’ have been extended to proteins and genes for target identification and selection. How should these concepts be integrated practically into the drug discovery process? This review summarizes the recent advances in the field and examines the usefulness of ‘the rules of the game’ in practice from a medicinal chemist's standpoint.}
}
@article{GRIFFEN20208695,
title = {Chemists: AI Is Here; Unite To Get the Benefits},
journal = {Journal of Medicinal Chemistry},
volume = {63},
number = {16},
pages = {8695-8704},
year = {2020},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.0c00163},
url = {https://www.sciencedirect.com/science/article/pii/S1520480420001672},
author = {Edward J. Griffen and Alexander G. Dossetter and Andrew G. Leach},
abstract = {The latest developments in artificial intelligence (AI) have arrived into an existing state of creative tension between computational and medicinal chemists. At their most productive, medicinal and computational chemists have made significant progress in delivering new therapeutic agents into the clinic. However, the relationship between these communities has the prospect of being weakened by application of oversimplistic AI methods that, if they fail to deliver, will reinforce unproductive prejudices. We review what can be learned from our history of integrating QSAR and structure-based methods into drug discovery. Now with synthesis and testing available as contract services, the environment for computational innovation has changed and we consider the impact this may have on the relationships in our disciplines. We discuss the current state of interdisciplinary communication and suggest approaches to bring the subdisciplines together in order to improve computational medicinal chemistry and, most importantly, deliver better medicines to the clinic faster.
}
}
@article{ZONG2024120192,
title = {Parameter estimation of multivariable Wiener nonlinear systems by the improved particle swarm optimization and coupling identification},
journal = {Information Sciences},
volume = {661},
pages = {120192},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120192},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524001051},
author = {Tiancheng Zong and Junhong Li and Guoping Lu},
keywords = {System identification, Multivariable Wiener system, Particle swarm optimization, Coupling identification, Auxiliary model},
abstract = {This paper investigates the parameter estimation of multivariable Wiener nonlinear systems. To solve the inconsistency problem of the parameter vector and the parameter matrix, the coupling identification concept is applied. Combined with particle swarm optimization (PSO) and an auxiliary model, the partially coupled improved particle swarm optimization (PC-IPSO) method is proposed. In this algorithm, the adaptive feedback inertia weight is improved to accelerate the convergence speed, and the retirement update mechanism is introduced to improve the optimization ability of the basic PSO algorithm. To verify the performance of PC-IPSO, we also derive a multivariable improved PSO (M-IPSO) method for comparison. The computational complexity analysis shows that the PC-IPSO algorithm requires less computational resources than the M-IPSO algorithm. Then, the convergence of the improved PSO method is analyzed. The simulation results indicate that the PC-IPSO method has a faster convergence speed and higher identification accuracy than the M-IPSO and several existing state-of-the-art methods for multivariable Wiener system identification.}
}
@article{LOWRIE20112244,
title = {Gender differences in students’ mathematics game playing},
journal = {Computers & Education},
volume = {57},
number = {4},
pages = {2244-2248},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511001394},
author = {Tom Lowrie and Robyn Jorgensen},
keywords = {Gender studies, Elementary education, Pedagogical issues, Numeracy practices},
abstract = {The investigation monitored the digital game-playing behaviours of 428 primary-aged students (aged 10–12 years). Chi-square analysis revealed that boys tend to spend more time playing digital games than girls while boys and girls play quite different game genres. Subsequent analysis revealed statistically significant gender differences in terms of the types of mathematics-rich games students prefer to play. Girls preferred to play games that required problem solving, quantitative computations and the interpretation of graphs. Boys preferred games that required visual/spatial engagement. Given the fact that boys outperform girls on spatial tasks and mathematics assessment items that contain graphics, this study has implications for the development of students' mathematics sense making.}
}
@article{BARRON1992245,
title = {A bibliography on computational molecular biology and genetics},
journal = {Mathematical and Computer Modelling},
volume = {16},
number = {6},
pages = {245-319},
year = {1992},
issn = {0895-7177},
doi = {https://doi.org/10.1016/0895-7177(92)90166-I},
url = {https://www.sciencedirect.com/science/article/pii/089571779290166I},
author = {Sarah Barron and Matthew Witten and Gongxian Liu},
abstract = {The field of computational molecular biology and genetics is expanding at an enormous rate. Journals such as CABIOS and Nucleic Acids Research routinely publish articles on computational and mathematical aspects of biology. The purpose of this paper is to provide a bibliographic review of the literature in this area related to DNA mapping and sequence analysis. We have focused on computer and mathematical aspects of molecular biology and genetics (interpreted in a broad sense). Authors are solicited for their additions/corrections to this bibliography. Contact us at the above address.}
}
@article{LEIVANT198651,
title = {Typing and computational properties of lambda expressions},
journal = {Theoretical Computer Science},
volume = {44},
pages = {51-68},
year = {1986},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(86)90109-X},
url = {https://www.sciencedirect.com/science/article/pii/030439758690109X},
author = {Daniel Leivant},
abstract = {We use a perception of second-order typing in the λ-Calculus, as conveying semantic properties of expressions in models over λ-expressions, to exhibit natural and uniform proofs of theorems of Girard (1971/1972) and of Coppo, Dezani and Veneri (1981) about the relations between typing properties and computational properties of λ-expressions (solvability, normalizability, strong normalizability), and of some generalizations of these theorems.}
}
@incollection{VHORA2024709,
title = {Investigating Fluid Flow Dynamics in Triply Periodic Minimal Surfaces (TPMS) Structures Using CFD Simulation},
editor = {Flavio Manenti and Gintaras V. Reklaitis},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {53},
pages = {709-714},
year = {2024},
booktitle = {34th European Symposium on Computer Aided Process Engineering / 15th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-28824-1.50119-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443288241501198},
author = {Kasimhussen Vhora and Tanya Neeraj and Dominique Thévenin and Gábor Janiga and Kai Sundmacher},
keywords = {Computational Fluid Dynamic, TPMS Structure, Pressure Drop, LBM},
abstract = {Efficient absorption processes require optimized packed bed column structures, which affect gas-liquid contact, flow distribution, and pressure drop. An optimal setup ensures efficient mass transfer with high surface area while keeping down the pressure drop, which leads to energy savings and better absorption. TPMS structures such as the Gyroid, Schwarz-P, and Schwarz-D were investigated in this study, with a focus on balancing porosity and surface area to achieve reduced pressure drops and optimal phase contact. Single-phase flow simulations were conducted using the commercial software STAR- CCM+, compared to the lattice Boltzmann method (LBM) to provide an alternative perspective on fluid dynamics. Validation, analysis of the results and identification of possible improvements were achieved through these comparisons. According to the results, the Schwarz-D structure with 70% porosity and 2 mm unit cell leads to the best performance, exhibiting a pressure drop of 655 Pa m-1 and a specific surface area of 1776 m2 m-3 when analysed with STAR-CCM+. The predicted pressure drop was successfully confirmed using LBM simulations, adding robustness to the findings.}
}
@article{FURNARI2023103763,
title = {Streaming egocentric action anticipation: An evaluation scheme and approach},
journal = {Computer Vision and Image Understanding},
volume = {234},
pages = {103763},
year = {2023},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2023.103763},
url = {https://www.sciencedirect.com/science/article/pii/S1077314223001431},
author = {Antonino Furnari and Giovanni Maria Farinella},
keywords = {Action anticipation, Egocentric vision, Streaming perception},
abstract = {Egocentric action anticipation aims to predict the future actions the camera wearer will perform from the observation of the past. While predictions about the future should be available before the predicted events take place, most approaches do not pay attention to the computational time required to make such predictions. As a result, current evaluation schemes assume that predictions are available right after the input video is observed, i.e., presuming a negligible runtime, which may lead to overly optimistic evaluations. We propose a streaming egocentric action evaluation scheme which assumes that predictions are performed online and made available only after the model has processed the current input segment, which depends on its runtime. To evaluate all models considering the same prediction horizon, we hence propose that slower models should base their predictions on temporal segments sampled ahead of time. Based on the observation that model runtime can affect performance in the considered streaming evaluation scenario, we further propose a lightweight action anticipation model based on feed-forward 3D CNNs which is optimized using knowledge distillation techniques with a novel past-to-future distillation loss. Experiments on the three popular datasets EPIC-KITCHENS-55, EPIC-KITCHENS-100 and EGTEA Gaze+ show that (i) the proposed evaluation scheme induces a different ranking on state-of-the-art methods as compared to classic evaluations, (ii) lightweight approaches tend to outmatch more computationally expensive ones, and (iii) the proposed model based on feed-forward 3D CNNs and knowledge distillation outperforms current art in the streaming egocentric action anticipation scenario.}
}
@article{QIN2025102994,
title = {A comprehensive taxonomy of machine consciousness},
journal = {Information Fusion},
volume = {119},
pages = {102994},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.102994},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525000673},
author = {Ruilin Qin and Changle Zhou and Mengjie He},
keywords = {Consciousness, Machine consciousness, Artificial consciousness, Conscious robot, Qualia, Large language model},
abstract = {Machine consciousness (MC) is the ultimate challenge to artificial intelligence. Although great progress has been made in artificial intelligence and robotics, consciousness is still an enigma and machines are far from having it. To clarify the concepts of consciousness and the research directions of machine consciousness, in this review, a comprehensive taxonomy for machine consciousness is proposed, categorizing it into seven types: MC-Perception, MC-Cognition, MC-Behavior, MC-Mechanism, MC-Self, MC-Qualia and MC-Test, where the first six types aim to achieve a certain kind of conscious ability, and the last type aims to provide evaluation methods and criteria for machine consciousness. For each type, the specific research contents and future developments are discussed in detail. Especially, the machine implementations of three influential consciousness theories, i.e. global workspace theory, integrated information theory and higher-order theory, are elaborated in depth. Moreover, the challenges and outlook of machine consciousness are analyzed in detail from both theoretical and technical perspectives, with emphasis on new methods and technologies that have the potential to realize machine consciousness, such as brain-inspired computing, quantum computing and hybrid intelligence. The ethical implications of machine consciousness are also discussed. Finally, a comprehensive implementation framework of machine consciousness is provided, integrating five suggested research perspectives: consciousness theories, computational methods, cognitive architectures, experimental systems, and test platforms, paving the way for the future developments of machine consciousness.}
}
@article{HALL198939,
title = {Computational approaches to analogical reasoning: A comparative analysis},
journal = {Artificial Intelligence},
volume = {39},
number = {1},
pages = {39-120},
year = {1989},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(89)90003-9},
url = {https://www.sciencedirect.com/science/article/pii/0004370289900039},
author = {Rogers P. Hall},
abstract = {Analogical reasoning has a long history in artificial intelligence research, primarily because of its promise for the acquisition and effective use of knowledge. Defined as a representational mapping from a known “source” domain into a novel “target” domain, analogy provides a basic mechanism for effectively connecting a reasoner's past and present experience. Using a four-component process model of analogical reasoning, this paper reviews sixteen computational studies of analogy. These studies are organized chronologically within broadly defined task domains of automated deduction, problem solving and planning, natural language comprehension, and machine learning. Drawing on these detailed reviews, a comparative analysis of diverse contributions to basic analogy processes identifies recurrent problems for studies of analogy and common approaches to their solution. The paper concludes by arguing that computational studies of analogy are in a state of adolescence: looking to more mature research areas in artificial intelligence for robust accounts of basic reasoning processes and drawing upon a long tradition of research in other disciplines.}
}
@article{YANG201616,
title = {The future nexus of the Brahmaputra River Basin: Climate, water, energy and food trajectories},
journal = {Global Environmental Change},
volume = {37},
pages = {16-30},
year = {2016},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2016.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959378016300036},
author = {Y.C. Ethan Yang and Sungwook Wi and Patrick A. Ray and Casey M. Brown and Abedalrazq F. Khalil},
keywords = {The Yarlung Tsangpo River, The Jamuna River, Water resources systems analysis, Transboundary water management, Ex post scenario analysis},
abstract = {Advance knowledge of conflicting trajectories of water–energy–food (WEF) nexus is highly relevant for water policy and planning, especially for basins that cross national boundaries. The Brahmaputra River Basin in South Asia, home for 130 million people, is such a basin. Development of new hydropower projects, upstream water diversions and possible climate changes introduce concerns among riparian countries about future water supply for energy and food production in the basin. This study presents a new hydro-economic water system model of the basin coupled with ex post scenario analysis under the “nexus thinking” concept to identify and illustrate where development paths are in conflict. Results indicate that the ability of future development to remain free of conflict hinges mostly on the amount of precipitation falling in the basin in the future. Uncertain future precipitation along with uncertain future temperature and the unknown amount of upstream water diversion combine to strongly influence future water, energy and food production in the basin. Specifically, decreases in precipitation coupled with large upstream diversions (e.g., diversion in the territory of China) would leave one or more riparian countries unable to secure enough water to produce their desired energy and food. Future climate projected by General Circulation Models suggest a warmer and wetter climate condition in the region, which is associated with an increase in streamflow and easing of conflicts at the WEF nexus in the basin. The methodology presented here is expected to be generally useful for diagnosing the conditions that may cause water resources development goals to not be achieved due to either changes in climate or water use among competing users.}
}
@article{GERSTENBERG2024924,
title = {Counterfactual simulation in causal cognition},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {10},
pages = {924-936},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001074},
author = {Tobias Gerstenberg},
keywords = {counterfactuals, causality, mental simulation, intuitive physics, theory of mind},
abstract = {How do people make causal judgments and assign responsibility? In this review article, I argue that counterfactual simulations are key. To simulate counterfactuals, we need three ingredients: a generative mental model of the world, the ability to perform interventions on that model, and the capacity to simulate the consequences of these interventions. The counterfactual simulation model (CSM) uses these ingredients to capture people’s intuitive understanding of the physical and social world. In the physical domain, the CSM predicts people’s causal judgments about dynamic collision events, complex situations that involve multiple causes, omissions as causes, and causes that sustain physical stability. In the social domain, the CSM predicts responsibility judgments in helping and hindering scenarios.}
}
@article{ALQARALLEH20223913,
title = {Automated Handwriting Recognition and Speech Synthesizer for Indigenous Language Processing},
journal = {Computers, Materials and Continua},
volume = {72},
number = {2},
pages = {3913-3927},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.026531},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822014461},
author = {Bassam A. Y. Alqaralleh and Fahad Aldhaban and Feras Mohammed A-Matarneh and Esam A. AlQaralleh},
keywords = {Computational linguistics, handwriting character recognition, natural language processing, indigenous language},
abstract = {In recent years, researchers in handwriting recognition analysis relating to indigenous languages have gained significant internet among research communities. The recent developments of artificial intelligence (AI), natural language processing (NLP), and computational linguistics (CL) find useful in the analysis of regional low resource languages. Automatic lexical task participation might be elaborated to various applications in the NLP. It is apparent from the availability of effective machine recognition models and open access handwritten databases. Arabic language is a commonly spoken Semitic language, and it is written with the cursive Arabic alphabet from right to left. Arabic handwritten Character Recognition (HCR) is a crucial process in optical character recognition. In this view, this paper presents effective Computational linguistics with Deep Learning based Handwriting Recognition and Speech Synthesizer (CLDL-THRSS) for Indigenous Language. The presented CLDL-THRSS model involves two stages of operations namely automated handwriting recognition and speech recognition. Firstly, the automated handwriting recognition procedure involves preprocessing, segmentation, feature extraction, and classification. Also, the Capsule Network (CapsNet) based feature extractor is employed for the recognition of handwritten Arabic characters. For optimal hyperparameter tuning, the cuckoo search (CS) optimization technique was included to tune the parameters of the CapsNet method. Besides, deep neural network with hidden Markov model (DNN-HMM) model is employed for the automatic speech synthesizer. To validate the effective performance of the proposed CLDL-THRSS model, a detailed experimental validation process takes place and investigates the outcomes interms of different measures. The experimental outcomes denoted that the CLDL-THRSS technique has demonstrated the compared methods.}
}
@article{MASHAL201366,
title = {Enhanced left frontal involvement during novel metaphor comprehension in schizophrenia: Evidence from functional neuroimaging},
journal = {Brain and Language},
volume = {124},
number = {1},
pages = {66-74},
year = {2013},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2012.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X12002155},
author = {N. Mashal and T. Vishne and N. Laor and D. Titone},
keywords = {Schizophrenia, Novel metaphors, Lateralization, Language, fMRI},
abstract = {The neural basis involved in novel metaphor comprehension in schizophrenia is relatively unknown. Fourteen people with schizophrenia and fourteen controls were scanned while they silently read novel metaphors, conventional metaphors, literal expressions, and meaningless word-pairs. People with schizophrenia showed reduced comprehension of both novel and conventional metaphors. Furthermore, while controls showed enhanced brain activation in right inferior frontal gyrus (IFG) for novel metaphors versus meaningless word-pairs, people with schizophrenia showed an over-activation of left IFG and middle frontal gyrus (MFG). Direct comparison between the groups revealed greater activation in left precuneus for both novel metaphors and literal expressions vs. baseline for individuals with schizophrenia. Direct comparison for novel metaphors vs. literal expressions also revealed increased activation for individuals with schizophrenia in left MFG. These results suggest that the inefficient processing of novel metaphors in schizophrenia involves compensatory recruitment of additional brain regions that include the left MFG and left precuneus.}
}
@article{LEUKHIN2018300,
title = {Bio-plausible simulation of three monoamine systems to replicate emotional phenomena in a machine},
journal = {Procedia Computer Science},
volume = {145},
pages = {300-305},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323639},
author = {Alexey Leukhin and Max Talanov and Jordi Vallverdú and Fail Gafarov},
keywords = {affective computing, affective computation, spiking neural networks, bio-inspired cognitive architecture},
abstract = {In this paper we present the validation of the three-dimensional model of emotions by Hugo Lövheim the “cube of emotion” via neurosimulation in the NEST. We also present the extension of original “cube of emotion” with the bridge to computational processes parameters. The neurosimulation is done via re-implementation of dopamine (DA), serotonin (5-HT) and noradrenaline (NA) subsystems of a rat brain to replicate 8 basic psycho-emotional states according to the “cube of emotion”. Results of neu-rosimulations indicate the incremental influence of DA and NA over computational resources of a psycho-emotional state while 5-HT decreases the computational resources used to calculate a psycho-emotional state. This way we indicate the feasibility of the bio-plausible re-implementation of psycho-emotional states in a computational system. This approach could be useful extension of decision making and load balancing components of modern artificial agents as well as intelligent robotic systems.}
}
@article{HU2023100795,
title = {A cardiologist-like computer-aided interpretation framework to improve arrhythmia diagnosis from imbalanced training datasets},
journal = {Patterns},
volume = {4},
number = {9},
pages = {100795},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100795},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923001502},
author = {Lianting Hu and Shuai Huang and Huazhang Liu and Yunmei Du and Junfei Zhao and Xiaoting Peng and Dantong Li and Xuanhui Chen and Huan Yang and Lingcong Kong and Jiajie Tang and Xin Li and Heng Liang and Huiying Liang},
keywords = {arrhythmia, inter-class bullying, waveform clustering, heartbeat splicing, Bayesian approach},
abstract = {Summary
Arrhythmias can pose a significant threat to cardiac health, potentially leading to serious consequences such as stroke, heart failure, cardiac arrest, shock, and sudden death. In computer-aided electrocardiogram interpretation systems, the inclusion of certain classes of arrhythmias, which we term “aggressive” or “bullying,” can lead to the underdiagnosis of other “vulnerable” classes. To address this issue, a method for arrhythmia diagnosis is proposed in this study. This method combines morphological-characteristic-based waveform clustering with Bayesian theory, drawing inspiration from the diagnostic reasoning of experienced cardiologists. The proposed method achieved optimal performance in macro-recall and macro-precision through hyperparameter optimization, including spliced heartbeats and clusters. In addition, with increasing bullying by aggressive arrhythmias, our model obtained the highest average recall and the lowest average drop in recall on the nine vulnerable arrhythmias. Furthermore, the maximum cluster characteristics were found to be consistent with established arrhythmia diagnostic criteria, lending interpretability to the proposed method.}
}
@article{PISTIKOPOULOS2021107252,
title = {Process systems engineering – The generation next?},
journal = {Computers & Chemical Engineering},
volume = {147},
pages = {107252},
year = {2021},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2021.107252},
url = {https://www.sciencedirect.com/science/article/pii/S0098135421000302},
author = {E N Pistikopoulos and Ana Barbosa-Povoa and Jay H Lee and Ruth Misener and Alexander Mitsos and G V Reklaitis and V Venkatasubramanian and Fengqi You and Rafiqul Gani},
keywords = {Process systems engineering, Synthesis-design, Optimization, Control, Modelling, Supply chain},
abstract = {Process Systems Engineering (PSE) is the scientific discipline of integrating scales and components describing the behavior of a physicochemical system, via mathematical modelling, data analytics, design, optimization and control. PSE provides the ‘glue’ within scientific chemical engineering, and offers a scientific basis and computational tools towards addressing contemporary and future challenges such as in energy, environment, the ‘industry of tomorrow’ and sustainability. This perspective article offers a guide towards the next generation of PSE developments by looking at its history, core competencies, current status and ongoing trends.}
}
@article{COLOMBO2016291,
title = {Analysing the connectivity and communication of suicidal users on twitter},
journal = {Computer Communications},
volume = {73},
pages = {291-300},
year = {2016},
note = {Online Social Networks},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2015.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S014036641500256X},
author = {Gualtiero B. Colombo and Pete Burnap and Andrei Hodorog and Jonathan Scourfield},
keywords = {Social media, Social network analysis, Twitter, Computational social science, Suicide},
abstract = {In this paper we aim to understand the connectivity and communication characteristics of Twitter users who post content subsequently classified by human annotators as containing possible suicidal intent or thinking, commonly referred to as suicidal ideation. We achieve this understanding by analysing the characteristics of their social networks. Starting from a set of human annotated Tweets we retrieved the authors’ followers and friends lists, and identified users who retweeted the suicidal content. We subsequently built the social network graphs. Our results show a high degree of reciprocal connectivity between the authors of suicidal content when compared to other studies of Twitter users, suggesting a tightly-coupled virtual community. In addition, an analysis of the retweet graph has identified bridge nodes and hub nodes connecting users posting suicidal ideation with users who were not, thus suggesting a potential for information cascade and risk of a possible contagion effect. This is particularly emphasised by considering the combined graph merging friendship and retweeting links.}
}
@incollection{VANDERFORD2017105,
title = {Chapter 10 - Transferable Skills: How to Describe What You Really Know},
editor = {Teresa M. Evans and Natalie Lundsteen and Nathan L. Vanderford},
booktitle = {ReSearch},
publisher = {Academic Press},
pages = {105-118},
year = {2017},
isbn = {978-0-12-804297-7},
doi = {https://doi.org/10.1016/B978-0-12-804297-7.00010-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042977000100},
author = {Nathan L. Vanderford},
keywords = {Alternative careers, Biomedical science, Career path, Communicating skills, Graduate student, Job market, Life science, Nontraditional career, PhD, Postdoc, Self-assessment, Transferable skills},
abstract = {Think beyond your label—years of academic life have pushed you to fine-tune a statement regarding your research interests that is short and to the point. It often starts with “I am a doctoral student in…” To hone your transferable skills, or the skills that are valued in research as well as other career areas, you have to break away from thinking about yourself in those terms. Prove that you can do the job even when you do not have direct job experience—you will do this by learning to think broadly and comprehensively about your transferable skills. Know how to identify your transferable skills. For everything that you have achieved in your life, there is an accompanying set of skills that will add value to you as a job applicant. Know how to describe them. Know how to portray your transferable skills in industry terms. There are phrases that resonate with key industries and organizations in their search for new recruits. Identify the correct terms to be understood in your chosen career field.}
}
@article{LIANG2022119384,
title = {Dynamic Causal Modelling of Hierarchical Planning},
journal = {NeuroImage},
volume = {258},
pages = {119384},
year = {2022},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2022.119384},
url = {https://www.sciencedirect.com/science/article/pii/S1053811922005031},
author = {Qunjun Liang and Jinhui Li and Senning Zheng and Jiajun Liao and Ruiwang Huang},
keywords = {Dynamic Causal Modelling (DCM), Parametric Empirical Bayes (PEB), fMRI, neural architecture, individual difference},
abstract = {Hierarchical planning (HP) is a strategy that optimizes the planning by storing the steps towards the goal (lower-level planning) into subgoals (higher-level planning). In the framework of model-based reinforcement learning, HP requires the computation through the transition value between higher-level hierarchies. Previous study identified the dmPFC, PMC and SPL were involved in the computation process of HP respectively. However, it is still unclear about how these regions interaction with each other to support the computation in HP, which could deepen our understanding about the implementation of plan algorithm in hierarchical environment. To address this question, we conducted an fMRI experiment using a virtual subway navigation task. We identified the activity of the dmPFC, premotor cortex (PMC) and superior parietal lobe (SPL) with general linear model (GLM) in HP. Then, Dynamic Causal Modelling (DCM) was performed to quantify the influence of the higher- and lower-planning on the connectivity between the brain areas identified by the GLM. The strongest modulation effect of the higher-level planning was found on the dmPFC→right PMC connection. Furthermore, using Parametric Empirical Bayes (PEB), we found the modulation of higher-level planning on the dmPFC→right PMC and right PMC→SPL connections could explain the individual difference of the response time. We conclude that the dmPFC-related connectivity takes the response to the higher-level planning, while the PMC acts as the bridge between the higher-level planning to behavior outcome.}
}
@article{KEE1984198,
title = {Computational modeling of flame structure},
journal = {Physica D: Nonlinear Phenomena},
volume = {12},
number = {1},
pages = {198-211},
year = {1984},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(84)90524-4},
url = {https://www.sciencedirect.com/science/article/pii/0167278984905244},
author = {Robert J. Kee and James A. Miller},
abstract = {In this paper we discuss the need to model the detailed structure of a flame. That is, we argue the value of tracing the elementary reaction steps that are responsible for the creation of pollutant species and the release of heat. Accomplishing this task requires the computational solution of equations describing the conservation of mass, momentum, energy, and chemical species. In the course of our development we compare the computational approach with that of large activation energy asymptotic analysis. In the second half of the paper we concentrate on the computational consequences of flame modeling. Typically the governing equations are large and stiff systems of partial differential equations. Computational solution requires strongly stable implicit numerical algorithms, and we discuss these methods. We also discuss the adaptive meshing strategies that are required to resolve accurately the structure of thin flames in relatively large domains.}
}
@article{CHATANAKA2022100007,
title = {Immunoinformatics: Pushing the boundaries of immunology research and medicine},
journal = {ImmunoInformatics},
volume = {5},
pages = {100007},
year = {2022},
issn = {2667-1190},
doi = {https://doi.org/10.1016/j.immuno.2021.100007},
url = {https://www.sciencedirect.com/science/article/pii/S2667119021000070},
author = {Miyo K. Chatanaka and Antigona Ulndreaj and Dorsa Sohaei and Ioannis Prassas},
keywords = {Immunoinformatics, Immunology, Informatics, Perspective},
abstract = {Immunology has come a long way, from its early religious beginnings thousands of years ago, to the explosion of immunological data in the 21st century. Thanks to discoveries in immunology, our world has seen tremendous progress in how we understand and treat disease. However, a lot of unmet clinical needs remain, which require focused, real-time collaboration at the clinical and scientific research forefronts. Moreover, the current exponential growth in the generation of research data makes it impossible to handle, analyze, visualize, and interpret such data without the use of advanced computational tools. We think immunoinformatics- a discipline at the intersection of immunology and computer science- will greatly increase efficiency in research productivity and disease treatment. This perspective paper aims to emphasize the role of immunoinformatics toward pushing the boundaries of immunology research. It will also illustrate its clinical applications, including disease prevention, diagnosis, prognosis, treatment, monitoring, as well as in drug discovery. We believe informatics approaches will be implemented increasingly more frequently in research. Thus, here we also discuss a set of fundamental prerequisites to facilitate the efficient and ethical integration of informatics in research and ensure immunological advancements provide maximum benefits to society.}
}
@article{HICKENDORFF2020101311,
title = {Fourth graders’ adaptive strategy use in solving multidigit subtraction problems},
journal = {Learning and Instruction},
volume = {67},
pages = {101311},
year = {2020},
issn = {0959-4752},
doi = {https://doi.org/10.1016/j.learninstruc.2020.101311},
url = {https://www.sciencedirect.com/science/article/pii/S0959475219307327},
author = {Marian Hickendorff},
keywords = {Mathematics education, Multidigit subtraction, Strategy flexibility, Strategy adaptivity, Choice/no-choice method},
abstract = {Using the choice/no-choice methodology we investigated Dutch fourth graders’ (N = 124) adaptive use of the indirect addition strategy to solve subtraction problems. Children solved multidigit subtraction problems in one choice condition, in which they were free to choose between direct subtraction and indirect addition, and in two no-choice conditions, in which they had to use either direct subtraction or indirect addition. Furthermore, children were randomly assigned to mental computation, written computation, or free choice between mental and written computation. One third of the children adaptively switched their strategy according to the number characteristics of the problems, whereas the remaining children consistently used the same strategy. The likelihood to adaptively switch strategies decreased when written computation was allowed or required, compared to mandatory mental computation. On average, children were adaptive to their own speed differences but not to the accuracy differences between the strategies.}
}
@article{BECK2017110,
title = {Can bootstrapping explain concept learning?},
journal = {Cognition},
volume = {158},
pages = {110-121},
year = {2017},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2016.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0010027716302578},
author = {Jacob Beck},
keywords = {Bootstrapping, Concept learning, Susan Carey, Concepts, Computational constraints},
abstract = {Susan Carey’s account of Quinean bootstrapping has been heavily criticized. While it purports to explain how important new concepts are learned, many commentators complain that it is unclear just what bootstrapping is supposed to be or how it is supposed to work. Others allege that bootstrapping falls prey to the circularity challenge: it cannot explain how new concepts are learned without presupposing that learners already have those very concepts. Drawing on discussions of concept learning from the philosophical literature, this article develops a detailed interpretation of bootstrapping that can answer the circularity challenge. The key to this interpretation is the recognition of computational constraints, both internal and external to the mind, which can endow empty symbols with new conceptual roles and thus new contents.}
}
@article{ENE20141110,
title = {Open Loop Reverse Supply Chain Network Design},
journal = {Procedia - Social and Behavioral Sciences},
volume = {109},
pages = {1110-1115},
year = {2014},
note = {2nd World Conference on Business, Economics and Management},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.12.596},
url = {https://www.sciencedirect.com/science/article/pii/S187704281305235X},
author = {Seval Ene and Nursel Öztürk},
keywords = {Supply chain management, open loop system, product recovery, network design, mathematical programming},
abstract = {Reverse supply chain management is a significant issue for sustainable economy, product recovery and green thinking. The purpose of this study is to contribute product recovery management by designing open loop reverse supply chain network. The main difference between open loop and closed loop reverse supply chain is in returning of used products. In a closed loop reverse supply chain, used products are generally returned to original producers. But in an open loop reverse supply chain, used products are not returned to original producers, outsider firms recover them. This paper presents a mathematical model for multi stage and multi period reverse supply chain network, which maximizes total profit of the network. The proposed model determines facility locations and material flows between stages in each period. Numerical experiments showed the applicability and efficiency of the model.}
}
@article{WANG2021102528,
title = {Automatic diagnosis of ECG disease based on intelligent simulation modeling},
journal = {Biomedical Signal Processing and Control},
volume = {67},
pages = {102528},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.102528},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421001257},
author = {Xu Wang and Runchuan Li and Shuhong Wang and Shengya Shen and Wenzhi Zhang and Bing Zhou and Zongmin Wang},
keywords = {Intelligent simulation modeling, Rule, ECG diseases, Diagnosis},
abstract = {In order to better assist doctors in diagnosing cardiovascular diseases, a set of end-to-end automatic diagnosis algorithms for ECG diseases based on intelligent simulation modeling are proposed. Firstly, wavelet transform and threshold method are used to denoise the ECG signal and locate the waveform in this paper. Secondly, waveform features are extracted. Finally, the rule method is used to convert the doctors’ thinking of diagnosing the disease into a description of the ECG characteristics of the disease to diagnose the ECG disease, and the algorithm is verified on the public database CCDD and the private data all-in-one machine data. The results show that this method is not inferior to the deep learning method. Now 11 types of diseases and 10 types of rhythm can be diagnosed.}
}
@article{HEIKKURINEN20181654,
title = {Degrowth by means of technology? A treatise for an ethos of releasement},
journal = {Journal of Cleaner Production},
volume = {197},
pages = {1654-1665},
year = {2018},
note = {Technology and Degrowth},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2016.07.070},
url = {https://www.sciencedirect.com/science/article/pii/S0959652616309593},
author = {Pasi Heikkurinen},
keywords = {Degrowth, Ethics, Practice, Releasement, Sustainability, Technology},
abstract = {The large-scale ecological damage caused by growth societies calls for economic degrowth in terms of a radical decrease in matter/energy throughput. This article examines the role of modern technology in degrowth with a focus on the question of agency and its ethical implications. After conceptualising technology as practice, the paper finds that while technological practice encompasses an agency for social change, it is restricted to transforming the non-human world to human-made objects. This is because in technological practice the world and its objects unfold as a standing-reserve for human use. Due to this calculative and anthropocentric thinking, technological practice does not and cannot support the emergence of a kind of agency that either does or can let things be. Moreover, the more technological the practice, the more objects are utilised. The paper concludes that technological practice does not support the transition to degrowth, because it directs its agents towards the continuous transformation of non-human-made objects into human-made objects resulting in an increase in cumulative throughput. The paper thus suggests that an ethos of releasement is needed to attain, as well as to live in, a degrowth society. The rationale provided for refraining from the technological practice in order to contribute to ecologically sensible social change is the chief contribution of this paper.}
}
@article{BAILLIE1989209,
title = {A comparison of the CM with the DAP for lattice gauge theory},
journal = {Parallel Computing},
volume = {12},
number = {2},
pages = {209-220},
year = {1989},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(89)90054-9},
url = {https://www.sciencedirect.com/science/article/pii/0167819189900549},
author = {Clive F Baillie and G {Stuart Pawley}},
keywords = {Connection Machine, Distributed Array Processor, SIMD, massively parallel, lattice gauge theory, QED, QCD, performance measurement, performance analysis},
abstract = {Lattice gauge theory is one of the most challenging large-scale scientific computations; a state of the art calculation requires at least 1014 floating-point operations, necessitating the use of advanced architecture massively parallel computers such as the Connection Machine (CM) made by Thinking Machines Corporation (TMC), and the Distributed Array Processor (DAP) made in the past by International Computers Limited (ICL) and currently by active Memory Technology (AMT). The most important gauge theory to be solved is that descrining the sub-nuclear world of high energy physics: Quantum Chromodynamics (QCD). The simples example of a gauge theory is Quantum Electro-dynamics (QED), the theory which describes the interaction of electrons and photons. Simulation of QCD requires computer software very similar to that for the simpler QED problem. Thus, as a first step towards computer simulation of QCD, we have developed code for QED on the CM, and compared this with similar code for the DAP. Experience with the DAP allows us to predict performances for QCD code on the CM, showing the latter to be a very serious proposition for such large-scale scientific computations.}
}
@article{CRISTOFARO2020344,
title = {“I feel and think, therefore I am”: An Affect-Cognitive Theory of management decisions},
journal = {European Management Journal},
volume = {38},
number = {2},
pages = {344-355},
year = {2020},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2019.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0263237319301094},
author = {Matteo Cristofaro},
keywords = {Sensemaking, Decision making, Socially situated cognition, Affect, Cognition, Rationality, Behavioral strategy},
abstract = {I propose an Affect-Cognitive Theory to comprehensively understand how decisions occur in organizations. To this aim, I first review the assumptions of sensemaking and decision-making streams of research, especially the influence of bounded rationality, affective states and their relationships with cognition; then, I integrate them on the common basis of socially situated cognition. This new theory emphasizes the role of affective states in determining/being determined by cognition and its errors, pointing out decision makers’ affect as the result of multi-level adaptations to the physical and social environment. Management decisions are path dependent but not immutable; they, indeed, bank on the predominant feeling resulting from the modifying interactions and regulations of decision makers with their physical and social environment. Here, decision makers are proposed as “emotional cognizers” overcoming the thinking-feeling dichotomy that has often featured in the study of management decisions. This theory is beneficial for behavioral strategy, offering the needed assumptions to intertwine human cognition, emotions, and social behavior.}
}
@article{RANA201761,
title = {Dynamic effects in the didehydro‐Diels‐Alder (DDDA) reaction of enyne‐ketoenes: 50% stepwise bond formation in spite of concerted transition state††This article is published as part of a special issue to celebrate the 80th birthday of Professor Waldemar Adam},
journal = {Journal of Physical Organic Chemistry},
volume = {30},
number = {9},
pages = {61-67},
year = {2017},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.3732},
url = {https://www.sciencedirect.com/science/article/pii/S0894323022014072},
author = {Anup Rana and Indrajit Paul and Michael Schmittel},
abstract = {The C2─C6/Diels‐Alder cyclization of enyne‐ketoene 1 was studied by experiments, theoretical calculations, and dynamic trajectory computations. The failure to trap possible intermediate(s), indicates a concerted reaction mechanism. A detailed search for stationary points revealed a concerted mechanism and surprisingly a diradical intermediate with no direct connection to the enyne‐ketoene 1. To probe the accessibility of this intermediate quasiclassical trajectories were initiated from the concerted transition state structure. Notably, 36% of the trajectories reach the product zone directly and 5% arrive at the product via the intermediate diradical. Additionally, 31% of the trajectories go to the intermediate zone and stay there within the simulation time limit.}
}
@incollection{EVETT1994115,
title = {Chapter 6 - Providing Computationally Effective Knowledge Representation via Massive Parallelism},
editor = {Laveen N. KANAL and Vipin KUMAR and Hiroaki KITANO and Christian B. SUTTNER},
series = {Machine Intelligence and Pattern Recognition},
publisher = {North-Holland},
volume = {14},
pages = {115-135},
year = {1994},
booktitle = {Parallel Processing for Artificial Intelligence},
issn = {0923-0459},
doi = {https://doi.org/10.1016/B978-0-444-81704-4.50012-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780444817044500120},
author = {Matthew P. Evett and William A. Andersen and James A. Hendler},
abstract = {PARKA is a frame-based knowledge representation system implemented on the Connection Machine. PARKA provides a representation language consisting of concept descriptions (frames) and binary relations on those descriptions (slots). The system is designed explicitly to provide extremely fast property inheritance inference capabilities. In particular, PARKA can perform fast “recognition” queries of the form “find all frames satisfying m property constraints” in O(d + m) time—proportional only to the depth (d) of the knowledge base (KB), and independent of its size. For conjunctive queries of this type, PARKA's performance is measured in tenths of a second, even for KBs with more than 100,000 frames. We show similar results for timings on on large IS-A networks derived from the Cyc commonsense KB, and for queries involving knowledge structure pattern matching in support of case-based planning. With such run-time performance, PARKA is possibly the “fastest knowledge representation system in the world”.}
}
@article{CHRISTAKOU2014302,
title = {Present simple and continuous: Emergence of self-regulation and contextual sophistication in adolescent decision-making},
journal = {Neuropsychologia},
volume = {65},
pages = {302-312},
year = {2014},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2014.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0028393214003133},
author = {Anastasia Christakou},
keywords = {Decision-making, Adolescence, Self-regulation, Corticostriatal circuits},
abstract = {Sophisticated, intentional decision-making is a hallmark of mature, self-aware behaviour. Although neural, psychological, interpersonal, and socioeconomic elements that contribute to such adaptive, foresighted behaviour mature and/or change throughout the life-span, here we concentrate on relevant maturational processes that take place during adolescence, a period of disproportionate developmental opportunity and risk. A brief, eclectic overview is presented of recent evidence, new challenges, and current thinking on the fundamental mechanisms that mature throughout adolescence to support adaptive, self-controlled decision-making. This is followed by a proposal for the putative contribution of frontostriatal mechanisms to the moment-to-moment assembly of evaluative heuristics that mediate increased decision-making sophistication, promoting the maturation of self-regulated behaviour through adolescence and young adulthood.}
}
@article{KRELLENSTEIN1987155,
title = {A reply to ”parallel computation and the mind-body problem”},
journal = {Cognitive Science},
volume = {11},
number = {2},
pages = {155-157},
year = {1987},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(87)80003-4},
url = {https://www.sciencedirect.com/science/article/pii/S0364021387800034},
author = {Marc Krellenstein}
}
@article{SKLAD2014710,
title = {The Development of the Heuristics and Biases Scale (HBS)},
journal = {Procedia - Social and Behavioral Sciences},
volume = {112},
pages = {710-718},
year = {2014},
note = {International Conference on Education & Educational Psychology 2013 (ICEEPSY 2013)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.01.1221},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814012385},
author = {Marcin Sklad and Rene Diekstra},
keywords = {Cognitive Heuristics Biases Education Psychometric Scale},
abstract = {Problem Statement
There is no comprehensive tool capturing general vulnerability to biases caused by the use of heuristics. Existing tools focus only on one specific bias or on personality traits.
Research Questions
Can general vulnerability to heuristic thinking be assessed and what are the sub-dimensions of this construct? Can undergraduate students be successfully involved in the research process?
Purpose of the Study
To demonstrate the results of an educational experiment in which undergraduate students are involved in the first stage of development of the Heuristics and Biases Scale (HBS).
Research Methods
After getting acquainted with the underlying theory, students chose one specific bias or heuristic, investigated related results of the experiments and paradigms. At the later stage, under supervision, students developed items intended to capture the chosen bias. Finally, positively evaluated items were combined together and piloted. The psychometrical properties of the items and course outcomes were assessed.
Findings
Developed items formed scales with satisfactory reliability. Course received positive student evaluations, and the assessment indicated that the majority of students achieved intended learning outcomes.
Conclusions
The study indicates that it is possible to develop a psychometrically sound assessment to measure vulnerability to a range of common cognitive biases. Moreover, it is also possible to successfully involve undergraduate students in the development of a psychometrical tool.
Acknowledgments
Authors would like to thank the Students of University College Roosevelt contributing to this work as their Independent Research Projects or as a part of Social Psychology or Statistics Course.}
}
@incollection{CHIARENZA202317,
title = {Chapter 2 - The psychophysiology of “covert” goal-directed behavior},
editor = {Tal Dotan Ben-Soussan and Joseph Glicksohn and Narayanan Srinivasan},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {280},
pages = {17-42},
year = {2023},
booktitle = {Neurophysiology of Silence Part B: Theory and Review},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2023.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079612323000067},
author = {Giuseppe Augusto Chiarenza},
keywords = {Covert behavior, Movement related potentials, Bereitschaftspotential, Skilled performance positivity, Development, Dyslexia, Education},
abstract = {Covert behavior is defined as behavior that is not directly visible and is thus comparable to a type of behavioral silence that requires modern psychophysiological techniques to reveal. Goal-directed behavior is teleologically purposive. Fundamentally, there are two approaches to accounting for purposeful behavior. One is the cybernetic approach, which views behavior as homeostatic and largely reflexive. The other one views behavior as a cognitive process that involves an interaction between neural events representing the previous experience, the present state of the individual, and the occurrence of particular features in the environment. This review, based on published data, presents a non-invasive psychophysiological method for investigating the electrical brain activity associated with those “silent” behaviors such as intention, evaluation of results, and memorization. Movement-related potentials (MRPs) are ideal for studying these processes. The MRPs are recorded during the execution of the skilled performance task (SPT). This task requires the execution of fast ballistic movements with the thumbs of both hands, learning a precise and short time interval between the two thumb presses, and scoring the highest number of target performances. The subject receives real-time feedback about the results of his performance. The MRPs associated with this task and present during covert behavior are the Bereitschaftspotential (BP) present before the onset of movement and the Skilled Performance Positivity (SPP) after movement, which coincides with the subject's awareness of the success or failure of his performance. These potentials show a maturational trend, reaching the adult form around the age of 10 when formal and abstract thinking progress. SPT and MRPs are particularly suitable to study neurodevelopmental disorders. Children with developmental dyslexia show abnormal MRPs, both in latency and amplitude, in different brain areas.}
}
@article{GREENLEE20201043,
title = {Kinetic and Thermodynamic Control in Dynamic Covalent Synthesis},
journal = {Trends in Chemistry},
volume = {2},
number = {12},
pages = {1043-1051},
year = {2020},
issn = {2589-5974},
doi = {https://doi.org/10.1016/j.trechm.2020.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S258959742030232X},
author = {Andrew J. Greenlee and Chloe I. Wendell and Morgan M. Cencer and Summer D. Laffoon and Jeffrey S. Moore},
keywords = {dynamic, covalent, reversible, kinetic, thermodynamic},
abstract = {In recent years, dynamic covalent chemistry (DCC) has seen the synthesis of increasingly complex cyclooligomers, polymers, and diverse compound libraries. The reversible formation of covalent bonds characteristic of DCC reactions favors thermodynamic product distributions for simple unitopic reactions; however, kinetic effects are increasingly influential in reactions of multitopic precursors. In this review, we explore the interplay between thermodynamic and kinetic considerations when planning a DCC synthesis. Computational models, typically based on reaction thermodynamics, have aided in predicting DCC reaction outcomes with moderate success. A clear direction for the field is to develop more robust computational tools informed by thermodynamic and kinetic driving forces that can predict product distributions in DCC reactions.}
}
@article{WIERZBICKI2007610,
title = {Modelling as a way of organising knowledge},
journal = {European Journal of Operational Research},
volume = {176},
number = {1},
pages = {610-635},
year = {2007},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2005.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0377221705007010},
author = {Andrzej P. Wierzbicki},
keywords = {OR in research and development, Knowledge-based systems, Mathematical modelling, Knowledge management, Hard and soft systems approaches, Tacit knowledge and intuition, Epistemology},
abstract = {The paper is motivated by the need of to address a new the old topic of operational research and hard (but also soft) systems science: what is the role of mathematical modelling, how does it relate to knowledge, to creativity, to human concerns? Such a need arises because of the great change observed today, of informational revolution, of transition towards knowledge-based economy, towards networked organization of our social and economic life. During last 50years operational research, mathematical modelling and computerised techniques of model analysis and optimisation contributed essentially to the change of perception of contemporary world, characteristic for the current informational revolution indicating the change of civilisation eras. These contributions have been noted during these years inside operational research, but analysed mostly from so-called soft systems thinking perspective. Main contributions to the actual formation of the new era, however, came from the hard systems research, in particular, as we shall show, from mathematical modelling in applications to the development of technological systems. The new civilisation era of information and knowledge-based economy started around 1980. It is a long duration historical era, characterised by a new way of understanding the world. This understanding is systemic and chaotic; in particular, it assumes the emergence of qualitatively new properties of complex systems on higher layers of complexity, which cannot be reduced to the properties of system components. On this background, it is necessary to reflect a new on the theory of knowledge. The paper presents a discussion of the concept of knowledge from several perspectives, such as the perspective of operational research, of systems science, of mathematical modelling, of knowledge-based economy, of knowledge engineering and knowledge management, of interactive model-based decision support. The human-centred development of informational technology necessitates a re-appraisal of soft systems approaches; their values and limitations are discussed. Additionally, a rational theory of intuition is recalled to show its relation with the concept of tacit knowledge, of knowledge creation and with harmonious approaches to knowledge characterising Far East philosophy as well as Japanese approaches to knowledge management and creation. Epistemological conclusions from the rational theory of intuition are discussed, including a new concept of micro-theories of knowledge creation and the concept of Creative Space.}
}
@article{COIERA2007S98,
title = {Putting the technical back into socio-technical systems research},
journal = {International Journal of Medical Informatics},
volume = {76},
pages = {S98-S103},
year = {2007},
note = {Information Technology in Health Care: Sociotechnical Approaches},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2006.05.026},
url = {https://www.sciencedirect.com/science/article/pii/S1386505606001481},
author = {Enrico Coiera},
keywords = {Human–computer interaction, Information system design, Information system evaluation, Socio-technical systems},
abstract = {Socio-technical systems (STS) analysis has provided us with a powerful framework with which to analyse the reasons behind the poor acceptability, uptake and performance of many information or communication technology systems (ICT). However, for the contribution of STS thinking to be more than simply a means of critiquing current practices and ICT systems, it needs to also contribute to the process of developing new and more effective ICT systems. Specifically, we need to develop a formal design language for translating our insights about the socio-technical nature of work, into design specifications that result in better interventions in the work place. We need to get ‘technical’ about what we mean and about what we want from a design, and we need to work alongside technologists to shape technology, as well as the processes, organisations and cultures within which they will be embedded. Indeed the process of design itself can be seen as a socio-technical one, and understanding the decision to design itself may allow us one day to stop designing for people, and create STS that sustainably design themselves.}
}
@article{CORBETT2020e03250,
title = {Connectivism and leadership: harnessing a learning theory for the digital age to redefine leadership in the twenty-first century},
journal = {Heliyon},
volume = {6},
number = {1},
pages = {e03250},
year = {2020},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2020.e03250},
url = {https://www.sciencedirect.com/science/article/pii/S2405844020300955},
author = {Frederique Corbett and Elio Spinello},
keywords = {Connectivism, Learning, Education, Learning theory, Leadership, Computer science, Human-centered computing, Information systems, Network (computer science)},
abstract = {This manuscript provides a literature review of connectivism. It presents evidence and thinking in which connectivism, a new learning theory which has typically been used for online learning, is applied to leadership, with a provocative discussion on the yet unexplored opportunities to use connectivism to redefine leadership in the twenty-first century. The paper aims to bridge the gap between the contributions of digital learning in education and the field of leadership theory and development. It seeks to apply the critical tenets of connectivism in education and learning to leadership theory and to stimulate a debate on new forms of leadership.}
}
@article{NI2025168,
title = {Hybrid solar-energy harvest model for durable photocatalytic hydrogen production},
journal = {International Journal of Hydrogen Energy},
volume = {116},
pages = {168-177},
year = {2025},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2025.03.119},
url = {https://www.sciencedirect.com/science/article/pii/S0360319925012145},
author = {Nan Ni and Yifan Hao and Yinglao Liu and Haibo Li and Jin Feng and Wei Liu and Wenxu Zheng},
keywords = {Photocatalyst, Water splitting, Hydrogen generation, Photon absorption, Semiconductors},
abstract = {Hybrid solar-energy harvest model for next-generation photocatalysts is customized for central metallic manipulation to achieve superior hydrogen generation with outstanding stability and long-lasting reduction reactions. Current single catalysts fail to satisfy demands of photoelectric conversion owing to irreversible photo-corrosion and charge-carrier trapping, leading to inner transmission wanes. Here we present a hybrid solar-energy harvest model with a organic-inorganic hybrid mesoscopic system, CoT(tz)PP/CdS, ranging from ordered to disordered frameworks with sufficient reactive sites and controllable active surface, which erase the energy barriers driven by existing water decomposition. This design enables simultaneous knocked out and coupling interactions of fermions and bosons at surface of binary semiconductors without invisible multi-path fading of generation efficiency. Experimentally, multi-dimension characterizations reveal the intrinsic fine genes of such novel catalyst are innate ideas, preventing unmeaning matters of energy loss and its hydrogen evolution rate reaches up to 66.44 mmol g−1 h−1. Molecular loop domain from CoT(tz)PP limits collapse of molecules in energy transfer, mitigating recombination of electron-hole pairs and enhancing morphological integrity. Overall, these results suggest that CoT(tz)PP/CdS assists hydrogen evolution in predicated review of solar energy utilization trials, reducing internal obstacles and loss on hydrogen outcomes and offering a more valid certificate in sustainable initiative of green energy.}
}
@article{GREEN2017125,
title = {Fluid reasoning predicts future mathematical performance among children and adolescents},
journal = {Journal of Experimental Child Psychology},
volume = {157},
pages = {125-143},
year = {2017},
issn = {0022-0965},
doi = {https://doi.org/10.1016/j.jecp.2016.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0022096516302995},
author = {Chloe T. Green and Silvia A. Bunge and Victoria {Briones Chiongbian} and Maia Barrow and Emilio Ferrer},
keywords = {Children, Math, Cognitive development, Fluid reasoning, Working memory, Problem solving},
abstract = {The aim of this longitudinal study was to determine whether fluid reasoning (FR) plays a significant role in the acquisition of mathematics skills above and beyond the effects of other cognitive and numerical abilities. Using a longitudinal cohort sequential design, we examined how FR measured at three assessment occasions, spaced approximately 1.5years apart, predicted math outcomes for a group of 69 participants between ages 6 and 21years across all three assessment occasions. We used structural equation modeling (SEM) to examine the direct and indirect relations between children’s previous cognitive abilities and their future math achievement. A model including age, FR, vocabulary, and spatial skills accounted for 90% of the variance in future math achievement. In this model, FR was the only significant predictor of future math achievement; age, vocabulary, and spatial skills were not significant predictors. Thus, FR was the only predictor of future math achievement across a wide age range that spanned primary school and secondary school. These findings build on Cattell’s conceptualization of FR as a scaffold for learning, showing that this domain-general ability supports the acquisition of rudimentary math skills as well as the ability to solve more complex mathematical problems.}
}
@article{BOHSALI2025105535,
title = {Neural connectivity underlying core language functions},
journal = {Brain and Language},
volume = {262},
pages = {105535},
year = {2025},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2025.105535},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X25000045},
author = {Anastasia A. Bohsali and Joseph M. Gullett and David B. FitzGerald and Thomas Mareci and Bruce Crosson and Keith White and Stephen E. Nadeau},
keywords = {Broca’s region, Tractography, Language, Aphasia, Grammar, Supramarginal gyrus, Angular gyrus, Temporal lobe},
abstract = {Introduction
Although many white matter tracts underlying language functions have been identified, even in aggregate they do not provide a sufficiently detailed and expansive picture to enable us to fully understand the computational processes that might underly language production and comprehension. We employed diffusion tensor tractography (DTT) with a tensor distribution model to more extensively explore the white matter tracts supporting core language functions. Our study was guided by hypotheses stemming largely from the aphasia literature.
Methods
We employed high angular resolution diffusion imaging (HARDI) with a dual region of interest tractography approach. Our diffusion tensor distribution model uses a mixture of Wishart distributions to estimate the water molecule displacement probability functions on a voxel-by-voxel basis and to model crossing/branching fibers using a multicompartmental approach.
Results
We replicated the results of previously published studies of tracts underlying language function. Our study also yielded a number of novel findings: 1) extensive connectivity between Broca’s region and the entirety of the middle and superior frontal gyri; 2) extensive interconnectivity between the four subcomponents of Broca’s region, pars orbitalis, pars triangularis, pars opercularis, and the inferior precentral gyrus; 3) connectivity between the mid-superior temporal gyrus and the transverse gyrus; 4) connectivity between the mid-superior temporal gyrus, the transverse gyrus, and the planum temporale and the inferior and middle temporal gyri; and 5) connectivity between mid- and anterior superior temporal gyrus and all components of Broca’s region.
Discussion
These results, which replicate the results of prior DTT studies, also considerably extend them and thereby provide a fuller picture of the structural basis of language function and the basis for a novel model of the neural network architecture of language function. This new model is entirely consistent with discoveries from the aphasia literature and with parallel distributed processing conceptualizations of language function.}
}
@article{GU2025105551,
title = {Semantic memory structure mediates the role of brain functional connectivity in creative writing},
journal = {Brain and Language},
volume = {264},
pages = {105551},
year = {2025},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2025.105551},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X25000203},
author = {Jing Gu and Xueyang Wang and Cheng Liu and Kaixiang Zhuang and Li Fan and Jingyi Zhang and Jiangzhou Sun and Jiang Qiu},
keywords = {Creativity, Writing, Semantic network, Functional connectivity},
abstract = {Associative theories of creativity posit that high-creativity individuals possess flexible semantic memory structures that allow broad access to varied information. However, the semantic memory structure characteristics and neural substrates of creative writing are unclear. Here, we explored the semantic network features and the predictive whole-brain functional connectivity associated with creative writing and generated mediation models. Participants completed two creative story continuation tasks. We found that keywords from written texts with superior creative writing performance encompassed more semantic categories and were highly interconnected and transferred efficiently. Connectome predictive modeling (CPM) was conducted with resting-state functional magnetic resonance imaging (fMRI) data to identify whole-brain functional connectivity patterns related to creative writing, dominated by default mode network (DMN). Semantic network features were found to mediate the relationship between brain functional connectivity and creative writing performance. These results highlight how semantic memory structure and the DMN-driven brain functional connectivity patterns support creative writing performance. Our findings extend prior research on the role of semantic memory structure and the DMN in creativity, expand upon previous research on semantic creativity, and provide insight into the cognitive and neural foundations of creative writing.}
}
@article{TRAN2019284,
title = {Creating material data for thermoset injection molding simulation process},
journal = {Polymer Testing},
volume = {73},
pages = {284-292},
year = {2019},
issn = {0142-9418},
doi = {https://doi.org/10.1016/j.polymertesting.2018.11.042},
url = {https://www.sciencedirect.com/science/article/pii/S0142941818316295},
author = {Ngoc Tu Tran and Michael Gehde},
keywords = {Thermoset injection molding, Reactive viscosity and cure kinetics model, Thermoset material data, Reactive injection molding simulation, Wall slip boundary condition},
abstract = {Thermoset material data for reactive injection molding simulation process is found in limited sources and seldom available from data bank of simulation tools because of complication not only in rheological and thermal properties measurement but also in writing optimization algorithm to model rheological and thermal mathematical equations. In this paper, rheological and thermal properties of thermoset injection molding compounds were successfully measured. In addition, a numerical method was developed to create material data of thermoset injection molding compounds, which was directly imported into a simulation tool, namely, Moldex3D to investigate its application in thermoset injection molding simulation process. Furthermore, a strong slip phenomenon on the interface between thermoset melt and wall surface which was investigated and detected during injection molding experiments was taken into account in the filling simulation process. The computation was found to be in good agreement with the experimental results, indicating that the new generated material data is reasonable and the influence of wall slip on the mold filling characterization of thermoset injection compounds during simulation process is not ignorable.}
}
@article{YEUNG2024104999,
title = {A systematic review of Drone integrated STEM education at secondary schools (2005–2023): Trends, pedagogies, and learning outcomes},
journal = {Computers & Education},
volume = {212},
pages = {104999},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.104999},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524000137},
author = {Richard Chung Yiu Yeung and Chi Ho Yeung and Daner Sun and Chee-Kit Looi},
keywords = {Systematic review, Drone-integrated learning, STEM education, Secondary schools},
abstract = {As the prominence of drone technology continues to captivate interest for its myriad applications in education, an understanding of the current status of drone-integrated education becomes imperative. This systematic review endeavors to furnish an updated and comprehensive analysis of the drone education studies across academic levels, with a specific emphasis on secondary education settings. To accomplish this objective, a review study with 181 publications was conducted, with a particular focus on 41 publications explicitly addressing the integration of drones in secondary STEM education. Employing a systematic approach, this review identifies, analyzes, and synthesizes pertinent literature, ensuring a thorough comprehension of the current state of the field. The key findings of this review can be summarized as follows: 1) Among the diverse array of subjects incorporating drones, STEM disciplines emerge as the most prominently featured. 2) Experiential and project-based learning stand out as the most commonly adopted pedagogical methods in drone-integrated STEM education. The incorporation of teamwork and hands-on activities is frequently cited as instructional strategies aimed at enhancing drone-integrated STEM learning experiences. 3) Beyond the acquisition of drone-related technical skills, the reported learning outcomes encompass a spectrum of aspects, including heightened STEM career awareness, increased engagement and learning interest, and collaborative problem-solving abilities. The findings underscore the potential of drones to ignite passion for STEM subjects among secondary students, achieved through interdisciplinary, hands-on applications that foster problem-solving and design competencies.}
}
@article{WANG201837,
title = {Linguistic terms with weakened hedges: A model for qualitative decision making under uncertainty},
journal = {Information Sciences},
volume = {433-434},
pages = {37-54},
year = {2018},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.12.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517311593},
author = {Hai Wang and Zeshui Xu and Xiao-Jun Zeng},
keywords = {Decision making, Linguistic hedges, Linguistic term sets, Multi-granularity linguistic decision making, Semantics},
abstract = {When expressing the experts’ opinions in qualitative decision making (QDM), linguistic hedges can be considered to modify the force expressed by a predefined linguistic term. If an expert is not sure to select one term, weakened hedges would be a natural way to express the uncertainty. This is usually implemented by using a hedge to modify the most possible term, like the expression “more or less good”. To model the uncertainty implied by hedges in QDM, this paper presents a novel linguistic representational and computational model in which the linguistic expressions take the form of a weakened hedge and a linguistic term, which is named as linguistic term with weakened hedge (LTWH). The syntax of LTWHs is defined by a set of hedges and a set of linguistic terms. The semantics of a LTWH is determined, objectively, based on the semantics of the term and a similarity measure of the reference domain. Accordingly, the negation, order relations and some basic operations of LTWHs are defined. To illustrate the effectiveness of LTWHs in granular computing, the connection to some multi-granularity linguistic models is exploited and a process for unifying multi-granularity linguistic information is developed. The major contritions of this paper are: (1) The proposed model enables a new manner to express and operate uncertain linguistic information in QDM; (2) it possesses clear syntax and semantics and the computational results are very interpretable; and (3) the proposed solution of multi-granularity linguistic unification maintains the semantics of the original linguistic information.}
}
@incollection{LEEFRANCISS2025237,
title = {Chapter 13 - Generative artificial intelligence in genetics: A comprehensive review},
editor = {Khalid Raza},
booktitle = {Deep Learning in Genetics and Genomics},
publisher = {Academic Press},
pages = {237-247},
year = {2025},
isbn = {978-0-443-27523-4},
doi = {https://doi.org/10.1016/B978-0-443-27523-4.00005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443275234000056},
author = {Nicholas {Lee Franciss}},
keywords = {Generative artificial intelligence, Generative pretrained transformers, Large language models, Model architecture, Transformers},
abstract = {Generative artificial intelligence (GenAI) is revolutionizing genetics by applying the computational capabilities of predictive algorithms to unveil the genome's intricate complexities. From protein prediction to gene discovery and motif detection, GenAI techniques are transforming our understanding of genetic processes that were not previously possible. Here we explore how Markov chains, long-standing predecessors of more modern technologies like large language models (LLMs) and generative pretrained transformers (GPTs), have been complemented by these advanced methods, empowering researchers to extract unprecedented levels of information from DNA sequences, including regulatory networks that govern gene expression. We dive deep into how the individual model architectures enable their capability to implicitly understand and generate biological data. The cultural and intellectual implications of DeepMind's AlphaFold on the prediction of three-dimensional protein structures and, with it, its cultural impact on generative approaches in protein design and is also explored.}
}
@incollection{SUKHAI2017249,
title = {22 - Simulation learning},
editor = {Mahadeo A. Sukhai and Chelsea E. Mohler},
booktitle = {Creating a Culture of Accessibility in the Sciences},
publisher = {Academic Press},
pages = {249-255},
year = {2017},
isbn = {978-0-12-804037-9},
doi = {https://doi.org/10.1016/B978-0-12-804037-9.00022-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012804037900022X},
author = {Mahadeo A. Sukhai and Chelsea E. Mohler},
keywords = {Simulation learning, accommodation, teaching tool, computer technology, application of best practices},
abstract = {Simulation learning can be a valuable tool deployed in support of the learning of students with disabilities in the sciences. In thinking about simulation learning, we must consider two scenarios: (1) When simulation learning will benefit a student with a disability, because other accommodation methods are not appropriate or feasible; and, (2) When simulation learning is applied to all students, where accessibility considerations of the simulation must be taken into account for students with disabilities in the class. In this chapter, we will review the application of both scenarios for simulation learning to students with disabilities in the sciences.}
}
@article{VAR2025e41447,
title = {A new strategy for constructing alternative consumer confidence indexes to explain household consumption: A fuzzy DEMATEL approach},
journal = {Heliyon},
volume = {11},
number = {2},
pages = {e41447},
year = {2025},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e41447},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024174786},
author = {Özge Var and Alptekin Durmuşoğlu and Türkay Dereli},
keywords = {Consumer confidence index, Consumer surveys, Fuzzy DEMATEL, Household consumption, Lasso regression},
abstract = {Background
Consumer Confidence Index (CCI) is a measure obtained from consumer surveys (CS) that gauges assessments and expectations of the economic environment. Common practice uses 4 of the 12 questions in CCI calculation. However, efforts to find best set of questions continue, such as the European Commission swapping two questions in 2019. Literature studies employ different combinations of questions; however all-alternative combinations take too much time and computational power. The questions also exhibit cause-and-effect relationships as household consumption predictors and are not statistically independent of one another.
Objective
We suggest classifying the CS questions as "Causes" and "Effects." It makes sense that inquiries in the cause group should provide a better explanation of household consumption. If this theory turns out to be correct, a smaller solution space will be able to be used to find the ideal substitute CCI.
Method
A fuzzy DEMATEL (Decision-Making Trial and Evaluation Laboratory), a reliable method to present causal relationships, is used to classification. The prediction power of cause group (in terms of explaining household expenditures) is measured with the Lasso regression (Least Absolute Shrinkage and Selection Operator), which provides more interpretable regression models. This approach was applied to European Union dataset from 2007Q3 to 2021Q2.
Results
The cause group included four CS questions and explained the 75% variability of the consumption expenditures. It is performed comparably to earlier studies that took into account all possible question combinations. The Türkiye case, covering data from 2007 to 2021, supported the finding of EU case, explaining 84% variation in consumption expenditures.
Conclusion
These encouraging results suggest that comparable prediction power can be attained with a significant reduction in effort (in comparison to all brute force). Therefore, this approach would provide shortcut for constructing alternative CCIs to the authorities.}
}
@article{JADHAV2022127935,
title = {Scale-up of the bioelectrochemical system: Strategic perspectives and normalization of performance indices},
journal = {Bioresource Technology},
volume = {363},
pages = {127935},
year = {2022},
issn = {0960-8524},
doi = {https://doi.org/10.1016/j.biortech.2022.127935},
url = {https://www.sciencedirect.com/science/article/pii/S0960852422012688},
author = {Dipak A. Jadhav and Ashvini D. Chendake and Vandana Vinayak and Abdulaziz Atabani and Mohammad {Ali Abdelkareem} and Kyu-Jung Chae},
keywords = {Energy balance, Microbial electrochemical technology, Net energy recovery, Normalization of performance, Resource recovery, Techno-economic feasibility},
abstract = {Electrochemists and ecological engineers find environmental bioelectrochemistry appealing; however, there is a big gap between expectations and actual progress in bioelectrochemical system (BES). Implementing such technology opens new opportunities for novel electrochemical reactions for resource recovery and effective wastewater treatment. Loopholes of BES exist in its scaling-up applications, and numerous attempts toward practical applications (200, 1000, and 1500 L) are key successive indicators toward its commercialization. This review emphasized the critical rethinking of standardization of performance indices i.e. current generation (A/m2), net energy recovery (kWh/kg·COD), product/resource yield (mM), and economic feasibility ($/kWh) to make fair comparison with the existing treatment system. Therefore, directional perspectives, including modularity, energy-cost balance, energy and resource recovery, have been proposed for the sustainable market of BES. The current state of the art and up-gradation in resource recovery and contaminant removal warrants a systematic rethinking of functional worth and niches of BES for practical applications.}
}
@article{MAHMOUD202263,
title = {Where to from here? On the future development of autonomous vehicles from a cognitive systems perspective},
journal = {Cognitive Systems Research},
volume = {76},
pages = {63-77},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000444},
author = {Sara Mahmoud and Erik Billing and Henrik Svensson and Serge Thill},
keywords = {Artificial cognition, Self-driving cars, Cognitive paradigms},
abstract = {Self-driving cars not only solve the problem of navigating safely from location A to location B; they also have to deal with an abundance of (sometimes unpredictable) factors, such as traffic rules, weather conditions, and interactions with humans. Over the last decades, different approaches have been proposed to design intelligent driving systems for self-driving cars that can deal with an uncontrolled environment. Some of them are derived from computationalist paradigms, formulating mathematical models that define the driving agent, while other approaches take inspiration from biological cognition. However, despite the extensive work in the field of self-driving cars, many open questions remain. Here, we discuss the different approaches for implementing driving systems for self-driving cars, as well as the computational paradigms from which they originate. In doing so, we highlight two key messages: First, further progress in the field might depend on adapting new paradigms as opposed to pushing technical innovations in those currently used. Specifically, we discuss how paradigms from cognitive systems research can be a source of inspiration for further development in modelling driving systems, highlighting emergent approaches as a possible starting point. Second, self-driving cars can themselves be considered cognitive systems in a meaningful sense, and are therefore a relevant, yet underutilized resource in the study of cognitive mechanisms. Overall, we argue for a stronger synergy between the fields of cognitive systems and self-driving vehicles.}
}
@incollection{KUMBALE2021306,
title = {Models for Personalized Medicine},
editor = {Olaf Wolkenhauer},
booktitle = {Systems Medicine},
publisher = {Academic Press},
address = {Oxford},
pages = {306-317},
year = {2021},
isbn = {978-0-12-816078-7},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.11349-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383113492},
author = {Carla M. Kumbale and Jacob D. Davis and Eberhard O. Voit},
keywords = {Dynamic model, Health simplex, Health trajectory, Machine learning, Modeling, Networks, Personalized medicine, Precision medicine, Systems biology, Theranostics},
abstract = {The customization of medicine to specific individuals promises clear improvements in disease treatment, but also faces substantial challenges, many of which have their roots in the complexity of the human body. This complexity cannot be grasped with intuition alone and is not appropriately captured by reductionist methods, which have been dominating biology and medicine for the past decades. Experimental and computational systems biology have the potential of generating adequate datasets and analyzing them in a manner that captures the complexity of health and disease systems in a personalized manner. This potential has not yet fully materialized, but examples and case studies provide a glimpse of the power these approaches are likely to have in the future.}
}
@article{LEANZA20236716,
title = {Into the dynamics of rotaxanes at atomistic resolution††Electronic supplementary information (ESI) available: ESI Movies 1 and 2. See DOI: https://doi.org/10.1039/d3sc01593a},
journal = {Chemical Science},
volume = {14},
number = {24},
pages = {6716-6729},
year = {2023},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d3sc01593a},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023062065},
author = {Luigi Leanza and Claudio Perego and Luca Pesce and Matteo Salvalaglio and Max {von Delius} and Giovanni M. Pavan},
abstract = {Mechanically-interlocked molecules (MIMs) are at the basis of artificial molecular machines and are attracting increasing interest for various applications, from catalysis to drug delivery and nanoelectronics. MIMs are composed of mechanically-interconnected molecular sub-parts that can move with respect to each other, imparting these systems innately dynamical behaviors and interesting stimuli-responsive properties. The rational design of MIMs with desired functionalities requires studying their dynamics at sub-molecular resolution and on relevant timescales, which is challenging experimentally and computationally. Here, we combine molecular dynamics and metadynamics simulations to reconstruct the thermodynamics and kinetics of different types of MIMs at atomistic resolution under different conditions. As representative case studies, we use rotaxanes and molecular shuttles substantially differing in structure, architecture, and dynamical behavior. Our computational approach provides results in agreement with the available experimental evidence and a direct demonstration of the critical effect of the solvent on the dynamics of the MIMs. At the same time, our simulations unveil key factors controlling the dynamics of these systems, providing submolecular-level insights into the mechanisms and kinetics of shuttling. Reconstruction of the free-energy profiles from the simulations reveals details of the conformations of macrocycles on the binding site that are difficult to access via routine experiments and precious for understanding the MIMs' behavior, while their decomposition in enthalpic and entropic contributions unveils the mechanisms and key transitions ruling the intermolecular movements between metastable states within them. The computational framework presented herein is flexible and can be used, in principle, to study a variety of mechanically-interlocked systems.}
}
@article{HALTAUFDERHEIDE2023,
title = {Cultural Implications Regarding Privacy in Digital Contact Tracing Algorithms: Method Development and Empirical Ethics Analysis of a German and a Japanese Approach to Contact Tracing},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/45112},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123004831},
author = {Joschka Haltaufderheide and Davide Viero and Dennis Krämer},
keywords = {digital contact tracing, algorithms, methodology, empirical ethics, privacy, culture-sensitive ethics, mobile phone},
abstract = {Background
Digital contact tracing algorithms (DCTAs) have emerged as a means of supporting pandemic containment strategies and protecting populations from the adverse effects of COVID-19. However, the impact of DCTAs on users’ privacy and autonomy has been heavily debated. Although privacy is often viewed as the ability to control access to information, recent approaches consider it as a norm that structures social life. In this regard, cultural factors are crucial in evaluating the appropriateness of information flows in DCTAs. Hence, an important part of ethical evaluations of DCTAs is to develop an understanding of their information flow and their contextual situatedness to be able to adequately evaluate questions about privacy. However, only limited studies and conceptual approaches are currently available in this regard.
Objective
This study aimed to develop a case study methodology to include contextual cultural factors in ethical analysis and present exemplary results of a subsequent analysis of 2 different DCTAs following this approach.
Methods
We conducted a comparative qualitative case study of the algorithm of the Google Apple Exposure Notification Framework as exemplified in the German Corona Warn App and the Japanese approach of Computation of Infection Risk via Confidential Locational Entries (CIRCLE) method. The methodology was based on a postphenomenological perspective, combined with empirical investigations of the technological artifacts within their context of use. An ethics of disclosure approach was used to focus on the social ontologies created by the algorithms and highlight their connection to the question about privacy.
Results
Both algorithms use the idea of representing a social encounter of 2 subjects. These subjects gain significance in terms of risk against the background of a representation of their temporal and spatial properties. However, the comparative analysis reveals 2 major differences. Google Apple Exposure Notification Framework prioritizes temporality over spatiality. In contrast, the representation of spatiality is reduced to distance without any direction or orientation. However, the CIRCLE framework prioritizes spatiality over temporality. These different concepts and prioritizations can be seen to align with important cultural differences in considering basic concepts such as subject, time, and space in Eastern and Western thought.
Conclusions
The differences noted in this study essentially lead to 2 different ethical questions about privacy that are raised against the respective backgrounds. These findings have important implications for the ethical evaluation of DCTAs, suggesting that a culture-sensitive assessment is required to ensure that technologies fit into their context and create less concern regarding their ethical acceptability. Methodologically, our study provides a basis for an intercultural approach to the ethics of disclosure, allowing for cross-cultural dialogue that can overcome mutual implicit biases and blind spots based on cultural differences.}
}
@article{KHAN2024e31470,
title = {Catch-up growth with alpha and beta decoupling and their relationships between CO2 emissions by GDP, population, energy production, and consumption},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31470},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31470},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024075017},
author = {Rabnawaz Khan},
keywords = {Economic growth, Alpha and beta decoupling, CO emissions, Energy production and consumption, Populace},
abstract = {This study explores the relationship between CO2 emissions by GDP, population, energy production, and consumption in the United States, China, Romania, and Thailand economies from 1990 to 2019. It evaluates the phenomenon of catch-up growth, which transpires when an lagging economy goes through an expansionary phase after a period of below-average performance. We used the stochastic model to illustrate in terms of alpha and beta decoupling techniques. The outcomes validated by positive and negative decoupling attitudes play a crucial role in predicting a rise in CO2 emissions owing to oil, gas, and coal use in comparison to Romania. Thailand and Romania have a more viable road to sustainability than the United States and China. The United States and China appear to have an antagonistic relationship, as suggested by decoupling attitudes. Thailand and Romania are considered to be highly environmentally sustainable countries on account of their minimal carbon emissions, efficient energy usage, and forward-thinking environmental policies. Accordingly, policy recommendations are offered based on CO2 emissions and effective mitigation policies, since this allows for determining which countries with high emissions need technological advances, best practices, and intersectoral policies.}
}
@article{PRASAD2023104,
title = {Irrigation development under uncertainty: A call for adaptive investment pathways},
journal = {Environmental Science & Policy},
volume = {140},
pages = {104-110},
year = {2023},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2022.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S1462901122003653},
author = {Pooja Prasad and Annelieke Duker and Charlotte {de Fraiture} and Pieter {van der Zaag}},
keywords = {Adaptation pathways, Irrigation, Investments, Uncertainty, Development, Sub-Saharan Africa},
abstract = {There is an urgent need in sub-Saharan Africa (SSA) to enhance irrigation access to meet the challenges of growing population and climate risk. To achieve this, big investments are currently planned in large irrigation infrastructure. We believe there is danger in following this conventional approach, which requires big lumpsum investments, locking large capital into projects that do not adapt to deep uncertainties from climatic or socio-political factors. Instead, in this Perspective article, we propose an alternate “adaptive investment pathways” (AdIP) approach for planning step-wise investments towards desired objectives, implemented progressively depending on how the future unfolds, in order to gain flexibility. AdIP extends the adaptation pathways concept, which refers to a sequence of actions to be taken in response to a changing reality, and applies it to the context of development under uncertainty. Monitoring and learning is at the heart of this approach, which ensures that the plan adapts as new knowledge becomes available. Thus, AdIP internalizes risk and reduces chances of failures. For financial institutions backing development projects, following a pathway of smaller de-centralized investments lowers risk and incorporates a learning approach that allows re-thinking and adapting along the path. We illustrate the AdIP approach using the case of ephemeral sand river based small-scale irrigation in the drylands of SSA. We conclude that in face of deep uncertainties, the path to successful irrigation development in SSA requires a shift from making few large upfront investments in large-scale projects to making large numbers of smaller investments that assure flexibility.}
}
@article{SAVILLE201577,
title = {Application of information and communication technology and data sharing management scheme for the coastal fishery using real-time fishery information},
journal = {Ocean & Coastal Management},
volume = {106},
pages = {77-86},
year = {2015},
issn = {0964-5691},
doi = {https://doi.org/10.1016/j.ocecoaman.2015.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0964569115000289},
author = {Ramadhona Saville and Katsumori Hatanaka and Minoru Sano and Masaaki Wada},
keywords = {Catchable stock index, Self-management support, Real-time data sharing, Cloud computing, ICT, Swept area method, Sea cucumber},
abstract = {In this paper, we propose an automatic computation and data sharing scheme to support management system in coastal fishery using real-time fishery information through information and communication technology (ICT). In Japan, several species of fisheries commodity have not been specified in Total Allowable Catch policy, causing a lot of confusion on fishery cooperatives and fishermen on how to set the catch limit. To deal with the problem, in the previous study, we developed catchable stock index, a method to estimate a certain extent of resource via the swept area method. However, as the calculation of the index was computed on a GIS software manually, it was very time consuming, costly and unable to give an immediate evaluation of the fishing operation. This study aims to support management system in a coastal fishery through the development of automatic catchable stock index algorithm. In this study, ICT was utilized to obtain and transmit the real-time data sharing of fishery information as well as to distribute the computation results to the fishermen and fishery cooperative. The data used were vessels' trajectories and catch records, which included the start/end time and catch amount of each fishing operation. The catchable stock index was automatically computed in an originally developed cloud computing service. We have conducted the test run of the present method in sea cucumber dredge-net fishery on the coast of Rumoi City, Hokkaido, Japan. Data were collected from the entire vessels in Rumoi (16 vessels) during the 2012 and 2013 fishing seasons. The results were returned to the fishermen via the Internet each day during the fishing season, therefore, fishermen were able to immediately evaluate their catch. The estimated catchable stock index for the 2012 and 2013 seasons was 85.5 tons and 92.3 tons, respectively. By referring to the present system, fishermen voluntarily stopped the 2012 and 2013 fishing season several weeks earlier than their initial schedule to avoid overfishing. Moreover, in the previous study, the spacing of the grid has been decided empirically, but in this study, the adequate grid size could be evaluated due to the fast computation through ratio of the area of a grid cell to the total dredged area. In light of the evidence, the present automatic algorithm provided useful information for supporting the self-management of this coastal fishery.}
}
@article{ALLISON2018147,
title = {Dilemmas of modelling and decision-making in environmental research},
journal = {Environmental Modelling & Software},
volume = {99},
pages = {147-155},
year = {2018},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2017.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364815217300749},
author = {Andrew E.F. Allison and Mark E. Dickson and Karen T. Fisher and Simon F. Thrush},
keywords = {Wicked problems, Agent-based modelling, Post-normal science, Social-ecological systems, Shallow coastal systems},
abstract = {Multiple dilemmas confound social-ecological modelling. This review paper focuses on two: a modeller's dilemma associated with determining appropriate levels of model simplification, and a dilemma of decision-making relating to the use of models that were never designed to predict. We analyse approaches for addressing these dilemmas as they relate to shallow coastal systems and conclude that wicked problems cannot be adequately addressed using traditional disciplinary or systems engineering modelling. Simplified inter- and trans-disciplinary models have the potential to identify directions of system change, challenge thinking in disciplinary silos, and ultimately confront the dilemmas of social-ecological modelling.}
}
@incollection{CHOQUET1995421,
title = { - Viscous flow computations on the connection machine by a finite element Petrov-Galerkin scheme},
editor = {A. Ecer and J. Hauser and P. Leca and J. Periaux},
booktitle = {Parallel Computational Fluid Dynamics 1993},
publisher = {North-Holland},
address = {Amsterdam},
pages = {421-428},
year = {1995},
isbn = {978-0-444-81999-4},
doi = {https://doi.org/10.1016/B978-044481999-4/50175-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780444819994501754},
author = {Remi Choquet and Penelope Leyland},
abstract = {Publisher Summary
This chapter studies the numerical solution of the compressible Navier–Stokes equations with matrix-free implicit schemes, and its implementation on the Connection Machine CM-200 in the framework of unstructured grids. First, a Petrov Galerkin formulation is chosen following ideas of Hughes, which give at each time step a non-linear problem to be solved F(u)=0. Regarding the cost side of such a resolution, the main difficulties are due to communications and to the nonlinear solver. This chapter considers such problems. In the resolution process, either the jacobian of F is needed or the product of such jacobian by a vector. To obtain either of them, elementary contributions are assembled. Then at some stage of the algorithm of resolution, the new solution obtained globally is explored. Each of these operations involves communications among processors, which are quite costly on a single instruction, multiple data (SIMD) computer. So, existing libraries are selected because they are both easy to use and reasonably efficient compared to more sophisticated approaches. This enables to focus the study on the algorithmic part of the code. The nonlinear equations are solved by Newton-generalized minimal residual method (GMRES). Newton iterations are applied to linearize the problem and the induced linear system is solved by the iterative scheme GMRES, which only needs matrix vector product and is well-suited to nonsymmetric large matrices.}
}
@article{ROGOWSKI2024109246,
title = {Unlocking massively parallel spectral proper orthogonal decompositions in the PySPOD package},
journal = {Computer Physics Communications},
volume = {302},
pages = {109246},
year = {2024},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2024.109246},
url = {https://www.sciencedirect.com/science/article/pii/S0010465524001693},
author = {Marcin Rogowski and Brandon C.Y. Yeung and Oliver T. Schmidt and Romit Maulik and Lisandro Dalcin and Matteo Parsani and Gianmarco Mengaldo},
keywords = {Spectral proper orthogonal decomposition, SPOD, Parallel, Distributed, MPI, Modal decomposition, Dynamical systems},
abstract = {We propose a parallel (distributed) version of the spectral proper orthogonal decomposition (SPOD) technique. The parallel SPOD algorithm distributes the spatial dimension of the dataset preserving time. This approach is adopted to preserve the non-distributed fast Fourier transform of the data in time, thereby avoiding the associated bottlenecks. The parallel SPOD algorithm is implemented in the PySPOD library and makes use of the standard message passing interface (MPI) library, implemented in Python via mpi4py. An extensive performance evaluation of the parallel package is provided, including strong and weak scalability analyses. The open-source library allows the analysis of large datasets of interest across the scientific community. Here, we present applications in fluid dynamics and geophysics, that are extremely difficult (if not impossible) to achieve without a parallel algorithm. This work opens the path toward modal analyses of big quasi-stationary data, helping to uncover new unexplored spatio-temporal patterns.
Program summary
Program Title: PySPOD CPC Library link to program files: https://doi.org/10.17632/jf5bf26jcj.1 Developer's repository link: https://github.com/MathEXLab/PySPOD Licensing provisions: MIT License Programming language: Python Nature of problem: Large spatio-temporal datasets may contain coherent patterns that can be leveraged to better understand, model, and possibly predict the behavior of complex dynamical systems. To this end, modal decomposition methods, such as the proper orthogonal decomposition (POD) and its spectral counterpart (SPOD), constitute powerful tools. The SPOD algorithm allows the systematic identification of space-time coherent patterns. This can be used to understand better the physics of the process of interest, and provide a path for mathematical modeling, including reduced order modeling. The SPOD algorithm has been successfully applied to fluid dynamics, geophysics and other domains. However, the existing open-source implementations are serial, and they prevent running on the increasingly large datasets that are becoming available, especially in computational physics. The inability to analyze via SPOD large dataset in turn prevents unlocking novel mechanisms and dynamical behaviors in complex systems. Solution method: We provide an open-source parallel (MPI distributed) code, namely PySPOD, that is able to run on large datasets (the ones considered in the present paper reach about 200 Terabytes). The code is built on the previous serial open-source code PySPOD that was published in https://joss.theoj.org/papers/10.21105/joss.02862.pdf. The new parallel implementation is able to scale on several nodes (we show both weak and strong scalability) and solve some of the bottlenecks that are commonly found at the I/O stage. The current parallel code allows running on datasets that was not easy or possible to analyze with serial SPOD algorithms, hence providing a path towards unlocking novel findings in computational physics. Additional comments including restrictions and unusual features: The code comes with a set of built-in postprocessing tools, for visualizing the results. It also comes with extensive continuous integration, documentation, and tutorials, as well as a dedicated website in addition to the associated GiHub repository. Within the package we also provide a parallel implementation of the proper orthogonal decomposition (POD), that leverages the I/O parallel capabilities of the SPOD algorithm.}
}