@article{BRUNDAGE201532,
title = {Taking superintelligence seriously: Superintelligence: Paths, dangers, strategies by Nick Bostrom (Oxford University Press, 2014)},
journal = {Futures},
volume = {72},
pages = {32-35},
year = {2015},
note = {Confronting Future Catastrophic Threats To Humanity},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2015.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0016328715000932},
author = {Miles Brundage},
keywords = {Existential risk, Artificial intelligence, Superintelligence, Responsible innovation},
abstract = {A new book by Nick Bostrom, Superintelligence: Paths, Dangers, Strategies, is reviewed. Superintelligence explores the future of artificial intelligence and related technologies and the risks they may pose to human civilization. The book ably demonstrates the potential for serious thinking aimed at the long-term future. Bostrom succeeds in arguing that the development of superintelligent machines will, if not properly managed, create catastrophic risks to humanity. The book falls short in some respects, and some sections are more compelling and novel than others. Overall, however, Bostrom’s book succeeds in demolishing the “null hypothesis” according to which the possibility and risks of superintelligence can continue to be ignored, and is a must-read for those interested in the long-term future of humanity.}
}
@article{SOSA201656,
title = {Visual divergence in humans and computers},
journal = {Design Studies},
volume = {42},
pages = {56-85},
year = {2016},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000836},
author = {Ricardo Sosa and Nicolas Rojas and John S. Gero and Qinqi Xu},
keywords = {creativity, sketching, computer models, solution space},
abstract = {Studies of design creativity have underlined the importance of divergent reasoning and visual reasoning in idea generation. Connecting these two key design skills, this paper presents a model of divergent visual reasoning for the study of creativity. A visual divergence task called ShapeStorm is demonstrated for the study of creative ideation that can be applied to humans as well as computational systems. The model is examined in a study with human subjects, a computational stochastic generator, and a geometrical analysis of the solution space. The main significance of this task is that it offers a straightforward means to define a simple design task that can be used across research studies. Several scenarios for the application of ShapeStorm for the study of creativity are advanced.}
}
@article{GAO20222707,
title = {Similarity reductions for a generalized (3+1)-dimensional variable-coefficient B-type Kadomtsev–Petviashvili equation in fluid dynamics},
journal = {Chinese Journal of Physics},
volume = {77},
pages = {2707-2712},
year = {2022},
issn = {0577-9073},
doi = {https://doi.org/10.1016/j.cjph.2022.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0577907322001228},
author = {Xin-Yi Gao and Yong-Jiang Guo and Wen-Rui Shan},
keywords = {Fluid dynamics, Generalized (3+1)-dimensional variable-coefficient B-type Kadomtsev–Petviashvili equation, Similarity reductions, Symbolic computation},
abstract = {Rather intriguing, the paper Chin. J. Phys. 73 (2021) 600-612 has studied a (3+1)-dimensional B-type Kadomtsev–Petviashvili equation in fluid dynamics, while fluid dynamics has a wide range of applications, including those for geophysics, mechanical engineering, civil engineering, chemical engineering, astrophysics and biology. In this paper, taking into consideration certain nonlinear waves in fluid dynamics, we investigate a generalized variable-coefficient version of the aforementioned equation. Making use of symbolic computation, with respect to the amplitude or elevation of the relevant wave, we construct out two sets of the similarity reductions, which rely on the variable coefficients in the generalized equation.}
}
@article{LOMBARDI2022100601,
title = {Understanding emerging patterns and dynamics through the lenses of the cyber-physical universe},
journal = {Patterns},
volume = {3},
number = {11},
pages = {100601},
year = {2022},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2022.100601},
url = {https://www.sciencedirect.com/science/article/pii/S2666389922002264},
author = {Mauro Lombardi and Simone Vannuccini},
keywords = {cyber-physical universe, ubiquitous computing, information technology, artificial intelligence, decision making},
abstract = {Summary
The complex interaction among contemporary techno- and socio-economic processes has set the stage for the emergence of a cyber-physical universe, the novel landscape in which agents behave and interact, and which is centered on the fundamental role played by information and computation at all levels. In this paper, we weave into a single analysis the different threads that lead to (and characterize) the cyber-physical universe and outline a map of its building blocks and the complex dynamics at work in the new environment. The resulting description is used to assess how decision-making processes should evolve in order to be able to address the opportunities and challenges of the current era of deep and extended changes. The analysis offers an encompassing interpretative grid to understand and unpack patterns in the contemporary socio-technical systems that experience a fundamental informational turn; this can inform new research trajectories and help open up new areas for scientific inquiry.}
}
@article{KNYAZEV201817,
title = {Resting state connectivity mediates the relationship between collectivism and social cognition},
journal = {International Journal of Psychophysiology},
volume = {123},
pages = {17-24},
year = {2018},
issn = {0167-8760},
doi = {https://doi.org/10.1016/j.ijpsycho.2017.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167876017305470},
author = {Gennady G. Knyazev and Alexander N. Savostyanov and Andrey V. Bocharov and Ekaterina A. Merkulova},
keywords = {Collectivism, Social cognition, Medial prefrontal cortex, Connectivity, Mediation analysis},
abstract = {Humans are intrinsically social beings and it is natural that self-processing is associated with social cognition. The degree to which the self is perceived as a part of social environment is modulated by cultural stereotypes, such as collectivism and individualism. Here, we tested the hypothesis that individuals who endorse collectivist values would spontaneously think more about their relationships with other people and this association would be mediated by connectivity between the medial prefrontal cortex (MPFC) and the rest of the brain. Connectivity was evaluated based on resting state EEG data using the recently developed methods, which combine beamformer spatial filtering with seed based connectivity estimation. The formal mediation analysis revealed that collectivism is associated with an enhanced connectivity of MPFC with a set of cortical regions that are frequently co-activated in moral reasoning, empathy, and theory of mind tasks and with diminished connectivity with the precuneus\posterior cingulate cortex, which is involved in self-centered cognition. The relationship between collectivism and social cognition was mediated by MPFC connectivity with the left middle temporal gyrus implying that in participants with collectivistic attitude, thinking about relationships with other people may be associated with semantic memory retrieval and reasoning on moral issues and others' intentions.}
}
@article{VARGASCARPINTERO2025120104,
title = {Development of an integrated multi-criteria framework to assess the implementation potential of biobased value chains and webs with a territorial approach},
journal = {Industrial Crops and Products},
volume = {223},
pages = {120104},
year = {2025},
issn = {0926-6690},
doi = {https://doi.org/10.1016/j.indcrop.2024.120104},
url = {https://www.sciencedirect.com/science/article/pii/S0926669024020818},
author = {Ricardo Vargas-Carpintero},
keywords = {Biobased value chain, Biobased value web, Biorefinery, Territorial bioeconomy system, Multi-criteria assessment, Land-based bioeconomy},
abstract = {Biobased value chains and webs (BVCW) encompass value adding activities and actors from biomass production, its processing into biobased products for manifold sectors, until their commercialization and use. BVCW are part of territorial bioeconomy systems and are shaped by contextual settings. The design and development of BVCW involve strategic decisions towards their sustainable implementation. Throughout the design and development of BVCW, the adoption of an integral approach that links technical aspects of biomass-to-product pathways with non-technical aspects and context factors is necessary to increase the BVCW implementation potential. Accordingly, an active incorporation of the territorial context of BVCW in the design process is required. In view of these requirements, in this study an integrated, multi-criteria framework is developed to assess the implementation potential in BVCW design. For this purpose, key elements from existing biorefinery and biomass supply chain design methodologies are identified and integrated in a multi-criteria framework that allows the consideration of both an internal and external perspective of the BVCW in relation to the context. The conceptualized framework serves as an evaluation approach to check the implementability of biomass-to-product pathways BVCW configurations in form of by means of a multi-criteria catalogue. The set of criteria integrates relevant aspects for the design and development of BVCW from land-based biomass (e.g. crops and crop residues). It entails key criteria related to the functionality of the biomass-to-product pathway in technical-economic terms and the surrounding biophysical, social and economic context. The further operationalization of the multi-criteria catalogue by means of an indicator-based assessment could enable the prioritization and selection of BVCW configurations with best implementation potential. In this way, the framework provides a practical approach for decision-makers, local actors and researchers involved in the design and development of BVCW tailored to the territorial context.}
}
@article{COOK201895,
title = {An investigation of an undergraduate student’s reasoning with zero-divisors and the zero-product property},
journal = {The Journal of Mathematical Behavior},
volume = {49},
pages = {95-115},
year = {2018},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2017.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312317301748},
author = {John Paul Cook},
keywords = {Abstract algebra, Zero-product property, Zero-divisors, Equation solving, Student thinking, Realistic Mathematics Education},
abstract = {The zero-product property (ZPP), often stated as ‘if ab = 0, then a = 0 or b = 0,’ is an important concept in secondary algebra (as a tool for solving equations) and abstract algebra (as a property of integral domains). This study analyzes results from a teaching experiment to investigate how an undergraduate mathematics major might intuitively reason with zero-divisors and the ZPP. There are two primary findings. First, a procedurally embodied view of equation solving might preclude students’ attention to the algebraic properties (including the ZPP) that justify the equivalence of two equations. Second, students might not carefully attend to zero-divisors because they are employing the converse of the ZPP instead of the ZPP itself. These findings advance a hypothesis about why students might view abstract algebra as a different subject than school algebra and also affirm the utility of the student-centered theoretical perspective that guided the instructional design and analysis of student activity.}
}
@article{EVANS2003454,
title = {In two minds: dual-process accounts of reasoning},
journal = {Trends in Cognitive Sciences},
volume = {7},
number = {10},
pages = {454-459},
year = {2003},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2003.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1364661303002250},
author = {Jonathan St.B.T. Evans},
abstract = {Researchers in thinking and reasoning have proposed recently that there are two distinct cognitive systems underlying reasoning. System 1 is old in evolutionary terms and shared with other animals: it comprises a set of autonomous subsystems that include both innate input modules and domain-specific knowledge acquired by a domain-general learning mechanism. System 2 is evolutionarily recent and distinctively human: it permits abstract reasoning and hypothetical thinking, but is constrained by working memory capacity and correlated with measures of general intelligence. These theories essentially posit two minds in one brain with a range of experimental psychological evidence showing that the two systems compete for control of our inferences and actions.}
}
@article{VONRICHTHOFEN2018573,
title = {The ‘Urban Elements’ method for teaching parametric urban design to professionals},
journal = {Frontiers of Architectural Research},
volume = {7},
number = {4},
pages = {573-587},
year = {2018},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2018.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S209526351830044X},
author = {Aurel {von Richthofen} and Katja Knecht and Yufan Miao and Reinhard König},
keywords = {Urban design education, Parametric urban design, Singapore, Urban Elements},
abstract = {The article proposes a method for teaching advanced urban design to working professionals in Singapore. The article aims to expand the discourse on parametric urban design education by introducing ‘Urban Elements’ as conceptual urban design instruments with an inherent rule-based logic, which can help to bridge gaps in teaching parametric urban design thinking. As case study we present a course developed for and delivered to the Urban Redevelopment Authority (URA) in Singapore in 2017 by the Future Cities Laboratory at the Singapore-ETH Centre. The article reports on the pedagogical method, course results and course feedback. The main difficulties of teaching professionals in parametric urban design are described and possible reasons and improvements are discussed. The results show that participants using the ‘Urban Elements’ method successfully linked theoretical input to urban design problems, applied evidence-based urban design strategies to these problems, and developed parametric definitions to explore the solution spaces of these urban design challenges. The teaching methodology presented opens up a new research field for urban design pedagogy at the intersection of explicating urban design intent, integrating multidisciplinary knowledge and exploring new software driven tools.}
}
@article{KASHYAPKASHYAP2021395,
title = {The universal language: mathematics or music?},
journal = {Journal for Multicultural Education},
volume = {15},
number = {4},
pages = {395-415},
year = {2021},
issn = {2053-535X},
doi = {https://doi.org/10.1108/JME-05-2021-0064},
url = {https://www.sciencedirect.com/science/article/pii/S2053535X21000197},
author = {RaviRavi KashyapKashyap},
keywords = {Mathematics, Multicultural, Music, Education policy, Artistic encoding of knowledge, Universal language},
abstract = {Purpose
Music could be a challenger for mathematics and a potential candidate for the title “The Universal Language.” This paper aims to discuss the primary objectives of engaging with music, including the therapeutic benefits. Similarities, between mathematics and music and how studying one might enhance one’s abilities of the other are pointed out.
Design/methodology/approach
A formal definition for a universal language is given. A qualitative approach, supplemented with rigorous reasoning, is adopted. The narrative relies on the author’s experiences, teaching mathematical concepts and musical interactions, with students from several countries. A vast amount of literature is reviewed and the corresponding findings are connected toward the arguments made.
Findings
The paper demonstrates that one day, once we understand both mathematics and music better, we might see both of them as the same language. Until then, it is essential to supplement mathematics with music. The educational implications, for all fields, are to ensure that the future creators of knowledge are equally adept at both music and mathematics. The wider policy connotations are to create a blueprint for a society with a vibrant musical and artistic environment.
Originality/value
This study illuminates new ways of thinking about music and mathematics. The possibility that many seemingly complex entities (including our universe, virtual computer worlds, mathematical operations, etc.), are made up of combinations of much simpler building blocks is hinted at. Familiarity with any intricate element of life, without getting flustered, is bound to produce remarkable results in other such endeavors.}
}
@article{LAVALLEY2024108825,
title = {Transdiagnostic failure to adapt interoceptive precision estimates across affective, substance use, and eating disorders: A replication and extension of previous results},
journal = {Biological Psychology},
volume = {191},
pages = {108825},
year = {2024},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2024.108825},
url = {https://www.sciencedirect.com/science/article/pii/S030105112400084X},
author = {Claire A. Lavalley and Navid Hakimi and Samuel Taylor and Rayus Kuplicki and Katherine L. Forthman and Jennifer L. Stewart and Martin P. Paulus and Sahib S. Khalsa and Ryan Smith},
keywords = {Interoception, Depression, Anxiety, Substance use, Eating disorders, Precision, Priors, Bayesian perception, Computational modeling},
abstract = {Recent Bayesian theories of interoception suggest that perception of bodily states rests upon a precision-weighted integration of afferent signals and prior beliefs. In a previous study, we fit a computational model of perception to behavior on a heartbeat tapping task to test whether aberrant precision-weighting could explain misestimation of cardiac states in psychopathology. We found that, during an interoceptive perturbation designed to amplify afferent signal precision (inspiratory breath-holding), healthy individuals increased the precision-weighting assigned to ascending cardiac signals (relative to resting conditions), while individuals with anxiety, depression, substance use disorders, and/or eating disorders did not. In this pre-registered study, we aimed to replicate and extend our prior findings in a new transdiagnostic patient sample (N = 285) similar to the one in the original study. As expected, patients in this new sample were also unable to adjust beliefs about the precision of cardiac signals – preventing the ability to accurately perceive changes in their cardiac state. Follow-up analyses combining samples from the previous and current study (N = 719) also afforded power to identify group differences between narrower diagnostic categories, and to examine predictive accuracy when logistic regression models were trained on one sample and tested on the other. With this confirmatory evidence in place, future studies should examine the utility of interoceptive precision measures in predicting treatment outcomes and test whether these computational mechanisms might represent novel therapeutic targets.}
}
@article{EVANS2022281,
title = {The explainability paradox: Challenges for xAI in digital pathology},
journal = {Future Generation Computer Systems},
volume = {133},
pages = {281-296},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22000838},
author = {Theodore Evans and Carl Orge Retzlaff and Christian Geißler and Michaela Kargl and Markus Plass and Heimo Müller and Tim-Rasmus Kiehl and Norman Zerbe and Andreas Holzinger},
keywords = {Explainable AI, Digital pathology, Usability, Trust, Artificial intelligence},
abstract = {The increasing prevalence of digitised workflows in diagnostic pathology opens the door to life-saving applications of artificial intelligence (AI). Explainability is identified as a critical component for the safety, approval and acceptance of AI systems for clinical use. Despite the cross-disciplinary challenge of building explainable AI (xAI), very few application- and user-centric studies in this domain have been carried out. We conducted the first mixed-methods study of user interaction with samples of state-of-the-art AI explainability techniques for digital pathology. This study reveals challenging dilemmas faced by developers of xAI solutions for medicine and proposes empirically-backed principles for their safer and more effective design.}
}
@article{NG2024100090,
title = {Using cospaces in augmented reality digital story creation: A thematic analysis},
journal = {Computers & Education: X Reality},
volume = {5},
pages = {100090},
year = {2024},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2024.100090},
url = {https://www.sciencedirect.com/science/article/pii/S2949678024000400},
author = {Davy Tsz Kit Ng and Wan Yee Winsy Lai and Morris Siu-yung Jong and Chi Wui Ng},
keywords = {Digital storytelling, CoSpaces, Online community, Augmented reality, Language learning},
abstract = {With the digital affordances of augmented reality (AR) technologies, research has shown their value for contextualized, interactive and collaborative language learning through supporting real-world immersion. In recent years, CoSpaces has been a popular AR learning tool with an extensive library of 3D models and constructive gadgets, as well as a visual programming platform. With this tool, students can create projects of digital stories by building personalized AR artifacts, scenes, and storylines, and then share their projects in a dynamic and global community of children. This study examined the characteristics of 39 selected CoSpaces’ open projects via thematic analysis and categorization into five learning contexts: (1) art, history, culture and design, (2) STEM, (3) classroom English and everyday communication, (4) fairy tale/literature, and (5) campus tour. Furthermore, this study identified six language learning competencies derived from digital story creation: (1) discovering knowledge, (2) connecting to prior experience and knowledge, (3) conducting research, (4) problem-solving, (5) expressing and creating digitally, as well as (6) presenting, appreciating and evaluating. Digital literacy refers to the ability to use technology to find, evaluate, create, and communicate information. In addition, three major types of digital literacy skills necessary for AR digital storytelling processes have been identified, encompassing digital creativity, technoligcal proficiency, and research skills. Our results contribute to discovering educational values in developing digital language competency through AR digital story creation. Recommendations are offered for future research and for educators to design appropriate AR learning experiences.}
}
@article{20213341,
title = {Tim Behrens},
journal = {Neuron},
volume = {109},
number = {21},
pages = {3341-3343},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.09.047},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321007200},
abstract = {Summary
Tim Behrens discusses with Neuron creative ways to facilitate virtual meetings, the multiple ways that the pandemic has affected different people, and his advice for the younger generation of neuroscientists in general and computational scientists in particular.}
}
@article{LEUKHIN2018166,
title = {Bio-plausible simulation of three monoamine systems to replicate emotional phenomena in a machine},
journal = {Biologically Inspired Cognitive Architectures},
volume = {26},
pages = {166-173},
year = {2018},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2018.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X1830152X},
author = {Alexey Leukhin and Max Talanov and Jordi Vallverdú and Fail Gafarov},
keywords = {Affective computing, Affective computation, Spiking neural networks, Bio-inspired cognitive architecture},
abstract = {In this paper we present the validation of the three-dimensional model of emotions by Hugo Lövheim the “cube of emotion” via neurosimulation in the NEST. We also present the extension of original “cube of emotion” with the bridge to computational processes parameters. The neurosimulation is done via re-implementation of DA, 5-HT and NA subsystems of a rat brain to replicate 8 basic psycho-emotional states according to the “cube of emotion”. Results of neurosimulations indicate the incremental influence of DA and NA over computational resources of a psycho-emotional state while 5-HT decreases the computational resources used to calculate a psycho-emotional state. This way we indicate the feasibility of the bio-plausible re-implementation of psycho-emotional states in a computational system. This approach could be useful extension of decision making and load balancing components of modern artificial agents as well as intelligent robotic systems.}
}
@article{PAMPLONA2020100189,
title = {An overview of air delay: A case study of the Brazilian scenario},
journal = {Transportation Research Interdisciplinary Perspectives},
volume = {7},
pages = {100189},
year = {2020},
issn = {2590-1982},
doi = {https://doi.org/10.1016/j.trip.2020.100189},
url = {https://www.sciencedirect.com/science/article/pii/S2590198220301007},
author = {Daniel Alberto Pamplona and Claudio Jorge Pinto Alves},
keywords = {Air delay, Air traffic flow, Problem-structuring method, Value-focused thinking},
abstract = {Delay is a key point in air transportation activity. As a performance metric, it affects common policy concerns. Delay impacts passenger satisfaction and imposes costs. The complexity that sets in for the air traffic manager is how to mitigate delay, especially in an environment with several stakeholders. The present article applied a problem-structuring method (PSM), named value-focused thinking (VFT), to structure the problem of the air traffic flow management arrival delay. The inflexibility of incorporating a flight operator's specific needs is considered one of the reasons for the limited success of air traffic flow management (ATFM) programs. PSM allows participants to clarify their dilemmas, converge on a mutually liable problem, or agree to the proposed solutions and compromise on what partially solves the issue. The problem is that most papers focus only on the applied solution for air delay mitigation. Before implementing operational research techniques, we investigated the nature and characteristics of air delay. Results showed that there were several stakeholders with distinctive requirements for their business and many of their objectives are interconnected. The use of VFT provided an objective map that can be used as a guide for future solutions.}
}
@article{RASANAN2024857,
title = {Beyond discrete-choice options},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {9},
pages = {857-870},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S136466132400175X},
author = {Amir Hosein Hadian Rasanan and Nathan J. Evans and Laura Fontanesi and Catherine Manning and Cynthia Huang-Pollock and Dora Matzke and Andrew Heathcote and Jörg Rieskamp and Maarten Speekenbrink and Michael J. Frank and Stefano Palminteri and Christopher G. Lucas and Jerome R. Busemeyer and Roger Ratcliff and Jamal Amani Rad},
abstract = {While decision theories have evolved over the past five decades, their focus has largely been on choices among a limited number of discrete options, even though many real-world situations have a continuous-option space. Recently, theories have attempted to address decisions with continuous-option spaces, and several computational models have been proposed within the sequential sampling framework to explain how we make a decision in continuous-option space. This article aims to review the main attempts to understand decisions on continuous-option spaces, give an overview of applications of these types of decisions, and present puzzles to be addressed by future developments.}
}
@article{KANCHANATAWAN2018168,
title = {Affective symptoms in schizophrenia are strongly associated with neurocognitive deficits indicating disorders in executive functions, visual memory, attention and social cognition},
journal = {Progress in Neuro-Psychopharmacology and Biological Psychiatry},
volume = {80},
pages = {168-176},
year = {2018},
note = {Peripheral markers of inflammation, oxidative & nitrosative stress pathways and memory functions as a new target of pharmacotherapy in depression},
issn = {0278-5846},
doi = {https://doi.org/10.1016/j.pnpbp.2017.06.031},
url = {https://www.sciencedirect.com/science/article/pii/S027858461730129X},
author = {Buranee Kanchanatawan and Supaksorn Thika and George Anderson and Piotr Galecki and Michael Maes},
keywords = {Major depression, Bipolar, Anxiety, Schizophrenia, CANTAB, Cognition},
abstract = {The aim of this study was to assess the neurocognitive correlates of affective symptoms in schizophrenia. Towards this end, 40 healthy controls and 80 schizophrenia patients were investigated with six tests of the Cambridge Neuropsychological Test Automated Battery (CANTAB), assessing spatial working memory, paired-association learning, one touch stocking, rapid visual information (RVP), emotional recognition test and intra/extradimensional set shifting. The Hamilton Depression (HDRS) and Anxiety (HAMA) Rating Scales and the Calgary Depression Scale for Schizophrenia (CDSS) as well as the Positive and Negative Syndrome Scale (PANSS) were also used. There were highly significant associations between all 6 CANTAB tests and HDRS, HAMA and CDSS (except RVP) scores. The most significant items associating with neurocognitive impairments in schizophrenia were self-depreciation (CDSS), fatigue, psychomotor retardation and agitation, psychic and somatic anxiety (HDRS), fears, cognitive symptoms, somatic-muscular, genito-urinary and autonomic symptoms and anxious behavior (HAMA). The selected HDRS and HAMA symptoms indicate fatigue, fears, anxiety, agitation, retardation, somatization and subjective cognitive complaints (SCC) and are therefore labeled “FAARS”. Up to 28.8% of the variance in the 6 CANTAB measurements was explained by FAARS, which are better predictors of neurocognitive impairments than the PANSS negative subscale score. Neurocognitive deficits in schizophrenia are best predicted by FAARS combined with difficulties in abstract thinking. In conclusion, depression and anxiety symptoms accompanying the negative and positive symptoms of schizophrenia are associated with neurocognitive deficits indicating disorders in executive functions, attention, visual memory, and social cognition. Neurocognitive deficits in schizophrenia reflect difficulties in abstract thinking and FAARS, including subjective cognitive complaints.}
}
@article{HARWOOD201610,
title = {Locking up passwords – for good},
journal = {Network Security},
volume = {2016},
number = {4},
pages = {10-13},
year = {2016},
issn = {1353-4858},
doi = {https://doi.org/10.1016/S1353-4858(16)30037-X},
url = {https://www.sciencedirect.com/science/article/pii/S135348581630037X},
author = {Will Harwood},
abstract = {It's clear that bulk identity thefts – that is, the mass stealing of passwords or other personally identifiable information (PII) – are among the most harmful types of cyber-attack faced by businesses. They're a huge problem, not only in terms of the damage each attack causes, but also the volume of attacks overall. A cursory glance over the business headlines for the past few years announces huge password or PII thefts from organisations ranging from Sony PlayStation to eBay and Facebook to JP Morgan. We were barely a week into 2016 when it was revealed that email passwords for up to 320,000 users had been stolen from Time Warner. Bulk identity thefts are among the most harmful types of cyber-attack faced by businesses today and part of the problem is that businesses, security firms and cyber-criminals all share the same playing field. Thinking beyond standard computing architectures is the only solution to the ongoing arms race between hackers and security vendors. In a battle against cyber-criminality, in which businesses are always playing catch-up, this is a way of getting on the front foot and beginning to operate in a world beyond the attackers' reach, says Dr Will Harwood of Silicon:SAFE.}
}
@article{SHIVERSMCNAIR201836,
title = {User-Centered Design In and Beyond the Classroom: Toward an Accountable Practice},
journal = {Computers and Composition},
volume = {49},
pages = {36-47},
year = {2018},
note = {User-Centered Design and Usability in the Composition Classroom},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2018.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S8755461518300379},
author = {Ann Shivers-McNair and Joy Phillips and Alyse Campbell and Hanh H. Mai and Alice Yan and John Forrest Macy and James Wenlock and Savannah Fry and Yishan Guan},
keywords = {user-centered design, user experience, usability testing, design thinking},
abstract = {The authors, an instructor and students, describe our practice of user-centered design on three levels: in the design and structure of an advanced undergraduate course in which we all participated, in student projects designed during the course, and in our reflections on the course presented here. We argue that principles of user-centered design can and should be more than course concepts and assignments; they can be core practices of the course that hold both students and teachers accountable for the impacts of their rhetorical choices. We offer a model for other teacher-scholars looking to involve students in the design of their courses and in writing together about their work.}
}
@article{YANG2024109519,
title = {Global optimization strategy of prosumer data center system operation based on multi-agent deep reinforcement learning},
journal = {Journal of Building Engineering},
volume = {91},
pages = {109519},
year = {2024},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.109519},
url = {https://www.sciencedirect.com/science/article/pii/S2352710224010878},
author = {Dongfang Yang and Xiaoyuan Wang and Rendong Shen and Yang Li and Lei Gu and Ruifan Zheng and Jun Zhao and Xue Tian},
keywords = {Data center system, Global cooperative optimization, D3QN, VDN},
abstract = {The escalating issues of high energy consumption and carbon emissions in data centers (DCs) necessitate the optimization of system operations. However, early optimization strategies were overly simplistic and lacked automated updating and iterative capabilities. With the evolution of artificial intelligence (AI), researchers have applied deep reinforcement learning (DRL) algorithms to system operations. However, the optimization focus has been limited to the internal systems, lacking global optimization. In this paper, a global optimization control strategy based on the Dueling double-deep Q network (D3QN) and value decomposition network (VDN) algorithms is proposed to make the DCs system operate more closely with the upstream, midstream, and downstream. By adjusting battery charging/discharging capacity, computational workload, and waste heat utilization heating temperature global synergistic optimization is achieved. Compared with without optimization, renewable energy waste, operation cost, total electricity consumption, and grid electricity consumption are reduced by 18.37%, 9.78%, 4.01%, and 29.74%, respectively. Additionally, a detailed comparison between non-algorithmic optimization and algorithmic optimization is provided, offering valuable insights for substantial energy savings and emissions reduction in DCs. The results demonstrate the importance of fully exploring the interactive potential between upstream energy supply, midstream computational workload, and downstream waste heat recovery to achieve synergistic global optimization of “computing power", “thermal energy" and “electrical energy" for the sustainable and green development of DCs or other prosumer buildings.}
}
@article{THAGARD1986301,
title = {Parallel computation and the mind-body problem},
journal = {Cognitive Science},
volume = {10},
number = {3},
pages = {301-318},
year = {1986},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(86)80020-9},
url = {https://www.sciencedirect.com/science/article/pii/S0364021386800209},
author = {Paul Thagard},
abstract = {The position in the philosophy of mind called functionalism claims that mental states are to be understood in terms of their functional relationships to other mental states, not in terms of their material instantiation in any particular kind of hardware. But the argument that material instantiation is irrelevant to functional relationships is computationally naive. This paper uses recent work on parallel computation to argue that software and hardware are much more intertwined than the functionalists allow. Parallelism offers qualitative as well as quantitative advantages, leading to different styles of programming as well as increased speed. Hence hardware may well matter to the mental: only by further empirical investigations of the relation between the mind and brain and between artificial intelligence software and underlying hardware will we be able to achieve a defensible solution to the mind-body problem. The major disadvantage of parallel systems is the need to coordinate their subprocesses, but recent proposals that consciousness provides a serial control for parallel computation are implausible.}
}
@article{MOEBEHRENS2013e201304003,
title = {THE BIOLOGICAL MICROPROCESSOR, OR HOW TO BUILD A COMPUTER WITH BIOLOGICAL PARTS},
journal = {Computational and Structural Biotechnology Journal},
volume = {7},
number = {8},
pages = {e201304003},
year = {2013},
issn = {2001-0370},
doi = {https://doi.org/10.5936/csbj.201304003},
url = {https://www.sciencedirect.com/science/article/pii/S200103701460026X},
author = {Gerd HG Moe-Behrens},
abstract = {Systemics, a revolutionary paradigm shift in scientific thinking, with applications in systems biology, and synthetic biology, have led to the idea of using silicon computers and their engineering principles as a blueprint for the engineering of a similar machine made from biological parts. Here we describe these building blocks and how they can be assembled to a general purpose computer system, a biological microprocessor. Such a system consists of biological parts building an input / output device, an arithmetic logic unit, a control unit, memory, and wires (busses) to interconnect these components. A biocomputer can be used to monitor and control a biological system.}
}
@article{BARNES2021,
title = {Gene Expression and Data Analysis Pipeline Using Cancer BioPortal in the Classroom},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2315},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000277},
author = {Chassidy N. Barnes and Blake P. Johnson and Stefanie W. Leacock and Ruben M. Ceballos and Lori L. Hensley and Nathan S. Reyna},
abstract = {At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis.
ABSTRACT
At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis. Cancer BioPortal (cBioPortal) is an open-access collective cancer research resource for storing and exploring clinical, genomic, proteomic, and transcriptomic data. cBioPortal eliminates the computational barrier of interpreting complex genomic data by providing easily understandable visualization that can be interpreted and translated into relevant biological insights. Because no prior computational knowledge is required, cBioPortal is an ideal educational tool for either in-person or distance learning environments. We developed a pedagogical approach, video tutorials, and data analysis workflows centered on using cBioPortal. Pedagogically, students develop an initial research outline that is continually updated and graded throughout the project. Progress during the project or course is assessed by a series of student presentations that are 5 to 15 min in length and are aimed at explaining the approach used in data acquisition, interpretation of the data, and relevance to the initial hypothesis. While cancer-specific, this analysis platform appeals to a wide range of classes and student interests. Further, the project has been successfully done both as an independent research experience and as part of a virtual class-based research project.}
}
@article{MILDNER2019763,
title = {Spontaneous Thought as an Unconstrained Memory Process},
journal = {Trends in Neurosciences},
volume = {42},
number = {11},
pages = {763-777},
year = {2019},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2019.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0166223619301626},
author = {Judith N. Mildner and Diana I. Tamir},
keywords = {spontaneous thought, memory, computational model, mind wandering, default network},
abstract = {The stream of thought can flow freely, without much guidance from attention or cognitive control. What determines what we think about from one moment to the next? Spontaneous thought shares many commonalities with memory processes. We use insights from computational models of memory to explain how the stream of thought flows through the landscape of memory. In this framework of spontaneous thought, semantic memory scaffolds episodic memory to form the content of thought, and drifting context modulated by one's current state – both internal and external – constrains the area of memory to explore. This conceptualization of spontaneous thought can help to answer outstanding questions such as: what is the function of spontaneous thought, and how does the mind select what to think about?}
}
@article{PIETARINEN2025105410,
title = {Synechism 2.0: Contours of a new theory of continuity in bioengineering},
journal = {BioSystems},
volume = {250},
pages = {105410},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2025.105410},
url = {https://www.sciencedirect.com/science/article/pii/S0303264725000206},
author = {Ahti-Veikko Pietarinen and Vera Shumilina},
keywords = {Charles S. Peirce, Synechism, Collective agency, Synthetic intelligence, Michael E. Levin, Bioengineering, Bioelectricity},
abstract = {The methodological principle of synechism, the all-pervading continuity first proposed by Charles Peirce in 1892, is reinvigorated in the present paper to prompt a comprehensive reevaluation of the integrated concepts of life, machines, agency, and intelligence. The evidence comes from the intersections of synthetic bioengineering, developmental biology, and cognitive and computational sciences. As a regulative principle, synechism, “that continuity governs the whole domain of experience in every element of it”, has been shown to infiltrate fundamental issues of contemporary biology, including cognition in different substrates, embodied agency, collectives (swarm and nested), intelligence on multiple scales, and developmental bioelectricity in morphogenesis. In the present paper, we make explicit modern biology's turn to this fundamental feature of science in its rejection of conceptual binaries, preference for collectives over individuals, quantitative over qualitative, and multiscale applicability of the emerging hypotheses about the integration of the first principles of the diversity of life. Specifically, synechism presents itself as the bedrock for research encompassing biological machines, chimaeras, organoids, and Xenobots. We then review a synechistic framework that embeds functionalist, information-theoretic, pragmaticist and inferentialist approaches to springboard to continuum-driven biosystemic behaviour.}
}
@article{MENG201851,
title = {Conducting highly principled data science: A statistician’s job and joy},
journal = {Statistics & Probability Letters},
volume = {136},
pages = {51-57},
year = {2018},
note = {The role of Statistics in the era of big data},
issn = {0167-7152},
doi = {https://doi.org/10.1016/j.spl.2018.02.053},
url = {https://www.sciencedirect.com/science/article/pii/S0167715218300981},
author = {Xiao-Li Meng},
keywords = {Astrostatistics, Computational efficiency, Principled corner cutting, Scientific justification},
abstract = {Highly Principled Data Science insists on methodologies that are: (1) scientifically justified; (2) statistically principled; and (3) computationally efficient. An astrostatistics collaboration, together with some reminiscences, illustrates the increased roles statisticians can and should play to ensure this trio, and to advance the science of data along the way.}
}
@article{VEGA2008255,
title = {The catwalk task: Reflections and synthesis: Part 2},
journal = {The Journal of Mathematical Behavior},
volume = {27},
number = {4},
pages = {255-263},
year = {2008},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2009.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312309000042},
author = {Emiliano Vega and Shawn Hicks},
keywords = {Modeling, Representation, Teacher learning, Task design},
abstract = {In this article we recount our experiences with a series of encounters with the catwalk task and reflect on the professional growth that these opportunities afforded. First, we individually reflect on our own mathematical work on the catwalk task. Second, we reflect on our experiences working with a group of community college students on the catwalk task and our interpretations of their mathematical thinking. In so doing we also detail a number of innovative and novel student-generated representations of the catwalk photos. Finally, we each individually reflect on the entire experience with the catwalk problem, as mathematics learners, as teachers, and as professionals.}
}
@incollection{STEEDMAN2011925,
title = {21 - Temporality},
editor = {Johan {van Benthem} and Alice {ter Meulen}},
booktitle = {Handbook of Logic and Language (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {London},
pages = {925-969},
year = {2011},
isbn = {978-0-444-53726-3},
doi = {https://doi.org/10.1016/B978-0-444-53726-3.00021-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780444537263000219},
author = {Mark Steedman},
keywords = {tense, aspect, natural language semantics, computational semantics, temporal semantics, aktionsarten, causality, evidentiality},
abstract = {Publisher Summary
In thinking about the logical and computational semantics of temporal categories in natural languages, issues of temporal ontology, or metaphysics, must be distinguished from issues of temporal relation. The first thing to observe about the temporal ontology implicit in natural languages is that it is not purely temporal. To take a simple example, the English perfect, when predicated of an event like losing a watch, says that some contextually retrievable consequences of the event in question hold at the time under discussion. Thus, conjoining such a perfect with a further clause denying those consequences is infelicitous. The claim that the semantics depends directly on the conceptual representation of action and contingency suggests that this semantics might be universal, despite considerable differences in its syntactic and morphological encoding across languages. The work described in this chapter suggests that such differences across languages are superficial. Ironically, the English tense/aspect system seems to be based on semantic primitives remarkably like those, which Whorf ascribed to Hopi. Matters of temporal sequence and temporal locality seem to be quite secondary to matters of perspective and contingency. This observation in turn suggests that the semantics of tense and aspect is profoundly shaped by concerns with goals, actions, and consequences, and that temporality in the narrow sense of the term is merely one facet of this system among many.}
}
@article{ROBINSON20231189,
title = {Opportunities and challenges for microbiomics in ecosystem restoration},
journal = {Trends in Ecology & Evolution},
volume = {38},
number = {12},
pages = {1189-1202},
year = {2023},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2023.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0169534723002112},
author = {Jake M. Robinson and Riley Hodgson and Siegfried L. Krauss and Craig Liddicoat and Ashish A. Malik and Belinda C. Martin and Jakki J. Mohr and David Moreno-Mateos and Miriam Muñoz-Rojas and Shawn D. Peddle and Martin F. Breed},
keywords = {ecosystem restoration, microbiome, microbiomics, metagenomics, restoration ecology, innovation},
abstract = {Microbiomics is the science of characterizing microbial community structure, function, and dynamics. It has great potential to advance our understanding of plant–soil–microbe processes and interaction networks which can be applied to improve ecosystem restoration. However, microbiomics may be perceived as complex and the technology is not accessible to all. The opportunities of microbiomics in restoration ecology are considerable, but so are the practical challenges. Applying microbiomics in restoration must move beyond compositional assessments to incorporate tools to study the complexity of ecosystem recovery. Advances in metaomic tools provide unprecedented possibilities to aid restoration interventions. Moreover, complementary non-omic applications, such as microbial inoculants and biopriming, have the potential to improve restoration objectives by enhancing the establishment and health of vegetation communities.}
}
@article{SPENCE2022100433,
title = {Gastrophysics: Getting creative with pairing flavours},
journal = {International Journal of Gastronomy and Food Science},
volume = {27},
pages = {100433},
year = {2022},
issn = {1878-450X},
doi = {https://doi.org/10.1016/j.ijgfs.2021.100433},
url = {https://www.sciencedirect.com/science/article/pii/S1878450X21001323},
author = {Charles Spence},
keywords = {Food pairing, Flavour pairing hypothesis, Sonic seasoning, Computational gastronomy, Data engineering, Gastrophysics},
abstract = {Traditionally, in the West, the decision about which flavours to pair in a tasting experience has been as much the personal choice of the chef or, more likely, the sommelier, as anything else. However, the last couple of decades have seen a rapid growth of research interest in the pairing of flavours. Nowadays, one can find examples of people pairing everything from beer with food, tea with cheese and chocolate, etc. As interest in the marketing potential of flavour pairing has risen, along with the growing public fascination in the topic, scientists have become increasingly interested in trying to understand the principles (both cognitive/intellectual and perceptual) underlying the successful pairing of flavours. In this narrative review, the relative strengths and weaknesses of the chemical, computational (gastronomy), and perceptual approaches to pairing flavours are highlighted. Thereafter, I show how the various principles of pairing (both perceptual and cognitive/intellectual) can be extended beyond the domain of pairing flavour with flavour to consider the rapidly growing are of sonic seasoning. The latter term refers to those situations in which specific pieces of music or soundscapes are matched, or paired, with particular tastes/flavours based on the crossmodal correspondences. The review ends by considering the future development of pairings flavours, and assessing novel means of establishing connections between flavours and other sensations.}
}
@article{COON1995787,
title = {Generalized block-tridiagonal matrix orderings for parallel computation in process flowsheeting},
journal = {Computers & Chemical Engineering},
volume = {19},
number = {6},
pages = {787-805},
year = {1995},
note = {Applications of Parallel Computing},
issn = {0098-1354},
doi = {https://doi.org/10.1016/0098-1354(94)00081-6},
url = {https://www.sciencedirect.com/science/article/pii/0098135494000816},
author = {A.B. Coon and M.A. Stadtherr},
abstract = {A new graph partitioning algorithm for use on structurally unsymmetric systems is presented. Unlike other partitioning algorithms that have been used to provide reorderings for structurally symmetric matrices, this algorithm employs a bipartite graph model, and hence, can be used to consider unsymmetric permutations of structurally unsymmetric matrices. It is shown that the algorithm can be used in identifying coarse-granular, balanced tasks in the direct solution of flowsheeting matrices by parallel techniques based on generalized block-tridiagonal and nested-block-tridiagonal matrix structures. It is also shown that such reorderings can be obtained inexpensively, in worst-case running times that increase linearly with the order of the matrix.}
}
@article{BOSCH2017,
title = {Graduate Biomedical Science Education Needs a New Philosophy},
journal = {mBio},
volume = {8},
number = {6},
year = {2017},
issn = {2150-7511},
doi = {https://doi.org/10.1128/mbio.01539-17},
url = {https://www.sciencedirect.com/science/article/pii/S2161212917003111},
author = {Gundula Bosch and Arturo Casadevall},
keywords = {Ph.D., education, graduate},
abstract = {ABSTRACT
There is a growing realization that graduate education in the biomedical sciences is successful at teaching students how to conduct research but falls short in preparing them for a diverse job market, communicating with the public, and remaining versatile scientists throughout their careers. Major problems with graduate level education today include overspecialization in a narrow area of science without a proper grounding in essential critical thinking skills. Shortcomings in education may also contribute to some of the problems of the biomedical sciences, such as poor reproducibility, shoddy literature, and the rise in retracted publications. The challenge is to modify graduate programs such that they continue to generate individuals capable of conducting deep research while at the same time producing more broadly trained scientists without lengthening the time to a degree. Here we describe our first experiences at Johns Hopkins and propose a manifesto for reforming graduate science education.}
}
@article{MIDGLEY2019181,
title = {Anticipatory practice and the making of surplus food},
journal = {Geoforum},
volume = {99},
pages = {181-189},
year = {2019},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2018.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0016718518302720},
author = {Jane L. Midgley},
keywords = {Surplus food, Anticipation, Market devices, Redistribution, United Kingdom},
abstract = {This paper explores the practices that have evolved between a global food retailer and a leading charitable surplus food redistributor to enable the utilization of surplus food in community and charitable meal settings in the UK. I argue that to understand surplus food and its potential futures (consumed or wasted), closer engagement with anticipatory thinking is needed. Drawing on interview data with key stakeholders and observations of the food industry redistribution process the paper explores the anticipatory actions taken by different actors as they attempt to manage the possible futures of foods that become categorized as surplus. The paper shows how different market devices are used to manage market concerns about surplus food and work to assure its future consumption. The devices focus on managing the risks of the food becoming unsafe and the associated legal liabilities. The market concerns, as expressions of anticipatory thinking, inform a series of anticipatory practices throughout the redistribution process to enable all actors, and especially the Retailer, to trust in the process. The paper concludes by noting how reliant the redistribution process is on anticipatory practices, especially pre-emption and improvisation to make the process workable, but also how these work to contain the various concerns within market arrangements. The paper highlights the importance of anticipation as a theoretical basis for exploring surplus food and the concept of surplus more widely.}
}
@article{DELLANNA2022105064,
title = {Evolving Fuzzy logic Systems for creative personalized Socially Assistive Robots},
journal = {Engineering Applications of Artificial Intelligence},
volume = {114},
pages = {105064},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105064},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622002251},
author = {Davide Dell’Anna and Anahita Jamshidnejad},
keywords = {Evolving Fuzzy logic Systems, Personalized Socially Assistive Robots, Robot creativity},
abstract = {Socially Assistive Robots (SARs) are increasingly used in dementia and elderly care. In order to provide effective assistance, SARs need to be personalized to individual patients and account for stimulating their divergent thinking in creative ways. Rule-based fuzzy logic systems provide effective methods for automated decision-making of SARs. However, expanding and modifying the rules of fuzzy logic systems to account for the evolving needs, preferences, and medical conditions of patients can be tedious and costly. In this paper, we introduce EFS4SAR, a novel Evolving Fuzzy logic System for Socially Assistive Robots that supports autonomous evolution of the fuzzy rules that steer the behavior of the SAR. EFS4SAR combines traditional rule-based fuzzy logic systems with evolutionary algorithms, which model the process of evolution in nature and have shown to result in creative behaviors. We evaluate EFS4SAR via computer simulations on both synthetic and real-world data. The results show that the fuzzy rules evolved over time are not only personalized with respect to the personal preferences and therapeutic needs of the patients, but they also meet the following criteria for creativity of SARs: originality and effectiveness of the therapeutic tasks proposed to the patients. Compared to existing evolving fuzzy systems, EFS4SAR achieves similar effectiveness with higher degree of originality.}
}
@article{KAMARI2017330,
title = {Sustainability focused decision-making in building renovation},
journal = {International Journal of Sustainable Built Environment},
volume = {6},
number = {2},
pages = {330-350},
year = {2017},
issn = {2212-6090},
doi = {https://doi.org/10.1016/j.ijsbe.2017.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S221260901730064X},
author = {Aliakbar Kamari and Rossella Corrao and Poul Henning Kirkegaard},
keywords = {Sustainability, Building renovation, Decision support, Knowledge management, Soft Systems Methodology (SSM), Value Focused Thinking (VFT)},
abstract = {An overview of recent research related to building renovation has revealed that efforts to date do not address sustainability issues comprehensively. The question then arises in regard to the holistic sustainability objectives within building renovation context. In order to deal with this question, the research adopts a multi-dimensional approach involving literature review, exploration of existing assessment methods and methodologies, individual and focus group interviews, and application of Soft Systems Methodologies (SSM) with Value Focused Thinking (VFT). In doing so, appropriate data about sustainability objectives have been collected and structured, and subsequently verified using a Delphi study. A sustainability framework was developed in cooperation with University of Palermo and Aarhus University to audit, develop and assess building renovation performance, and support decision-making during the project’s lifecycle. The paper represents the results of research aiming at addressing sustainability of the entire renovation effort including new categories, criteria, and indicators. The developed framework can be applied during different project stages and to assist in the consideration of the sustainability issues through support of decision-making and communication with relevant stakeholders. Early in a project, it can be used to identify key performance criteria, and later to evaluate/compare the pros and cons of alternative retrofitting solutions either during the design stage or upon the project completion. According to the procedure of the consensus-based process for the development of an effective sustainability decision-making framework which was employed in this study, the outcome can also be considered as an outset step intended for the establishment of a Decision Support Systems (DSS) and assessment tool suited to building renovation context.}
}
@article{ENE2016973,
title = {A genetic algorithm for minimizing energy consumption in warehouses},
journal = {Energy},
volume = {114},
pages = {973-980},
year = {2016},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2016.08.045},
url = {https://www.sciencedirect.com/science/article/pii/S0360544216311586},
author = {Seval Ene and İlker Küçükoğlu and Aslı Aksoy and Nursel Öztürk},
keywords = {Genetic algorithm, Green supply chain, Minimization of energy consumption, Warehouse management},
abstract = {Green supply chain management is generally defined as integration of green thinking and environmental issues into the whole supply chain operations like product design, manufacturing process, warehousing, distribution etc. Within this context green principles should be adopted in warehouse management to minimize negative impact on the environment. In warehouse operations, picking must be analyzed attentively which is widely studied in literature for minimizing service time levels because of its close relation to the higher costs. The efficiency of picking in warehouses mainly depends on storage assignment policy that directly affects picking performance in warehouses. In this paper, picking operation in warehouses is studied to minimize energy consumption with proper storage policy other than service time. Genetic algorithm (GA) is proposed to solve the problem and numerical examples are presented to demonstrate the performance of the GA. Results show that, the GA gives efficient solutions to the problem.}
}
@article{EARL2019303,
title = {Elusive optima: A process tracing analysis of procedural rationality in mobile phone connection plan choices},
journal = {Journal of Economic Behavior & Organization},
volume = {161},
pages = {303-322},
year = {2019},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2019.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167268119300988},
author = {Peter E. Earl and Lana Friesen and Christopher Shadforth},
keywords = {Consumer capabilities, Choice overload, Procedural rationality, Process tracing},
abstract = {This paper reports an experiment in which subjects were rewarded on the basis of how close they came to finding the cheapest mobile phone plan to serve a particular usage remit by searching freely in the Internet. During the task, subjects were required to ‘think aloud’ and recordings were made of what they said and what they did on their computer screens. Analysis of the screen-capture movie recordings revealed major shortfalls in procedural rationality, including poor strategic thinking about how to deal with choice overload, poor conceptual understanding of mobile phone plans and pricing systems, as well as cognitive and calculation errors. Our novel method leads to a very different policy focus from that implied by viewing the problem in terms of excess information per se and irrationality as driven by innate heuristics and biases.}
}
@article{LI2022126546,
title = {Dynamic forecasting performance and liquidity evaluation of financial market by Econophysics and Bayesian methods},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {588},
pages = {126546},
year = {2022},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2021.126546},
url = {https://www.sciencedirect.com/science/article/pii/S0378437121008190},
author = {Jiang-Cheng Li and Chen Tao and Hai-Feng Li},
keywords = {Econophysics, Agent-based model, Liquidity risk assessment, Machine learning thinking, Microcosmic evolution models},
abstract = {In a complex financial system, what is the forecasting performance of macro and micro evolution models of Econophysics on asset prices? For this problem, from the perspective of machine learning, we study the dynamic forecasting and liquidity assessment of financial markets, based on econophysics and Bayesian methods. We establish eight dynamic prediction methods, based on our proposed likelihood estimation and Bayesian estimation methods of macro and micro evolution models of econophysics. Combined machine learning thinking and real data, we empirically study and simulate the out-of-sample dynamic forecasting analysis of eight proposed methods and compare with the benchmark GARCH model. A variety of loss functions, superior predictive ability test (SPA), Akaike and Bayesian information criterion (AIC and BIC) methods are introduced to further evaluate the forecasting performance of our proposed methods. The research of out of sample prediction shows that (1) the method of the simplified stochastic model with Bayesian method for only sample return has the best forecasting performance; (2) the method of the stochastic model with Bayesian method for only return samples has the worst forecasting performance. For the liquidity assessment problem, there is a strong correlation between the trading probability evaluated by the proposed eight methods and the real turnover rate, and an increase of liquidity is correspond to the increase of asset risk. In other words, it suggests that all proposed methods can well evaluate market liquidity.}
}
@article{WHITE200337,
title = {Promoting productive mathematical classroom discourse with diverse students},
journal = {The Journal of Mathematical Behavior},
volume = {22},
number = {1},
pages = {37-53},
year = {2003},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(03)00003-8},
url = {https://www.sciencedirect.com/science/article/pii/S0732312303000038},
author = {Dorothy Y. White},
keywords = {Classroom discourse, Questioning techniques, Equity/diversity, Elementary mathematics teaching},
abstract = {Productive mathematical classroom discourse allows students to concentrate on sense making and reasoning; it allows teachers to reflect on students’ understanding and to stimulate mathematical thinking. The focus of the paper is to describe, through classroom vignettes of two teachers, the importance of including all students in classroom discourse and its influence on students’ mathematical thinking. Each classroom vignette illustrates one of four themes that emerged from the classroom discourse: (a) valuing students’ ideas, (b) exploring students’ answers, (c) incorporating students’ background knowledge, and (d) encouraging student-to-student communication. Recommendations for further research on classroom discourse in diverse settings are offered.}
}
@article{HUANG201724,
title = {Energy and carbon performance evaluation for buildings and urban precincts: review and a new modelling concept},
journal = {Journal of Cleaner Production},
volume = {163},
pages = {24-35},
year = {2017},
note = {Achieving Low/no Fossil-carbon Economies based upon the Essential Transformations to Support them},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2015.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0959652615018235},
author = {Bin Huang and Ke Xing and Stephen Pullen},
keywords = {Buildings, Integrated modelling, Life cycle energy, Systems thinking, Urban precincts},
abstract = {With the accelerating pace of urbanisation around the world, the planning, development and operation of buildings and precincts have become increasingly important with respect to energy use and the associated carbon footprint of the modern built environment. Over recent decades, much effort, both in research and in practice, has been devoted to building construction and urban planning for the improvement of energy efficiency and greenhouse gas emissions. However, the accuracy of modelling and evaluation of energy and carbon performance for buildings and urban precincts remains limited, affected by inadequate energy intensity data and highly integrated building systems, as well as the complex interactions between buildings and the urban eco-system. This paper presents a critical review of current measures and models for representing and assessing life cycle energy as well as associated emissions profiles at both the building and the precinct levels. It also identifies influential factors and explores interactions among buildings, surrounding environment and user behaviours at the urban precinct level by taking a systems perspective. Based on such a review, this study maps out some key challenges for integrating energy and carbon metrics, and finally proposes a precinct-level system boundary definition and an integrated model following systems thinking. The proposed model can facilitate a critical thinking approach about the evaluations of global energy and emissions, and support the quantification of energy consumption and associated emissions for building precinct systems.}
}
@article{MOLNAR20152667,
title = {Three Dimensional Applications in Teaching and Learning Processes},
journal = {Procedia - Social and Behavioral Sciences},
volume = {191},
pages = {2667-2673},
year = {2015},
note = {The Proceedings of 6th World Conference on educational Sciences},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.04.600},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815028608},
author = {György Molnár and András Benedek},
keywords = {ICT, 3D interactive system, new learning potential, Leonar3Do ;},
abstract = {In the world of today's information society the torrent of information we are dailyfaced with has to be appropriately transformed and translated in order to yield representationswe are somehow capable of understanding. By extending 2D representations to three-dimensional ones, pictorialcontents become more lifelike, getting closer to practice, creating the basis for a new view ofpictorial thinking, giving rise to the emergence to a very effective method of dealing withinformation overload. To depict three-dimensionalreality onto a two-dimensional plane of course constitutes an age-old scientific problem, theprincipal aim of the technique sought after being the exact representation.We also present a general review of Hungarian and international experienceson ICT application and its environment that comply with current practice.}
}
@article{MOSTERT202448,
title = {The Shortfalls of Mental Health Compartment Models: A Call to Improve Mental Health Investment Cases in Developing Countries},
journal = {Value in Health Regional Issues},
volume = {41},
pages = {48-53},
year = {2024},
issn = {2212-1099},
doi = {https://doi.org/10.1016/j.vhri.2023.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S2212109923001449},
author = {Cyprian M. Mostert and Andrew Aballa and Linda Khakali and Willie Njoroge and Jasmit Shah and Samim Hasham and Zul Merali and Lukoye Atwoli},
keywords = {developing countries, investment cases, mental health compartment model},
abstract = {Objectives
There are irregularities in investment cases generated by the Mental Health Compartment Model. We discuss these irregularities and highlight the costing techniques that may be introduced to improve mental health investment cases.
Methods
This analysis uses data from the World Bank, the World Health Organization Mental Health Compartment Model, the United Nations Development Program, the Kenya Ministry of Health, and Statistics from the Kenyan National Commission of Human Rights.
Results
We demonstrate that the Mental Health Compartment Model produces irrelevant outcomes that are not helpful for clinical settings. The model inflated the productivity gains generated from mental health investment. In some cases, the model underestimated the economic costs of mental health. Such limitation renders the investment cases poor in providing valuable intervention points from the perspectives of both the users and the providers.
Conclusions
There is a need for further calibration and validation of the investment case outcomes. The current estimated results cannot be used to guide service provision, research, and mental health programming comprehensively.}
}
@article{SMYE2022105015,
title = {Interdisciplinary approaches to metastasis},
journal = {iScience},
volume = {25},
number = {9},
pages = {105015},
year = {2022},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2022.105015},
url = {https://www.sciencedirect.com/science/article/pii/S2589004222012871},
author = {Stephen W. Smye and Robert A. Gatenby},
abstract = {Summary
Interdisciplinary research is making a significant contribution to understanding metastasis - one of the grand challenges in cancer research. Examples drawn from apparently unconnected areas of physics, and described at a recent workshop on metastasis, illustrate the value of interdiscplinary thinking.}
}
@article{YOON2021100865,
title = {United States and South Korean citizens’ interpretation and assessment of COVID-19 quantitative data},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100865},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100865},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000262},
author = {Hyunkyoung Yoon and Cameron O’Neill Byerley and Surani Joshua and Kevin Moore and Min Sook Park and Stacy Musgrave and Laura Valaas and James Drimalla},
keywords = {COVID-19, Graphs, Representations of quantitative data, Rate of change, Exponential growth},
abstract = {We investigate United States and South Korean citizens’ mathematical schemes and how these schemes supported or hindered their attempts to assess the severity of COVID-19. We selected web and media-based COVID-19 data representations that we hypothesized citizens would interpret differently depending on their mathematical schemes. We included items that we conjectured would be easier or more difficult to interpret with schemes that prior research had reported were more or less productive, respectively. We used the representations during clinical interviews with 25 United States and seven South Korean citizens. We illustrate that citizens’ mathematical schemes (as well as their beliefs) impacted how they assessed the severity of COVID-19. We present vignettes of citizens’ schemes that inhibited interpreting representations of COVID-19 in ways compatible with the displayed quantitative data, schemes that aided them in assessing the severity of COVID-19, and beliefs about the reliability of scientific data that overrode their mathematical conclusions.}
}
@incollection{LEACH202221,
title = {Chapter 2 - AI and the limits of human creativity in urban planning and design},
editor = {Imdat As and Prithwish Basu and Pratap Talwar},
booktitle = {Artificial Intelligence in Urban Planning and Design},
publisher = {Elsevier},
pages = {21-37},
year = {2022},
isbn = {978-0-12-823941-4},
doi = {https://doi.org/10.1016/B978-0-12-823941-4.00013-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128239414000135},
author = {Neil Leach},
keywords = {AlphaGo, AI, Strategy, Urban planning, Creativity, Perception},
abstract = {What can architects learn from AlphaGo? This chapter explores the lessons to be learnt from the famous match where AlphaGo, a machine-learning system developed by DeepMind, beat leading Korean Go player, Lee Sedol. It explores the ramifications of this victory on a series of different levels, from the global impact of the match on research into AI to the impact on Xkool Technologies and Spacemaker AI, two architectural start-ups developing AI systems for architecture and urban planning. It makes a particular comparison between the operations of AlphaGo and the strategic thinking of urban planning, arguing that AI now puts the future of urban planners—and possibly also architects—at risk. It then goes on to appraise the famous Move 37 made by AlphaGo in Game 2 of this match. It argues that, despite appearances, this move was not actually creative. Finally, it explores how we might view human creativity in the light of comments made about AlphaGo. The chapter concludes by speculating whether the ultimate lesson of AlphaGo is that creativity is simply a question of “perceived creativity.”}
}
@incollection{STAUFFER2006i,
title = {Biology, Sociology, Geology by Computational Physicists},
editor = {D. Stauffer and S. Moss {de Oliveira} and P.M.C. {de Oliveira} and J.S. Sá Martins},
series = {Monograph Series on Nonlinear Science and Complexity},
publisher = {Elsevier},
volume = {1},
pages = {i-276},
year = {2006},
booktitle = {Biology, Sociology, Geology by Computational Physicists},
issn = {1574-6917},
doi = {https://doi.org/10.1016/S1574-6917(05)01001-9},
url = {https://www.sciencedirect.com/science/article/pii/S1574691705010019},
author = {D. Stauffer and S. Moss {de Oliveira} and P.M.C. {de Oliveira} and J.S. Sá Martins}
}
@article{CAO2024101244,
title = {Explanatory models in neuroscience, Part 1: Taking mechanistic abstraction seriously},
journal = {Cognitive Systems Research},
volume = {87},
pages = {101244},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101244},
url = {https://www.sciencedirect.com/science/article/pii/S138904172400038X},
author = {Rosa Cao and Daniel Yamins},
keywords = {Mechanism, Models, Explanation, Constraints, Similarity, Mapping, Abstraction, Functional abstraction, Neural networks, Computation, Philosophy, Vision, Constraint, Prediction, Transform, Levels of explanation, Mechanistic explanation, Neuroscience, Understanding},
abstract = {Despite the recent success of neural network models in mimicking animal performance on various tasks, critics worry that these models fail to illuminate brain function. We take it that a central approach to explanation in systems neuroscience is that of mechanistic modeling, where understanding the system requires us to characterize its parts, organization, and activities, and how those give rise to behaviors of interest. However, it remains controversial what it takes for a model to be mechanistic, and whether computational models such as neural networks qualify as explanatory on this approach. We argue that certain kinds of neural network models are actually good examples of mechanistic models, when an appropriate notion of mechanistic mapping is deployed. Building on existing work on model-to-mechanism mapping (3M), we describe criteria delineating such a notion, which we call 3M++. These criteria require us, first, to identify an abstract level of description that is still detailed enough to be “runnable”, and then, to construct model-to-brain mappings using the same principles as those employed for brain-to-brain mapping across individuals. Perhaps surprisingly, the abstractions required are just those already in use in experimental neuroscience and deployed in the construction of more familiar computational models — just as the principles of inter-brain mappings are very much in the spirit of those already employed in the collection and analysis of data across animals. In a companion paper, we address the relationship between optimization and intelligibility, in the context of functional evolutionary explanations. Taken together, mechanistic interpretations of computational models and the dependencies between form and function illuminated by optimization processes can help us to understand why brain systems are built they way they are.}
}
@article{LOWENSTEIN20191237,
title = {Visual perception, cognition, and error in dermatologic diagnosis: Diagnosis and error},
journal = {Journal of the American Academy of Dermatology},
volume = {81},
number = {6},
pages = {1237-1245},
year = {2019},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2018.12.072},
url = {https://www.sciencedirect.com/science/article/pii/S0190962219303251},
author = {Eve J. Lowenstein and Richard Sidlow and Christine J. Ko},
keywords = {cognitive error, diagnostic error, heuristic, metacognition, patient safety, visual intelligence},
abstract = {Diagnostic error in dermatology is a large practice gap that has received little attention. Diagnosis in dermatology relies heavily on a heuristic approach that is responsible for our perception of clinical findings. To improve our diagnostic accuracy, a better understanding of the strengths and limitations of heuristics (cognitive shortcuts) used in dermatology is essential. Numerous methods have been proposed to improve diagnostic accuracy, including brain training, reducing cognitive load, and getting feedback and second opinions. Becoming comfortable with the uncertainty intrinsic to medicine is essential. Ultimately, the practice of metacognition, or thinking about how we think, can offer corrective insights to improve accuracy in diagnosis.}
}
@article{NARIMANI202441,
title = {Intelligent Control for Aerospace Engineers: A Novel Educational Framework},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {16},
pages = {41-46},
year = {2024},
note = {2nd IFAC Workshop on Aerospace Control Education - WACE 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.459},
url = {https://www.sciencedirect.com/science/article/pii/S240589632401228X},
author = {Mohammad Narimani and Seyyed Ali Emami and Paolo Castaldi},
keywords = {Aerospace control education, Intelligent control systems, Neural networks, Reinforcement learning, Model-based control, Adaptive control, Expert systems},
abstract = {The integration of intelligent control techniques into aerospace engineering education remains a challenge. This paper presents a novel approach for teaching intelligent control specifically designed for aerospace engineers, bridging the gap between theoretical foundations and practical applications. The proposed framework encompasses a comprehensive curriculum covering model-based and model-free approaches, leveraging neural networks, reinforcement learning, and other computational intelligence techniques. It emphasizes hands-on experiences through simulation-based exercises, hardware-in-the-loop experiments, and design projects tailored to different aerospace vehicle categories, including multi-rotor UAVs, helicopters, fixed-wing aircraft, and Hypersonic Flight Vehicles. The framework also addresses assessment methods, industry collaborations, and case studies to enhance student learning outcomes.}
}
@article{ZUO2010268,
title = {Integrating performance-based design in beginning interior design education: an interactive dialog between the built environment and its context},
journal = {Design Studies},
volume = {31},
number = {3},
pages = {268-287},
year = {2010},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2009.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X09000969},
author = {Qun Zuo and Wesley Leonard and Eileen E. MaloneBeach},
keywords = {performance-based design, interior design, design education, computer aided design, design process},
abstract = {This paper presents a new paradigm in interior design education in which building performance simulation was employed for decision making and design generation. Digital technology was intermixed with conventional paper-based media in the design process to explore formal, spatial and passive solar energy solutions. The intention of the study was to re-discover the value of computers in assisting design thinking and improving effective learning. The results indicated the Performance-Based Design approach resulted in an early awareness of sustainable energy for beginning interior design students. Further, it enhanced understanding of the mutual relationship between interior and exterior and between the built and natural environment. This paper acknowledged the achievements as well as limitations and future directions for the integration of Performance-Based Design into interior design curriculum.}
}
@incollection{NIE2019205,
title = {Two-Stage Land Use Optimization for A Food-Energy-Water Nexus System: A Case Study In Texas Edwards Region},
editor = {Salvador Garcia Muñoz and Carl D. Laird and Matthew J. Realff},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {47},
pages = {205-210},
year = {2019},
booktitle = {Proceedings of the 9th International Conference on Foundations of Computer-Aided Process Design},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-12-818597-1.50033-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128185971500333},
author = {Yaling Nie and Styliani Avraamidou and Xin Xiao and Efstratios N. Pistikopoulos and Jie Li},
keywords = {Land use optimization, Food-Energy-Water Nexus, multi-period planning},
abstract = {Efficient land use planning and scheduling in Food-Energy-Water Nexus (FEW-N) related systems is a complicated decision-making problem with resource competitions and conflicting objectives. Systematic thinking based on FEW-N is a necessity for modeling and optimization of the systems. However, challenges arise in making decisions while encountering conflicting objectives, multi-scale and multi-period problems, and multiple stakeholders. To address these challenges, we developed a generic optimization-based land allocation approach, which provides i) a composite FEW-N metric to help solve the multi-objective optimization problem and carry out assessments, and ii) a two-stage decomposition strategy to solve the multi-scale and multi-period planning and scheduling problem. The developed strategy was applied in a case study within the Texas Edwards Region. Computational results indicate that the approach can provide a comprehensive FEW-N metric to select strategies for optimal land allocation and limit stresses in the FEW-N, and achieve trade-off solutions for the multi-scale and multi-period FEW land use systems.}
}
@article{AYOUGH2025111141,
title = {Modeling workers rotation in divisional seru production systems},
journal = {Computers & Industrial Engineering},
pages = {111141},
year = {2025},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2025.111141},
url = {https://www.sciencedirect.com/science/article/pii/S0360835225002876},
author = {Ashkan Ayough and Fatameh Sadeghi Nouri and Behrooz Khorshidvand and Farbod Farhadi},
keywords = {Divisional  production system, Job rotation scheduling, Workforce adaptability, Invasive weed optimization},
abstract = {This study proposes a mathematical model for the job rotation problem in the Divisional seru Production System (DSPS) and develops an efficient solution algorithm. DSPS, a transitional phase toward a fully realized seru system, enhances flexibility and workforce adaptability in volatile manufacturing environments. A non-linear programming model optimizes maximum flow time in job rotation scheduling. Small-scale instances are solved using GAMS, while the Invasive Weed Optimization (IWO) meta-heuristic handles medium- and large-scale cases. Results show that IWO significantly outperforms GAMS in computation time while maintaining solution accuracy, with differences in objective values under 5% for most cases. Additionally, in 62.5% of cases, the number of assigned workers is fewer than the initial number of workers provided for each problem. Randomly generated test instances validate the model and algorithm, confirming their effectiveness in reducing flow time and workforce requirements. Post-optimal trials indicate that the number of rotation periods can be adjusted to minimize the flow time. It was discussed that when the number of rotation periods is optimized to minimize the flow time, imbalances among cells are also minimized. This study fills a gap in the literature and provides new insights for optimizing DSPS.}
}
@incollection{TSOTSOS1993261,
title = {The Role of Computational Complexity in Perceptual Theory},
editor = {Sergio C. Masin},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {99},
pages = {261-296},
year = {1993},
booktitle = {Foundations of Perceptual Theory},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(08)62776-4},
url = {https://www.sciencedirect.com/science/article/pii/S0166411508627764},
author = {John K. Tsotsos},
abstract = {The validity of perceptual theories cannot be considered only in terms of how well the explanations fit experimental observations. Rather, it is argued that sufficient consideration must also be given to the physical realizability of the explanation. Experimental scientists attempt to explain their data and not just describe it, in essence, providing an algorithm whose behavior leads to the observed data. Thus, computational plausibility is not only an appropriate but a necessary consideration. One dimension of plausibility is satisfaction of the constraints imposed by the computational complexity of the problem, the resources available for the solution of the problem, and the specific algorithm proposed. It is shown that such constraints play critical roles in the explanations of perception, intelligent behavior, and evolution.}
}
@article{USKOKOVIC2023e15015,
title = {Natural sciences and chess: A romantic relationship missing from higher education curricula},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e15015},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e15015},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023022223},
author = {Vuk Uskoković},
keywords = {Chemistry, Chess, Creativity, Culture, Education, Instruction, Science},
abstract = {Chess is a game that delicately weaves analytical thinking around artistic experience, yet recent conversions of STEM (Science-Technology-Engineering-Mathematics) to STEAM (Science-Technology-Engineering-Art-Mathematics) have omitted adding chess as an elementary coursework to K-12 and higher education curricula. Chess, as per arguments presented in this essay, can be considered as a language and a tool for furthering the development of artistic skills among scientists and analytical, pattern-recognition skills among artists. It can also serve as a missing link between science and art in STEAM curricula thanks to its finding itself halfway between the two. A handful of analogies are drawn here from chess, illustrated sporadically with positions from real-life chess games and converted to lessons in creativity for students in natural sciences. The discussion centered around these analogies is reinforced by a literature review of studies conducted over the past 80 years to assess the effect of exposing students to lessons in chess on their learning in distant domains. Overall, great benefits can emerge from complementing science education with chess and it is hoped that chess will become an integral part of basic education in primary schools and universities worldwide in the near future.}
}
@article{TRAYVICK2024116109,
title = {Speech and language patterns in autism: Towards natural language processing as a research and clinical tool},
journal = {Psychiatry Research},
volume = {340},
pages = {116109},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.116109},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124003949},
author = {Jadyn Trayvick and Sarah B. Barkley and Alessia McGowan and Agrima Srivastava and Arabella W. Peters and Guillermo A. Cecchi and Jennifer H. Foss-Feig and Cheryl M. Corcoran},
keywords = {Autism, Speech, Language, Natural language processing, Automated speech analysis, Acoustics, Computational phenotyping},
abstract = {Speech and language differences have long been described as important characteristics of autism spectrum disorder (ASD). Linguistic abnormalities range from prosodic differences in pitch, intensity, and rate of speech, to language idiosyncrasies and difficulties with pragmatics and reciprocal conversation. Heterogeneity of findings and a reliance on qualitative, subjective ratings, however, limit a full understanding of linguistic phenotypes in autism. This review summarizes evidence of both speech and language differences in ASD. We also describe recent advances in linguistic research, aided by automated methods and software like natural language processing (NLP) and speech analytic software. Such approaches allow for objective, quantitative measurement of speech and language patterns that may be more tractable and unbiased. Future research integrating both speech and language features and capturing “natural language” samples may yield a more comprehensive understanding of language differences in autism, offering potential implications for diagnosis, intervention, and research.}
}
@article{KHAN2021104263,
title = {A novel hybrid gravitational search particle swarm optimization algorithm},
journal = {Engineering Applications of Artificial Intelligence},
volume = {102},
pages = {104263},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104263},
url = {https://www.sciencedirect.com/science/article/pii/S095219762100110X},
author = {Talha Ali Khan and Sai Ho Ling},
keywords = {PSO, GSA, Hybrid, DNA computation},
abstract = {Particle Swarm Optimization (PSO) algorithm is a member of the swarm computational family and widely used for solving nonlinear optimization problems. But, it tends to suffer from premature stagnation, trapped in the local minimum and loses exploration capability as the iteration progresses. On the contrary, Gravitational Search Algorithm (GSA) is proficient for searching global optimum, however, its drawback is its slow searching speed in the final phase. To overcome these problems in this paper a novel Hybrid Gravitational Search Particle Swarm Optimization Algorithm (HGSPSO) is presented. The key concept behind the proposed method is to merge the local search ability of GSA with the capability for social thinking (gbest) of PSO. To examine the effectiveness of these methods in solving the abovementioned issues of slow convergence rate and trapping in local minima five standard and some modern CEC benchmark functions are used to ensure the efficacy of the presented method. Additionally, a DNA sequence problem is also solved to confirm the proficiency of the proposed method. Different parameters such as Hairpin, Continuity, H-measure, and Similarity are employed as objective functions. A hierarchal approach was used to solve this multi-objective problem where a single objective function is first obtained through a weighted sum method and the results were then empirically validated. The proposed algorithm has demonstrated an extraordinary performance per solution stability and convergence.}
}
@article{DAS2023100065,
title = {Informatics on a social view and need of ethical interventions for wellbeing via interference of artificial intelligence},
journal = {Telematics and Informatics Reports},
volume = {11},
pages = {100065},
year = {2023},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2023.100065},
url = {https://www.sciencedirect.com/science/article/pii/S2772503023000257},
author = {Kabita Das and Manaswini Pattanaik and Smitimayee Basantia and Radhashyam Mishra and Debashreemayee Das and Kanhucharan Sahoo and Biswaranjan Paital},
keywords = {Artificial intelligence, Ethical enquiry, Ethics in technology, Human conduct, Moral value, Social cognition, Human intelligence},
abstract = {The main focus of this paper was to discuss and appraise the attribution of intelligence and value judgement on Artificial Intelligence (AI) and its regulated use in society. Humans are tool-making creatures and AI is used for civilization via tools. During the time of pre-civilization, tools were simple in the form of crude construction, using hand skills but at present, the achievements are the substitution of machinery to relieve/replace human intellect. AI is the scientific technique of bringing learning, adaptation, and self-organization of machines. It encompasses various concepts and methods, deployed by researchers in many diverse fields of computation and cognition. This is the computational mode of a brain, based on artificial neural networks. The usefulness of AI ethically, initiates a big question i.e. if the human mind is not self-sufficient for any work without harming the moral sentiment of others then, how can people believe in a computational model of the mind, is a machine, morally responsible for any good or bad action. We highlight issues on the use of AI in the replacement of the human mind asking what is the value of humans in this age of AI? Can AI reciprocate and respect human values better than human beings? Can AI replace human intelligence? In the case of ethical enquiry, it is rather a herculean task to consider a machine's action to be moral or immoral, after all, it is just a machinery action devoid of any moral quality.}
}
@article{URECH2022101731,
title = {A simulation-based design framework to iteratively analyze and shape urban landscapes using point cloud modeling},
journal = {Computers, Environment and Urban Systems},
volume = {91},
pages = {101731},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101731},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521001381},
author = {Philipp R.W. Urech and Muhammad Omer Mughal and Carlos Bartesaghi-Koc},
keywords = {Point-cloud modeling, Computational fluid dynamics, Laser-scanned data, Urban landscape design, Design performance},
abstract = {The topic of this paper evolves on the discourse of digital modeling in landscape design. Current design methods stagger to address physical forms and dynamics present in the environment. This status quo limits possibilities to integrate scientific evidence when developing spatial and aesthetic configurations in urban landscapes. Remote sensing technology such as laser scanning measures physical forms to reproduce them as geo-specific digital 3D models, while dynamic simulation is widely used to predict how scenarios will perform under given conditions. However, there is still a need for a holistic design process that is capable of integrating both the measured physical forms and physical dynamics. This paper presents a novel framework using point cloud modeling to shape design scenarios that are iteratively evaluated for their performance. The proposed framework is demonstrated through a case study in Singapore. New spatial configurations are tested for the site through an iterative and comparative analysis of the design performance. The case study exposes (1) a site-specific design approach by iteratively modeling a laser-scanned point cloud model, (2) a workflow to convert the geometric data from the point cloud models into voxels and meshes, (3) an integration of computational fluid dynamics (CFD) simulation during design development as per-point attributes, and (4) a comparison of the configurations to identify best performing scenarios. This design framework can support city managers, planners, urban and landscape designers to better inform their decision-making process by relying on accurate scientific feedback. By guiding the design process with the consideration of the built environment as a complex adaptive system, it will be possible to improve how open spaces and ecosystem services perform in cities, and to design landscapes that can mitigate dynamic events such as urban heat islands.}
}
@article{KROGER2013189,
title = {An ERP study of passive creative conceptual expansion using a modified alternate uses task},
journal = {Brain Research},
volume = {1527},
pages = {189-198},
year = {2013},
issn = {0006-8993},
doi = {https://doi.org/10.1016/j.brainres.2013.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0006899313009566},
author = {Sören Kröger and Barbara Rutter and Holger Hill and Sabine Windmann and Christiane Hermann and Anna Abraham},
keywords = {Creativity, ERP, N400, Conceptual expansion, Alternate uses task, Divergent thinking, Semantic cognition},
abstract = {A novel ERP paradigm was employed to investigate conceptual expansion, a central component of creative thinking. Participants were presented with word pairs, consisting of everyday objects and uses for these objects, which had to be judged based on the two defining criteria of creative products: unusualness and appropriateness. Three subject-determined trial types resulted from this judgement: high unusual and low appropriate (nonsensical uses), low unusual and high appropriate (common uses), and high unusual and high appropriate (creative uses). Word pairs of the creative uses type are held to passively induce conceptual expansion. The N400 component was not specifically modulated by conceptual expansion but was, instead, generally responsive as a function of unusualness or novelty of the stimuli (nonsense=creative>common). Explorative analyses in a later time window (500–900ms) revealed that ERP activity in this phase indexes appropriateness (nonsense>creative=common). In the discussion of these findings with reference to the literature on semantic cognition, both components are proposed as indexing processes relevant to conceptual expansion as they are selectively involved in the encoding and integration of a newly established semantic connection between two previously unrelated concepts.}
}
@article{WHITACRE2020100816,
title = {The roles of tools and models in a prospective elementary teachers’ developing understanding of multidigit multiplication},
journal = {The Journal of Mathematical Behavior},
volume = {60},
pages = {100816},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100816},
url = {https://www.sciencedirect.com/science/article/pii/S0732312320300808},
author = {Ian Whitacre and Chepina Rumsey},
keywords = {Prospective teachers, Mental computation, Multiplication, Tools, Models},
abstract = {It is important for prospective elementary teachers to understand multidigit multiplication deeply; however, the development of such understanding presents challenges. We document the development of a prospective elementary teacher’s reasoning about multidigit multiplication during a Number and Operations course. We present evidence of profound progress in Valerie’s understanding of multidigit multiplication, and we highlight the roles of particular tools and models in her developing reasoning. In this way, we contribute an illuminating case study that can inform the work of mathematics teacher educators. We discuss specific instructional implications that derive from this case.}
}
@article{HASELI2023184,
title = {HECON: Weight assessment of the product loyalty criteria considering the customer decision's halo effect using the convolutional neural networks},
journal = {Information Sciences},
volume = {623},
pages = {184-205},
year = {2023},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.12.027},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522015201},
author = {Gholamreza Haseli and Ramin Ranjbarzadeh and Mostafa Hajiaghaei-Keshteli and Saeid {Jafarzadeh Ghoushchi} and Aliakbar Hasani and Muhammet Deveci and Weiping Ding},
keywords = {Customer loyalty, Deep learning, Convolutional neural networks, Multi-criteria decision-making, Halo effect},
abstract = {The economic pressures and increasing competition in markets have led to the CEOs of companies being forced to make the right strategic decisions in the development of products for selling the right products to the right customers. To achieve this goal, companies need to know which criteria of their products lead to customer loyalty to that product. In the past, various methods have been introduced to obtain the importance (weight) of criteria that use the opinions of experts or customers. There is a halo effect in human decisions that leads to biases in evaluating the criteria by influencing human emotions. This study introduces a new method for weight assessment of the product loyalty criteria by considering the customer's decisions halo effect using the convolutional neural network (CNN) called the halo effect using the convolutional neural networks (HECON) method. In the HECON method to consider the halo effect of the customer decisions, a CNN model is proposed as the deep learning pipeline to obtain more accurate weights of the criteria. The HECON method to obtain the weight of the criteria and identify criteria that lead to product loyalty needs to collect the feedback of a large number of customers based on the net promoter score (NPS) scale. The innovation of the HECON method is to obtain the effect level of each product criterion on selection and loyalty to the product through the feedback of a large number of customers by considering the halo effect on the customers' thinking. To date, the analyzing methods have often not been able to identify the halo effect in evaluating the reasons for customer loyalty to the product. The halo effect indicates sometimes some of the product criteria secretly affect the customers' opinions that require deep neural networks to analyze them. By using the deep CNN model of the HECON method to evaluate product criteria for understanding customer behavior, companies will be able to identify customers' behavior and develop their products exactly following the customer's desires. To evaluate the performance and demonstrate the applicability of the HECON method, presented two case studies. It is presented that there are challenging differences between the results of the HECON method with the other methods because the HECON method considers the halo effect on the customer decisions and demonstrates better performance.}
}
@article{HUANG2012250,
title = {The effectiveness of using procedural scaffoldings in a paper-plus-smartphone collaborative learning context},
journal = {Computers & Education},
volume = {59},
number = {2},
pages = {250-259},
year = {2012},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2012.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S0360131512000310},
author = {Hui-Wen Huang and Chih-Wei Wu and Nian-Shing Chen},
keywords = {Cooperative/collaborative learning, Improving classroom teaching, Teaching/learning strategies},
abstract = {The purpose of this study was to evaluate the effectiveness of using procedural scaffoldings in fostering students’ group discourse levels and learning outcomes in a paper-plus-smartphone collaborative learning context. All participants used built-in camera smartphones to learn new knowledge by scanning Quick Response (QR) codes, a type of two-dimensional barcode, embedded in paper-based learning materials in this study. Sixty undergraduate and graduate students enrolled at a four-year university in southern Taiwan participated in this study. Participants were randomly assigned into two different groups, using procedural scaffoldings learning and non-procedural scaffoldings learning. The learning unit about the Long Tail, an important concept used in products sales, was the learning task that participants were expected to complete. During the experiment, pretest–posttest and the completed group worksheets were used to collect data. The researchers applied content analyses, chi-square test, t-test, and ANCOVA to answer research questions. The findings indicated that participants in the experimental group using procedural scaffoldings achieved better learning outcomes than their counterparts in the control group in terms of group discourse levels, group learning, and individual learning.}
}
@article{ENDICOTT2003403,
title = {Moral reasoning, intercultural development, and multicultural experiences: relations and cognitive underpinnings},
journal = {International Journal of Intercultural Relations},
volume = {27},
number = {4},
pages = {403-419},
year = {2003},
note = {Special Training Issue},
issn = {0147-1767},
doi = {https://doi.org/10.1016/S0147-1767(03)00030-0},
url = {https://www.sciencedirect.com/science/article/pii/S0147176703000300},
author = {Leilani Endicott and Tonia Bock and Darcia Narvaez},
keywords = {Moral development, Intercultural development, Flexible thinking, Cognitive complexity, Multicultural experience, Schema theory},
abstract = {The relation between moral reasoning and intercultural sensitivity is discussed. We hypothesize that multicultural experiences are related to both types of development, describe the cognitive processes through which multicultural experiences theoretically facilitate development, and present empirical data supporting the association. Though the underlying developmental constructs were initially conceptualized as stage theories, we borrow from cognitive science and contemporary theories of human learning (Derry, 1996) to think of moral and intercultural development in terms of increasing sociocognitive flexibility. Intercultural and moral development share the common element of a critical shift from rigid to flexible thinking. In moral reasoning, this is characterized by the shift from conventional to post-conventional thinking. In intercultural development, a similar movement occurs between the ethnocentric and ethnorelative orientations of intercultural sensitivity. In order to test our hypothesis, college students (n=70) took measures of intercultural development (Intercultural Development Inventory), moral judgment (Defining Issues Test), and multicultural experience (Multicultural Experience Questionnaire). The results indicate that moral judgment and intercultural development are significantly related to one another. Both are related to multicultural experiences, particularly depth of the experiences, as opposed to breadth.}
}
@article{GAO2023103794,
title = {Developing virtual acoustic terrain for Urban Air Mobility trajectory planning},
journal = {Transportation Research Part D: Transport and Environment},
volume = {120},
pages = {103794},
year = {2023},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2023.103794},
url = {https://www.sciencedirect.com/science/article/pii/S1361920923001918},
author = {Zhenyu Gao and Alex Porcayo and John-Paul Clarke},
keywords = {Urban Air Mobility, Sustainable aviation, Noise modeling, Trajectory planning, Optimization},
abstract = {Urban Air Mobility (UAM) is a transformative concept that must operate harmoniously within the constraints imposed by societal impacts. Noise-aware flight trajectory planning can address UAM’s community noise concerns. However, the traditional trajectory optimization paradigm requires repetitive computations of a flight’s noise footprints in complex urban environments and is computationally expensive. In this work, we propose virtual acoustic terrain, a novel concept to enable an efficient trajectory optimization paradigm. By applying acoustic ray tracing and the principle of reciprocity in a complex urban environment, we convert different noise constraints into 3D exclusion zones which UAM operations should avoid to maintain limited noise impact. It combines with the physical urban terrain to define an acceptable fly zone for non-repetitive noise-aware trajectory optimization. This framework provides a new angle to future urban area airspace management and can also accommodate other forms of societal constraints.}
}
@incollection{MILLER2017103,
title = {6 - Graduate and postgraduate education at a crossroads},
editor = {Susan M. Miller and Walter H. Moos and Barbara H. Munk and Stephen A. Munk},
booktitle = {Managing the Drug Discovery Process},
publisher = {Woodhead Publishing},
address = {Boston},
pages = {103-128},
year = {2017},
isbn = {978-0-08-100625-2},
doi = {https://doi.org/10.1016/B978-0-08-100625-2.00006-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780081006252000064},
author = {Susan M. Miller and Walter H. Moos and Barbara H. Munk and Stephen A. Munk},
keywords = {Academia, Career, Critical thinking, Diversity, Education, Graduate school, Immigration, Industry, Jobs, Learn by doing, Medicinal chemistry, Online education, Organic chemistry, Postdoctoral, Postgraduate, Master's degree, Doctorate.},
abstract = {In this chapter we introduce the proverbial crossroads we have reached in graduate and postgraduate education and jobs. Many factors are at play, including an explosion of information, available now, at your fingertips, a move away from memorization toward critical thinking, the importance of learning by doing, and what has been called “the gathering storm.” Core drug discovery disciplines are discussed, such as medicinal and organic chemistry, especially in the context of academia–industry symbiosis. Challenges in making sure we continue to assemble the best and the brightest to tackle important biomedical problems are considered. Finally, we scratch the surface of how to navigate employers, employment, and careers.}
}
@article{CASTANEDA2023102391,
title = {A simulation-based approach for assessing the innovation barriers in the manufacturing firms},
journal = {Technology in Society},
volume = {75},
pages = {102391},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102391},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23001963},
author = {Monica Castaneda and Milton M. Herrera and Alberto Méndez-Morales},
keywords = {Product innovation, Process innovation, Manufacturing sector, System dynamics, Barriers to innovation, Innovation policy},
abstract = {One of the most important challenges organisations’ faces to innovate is dealing with different types of barriers. Particularly, the case of manufacturing firms confronts several barriers, such as demand uncertainty, product imitation, lack of employees, scarcity of government funding, absence of internal and external financing. This paper aims to provide new insights regarding to the innovation barriers faced by the manufacturing firms. To do this, we implemented a computational model for analysing the barriers to innovation in the Colombian case. In this model, product and processes innovation are studied. It was concluded that for the innovation of process, the highly important barrier is the shortcoming of internal financing, while for the innovation of product is the lack of employees. Results show that the government expenditure is scarce compared to private and external investment.}
}
@incollection{MARKOVA2015443,
title = {Representations, Social Psychology of},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {443-449},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.24084-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868240841},
author = {Ivana Marková},
keywords = {Anchoring, Cognitive polyphasia, Common sense, Communication, Dialogicality, Ego–Alter–Object, Ethics, Figurative scheme, Imagination, Interactional epistemology, Intervention strategies, Language, Objectification, Social representations, Themata},
abstract = {The theory of social representations studies the formation and transformation of meanings and activities of complex social phenomena like health and illness, political problems or environmental issues in and through language and communication, history and culture. There are two mutually interdependent meanings of social representations. The first meaning concerns the theory of social representations as an interactional theory of knowledge. It refers to networks of concepts and figurative schemes that are generated in and through tradition, common sense, daily knowledge, and communication; these are shared by particular groups and communities. The main features of this theory are the Ego–Alter–Object, the field, the interdependence of asymmetries and symmetries, ethics, figurative scheme, and cognitive polyphasia. Second, social representations refer to concrete social phenomena and to forms of apprehending and creating social realities in and through communication, experience, social practices, and interventions. Human thinking is characterized by the capacity to make distinctions and understand phenomena as dyadic antinomies or themata. Thematization of dyadic antinomies is linked with anchoring and objectification, through which social representations are formed and transformed.}
}
@article{WANG1996579,
title = {The IDS model of intelligent design system},
journal = {Computers & Structures},
volume = {61},
number = {3},
pages = {579-586},
year = {1996},
issn = {0045-7949},
doi = {https://doi.org/10.1016/0045-7949(96)00054-5},
url = {https://www.sciencedirect.com/science/article/pii/0045794996000545},
author = {Xiaotong Wang},
abstract = {Existing models of intelligent design system nowadays are generally logic-based, which solve only simple and small-scale design problems. In the author's opinion, these models which concentrate only on far-fetched use of logical inference and abstract knowledge deviate from designer's thinking and decision process; the crux of the deviation is the lack of imitating thinking with mental imagery ability. Considering the nature of design problems and imitating rational thinking with alternate use of pattern association and symbolic operation, a new intelligent design system (IDS) model and its implementation techniques are presented. Imitation of thinking with mental imagery which is also called pattern association in the IDS model is considered by applying artificial neural network (ANN) techniques. The pattern association in the IDS model imitates the rule of human thinking, “comprehending by analogy”, to some extent. Because of the robustness of the pattern-type knowledge used in pattern association, IDS provides a practical way in producing a design scheme using incomplete and/or undeterminate input data, which is very difficult to achieve in general expert design systems. According to the IDS model, an intelligent structural layout design system of wing (ISDW) is developed. ISDW realizes mapping from key parameters of design requirements and the environment of the wing to the layout design of wing structure in not only graphic form, but also in readable data form. After getting a layout of wing structure, the user will modify it interactively by Auto-CAD, and then return to the ISDW environment to produce FEM meshes by an intelligent meshing interface in order to do the preliminary static and dynamic structural analysis. The design schemes created by the system proved to be proper and usable, and this concludes that IDS model is practicable and practical.}
}
@article{SNEDDON20252898,
title = {Rapid (≤25 °C) cycloisomerization of anhydride-tethered triynes to benzynes – origin of a remarkable anhydride linker-induced rate enhancement††Electronic supplementary information (ESI) available. CCDC 2353613. For ESI and crystallographic data in CIF or other electronic format see DOI: https://doi.org/10.1039/d4sc07232d},
journal = {Chemical Science},
volume = {16},
number = {6},
pages = {2898-2906},
year = {2025},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d4sc07232d},
url = {https://www.sciencedirect.com/science/article/pii/S2041652025000392},
author = {Dorian S. Sneddon and Paul V. Kevorkian and Thomas R. Hoye},
abstract = {The hexadehydro-Diels–Alder (HDDA) reaction is a cycloisomerization between a conjugated diyne and a tethered diynophile that generates ortho-benzyne derivatives. Considerable fundamental understanding of aryne reactivity has resulted from this body of research. The multi-yne cycloisomerization substrate is typically pre-formed and the (rate-limiting) closure of this diyne/diynophile pair to produce the isomeric benzyne generally requires thermal input, often requiring reaction temperatures of >100 °C and times of 16–48 h to achieve near-full conversion. We report here that diynoic acids can be dimerized and that the resulting substrate, having a 3-atom anhydride linker (i.e., OCOCO), then undergoes HDDA cyclization within minutes at or below room temperature. This allows for the novel in situ assembly and cyclization of HDDA benzyne precursors in an operationally simple protocol. Experimental kinetic data along with DFT computations are used to identify the source of this surprisingly huge rate acceleration afforded by the anhydride linker: >107 faster than the analogous multi-yne having, instead, a CH2OCH2 ether linker.}
}
@article{FUKAI2021145,
title = {Neural mechanisms for learning hierarchical structures of information},
journal = {Current Opinion in Neurobiology},
volume = {70},
pages = {145-153},
year = {2021},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2021.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0959438821001252},
author = {Tomoki Fukai and Toshitake Asabuki and Tatsuya Haga},
abstract = {Spatial and temporal information from the environment is often hierarchically organized, so is our knowledge formed about the environment. Identifying the meaningful segments embedded in hierarchically structured information is crucial for cognitive functions, including visual, auditory, motor, memory, and language processing. Segmentation enables the grasping of the links between isolated entities, offering the basis for reasoning and thinking. Importantly, the brain learns such segmentation without external instructions. Here, we review the underlying computational mechanisms implemented at the single-cell and network levels. The network-level mechanism has an interesting similarity to machine-learning methods for graph segmentation. The brain possibly implements methods for the analysis of the hierarchical structures of the environment at multiple levels of its processing hierarchy.}
}
@incollection{HALFORD2020327,
title = {Cognitive Developmental Theories☆},
editor = {Janette B. Benson},
booktitle = {Encyclopedia of Infant and Early Childhood Development (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {327-336},
year = {2020},
isbn = {978-0-12-816511-9},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.05787-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245057874},
author = {G.S. Halford},
keywords = {Analogy, Cognitive complexity, Conceptual chunking, Dynamic systems, Information processing, Mental models, Neural net, Object permanence, Relational knowledge, Symbolic processes, Theory of mind, Working memory},
abstract = {Theories of cognitive development are reviewed, beginning with pioneering theories by Piaget and Vygotsky. Neo-Piagetian theories which integrated Piagetian theory with other conceptions of cognition were developed by McLaughlin, Pascual-Leone, Case, Fischer, and Chapman. Complexity theories propose that children become capable of dealing with more complex relations as they develop. Information processing theories, neural net theories, dynamic systems theories, and theories of reasoning processes all provide models of the reasoning processes employed by children at different ages. Microgenetic analysis methods are used to study the processes of transition from one level of thinking to the next. Conceptual coherence is achieved by categorizing cognitive processes according to their core properties.}
}
@article{WILKINSON2013394,
title = {The past and the future of business marketing theory},
journal = {Industrial Marketing Management},
volume = {42},
number = {3},
pages = {394-404},
year = {2013},
note = {Theoretical Perspectives in Industrial Marketing Management},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2013.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0019850113000266},
author = {Ian F. Wilkinson and Louise C. Young},
keywords = {Complex adaptive systems, Business relations and networks, Dynamics and evolution, Agent based models, Mechanisms},
abstract = {A complex systems approach to understanding and modelling business marketing systems is described. The focus is on the dynamics and evolution of such systems and the processes and mechanisms driving this, rather than the more usual comparative static, variables based statistical models. Order emerges in a self-organising, bottom up way from the local or micro actions and interactions of those involved. We describe the development of our thinking regarding this approach and its main features, including the development of agent based simulation models and the identification and modelling of underlying mechanisms and processes. We conclude by discussing the implications of this approach for business marketing theory and research.}
}
@article{SELOTE2025108302,
title = {A knowledge graph approach to drug repurposing for Alzheimer’s, Parkinson’s and Glioma using drug–disease–gene associations},
journal = {Computational Biology and Chemistry},
volume = {115},
pages = {108302},
year = {2025},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2024.108302},
url = {https://www.sciencedirect.com/science/article/pii/S1476927124002901},
author = {Ruchira Selote and Richa Makhijani},
keywords = {Knowledge graph, Drug repurposing, Node embeddings, Biased random walk, Feature learning, Cosine similarity},
abstract = {Drug Repurposing gives us facility to find the new uses of previously developed drugs rather than developing new drugs from start. Particularly during pandemic, drug repurposing caught much attention to provide new applications of the previously approved drugs. In our research, we provide a novel method for drug repurposing based on feature learning process from drug–disease–gene network. In our research, we aimed at finding drug candidates which can be repurposed under neurodegenerative diseases and glioma. We collected association data between drugs, diseases and genes from public resources and primarily examined the data related to Alzheimer’s, Parkinson’s and Glioma diseases. We created a Knowledge Graph using neo4j by integrating all these datasets and applied scalable feature learning algorithm known as node2vec to create node embeddings. These embeddings were later used to predict the unknown associations between disease and their candidate drugs by finding cosine similarity between disease and drug nodes embedding. We obtained a definitive set of candidate drugs for repurposing. These results were validated from the literature and CodReS online tool to rank the candidate drugs. Additionally, we verified the status of candidate drugs from pharmaceutical knowledge databases to confirm their significance.}
}
@article{YIM2014144,
title = {A development of a quantitative situation awareness measurement tool: Computational Representation of Situation Awareness with Graphical Expressions (CoRSAGE)},
journal = {Annals of Nuclear Energy},
volume = {65},
pages = {144-157},
year = {2014},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2013.10.029},
url = {https://www.sciencedirect.com/science/article/pii/S0306454913005598},
author = {Ho Bin Yim and Seung Min Lee and Poong Hyun Seong},
keywords = {Quantitative measure, Situation awareness, Graphical expression, NPP MCR operators},
abstract = {Operator performance measures are used for multiple purposes, such as control room design, human system interface (HSI) evaluation, training, and so on. Performance measures are often focused on results; however, especially for a training purpose – at least in a nuclear industry, more detailed descriptions about processes are required. Situation awareness (SA) measurements have directly/indirectly played as a complimentary measure and provided descriptive insights on how to improve performance of operators for the next training. Unfortunately, most of the well-developed SA measurement techniques, such as Situation Awareness Global Assessment Technique (SAGAT) need an expert opinion which sometimes troubles easy spread of measurement’s application or usage. A quantitative SA measurement tool named Computational Representation of Situation Awareness with Graphical Expressions (CoRSAGE) is introduced to resolve some of these concerns. CoRSAGE is based on production rules to represent a human operator’s cognitive process of problem solving, and Bayesian inference to quantify it. Petri Net concept is also used for graphical expressions of SA flow. Three components – inference transition, volatile/non-volatile memory tokens – were newly developed to achieve required functions. Training data of a Loss of Coolant Accident (LOCA) scenario for an emergency condition and an earthquake scenario for an abnormal condition by real plant operators were used to validate the tool. The validation result showed that CoRSAGE performed a reasonable match to other performance results.}
}
@article{BRENT19961,
title = {Advances in the computational study of language acquisition},
journal = {Cognition},
volume = {61},
number = {1},
pages = {1-38},
year = {1996},
note = {Compositional Language Acquisition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/S0010-0277(96)00779-2},
url = {https://www.sciencedirect.com/science/article/pii/S0010027796007792},
author = {Michael R. Brent},
abstract = {This paper provides a tutorial introduction to computational studies of how children learn their native languages. Its aim is to make recent advances accessible to the broader research community, and to place them in the context of current theoretical issues. The first section locates computational studies and behavioral studies within a common theoretical framework. The next two sections review two papers that appear in this volume: one on learning the meanings of words and one on learning the sounds of words. The following section highlights an idea which emerges independently in these two papers and which I have dubbed autonomous bootstrapping. Classical bootstrapping hypotheses propose that children begin to get a toe-hold in a particular linguistic domain, such as syntax, by exploiting information from another domain, such as semantics. Autonomous bootstrapping complements the cross-domain acquisition strategies of classical bootstrapping with strategies that apply within a single domain. Autonomous bootstrapping strategies work by representing partial and/or uncertain linguistic knowledge and using it to analyze the input. The next two sections review two more more contributions to this special issue: one on learning word meanings via selectional preferences and one on algorithms for setting grammatical parameters. The final section suggests directions for future research.}
}
@article{SCHAEFER198897,
title = {A history of ab initio computational quantum chemistry: 1950–1960},
journal = {Tetrahedron Computer Methodology},
volume = {1},
number = {2},
pages = {97-102},
year = {1988},
issn = {0898-5529},
doi = {https://doi.org/10.1016/0898-5529(88)90014-0},
url = {https://www.sciencedirect.com/science/article/pii/0898552988900140},
author = {Henry F. Schaefer},
keywords = {Quantum chemistry, Ab initio, Electronic structure theory, Molecular quantum mechanics, Computations},
abstract = {Although ab initio computational quantum chemistry produced virtually no predictions of chemical interest during the 1950's, an important foundation for future work was laid during this decade. Much of this fundamental computational research was carried out in the laboratories of Frank Boys in Cambridge (England) and Clemens Roothaan and Robert Mulliken in Chicago. Other senior contributors to ab initio chemical theory during this period include Klaus Ruedenberg, Robert Parr, John Pople, Robert Nesbet, Harrison Shull, Per-Olov Löwdin, Isaiah Shavitt, Albert Matsen, Douglas McLean, and Bernard Ransil.}
}
@article{SFARD20121,
title = {Introduction: Developing mathematical discourse—Some insights from communicational research},
journal = {International Journal of Educational Research},
volume = {51-52},
pages = {1-9},
year = {2012},
note = {Developing mathematical discourse–Some insights from communicational research},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2011.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0883035511001327},
author = {Anna Sfard},
keywords = {Mathematics, Discourse, Learning, Development, Cognition, Emotions, Interactions},
abstract = {Quite diverse in their foci and specific themes, the seven articles collected in this special issue are unified by their common conceptual framework. Grounded in the premise that thinking can be usefully defined as self-communicating and that mathematics can thus be viewed as a discourse, the communicational framework provides a unified set of conceptual tools with which to investigate cognitive, affective and social aspects of mathematics learning. The communicational tools are employed by the authors as they investigate diverse aspects of mathematical discourse and explore its development in the classroom and beyond. The seven studies combine together to produce a set of insights, some of which go against widespread beliefs about teaching and learning mathematics.}
}
@article{BOUDIN2016448,
title = {Opinion dynamics: Kinetic modelling with mass media, application to the Scottish independence referendum},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {444},
pages = {448-457},
year = {2016},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2015.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0378437115008602},
author = {Laurent Boudin and Francesco Salvarani},
keywords = {Opinion formation, Mass media, Kinetic equations},
abstract = {We consider a kinetic model describing some mechanisms of opinion formation in the framework of referendums, where the individuals, who can interact between themselves and modify their opinion by means of spontaneous self-thinking, are moreover under the influence of mass media. We study, at the numerical level, both the transient and the asymptotic regimes. In particular, we point out that a plurality of media, with different orientations, is a key ingredient to allow pluralism and prevent consensus. The forecasts of the model are compared to some surveys related to the Scottish independence referendum of 2014.}
}
@article{PIOLOPEZ2023103585,
title = {Morphoceuticals: Perspectives for discovery of drugs targeting anatomical control mechanisms in regenerative medicine, cancer and aging},
journal = {Drug Discovery Today},
volume = {28},
number = {6},
pages = {103585},
year = {2023},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2023.103585},
url = {https://www.sciencedirect.com/science/article/pii/S1359644623001010},
author = {Léo Pio-Lopez and Michael Levin},
keywords = {Biomedicine, Drug discovery, Morphogenesis},
abstract = {Morphoceuticals are a new class of interventions that target the setpoints of anatomical homeostasis for efficient, modular control of growth and form. Here, we focus on a subclass: electroceuticals, which specifically target the cellular bioelectrical interface. Cellular collectives in all tissues form bioelectrical networks via ion channels and gap junctions that process morphogenetic information, controlling gene expression and allowing cell networks to adaptively and dynamically control growth and pattern formation. Recent progress in understanding this physiological control system, including predictive computational models, suggests that targeting bioelectrical interfaces can control embryogenesis and maintain shape against injury, senescence and tumorigenesis. We propose a roadmap for drug discovery focused on manipulating endogenous bioelectric signaling for regenerative medicine, cancer suppression and antiaging therapeutics.}
}
@article{STREVENS202192,
title = {Permissible idealizations for the purpose of prediction},
journal = {Studies in History and Philosophy of Science Part A},
volume = {85},
pages = {92-100},
year = {2021},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2020.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0039368120301813},
author = {Michael Strevens},
keywords = {Prediction, Idealization, Modeling, Difference-making, Causal relevance},
abstract = {Every model leaves out or distorts some factors that are causally connected to its target phenomenon—the phenomenon that it seeks to predict or explain. If we want to make predictions, and we want to base decisions on those predictions, what is it safe to omit or to simplify, and what ought a causal model to describe fully and correctly? A schematic answer: the factors that matter are those that make a difference to the target phenomenon. There are several ways to understand differencemaking. This paper advances a view as to which is the most relevant to the forecaster and the decision-maker. It turns out that the right notion of differencemaking for thinking about idealization in prediction is also the right notion for thinking about idealization in explanation; this suggests a carefully circumscribed version of Hempel’s famous thesis that there is a symmetry between explanation and prediction.}
}
@article{MOSKOWITZ200387,
title = {The intertwining of psychophysics and sensory analysis: historical perspectives and future opportunities—a personal view},
journal = {Food Quality and Preference},
volume = {14},
number = {2},
pages = {87-98},
year = {2003},
issn = {0950-3293},
doi = {https://doi.org/10.1016/S0950-3293(02)00072-1},
url = {https://www.sciencedirect.com/science/article/pii/S0950329302000721},
author = {Howard R. Moskowitz},
keywords = {History, Psychology, Psychophysics},
abstract = {From today’s point of view, psychophysics and sensory analysis appear conjoined, at least from the vantage point of sensory analysis. This paper shows how psychophysical thinking has not only entered sensory analysis, but also shaped some of the ways that modern day sensory analysts conceptualize their problems and go about solving them. The paper also shows how this was not always the case. The rapprochement of the two fields has only gradually developed as sensory analysis has come to accept psychophysical thinking. The paper concludes by listing a series of trends that may bring the two fields even closer in the future.}
}
@article{MININA2022104684,
title = {Neuron quantum computers and a way to unification of science: A compendium of Efim Liberman's scientific work},
journal = {Biosystems},
volume = {217},
pages = {104684},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104684},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722000727},
author = {Svetlana V. Minina and Nikita E. Shklovskiy-Kordi},
keywords = {Efim liberman, cAMP, Biological computation, Biophysics, Chaimatics, Quantum biology, Unity of science, Quantum computation, Molecular cell computer, Quantum regulator},
abstract = {In 1972, Efim Liberman, a Soviet biophysicist, pioneered a brand-new approach to studying the operation of the brain, the live cell and the human mind by publishing a paper titled “Cell as a molecular computer” (1972). In this paper, Liberman posited that a consecutive/parallel stochastic molecular computer (MCC) controls a living cell. An MCC operates with molecule-words (DNA, RNA, proteins) according to the program recorded in DNA and RNA. Computational operations are implemented by molecular operators acting as enzymes. An MCC is present in each live cell. A neuron cell MCC can be involved in solving tasks for the entire organism. Neuron MCC investigation was started with studying an impact of an intracellular injection of cyclic AMP on electric activity of a neuron. Cyclic nucleotides were considered as input words for an MCC, which are generated inside a neuron as a result of synaptic activity. This led Efim Liberman to the idea that, in order to solve complex physical problems, which are encountered by a neuron and require rapid solutions, the molecular computer adjusts the operation of the quantum molecular regulator, which uses the “computational environment” of the cytoskeleton and quantum properties of the elementary hypersound quasiparticles for completing mathematical operations for the minimum price of action. Efim Liberman suggested that the human self-consciousness is a quantum computer of even a higher level and designated it as an extreme quantum regulator. In order to describe such systems, he suggested to join biology, physics and mathematics into a unified science, and formulated its four fundamental principles. Results of Efim Liberman’s theoretical and experimental studies on the topic of biological computation are summarized in this review.}
}
@article{GARAS2024100885,
title = {A data analytics case study analyzing IRS SOI migration data using no code, low code technologies},
journal = {Journal of Accounting Education},
volume = {66},
pages = {100885},
year = {2024},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2024.100885},
url = {https://www.sciencedirect.com/science/article/pii/S0748575124000010},
author = {Samy Garas and Susan L. Wright},
keywords = {Robotic process automation, UiPath, Alteryx, Tableau, Data automation, Data analytics, Data visualizations, Regional migration, Government planning, Business planning},
abstract = {Organizations generate and accumulate vast amounts of structured and unstructured data that have value for formulating and supporting strategic decisions. The advancement of no-code and low-code software has enabled the use of this data to provide significant data insights and business intelligence by employing multiple forms of data analytics. The imperative to cultivate a robust and proficient group of individuals with expertise in data analytics has led to a substantial increase in the number of educational programs focused on data science and analytics. Accounting educators can capitalize on these trends by integrating data analytics and software skills into the accounting curriculum. This case offers essential materials to aid in the development of the curriculum to support accounting and analytics educators. This case serves many objectives by providing a professional setting in which you take on the role of junior data analyst, offering necessary context and motivation for completing the tasks. The case allows you to analyze extensive data sets obtained from the IRS Statistics of Income (SOI) website in order to investigate migration patterns based on state, year, age, and income categories. UiPath-robotic process automation (RPA), Alteryx-based data analysis, and Tableau-based data visualization tools are employed to extract, generate, and present descriptive statistics and to conduct a simple times series analysis. These insights are highly valuable to decision makers in business and government organizations. You are encouraged to engage in critical thinking and to consider the potential impacts of migratory patterns on choices made by firm executives and public policy makers. Migration patterns have a significant impact on firm management decisions, influencing either to expand or reduce current operations and indicating the availability and expansion of new talent pools. Migration patterns have a significant impact on the decision made by public policy makers, particularly in relation to public utilities, infrastructure, and other services and benefits. You analyze temporal data to deduce the influence of changes in the tax code and shifts in the economy. You gain expertise in managing large data sets, exploring features of analytics software, and creating compelling visualizations to effectively communicate important discoveries. Instructors and students are given comprehensive instructions and videos to facilitate the efficient application of these technologies.}
}
@incollection{SUGHRUE2024151,
title = {Chapter 6 - Reimagining neurocognitive functions as emergent phenomena: What resting state is really showing us},
editor = {Michael E. Sughrue and Jacky T. Yeung and Nicholas B. Dadario},
booktitle = {Connectomic Medicine},
publisher = {Academic Press},
pages = {151-157},
year = {2024},
isbn = {978-0-443-19089-6},
doi = {https://doi.org/10.1016/B978-0-443-19089-6.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443190896000082},
author = {Michael E. Sughrue and Jacky T. Yeung and Nicholas B. Dadario},
keywords = {Brain hub, Brain landscape, Network control theory, Neurocognitive function, Resting-state fMRI, Structural connectome},
abstract = {In this chapter, we introduce a new way of thinking about neurocognitive functioning and related dysfunction. We discuss how structural wiring patterns, global rhythms in deep structures, and electrochemical gain from neurotransmitters play a key role in the internal dynamics of what the brain is doing. Importantly, together, these elements dictate how the brain can or cannot obtain different brain states. Simultaneously, disruption in intrinsic structures and internal dynamics alters the energetic landscape causing some brain states to become more favorable or less favorable. Importantly, we go on to describe how landscapes arise from structural connectomes, and how these connections can dictate spontaneous behavioral patterns and tendencies in normal as well as pathologic states, such as a depressed patient being stuck in a self-ruminating and negative state. Resting-state fMRI also provides a keyhole into these processes as the entire set of the structural connectome creates the patterns of functional connectivity seen in resting-state brain activity.}
}
@incollection{KUMAR2025185,
title = {Chapter 9 - Future prospective of neuromorphic computing in artificial intelligence: A review, methods, and challenges},
editor = {Harish Garg and Jyotir {Moy Chatterjee} and R. Sujatha and Shatrughan Modi},
booktitle = {Primer to Neuromorphic Computing},
publisher = {Academic Press},
pages = {185-197},
year = {2025},
isbn = {978-0-443-21480-6},
doi = {https://doi.org/10.1016/B978-0-443-21480-6.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443214806000080},
author = {Vivek Kumar and Kapil Joshi and Rajiv Kumar and Minakshi Memoria and Ashulekha Gupta and F. Ajesh},
keywords = {Neuromorphic computing, Artificial intelligence, Deep learning, Machine learning, Human brain modeling},
abstract = {Neuromorphic computing in the area of artificial intelligence (AI) offers the appeal of human brain modeling. In the Fourth Industrial Revolution era, AI is among the most advanced scientific knowledge that can integrate human behavior and intelligence into machines. Even though neuromorphic computing has been around since the 1980s, it is still a relatively new field. In the last 10 years, in particular, there has been a significant amount of study and the advancement of AI. The next stage of AI is thought to be Neuromorphic Computing. The development of neuromorphic computing technology will be crucial. The most potent computational device in existence, the human brain has long served as an inspiration for AI. This study discusses neuromorphic computing, a new form of sophisticated computing that draws inspiration from brain intelligence. The objective of this paper is to give a summary of the present status of AI and neuromorphic computing to express a viewpoint on the potential and challenges that lie ahead for the main applications of neuromorphic computing. We discuss the prospects for further development of these systems and highlight features of neuromorphic computing that are promising for the field's future.}
}
@incollection{BROWN201589,
title = {Space, Linguistic Expression of},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {89-93},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.57017-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868570172},
author = {Penelope Brown},
keywords = {Adpositions, Language and cognition, Language universals, Locative constructions, Motion verbs, Space, Spatial frames of reference, Topological language},
abstract = {Spatial cognition is central to human thinking, and spatial language is thus an important area of study, as it may reveal fundamental properties of human thought. Recent research has shown that spatial language is much more divergent across languages than had previously been thought, suggesting significant cultural patterning of spatial conceptualization. This article reviews spatial language cross-linguistically, sets out a typological framework for the language of space, and considers the relationship of spatial language to spatial cognition, in the context of extensive linguistic diversity in the spatial domain.}
}
@article{NAGOEV2020615,
title = {Model of the reasoning process in a multiagent cognitive system},
journal = {Procedia Computer Science},
volume = {169},
pages = {615-619},
year = {2020},
note = {Postproceedings of the 10th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2019 (Tenth Annual Meeting of the BICA Society), held August 15-19, 2019 in Seattle, Washington, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.202},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920303252},
author = {Zalimhan Nagoev and Inna Pshenokova and Murat Anchekov},
keywords = {Multi-Agent Systems, Neurocognitive Architecture, Simulation Model, Artificial Intelligence Systems, Reasoning Models},
abstract = {A model of the reasoning process in a multiagent cognitive system for the synthesis of intelligent solutions of the problem is presented. The approach based on the computational abstraction of multi-agent neurocognitive systems that illustrates architectural conformity to self-organizing neurocognitive networks of the brain. The model represents the process of reasoning in the form of cognitive blocks that synthesize intelligent solutions and allow the user to effectively solve the tasks.}
}
@article{ADRIAENSEN2023106294,
title = {Systems-theoretic interdependence analysis in robot-assisted warehouse management},
journal = {Safety Science},
volume = {168},
pages = {106294},
year = {2023},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2023.106294},
url = {https://www.sciencedirect.com/science/article/pii/S0925753523002369},
author = {Arie Adriaensen and Liliane Pintelon and Francesco Costantino and Giulio {Di Gravio} and Riccardo Patriarca},
keywords = {FRAM, Human-machine interaction, Industry 4.0, Industry 5.0, Cobots},
abstract = {The safe and efficient application of collaborative robots requires an understanding of actual work practices transformation, emerging from the adoption of new technological instruments. Functional systems-thinking is largely absent in literature about collaborative robot applications. In this context, this study proposes a framework that combines two safety analysis methods, being the Functional Resonance Analysis Method and Interdependence Analysis. Both safety and efficiency are examined by selected case study highlights to gain an in-depth understanding of human operators’ role as the central driver of human–machine (eco)systems in a warehouse distribution system, in which warehouse robot assistance is provided. Whereas the Functional Resonance Analysis Method first maps the work system interactions as a whole, Interdependence Analysis is subsequently applied to investigate individual inter-agent exchanges by the principles of Observability, Predictability, and Directability as a core principle for goal coordination between multiple agents, including warehouse robot agents. The case study examples reveal the combined effects of the working system environment and the robot application but also demonstrate possible operational solutions to deal with socio-technical complexity.}
}
@article{LEE2021101596,
title = {Measuring Mohr social capital},
journal = {Poetics},
volume = {88},
pages = {101596},
year = {2021},
note = {Measure Mohr Culture},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2021.101596},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X21000863},
author = {Monica Lee and Amaç Herdağdelen and Minsu Park and John Levi Martin},
abstract = {We here bring together two different traditions of thinking about social capital. One, the Tocquevillian, looks to associations and group memberships as the core of social capital. The other, the Colemanian, looks to interpersonal networks as the core of social capital. We argue that the most common way of articulating how humans use these types of relationships in different ways—the distinction between “bridging” and “bonding” social capital—is epistemically unstable. What might be possible, however, is to use the insights developed by Ronald Burt regarding tie non-redundancy to study associational social capital. We do this by drawing on the insights of the approach consistently adopted and developed by John Mohr, which emphasizes duality and diversity, to develop measures of group affiliation-based social capital. We accordingly, for both Tocquevillian and Colemanian social capital, distinguish measures that focus on the mass of social capital from those that focus on its diversity. To illustrate, we use de-identified data from 77 Million U.S. Facebook Groups users to measure their degree of all resulting types of social capital. We show that our understanding of who has the most social capital varies greatly by whether we are considering Tocquevillian or Colemanian capital, and whether we are focusing on mass or diversity.}
}
@incollection{HEGARTY2010265,
title = {Chapter 7 - Components of Spatial Intelligence},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {52},
pages = {265-297},
year = {2010},
booktitle = {The Psychology of Learning and Motivation},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(10)52007-3},
url = {https://www.sciencedirect.com/science/article/pii/S0079742110520073},
author = {Mary Hegarty},
abstract = {This chapter identifies two basic components of spatial intelligence, based on analyses of performance on tests of spatial ability and on complex spatial thinking tasks in domains such as mechanics, chemistry, medicine, and meteorology. The first component is flexible strategy choice between mental imagery (or mental simulation more generally) and more analytic forms of thinking. Research reviewed here suggests that mental simulation is an important strategy in spatial thinking, but that it is augmented by more analytic strategies such as task decomposition and rule-based reasoning. The second is meta-representational competence [diSessa, A. A. (2004). Metarepresentation: Native competence and targets for instruction. Cognition and Instruction, 22, 293–331], which encompasses ability to choose the optimal external representation for a task and to use novel external representations productively. Research on this aspect of spatial intelligence reveals large individual differences in ability to adaptively choose and use external visual–spatial representations for a task. This research suggests that we should not just think of interactive external visualizations as ways of augmenting spatial intelligence, but also consider the types of intelligence that are required for their use.}
}
@article{SCHWARZ201359,
title = {Business wargaming for teaching strategy making},
journal = {Futures},
volume = {51},
pages = {59-66},
year = {2013},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2013.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0016328713000864},
author = {Jan Oliver Schwarz},
keywords = {Business wargaming, Teaching, Simulation, Management education, Strategy making, Strategic thinking},
abstract = {An increasingly complex and dynamic business environment requires new approaches to teaching strategy to management students. Business wargaming, a dynamic strategic simulation, is discussed as a management simulation which can respond to the contemporary challenges in management education. Reflecting on the practical use of business wargaming in the classroom, it is described how such simulations prepare management students for making strategic decisions in complex and dynamic environments characterised by high uncertainty concerning the future.}
}
@article{KOPPAKA2024,
title = {Mechanism and Selectivity of Bi(V)-Aryl Oxyfunctionalization in Trifluoroacetic Acid Solvents},
journal = {Organometallics},
year = {2024},
issn = {0276-7333},
doi = {https://doi.org/10.1021/acs.organomet.4c00319},
url = {https://www.sciencedirect.com/science/article/pii/S0276733324003509},
author = {Anjaneyulu Koppaka and Dongdong Yang and Sanaz Mohammadzadeh Koumleh and Burjor Captain and Roy A. Periana and Daniel H. Ess},
abstract = {The oxidative functionalization of aromatic sp2 C–H bonds to C–O bonds is a difficult transformation. For main-group metals, the oxyfunctionalization step of a metal-aryl bond is generally slow and potentially problematic if carried out in a relatively strong acid solvent where protonation could prevent oxyfunctionalization. In this work, we experimentally and computationally analyzed the oxyfunctionalization reaction of (Ph)3BiV(TFA)2 (TFA = trifluoroacetate) in a trifluoroacetic acid (TFAH) solvent. Experiments showed a single oxyfunctionalization product phenyl TFA (PhTFA) and two equivalents of benzene. Explicit/continuum solvent density functional theory calculations revealed that a direct intramolecular reductive functionalization pathway is lower in energy than radical or ionic pathways, and surprisingly from (Ph)3BiV(TFA)2, the reductive functionalization pathway is potentially competitive with protonation. In contrast, for (Ph)2BiV(TFA)3 oxyfunctionalization is significantly lower in energy than protonation. For BiIII-phenyl intermediates, redox neutral protonation is significantly lower in energy than a second functionalization. We also examined the oxyfunctionalization versus protonation of BiV-phenyl complexes with a coordinated biphenyl ligand and a coordinated biphenyl sulfone ligand, which both resulted in oxyfunctionalization. For the biphenyl ligand complex, a protonation-first mechanism is proposed, while for the biphenyl sulfone ligand, an oxyfunctionalization first mechanism is consistent with both calculations and experiments.
}
}
@article{SATTARI2021104981,
title = {Application of Bayesian network and artificial intelligence to reduce accident/incident rates in oil & gas companies},
journal = {Safety Science},
volume = {133},
pages = {104981},
year = {2021},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2020.104981},
url = {https://www.sciencedirect.com/science/article/pii/S0925753520303787},
author = {Fereshteh Sattari and Renato Macciotta and Daniel Kurian and Lianne Lefsrud},
keywords = {Artificial intelligence, Bayesian network, Machine learning, Keyword analysis, Incident data, Process safety management, Latent causes},
abstract = {Process safety management (PSM) is a framework that demonstrates a company’s commitment to process safety, a better understanding of hazards and risks, a comprehensive assessment and management of risks, and enhanced learning from experience to improve overall safety and operational performance. Companies often use an incident data reporting system to execute PSM. While companies keep incident data in thousands of reports, rarely do they glean full value in learning from these to prevent and reduce future incidents. To overcome this challenge, this research applied machine learning and keyword analysis to label and classify 8199 incident reports from an oil and gas company into nine groups identified in the latest version of PSM guidelines published by the Center for Chemical Process Safety (CCPS). To converge on an optimal solution, two different Bayesian network techniques (Tabu and hill climbing) were applied. Both methods resulted in the same map, showing that the Total Number of Incidents has the maximum dependency (50%) on Asset Integrity & Reliability; this means focusing resources on this aspect could reduce the total number of incidents by half. Cross correlation analysis (CCA) was also applied, which validated and confirmed this result. This analysis identifies which measures enhance the company’s safety management strategy to reduce these latent causes, but also supports critical thinking, enhanced communication, and learning culture to improve organizational safety.}
}
@article{HAJELA20021,
title = {Soft computing in multidisciplinary aerospace design—new directions for research},
journal = {Progress in Aerospace Sciences},
volume = {38},
number = {1},
pages = {1-21},
year = {2002},
issn = {0376-0421},
doi = {https://doi.org/10.1016/S0376-0421(01)00015-X},
url = {https://www.sciencedirect.com/science/article/pii/S037604210100015X},
author = {Prabhat Hajela},
abstract = {There has been increased activity in the study of methods for multidisciplinary analysis and design. This field of research has been a busy one over the past decade, driven by advances in computational methods and significant new developments in computer hardware. There is a concern, however, that while new computers will derive their computational speed through parallel processing, current algorithmic procedures that have roots in serial thinking are poor candidates for use on such machines—a paradigm shift is required! Among new advances in computational methods, soft computing techniques have enjoyed a remarkable period of development and growth. Of these, methods of neural computing, evolutionary search, and fuzzy logic have been the most extensively explored in problems of multidisciplinary analysis and design. The paper will summarize important accomplishments to-date, of neurocomputing, fuzzy logic, and evolutionary search, including immune network modeling, in the field of multidisciplinary aerospace design.}
}
@article{1995462,
title = {95/06537 Historical rates of atmospheric Pb deposition using 210Pb dated peat cores: Corroboration, computation, and interpretation},
journal = {Fuel and Energy Abstracts},
volume = {36},
number = {6},
pages = {462},
year = {1995},
issn = {0140-6701},
doi = {https://doi.org/10.1016/0140-6701(95)98112-5},
url = {https://www.sciencedirect.com/science/article/pii/0140670195981125}
}
@article{GORMONG20231988,
title = {Neighboring Group Effects on the Rates of Cleavage of Si–O–Si-Containing Compounds},
journal = {The Journal of Organic Chemistry},
volume = {88},
number = {4},
pages = {1988-1995},
year = {2023},
issn = {0022-3263},
doi = {https://doi.org/10.1021/acs.joc.2c02126},
url = {https://www.sciencedirect.com/science/article/pii/S002232632300107X},
author = {Ethan A. Gormong and Dorian S. Sneddon and Theresa M. Reineke and Thomas R. Hoye},
abstract = {ABSTRACT
The presence of a nearby tethered functional group (G, G = tertiary amide or amine) can significantly impact the rate of cleavage of an Si–O bond. We report here an in situ1H NMR spectroscopic investigation of the relative rates of cleavage of model substrates containing two different Si–O substructures, namely alkoxydisiloxanes [GRO–Si­(Me2)–O–SiMe3] and carbodisiloxanes [GR–Si­(Me2)–O–SiMe3]. The trends in the relative rates (which slowed with increasing chain length, with a notable exception) of alkoxydisiloxane hydrolyses were probed via computation. The results correlated well with the experimental data. In contrast to the hydrolysis of the alkoxydisiloxanes, the carbodisiloxanes were not fully hydrolyzed, but rather formed an equilibrium mixture of starting asymmetric disiloxane, two silanols, and a new symmetrical disiloxane. We also uncovered a facile siloxy-metathesis reaction of an incoming silanol with the carbodisiloxane substrate [e.g., Me2NR–Si­(Me2)–O–SiMe3 + HOSiEt3 ⇋ Me2NR–Si­(Me2)–O–SiEt3 + HOSiMe3] facilitated by the pendant dimethylamino group, a process that was also probed by computation.}
}
@incollection{SUGHRUE2024205,
title = {Chapter 12 - Connectomic approaches to neurosurgical planning},
editor = {Michael E. Sughrue and Jacky T. Yeung and Nicholas B. Dadario},
booktitle = {Connectomic Medicine},
publisher = {Academic Press},
pages = {205-214},
year = {2024},
isbn = {978-0-443-19089-6},
doi = {https://doi.org/10.1016/B978-0-443-19089-6.00011-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443190896000112},
author = {Michael E. Sughrue and Jacky T. Yeung and Nicholas B. Dadario},
keywords = {Brain tumor surgery, Cerebral cortex, Cognitive deficits, fMRI, Graph theory, Neuro-Oncology, Onco-functional balance},
abstract = {In this chapter, we introduce how connectomics can provide an improved understanding of the structural and functional organization of the human brain which can be applied for intracerebral brain surgery. In particular, such connectomic thinking expands our ability to improve patient functional outcomes after surgery beyond mere motor and language functions by also considering the anatomy responsible for complex cognitive functions. We introduce the concept of “disconnection surgery,” where the surgical decisions when removing a tumor can be thought of a series of specific cuts that we plan to perform on the periphery of the tumor such that we can disconnect the tumor from the surrounding networks. Connectomics allows us to define the risks associated with specific tumors and surgical decisions, which can subsequently guide the operation but also tailor preoperative patient discussion. Novel mathematical concepts from the field of network neuroscience on graph theory are also introduced so as to better define truly eloquent brain regions on an individualized basis.}
}
@article{GLASSMEYER2021100873,
title = {Identifying and supporting teachers’ robust understanding of proportional reasoning},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100873},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100873},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000341},
author = {David Glassmeyer and Aaron Brakoniecki and Julie M. Amador},
keywords = {Content knowledge, Knowledge resource, Proportional reasoning, Proportions, Ratio, Teachers},
abstract = {This case study uses the Framework for Teachers’ Robust Understanding of Proportional Reasoning for Teaching (Weiland et al., 2020) to characterize how 51 mathematics teachers solved a comparison proportional problem. We found 50 of the 51 teachers productively drew upon four knowledge resources: (1) proportional situation, (2) ratios as part: part or part: whole, (3) unit rates, and (4) ratio as measure. This study details these and teachers’ less commonly used knowledge resources, as well as counterproductive statements related to the knowledge resources. We analyze the structure of the comparison proportion problem and suggest why teachers drew on particular knowledge resources. Lastly, we highlight how counterproductive statements highlight areas of focus for mathematics teacher educators and extends the operationalizing of the robust proportional reasoning framework for mathematics education researchers.}
}
@incollection{OXMAN2001269,
title = {Chapter 12 - The Mind in Design: A Conceptual Framework for Cognition in Design Education},
editor = {Charles M. Eastman and W. Michael McCracken and Wendy C. Newstetter},
booktitle = {Design Knowing and Learning: Cognition in Design Education},
publisher = {Elsevier Science},
address = {Oxford},
pages = {269-295},
year = {2001},
isbn = {978-0-08-043868-9},
doi = {https://doi.org/10.1016/B978-008043868-9/50012-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780080438689500127},
author = {Rivka Oxman},
abstract = {Publisher Summary
This chapter considers the role of cognitive content of design and design thinking as a basis for developing an educational approach. Various design researchers discussed cognitive approaches in design, and the role of knowledge and representations as a cognitive design-thinking tool. Most of these studies are related directly to design and design thinking rather than to the learning task in design learning and design education. Irrespective of the specific design domain, traditional educational models in design education are based upon the replication of professional-task performance. The measure of learning is generally equated with the evaluation of the product of designing rather than on what might be considered a learning increment. The cognitive properties of design learning have never been the subject of design education. As a consequence, there presently exists a lack of educational theories of learning that function as an underpinning of design education. It is now possible to demonstrate that the derivation of design knowledge through constructive processes, in itself, provides a medium for design learning. This chapter suggests that special design learning environments must be developed to enhance and supplement formal education and foster personal development in design learning.}
}