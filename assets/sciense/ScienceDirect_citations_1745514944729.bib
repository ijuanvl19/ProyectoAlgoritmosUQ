@article{EKINS2014115,
title = {Progress in computational toxicology},
journal = {Journal of Pharmacological and Toxicological Methods},
volume = {69},
number = {2},
pages = {115-140},
year = {2014},
issn = {1056-8719},
doi = {https://doi.org/10.1016/j.vascn.2013.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1056871913003250},
author = {Sean Ekins},
keywords = {Bayesian, Computational toxicology, Machine learning, Support Vector Machine},
abstract = {Introduction: Computational methods have been widely applied to toxicology across pharmaceutical, consumer product and environmental fields over the past decade. Progress in computational toxicology is now reviewed. Methods: A literature review was performed on computational models for hepatotoxicity (e.g. for drug-induced liver injury (DILI)), cardiotoxicity, renal toxicity and genotoxicity. In addition various publications have been highlighted that use machine learning methods. Several computational toxicology model datasets from past publications were used to compare Bayesian and Support Vector Machine (SVM) learning methods. Results: The increasing amounts of data for defined toxicology endpoints have enabled machine learning models that have been increasingly used for predictions. It is shown that across many different models Bayesian and SVM perform similarly based on cross validation data. Discussion: Considerable progress has been made in computational toxicology in a decade in both model development and availability of larger scale or ‘big data’ models. The future efforts in toxicology data generation will likely provide us with hundreds of thousands of compounds that are readily accessible for machine learning models. These models will cover relevant chemistry space for pharmaceutical, consumer product and environmental applications.}
}
@article{MA201542,
title = {Towards computational models of animal cognition, an introduction for computer scientists},
journal = {Cognitive Systems Research},
volume = {33},
pages = {42-69},
year = {2015},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2014.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041714000357},
author = {Zhanshan (Sam) Ma},
keywords = {Animal cognition, Cognitive ecology, Social learning, Bioinspired computing and communication, Behavioral informatics, Computational behavior biology},
abstract = {The last few years of the twentieth century witnessed the emerging convergence of biology and computer science and this trend has been accelerating since then. The study of animal behavior or behavior biology has been one of the major contributors for this convergence. Behavior is fascinating because it is the response of an organism to internal and external signals and it is controlled by complex interactions among nerves, the sensory and the motor systems. To some extent, behavior is similar to the output (or response) of a computer system or a network node if we consider an animal brain as a computer node. This paper is the first in a two-part series in which I review the state-of-the-art research in behavior biology inspired computing and communication, with the first part focusing on animal cognition and the second part on animal communication (Ma, 2014). The present article also assumes the task of presenting a general introduction on behavior biology literature, which sets a foundation for synthesizing both parts of the series but the synthesis will be performed in the second part of the series. I sets three objectives in this ‘cognition’ part: (i) to present a brief overview on the literature of behavior biology for computer scientists; (ii) to summarize the state-of-the-art studies in several cognitive aspects of animal behavior: focusing on emerging research in cognitive ecology, social learning and innovation, as well as animal logics; (iii) to review some important existing studies inspired by animal behavior and further present a perspective on the future research. These cognition-related topics offer insights for research fields such as machine learning, human computer interactions (HCI), brain computer interfaces (BCIs), evolutionary computing, pervasive computing, etc. In perspective, I suggest that the interaction between behavioral biology and computer science should be bidirectional, and a new subject, behavioral informatics, or more general computational behavior biology, should be developed by the cooperative efforts between biologists and computer scientists.}
}
@incollection{GALLEGATI20173,
title = {Chapter 1 - An Introduction to Agent-Based Computational Macroeconomics},
editor = {Mauro Gallegati and Antonio Palestrini and Alberto Russo},
booktitle = {Introduction to Agent-Based Economics},
publisher = {Academic Press},
pages = {3-11},
year = {2017},
isbn = {978-0-12-803834-5},
doi = {https://doi.org/10.1016/B978-0-12-803834-5.00002-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128038345000023},
author = {Mauro Gallegati and Antonio Palestrini and Alberto Russo}
}
@article{LOONG2014237,
title = {Tourism and Simulacrum: The Computational Economy of Algorithmic Destinations},
journal = {Procedia - Social and Behavioral Sciences},
volume = {144},
pages = {237-246},
year = {2014},
note = {5th Asia-Euro Conference 2014 in Tourism, Hospitality & Gastronomy},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.07.292},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814042207},
author = {Bernard Lew Shian Loong},
keywords = {gamified tourism, algorithmic destinations, simulacrum, computational economics, tourism computability, reflexivity},
abstract = {The paper establishes a conceptual and methodological link between destinations and simulacrum through gamified tourism. As a paradigm, gamified tourism provides a rationale and a setting within which to apply computational economics to tourism, an approach amounting to tourism computability. Algorithmic destinations serve as “petri dishes” for real destinations. Utilizing rule sets that embody destination growth dynamics and visitor behavioural norms, seeding points in a cellular automata model (CA) were grown into algorithmic destinations. This is followed by a morphological transformation of geo-tagged satellite images into spatial points. The overlap of this additive and subtractive approach is at the core of tourism computability. Finally, the spatio-temporal dynamics of economic resilience was traced out through a visual phenomenology of algorithmic destinations. The gamification of tourism should be embraced as it holds up a flicker of hope for mature destinations, amidst the onset of museumification and increased commoditization of heritage sites. Gamification is treated as part of the reflexive cycle for destination authenticity; a notion that that Cohen (1988) alluded to in his discussion of emergent authenticity in destination image formation. Seen in this light, the museumification of Venice and the proliferation of its simulacrum, such as the Venetian Hotel in Macao and Venice-themed hotels across the globe, are prefigures and archetypes of a glorious age of gamified tourism.}
}
@article{SAHA2021113452,
title = {Hierarchical Deep Learning Neural Network (HiDeNN): An artificial intelligence (AI) framework for computational science and engineering},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {373},
pages = {113452},
year = {2021},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2020.113452},
url = {https://www.sciencedirect.com/science/article/pii/S004578252030637X},
author = {Sourav Saha and Zhengtao Gan and Lin Cheng and Jiaying Gao and Orion L. Kafka and Xiaoyu Xie and Hengyang Li and Mahsa Tajdari and H. Alicia Kim and Wing Kam Liu},
keywords = {Deep learning, Machine learning, Reduced order model, Data-driven discovery, Multiscale simulation, Artificial intelligence},
abstract = {In this work, a unified AI-framework named Hierarchical Deep Learning Neural Network (HiDeNN) is proposed to solve challenging computational science and engineering problems with little or no available physics as well as with extreme computational demand. The detailed construction and mathematical elements of HiDeNN are introduced and discussed to show the flexibility of the framework for diverse problems from disparate fields. Three example problems are solved to demonstrate the accuracy, efficiency, and versatility of the framework. The first example is designed to show that HiDeNN is capable of achieving better accuracy than conventional finite element method by learning the optimal nodal positions and capturing the stress concentration with a coarse mesh. The second example applies HiDeNN for multiscale analysis with sub-neural networks at each material point of macroscale. The final example demonstrates how HiDeNN can discover governing dimensionless parameters from experimental data so that a reduced set of input can be used to increase the learning efficiency. We further present a discussion and demonstration of the solution for advanced engineering problems that require state-of-the-art AI approaches and how a general and flexible system, such as HiDeNN-AI framework, can be applied to solve these problems.}
}
@article{MCCLELLAND20221047,
title = {Capturing advanced human cognitive abilities with deep neural networks},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {12},
pages = {1047-1050},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S136466132200239X},
author = {James L. McClelland},
keywords = {scientific reasoning, mathematical cognition, neural networks, goal-directed thinking, artificial intelligence},
abstract = {How can artificial neural networks capture the advanced cognitive abilities of pioneering scientists? I suggest they must learn to exploit human-invented tools of thought and human-like ways of using them, and must engage in explicit goal-directed problem solving as exemplified in the activities of scientists and mathematicians and taught in advanced educational settings.}
}
@article{DEMARTINO20131222,
title = {In the Mind of the Market: Theory of Mind Biases Value Computation during Financial Bubbles},
journal = {Neuron},
volume = {79},
number = {6},
pages = {1222-1231},
year = {2013},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2013.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0896627313005680},
author = {Benedetto De Martino and John P. O’Doherty and Debajyoti Ray and Peter Bossaerts and Colin Camerer},
abstract = {Summary
The ability to infer intentions of other agents, called theory of mind (ToM), confers strong advantages for individuals in social situations. Here, we show that ToM can also be maladaptive when people interact with complex modern institutions like financial markets. We tested participants who were investing in an experimental bubble market, a situation in which the price of an asset is much higher than its underlying fundamental value. We describe a mechanism by which social signals computed in the dorsomedial prefrontal cortex affect value computations in ventromedial prefrontal cortex, thereby increasing an individual’s propensity to ‘ride’ financial bubbles and lose money. These regions compute a financial metric that signals variations in order flow intensity, prompting inference about other traders’ intentions. Our results suggest that incorporating inferences about the intentions of others when making value judgments in a complex financial market could lead to the formation of market bubbles.}
}
@article{JARAETTINGER2016589,
title = {The Naïve Utility Calculus: Computational Principles Underlying Commonsense Psychology},
journal = {Trends in Cognitive Sciences},
volume = {20},
number = {8},
pages = {589-604},
year = {2016},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2016.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364661316300535},
author = {Julian Jara-Ettinger and Hyowon Gweon and Laura E. Schulz and Joshua B. Tenenbaum},
abstract = {We propose that human social cognition is structured around a basic understanding of ourselves and others as intuitive utility maximizers: from a young age, humans implicitly assume that agents choose goals and actions to maximize the rewards they expect to obtain relative to the costs they expect to incur. This ‘naïve utility calculus’ allows both children and adults observe the behavior of others and infer their beliefs and desires, their longer-term knowledge and preferences, and even their character: who is knowledgeable or competent, who is praiseworthy or blameworthy, who is friendly, indifferent, or an enemy. We review studies providing support for the naïve utility calculus, and we show how it captures much of the rich social reasoning humans engage in from infancy.}
}
@article{OISHI2017327,
title = {Computational mechanics enhanced by deep learning},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {327},
pages = {327-351},
year = {2017},
note = {Advances in Computational Mechanics and Scientific Computation—the Cutting Edge},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2017.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S0045782517306199},
author = {Atsuya Oishi and Genki Yagawa},
keywords = {Deep learning, Artificial neural network, Numerical quadrature, Element stiffness matrix},
abstract = {The present paper describes a method to enhance the capability of, or to broaden the scope of computational mechanics by using deep learning, which is one of the machine learning methods and is based on the artificial neural network. The method utilizes deep learning to extract rules inherent in a computational mechanics application, which usually are implicit and sometimes too complicated to grasp from the large amount of available data A new method of numerical quadrature for the FEM stiffness matrices is developed by using the proposed method, where a kind of optimized quadrature rule superior in accuracy to the standard Gauss–Legendre quadrature is obtained on the element-by-element basis. The detailed formulation of the proposed method is given with the sample application above, and an acceleration technique for the proposed method is discussed}
}
@article{HENDRIARTO20241225,
title = {The development of mobile application for the deaf to learn better},
journal = {Procedia Computer Science},
volume = {245},
pages = {1225-1237},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.352},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031600},
author = {Helena Angelie Margaretha Hendriarto and Yudhistya Ayu Kusumawati and Rudi Yulio Arindiono},
keywords = {Deaf, Education, Learning features, Mobile application},
abstract = {Education is very important for all individuals, including people with disabilities such as the deaf, to advance the nation and survive. In this case, effective communication of educational material is important to create a conducive learning environment. Most people also believe that deaf people can make a big contribution to society if they receive the right education, and this becomes a challenge for deaf teachers and students. Therefore, this paper aims to find a solution that can become a means of independent education for deaf people. This paper is using design thinking method to achieve the goal. The result of this research is the development of an educational mobile application specifically for the deaf, namely 'V-Voice'. This application provides various learning features, such as; animated videos, education games and texts that are attractively designed. Through 'V-Voice', it is hoped that deaf people can study harder independently and be helped to manage information and develop their soft skills and hard skills.}
}
@article{THIRUNAVUKARASU2022106020,
title = {Towards computational solutions for precision medicine based big data healthcare system using deep learning models: A review},
journal = {Computers in Biology and Medicine},
volume = {149},
pages = {106020},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106020},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522007429},
author = {Ramkumar Thirunavukarasu and George Priya Doss C and Gnanasambandan R and Mohanraj Gopikrishnan and Venketesh Palanisamy},
keywords = {Personalized medicine, Precision medicine, Artificial intelligence, Deep learning, Healthcare big data},
abstract = {The emergence of large-scale human genome projects, advances in DNA sequencing technologies, and the massive volume of electronic medical records [EMR] shift the transformation of healthcare research into the next paradigm, namely ‘Precision Medicine.’ This new clinical system model uses patients' genomic profiles and disparate healthcare data sources to a greater extent and provides personalized deliverables. As an advanced analytical technique, deep learning models significantly impact precision medicine because they can process voluminous amounts of diversified data with improved accuracy. Two salient features of deep learning models, namely processing a massive volume of multi-model data at multiple levels of abstraction and the ability to identify inherent features from the input data on their own, attract the implication of deep learning techniques in precision medicine research. The proposed review highlights the importance of deep learning-based analytical models in handling diversified and disparate big data sources of precision medicine. To augment further, state-of-the-art precision medicine research based on the taxonomy of deep learning models has been reviewed along with their research outcomes. The diversified data inputs used in research attempts, their applications, benchmarking data repositories, and usage of various evaluation measures for accuracy estimations are highlighted in this review. This review also brings out some promising analytical avenues of precision medicine research that give directions for future exploration.}
}
@incollection{WARD201140,
title = {Analogies},
editor = {Mark A. Runco and Steven R. Pritzker},
booktitle = {Encyclopedia of Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {40-45},
year = {2011},
isbn = {978-0-12-375038-9},
doi = {https://doi.org/10.1016/B978-0-12-375038-9.00009-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123750389000091},
author = {T.B. Ward},
keywords = {ACME, Analogy, Case study, Computational modeling,  study, Laboratory study, Mapping, Multiconstraint theory, One-to-one correspondence, Parallel connectivity, Retrieval, SME, Source domain, Structure-mapping theory, Systematicity, Target domain},
abstract = {Analogical thinking is a fundamental cognitive process underlying creativity. Analogies map structured knowledge from one domain to another and serve as information for understanding, explaining and creating. Analogy is studied through case study, laboratory, in vivo and computational modeling approaches. The use of analogy is often suggested to be a helpful technique in applied approaches to creativity.}
}
@article{WANG20241359,
title = {On Metaphor Translation into English Based on Artificial Intelligence},
journal = {Procedia Computer Science},
volume = {247},
pages = {1359-1365},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.162},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924029636},
author = {Zikang Wang and Jinlian Chai},
keywords = {Artificial intelligence, English translation of metaphor, Machine translation},
abstract = {As a rhetorical device, metaphor plays an instrumental role in facilitating human thinking, cognition and communication. The translation of metaphors into English represents a significant challenge, involving cross-cultural, cross-linguistic and cross-domain considerations. In recent years, the rapid development of artificial intelligence has provided a new method and approach for English metaphor translation. This article mainly discusses the basic concept of artificial intelligence, puts forward the key technologies of metaphor translation in artificial intelligence, and then analyzes the difficulties and methods of metaphor translation with the purpose of providing a reference point and helpful insights.}
}
@article{TANG2024103266,
title = {A causal counterfactual graph neural network for arising-from-chair abnormality detection in parkinsonians},
journal = {Medical Image Analysis},
volume = {97},
pages = {103266},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103266},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524001919},
author = {Xinlu Tang and Rui Guo and Chencheng Zhang and Xiaohua Qian},
keywords = {Parkinson's disease, Arising-from-chair, Graph neural network, Causal inference, Counterfactual thinking},
abstract = {The arising-from-chair task assessment is a key aspect of the evaluation of movement disorders in Parkinson's disease (PD). However, common scale-based clinical assessment methods are highly subjective and dependent on the neurologist's expertise. Alternate automated methods for arising-from-chair assessment can be established based on quantitative susceptibility mapping (QSM) images with multiple-instance learning. However, performance stability for such methods can be typically undermined by the presence of irrelevant or spuriously-relevant features that mask the intrinsic causal features. Therefore, we propose a QSM-based arising-from-chair assessment method using a causal graph-neural-network framework, where counterfactual and debiasing strategies are developed and integrated into this framework for capturing causal features. Specifically, the counterfactual strategy is proposed to suppress irrelevant features caused by background noise, by producing incorrect predictions when dropping causal parts. The debiasing strategy is proposed to suppress spuriously relevant features caused by the sampling bias and it comprises a resampling guidance scheme for selecting stable instances and a causal invariance constraint for improving stability under various interferences. The results of extensive experiments demonstrated the superiority of the proposed method in detecting arising-from-chair abnormalities. Its clinical feasibility was further confirmed by the coincidence between the selected causal features and those reported in earlier medical studies. Additionally, the proposed method was extensible for another motion task of leg agility. Overall, this study provides a potential tool for automated arising-from-chair assessment in PD patients, and also introduces causal counterfactual thinking in medical image analysis. Our source code is publicly available at https://github.com/SJTUBME-QianLab/CFGNN-PDarising.}
}
@incollection{CARETTE202215,
title = {Chapter Two - Embracing the laws of physics: Three reversible models of computation},
editor = {Ali R. Hurson},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {126},
pages = {15-63},
year = {2022},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2021.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0065245821000838},
author = {Jacques Carette and Roshan P. James and Amr Sabry},
keywords = {Reversible programming, Reversible Boolean circuits, Monoidal categories, Type isomorphisms, Commutative semirings, Homotopy-type theory, Quantum circuits, Permutations},
abstract = {Our main models of computation (the Turing Machine and the RAM) and most modern computer architectures make fundamental assumptions about which primitive operations are realizable on a physical computing device. The consensus is that these primitive operations include logical operations like conjunction, disjunction and negation, as well as reading and writing to a large collection of memory locations. This perspective conforms to a macro-level view of physics and indeed these operations are realizable using macro-level devices involving thousands of electrons. This point of view is however incompatible with computation realized using quantum devices or analyzed using elementary thermodynamics as both these fundamental physical theories imply that information is a conserved quantity of physical processes and hence of primitive computational operations. Our aim is to redevelop foundational computational models in a way that embraces the principle of conservation of information. We first define what information is and what its conservation means in a computational setting. We emphasize the idea that computations must be reversible transformations on data. One can think of data as modeled using topological spaces and programs as modeled by reversible deformations of these spaces. We then illustrate this idea using three notions of data and their associated reversible computational models. The first instance only assumes unstructured finite data, i.e., discrete topological spaces. The corresponding notion of reversible computation is that of permutations. We show how this simple model subsumes conventional computations on finite sets. We then consider a modern structured notion of data based on the Curry–Howard correspondence between logic and type theory. We develop the corresponding notion of reversible deformations using a sound and complete programming language for witnessing type isomorphisms and proof terms for commutative semirings. We then “move up a level” to examine spaces that treat programs as data, which is a crucial notion for any universal model of computation. To derive the corresponding notion of reversible programs between programs, i.e., reversible program equivalences, we look at the “higher dimensional” analog to commutative semirings: symmetric rig groupoids. The coherence laws for these groupoids turn out to be exactly the sound and complete reversible program equivalences we seek. We conclude with some possible generalizations inspired by homotopy type theory and survey several open directions for further research.}
}
@incollection{PERRI202255,
title = {Chapter 4 - High-performance computing and computational intelligence applications with a multi-chaos perspective},
editor = {Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis},
booktitle = {Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems},
publisher = {Academic Press},
pages = {55-76},
year = {2022},
isbn = {978-0-323-90032-4},
doi = {https://doi.org/10.1016/B978-0-323-90032-4.00010-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323900324000109},
author = {Damiano Perri and Marco Simonetti and Osvaldo Gervasi and Sergio Tasso},
keywords = {Cloud computing, Computational intelligence, Container, High performance computing, Machine learning, Multi-chaos, Neural networks, Privacy, Quantum computing},
abstract = {The experience of the COVID-19 pandemic, which has accelerated many chaotic processes in modern society, has highlighted in a very serious and urgent way the need to understand complex processes in order to achieve the common well-being. Modern high performance computing technologies, quantum computing, computational intelligence are shown to be extremely efficient and useful in safeguarding the fate of mankind. These technologies are the state-of-the-art of IT evolution and are fundamental to be competitive and efficient today. If a company is familiar with these techniques and technologies, it will be able to deal with any unexpected and complicated scenarios more efficiently and effectively. The main contribution of our work is a set of best practices and case studies that can help the researcher address computationally complex problems. We offer a range of software technologies, from high performance computing to machine learning and quantum computing, which represent today the state-of-the-art to deal with extremely complex computational issues, driven by chaotic events and not easily predictable. In this chapter we analyze the different technologies and applications that will lead mankind to overcome this difficult moment as well as to understand more and more deeply the profound aspects of very complex phenomena. In this environment of rising complexity, in terms of technology, algorithms, and changing lifestyles, it is critical to emphasize the importance of achieving maximum efficiency and outcomes while protecting the integrity of everyone's personal data and respecting the human being as a whole.}
}
@article{MATENCIO2021129639,
title = {A physicochemical, thermodynamical, structural and computational evaluation of kynurenic acid/cyclodextrin complexes},
journal = {Food Chemistry},
volume = {356},
pages = {129639},
year = {2021},
issn = {0308-8146},
doi = {https://doi.org/10.1016/j.foodchem.2021.129639},
url = {https://www.sciencedirect.com/science/article/pii/S0308814621006452},
author = {Adrián Matencio and Fabrizio Caldera and Alberto {Rubin Pedrazzo} and Yousef {Khazaei Monfared} and Nilesh {K. Dhakar} and Francesco Trotta},
keywords = {Kynurenic acid, Cyclodextrin, Inclusion complex, Physicochemical, Stability},
abstract = {In this work, the interaction between Kynurenic acid (KYNA) and several natural and modified cyclodextrins (CDs) is carried out. Among all the CD tested, HPβ-CD showed the strongest complexation constant (KF), with a value of 270.94 ± 29.80 M−1. Between natural (α- and β-) CDs, the complex of KYNA with β-CD was the most efficient. The inclusion complex of KYNA with CDs showed a strong influence of pH and temperature. The KF value decreased at high pH values, when the pKa was passed. Moreover, an increase of the temperature caused a decrease in the KF values. The thermodynamic parameters of the complexation (ΔH°, ΔS° and ΔG°) were studied with negative entropy, enthalpy and spontaneity of the process at 25 °C. Moreover, the inclusion complex was also characterized using FTIR and TGA. Finally, molecular docking calculations provided different interactions and their influence in the complexation constant.}
}
@article{WANG2007126,
title = {Nature-inspired Computation — Effective Realization of Artificial Intelligence},
journal = {Systems Engineering - Theory & Practice},
volume = {27},
number = {5},
pages = {126-134},
year = {2007},
issn = {1874-8651},
doi = {https://doi.org/10.1016/S1874-8651(08)60034-4},
url = {https://www.sciencedirect.com/science/article/pii/S1874865108600344},
author = {Lei WANG and Qi KANG and Qi-di WU},
keywords = {nature-inspired computation, general mode, uniform framework mode, neural networks, swarm intelligence},
abstract = {In nature-inspired computation, different intelligent computation modes of agents usually have different extrinsic forms; but can they take on some relative uniform characteristics? To validate this idea, further systematic study on nature-inspired computation from a more macroscopical angle is made in this article and the uniform framework mode of nature-inspired computation is consequently summarized and presented, as well as described with feedback neural network and swarm intelligence algorithms. On the basis of the defined general mode framework, agents of the algorithms in a nature-inspired computation field can show a type of uniform intelligent computation mode.}
}
@incollection{DAVIS2017xv,
title = {Survival of the Fittest Computational Chemists, Computers, and Reference Works (Over a 30-Year Period)},
editor = {Samuel Chackalamannil and David Rotella and Simon E. Ward},
booktitle = {Comprehensive Medicinal Chemistry III},
publisher = {Elsevier},
address = {Oxford},
pages = {xv-xxii},
year = {2017},
isbn = {978-0-12-803201-5},
doi = {https://doi.org/10.1016/B978-0-12-409547-2.12337-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124095472123376},
author = {A.M. Davis and C.M. Edge}
}
@article{SU2021100862,
title = {Is the Text-Based Cognitive Tool More Effective Than the Concept Map on Improving the Pre-Service Teachers’ Argumentation Skills?},
journal = {Thinking Skills and Creativity},
volume = {41},
pages = {100862},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100862},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121000778},
author = {Guo Su and Taotao Long},
keywords = {Argumentation skills, cognitive tools, pre-service teachers},
abstract = {How to improve pre-service teachers’ argumentation skills has been receiving more and more attention from teacher educators. Visual cognitive tool refers to tools which users can learn with and creatively use to construct knowledge online. Current research revealed that it could help to improve learners’ higher-order thinking skills. This experimental study aimed to investigate the effect of two kinds of cognitive tools, the text-based online visual cognitive tool and the visual concept map, on improving the pre-service teachers’ skills on constructing and evaluating arguments. Post-test argumentation measurement scores and attitude questionnaire showed that the text-based cognitive tool was more effective than the concept map on improving pre-service teachers’ argumentation skills. However, the concept map was useful for externalizing the pre-service teachers’ thinking process as well as collaborative learning. This study also found that the pre-service teachers with teaching experience were inferior to the ones without any teaching experience in the ability on constructing arguments.}
}
@article{KORIYAMA2021458,
title = {Inclusive cognitive hierarchy},
journal = {Journal of Economic Behavior & Organization},
volume = {186},
pages = {458-480},
year = {2021},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2021.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167268121001578},
author = {Yukio Koriyama and Ali I. Ozkes},
keywords = {Cognitive hierarchy, Collective decision-making, Level- model, Strategic thinking},
abstract = {Cognitive hierarchy theory, a collection of structural models of non-equilibrium thinking, in which players’ best responses rely on heterogeneous beliefs on others’ strategies including naïve behavior, proved powerful in explaining observations from a wide range of games. We propose an inclusive cognitive hierarchy model, in which players do not rule out the possibility of facing opponents at their own thinking level. Our theoretical results show that inclusiveness is crucial for asymptotic properties of deviations from equilibrium behavior in expansive games. We show that the limiting behaviors are categorized in three distinct types: naïve, Savage rational with inconsistent beliefs, and sophisticated. We test the model in a laboratory experiment of collective decision-making. The data suggests that inclusiveness is indispensable with regard to explanatory power of the models of hierarchical thinking.}
}
@article{DALLACHIARA201894,
title = {A many-valued approach to quantum computational logics},
journal = {Fuzzy Sets and Systems},
volume = {335},
pages = {94-111},
year = {2018},
note = {Special Issue: Selected Papers from the 36th Linz Seminar on Fuzzy Set Theory},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2016.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0165011416304560},
author = {M.L. {Dalla Chiara} and R. Giuntini and G. Sergioli and R. Leporini},
keywords = {Quantum logics, Quantum tomography, Logical gates},
abstract = {Quantum computational logics are special examples of quantum logic where formulas are supposed to denote pieces of quantum information (qubit-systems or mixtures of qubit-systems), while logical connectives are interpreted as reversible quantum logical gates. Hence, any formula of the quantum computational language represents a synthetic logical description of a quantum circuit. We investigate a many-valued approach to quantum information, where the basic notion of qubit has been replaced by the more general notion of qudit. The qudit-semantics allows us to represent as reversible gates some basic logical operations of Łukasiewicz many-valued logics. In the final part of the article we discuss some problems that concern possible implementations of gates by means of optical devices.}
}
@incollection{LAWSON1990108,
title = {9 - Creative thinking},
editor = {Bryan Lawson},
booktitle = {How Designers Think (Second Edition)},
publisher = {Butterworth-Heinemann},
edition = {Second Edition},
pages = {108-120},
year = {1990},
isbn = {978-0-7506-0268-6},
doi = {https://doi.org/10.1016/B978-0-7506-0268-6.50013-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780750602686500139},
author = {Bryan Lawson},
abstract = {Publisher Summary
This chapter discusses creative thinking in design. Design is a creative occupation, and good designers are creative people. One of the most vexing and perennial questions in design education concerns the balance between the free, open-ended, and expressive work demanded of the student and attention to the acquisition of knowledge, discipline, and experience. The effects of experience on problem solving are not always beneficial. In industry, the need to improve already successful products provides the ultimate test of creative thinking. When using personal analogy, the problem solver identifies personally with some part of the problem or solution, thus acting out the situation. Fantasy analogy allows the designer to suspend the sense of credulity and to explore the seemingly fantastic or impossible. Creativity is not only skill or talent but is also related to context—the situation within which the person perceives the problem and performs the process.}
}
@article{MYERSCOUGH2014e143,
title = {Tracking the development of atherosclerosis in silico: a computational model for early inflammatory events},
journal = {Atherosclerosis},
volume = {235},
number = {2},
pages = {e143},
year = {2014},
issn = {0021-9150},
doi = {https://doi.org/10.1016/j.atherosclerosis.2014.05.404},
url = {https://www.sciencedirect.com/science/article/pii/S0021915014006406},
author = {M. Myerscough and A. Chalmers}
}
@article{KARPOVA2016v,
title = {Editorial overview: Neurobiology of cognitive behavior: Complexity of neural computation and cognition},
journal = {Current Opinion in Neurobiology},
volume = {37},
pages = {v-viii},
year = {2016},
note = {Neurobiology of cognitive behavior},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438816300125},
author = {Alla Karpova and Roozbeh Kiani}
}
@article{SUN200912529,
title = {A computational model of an intuitive reasoner for ecosystem control},
journal = {Expert Systems with Applications},
volume = {36},
number = {10},
pages = {12529-12536},
year = {2009},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2009.04.037},
url = {https://www.sciencedirect.com/science/article/pii/S0957417409003686},
author = {Yung-Chien Sun and Grant Clark},
keywords = {Artificial Intelligence, Intuition, Knowledge acquisition, Limited certainty},
abstract = {Intuition is the human capacity to make decisions under novel, complex situations where knowledge is incomplete and of variable levels of certainty. We take the view that intuition can be modeled as a rational and deductive mode of information processing which is suited to novel, complex situations. In this research, a computational algorithm, or “intuitive reasoner”, is proposed which mimics some aspects of human intuition by combining established mathematical tools, such as fuzzy set theory, and some novel innovations. A rule-based scheme is followed and a rule-learning module that allows rules to be learned from incomplete datasets is developed. The input and the rules drawn by the reasoner are allowed to be fuzzy, multi-valued, and low in certainty. A measure of the certainty level, Strength of Belief, is attached to each input as well as each rule. Solutions are formulated through iterations of consolidating intermediate reasoning results, during which the Strength of Belief of corroborating intermediate results is combined. An experimental implementation of the proposed intuitive reasoner is reported, in which the reasoner was used to solve a classification problem. The results showed that, when given increasingly sparse input data, the rule-learning module generated more rules of lower associated certainty than when presented with more complete data. The intuitive reasoner was able to make use of these low-certainty rules to solve the classification problems with an accuracy that compared favorably to that of traditional methods based on complete datasets.}
}
@article{MARUYAMA1987437,
title = {New economic thinking: Morphogenetic causal loops and product adaptation strategy},
journal = {Futures},
volume = {19},
number = {4},
pages = {437-441},
year = {1987},
issn = {0016-3287},
doi = {https://doi.org/10.1016/0016-3287(87)90005-X},
url = {https://www.sciencedirect.com/science/article/pii/001632878790005X},
author = {Magoroh Maruyama},
abstract = {This article sets out to dispel two widespread economic superstitions—the belief in an inherent equilibrium of the economic system, and the perception of international trade as a zero-sum game. The author argues that morphogenetic causal loops disprove the first assumption, and should be used to aid policy making; and that positive-sum results could be obtained by lifting import restrictions and adapting products for foreign markets.}
}
@article{DESTEXHE2011717,
title = {Intracellular and computational evidence for a dominant role of internal network activity in cortical computations},
journal = {Current Opinion in Neurobiology},
volume = {21},
number = {5},
pages = {717-725},
year = {2011},
note = {Networks, circuits and computation},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2011.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959438811001012},
author = {Alain Destexhe},
abstract = {The mammalian cerebral cortex is characterized by intense spontaneous activity, depending on brain region, age, and behavioral state. Classically, the cortex is considered as being driven by the senses, a paradigm which corresponds well to experiments in quiescent or deeply anesthetized states. In awake animals, however, the spontaneous activity cannot be considered as ‘background noise’, but is of comparable—or even higher—amplitude than evoked sensory responses. Recent evidence suggests that this internal activity is not only dominant, but also it shares many properties with the responses to natural sensory inputs, suggesting that the spontaneous activity is not independent of the sensory input. Such evidence is reviewed here, with an emphasis on intracellular and computational aspects. Statistical measures, such as the spike-triggered average of synaptic conductances, show that the impact of internal network state on spiking activity is major in awake animals. Thus, cortical activity cannot be considered as being driven by the senses, but sensory inputs rather seem to modulate and modify the internal dynamics of cerebral cortex. This view offers an attractive interpretation not only of dreaming activity (absence of sensory input), but also of several mental disorders.}
}
@article{LEE2024107,
title = {Project-Based Learning Course Design for Multi-Agent Autonomy Using Quadrotors⁎⁎This group design project of academic year 2023/24 has been sponsored by Leonardo S.p.A.},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {16},
pages = {107-112},
year = {2024},
note = {2nd IFAC Workshop on Aerospace Control Education - WACE 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.470},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324012394},
author = {Hae-In Lee and Dmitry Ignatyev and Hyo-Sang Shin and Antonios Tsourdos},
keywords = {Project-Based Learning, Autonomous Multi-Agent System, Unmanned Aerial Vehicles, Quadrotor, Surveillance},
abstract = {This paper proposes a project-based learning course utilising multiple quadrotors, aiming to solidify and amplify technical knowledge and develop critical thinking capabilities. An engineering problem is provided as a surveillance mission with multiple quadrotors autonomously searching, detecting, and tracking ground vehicles. The course covers all stages of multi-agent autonomy development, from identiflying system requirements, designing software and hardware, to conducting demonstrations in a drone flying arena. During the course, students improve their ability to critically formulate, solve and evaluate engineering problems as well as gain and apply technical knowledge in all aspects of autonomy such as fight dynamics, control, navigation, guidance, task allocation, situational awareness and communication. The paper details the problem design, course timeline, outcomes, and key lessons learnt from the course.}
}
@article{LI2025104962,
title = {Developing pre-service teachers' noticing skills in mathematics PBL contexts: Effects of a video-based teacher education course},
journal = {Acta Psychologica},
volume = {255},
pages = {104962},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.104962},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825002756},
author = {Sha Li and Chunxia Qi and Ruisi Li and Ying Jin and Liuchang Cheng and Guanxiong Liu},
keywords = {Teacher noticing, Pre-service mathematics teacher, Video, Teacher education, Project-based learning},
abstract = {This study highlights the importance of developing teacher noticing skills in the context of mathematics project-based learning (PBL), an area critical for improving instructional quality. The research aims to explore how and the extent to which pre-service teachers (PSTs) develop noticing skills through a video-based teacher education course. Drawing on frameworks of teacher noticing (attending, reasoning, and decision-making) and PBL's six A's (e.g., authenticity and academic rigor), the study employed longitudinal analysis pre-post designs to evaluate changes in PSTs' noticing skills. The findings reveal significant improvements in reasoning skills, with PSTs increasingly adopting interpretive stances and integrating specific mathematical knowledge. Decision-making direction diversified, with a notable rise in proposing next instructional steps. However, PSTs prioritized teacher-centered strategies and struggled to accurately apply PBL principles. Developmental paths varied, with 40 % of PSTs expanding their noticing vision to integrate student thinking and PBL elements, while others retained narrow perspectives. These results underscore the value of structured video-based course in enhancing noticing skills but highlight the need for further research to optimize such programs for better instructional practices. This study contributes to the field by addressing the intersection of teacher noticing and PBL, offering insights into effective teacher preparation strategies.}
}
@article{ALISHA20241202,
title = {Interactive role-playing game for elementary students to introducing Javan Langur},
journal = {Procedia Computer Science},
volume = {245},
pages = {1202-1212},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.350},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031582},
author = {Nurulizza Eshal Alisha and Yudhistya Ayu Kusumawati},
keywords = {Endangered animals, Interactive Game, Javan Langur, Learning Media},
abstract = {Indonesia is a country with a lot of biodiversity, both in the form of animals and plants, unfortunately, some of the biodiversity is classified as almost extinct, or even extinct, and the Javan Langur is included in the group of endangered animals because of its declining population, recorded at the Javan Langur Center there are only a few of Javan Langurs that have been successfully repatriated. Javan Langurs are also not widely known to people about their existence and extinction conditions, so there must be media to provide information to the wider community, especially to elementary students to form knowledge and prevention. With the rapid development of technology in the current era, there are various learning media that can be used, one of which is interactive games. This work aims to help students recognize endangered animals, including the Javan Langur, and help teaching institutions provide effective learning media for students. This research use design thinking as the research method. Questionnaires and interviews with resource persons who are elementary school students in grades 5 and 6, teachers, and parents. The result of this research is an interactive learning media in the form of a game with storytelling feature. This storytelling feature also include lesson contents and some challenge games with a character that will guide the storyline, much like a role-playing game or RPG.}
}
@article{DIAZ2021247,
title = {Evaluating Aspects of Usability in Video Game-Based Programming Learning Platforms},
journal = {Procedia Computer Science},
volume = {181},
pages = {247-254},
year = {2021},
note = {CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.141},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921001812},
author = {Jaime Díaz and Jeferson Arango López and Samuel Sepúlveda and Gabriel Mauricio {Ramírez Villegas} and Danay Ahumada and Fernando Moreira},
keywords = {Human-Computer Interaction, Usability, Video-games, Training, Computer Programming},
abstract = {Teaching computer programming is an important topic. Due to Science and Technology initiatives, these topics are considered in different training cycles. For higher education, students must cultivate fundamental concepts for the development of software applications, which not only contribute to the knowledge of programming languages but also to opening guidelines for computational thinking. However, selecting a proper tool can be complex. Especially for the diversity of alternatives on the web. Further, not all of them meet basic usability requirements. In this study, we present a set of platforms that seek to develop programming skills based on video games. The search consisted of 4 stages: (i) definition of the research questions, (ii) scope review, (iii) execution of search and (iv) platform selection. Finally, we employ a usability heuristic evaluation for a novice programming system to determine best practices.}
}
@article{READ2017237,
title = {Virtual personalities: Using computational modeling to understand within-person variability},
journal = {Journal of Research in Personality},
volume = {69},
pages = {237-249},
year = {2017},
note = {Within-Person Variability in Personality},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2016.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0092656616301738},
author = {Stephen J. Read and Benjamin J. Smith and Vitaliya Droutman and Lynn C. Miller},
keywords = {Virtual personalities, Within-person variability, Between-person variability, Social computational modeling},
abstract = {How can the same underlying psychological/neurobiological system result in both stable between-individual differences and high levels of within-individual variability in personality states over time and situations? We argue that both types of variability result from a psychological system based on structured, chronic motivations, where behavior at a specific point in time is a joint function of the current availability of motive affordances in the situation, current motivationally relevant bodily or interoceptive states, and the result of the competition among alternative active motives. Here we present a biologically-based theoretical framework, embodied in two different computational models, that shows how individuals with stable personality characteristics, can nevertheless exhibit considerable within-person variability in personality states across time and situations.}
}
@article{MAITY2016152,
title = {A Computational Model to Predict Aesthetic Quality of Text Elements of GUI},
journal = {Procedia Computer Science},
volume = {84},
pages = {152-159},
year = {2016},
note = {Proceeding of the Seventh International Conference on Intelligent Human Computer Interaction (IHCI 2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.04.081},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916300965},
author = {Ranjan Maity and Akshay Madrosiya and Samit Bhattacharya},
keywords = {Aesthetics, web page, text elements, aesthetic score, categorization},
abstract = {The role of aesthetics in determining usability of interactive systems has come under focus in recent time. The issue is relevant for Graphical User Interfaces (GUI) containing elements of widely varying nature. It is important to evaluate GUI aesthetically to determine their acceptability to the users. Computational models have been reported in the literature to perform objective assessment of interface aesthetics. However, the existing models only consider geometric features at the highest level, without considering the content inside the geometry. To address this issue, we propose a computational model to evaluate aesthetics of textual contents present on a GUI. The proposed model is based on empirical data collected from user studies. The model is a weighted sum of six features characterizing text: chromatic contrast, luminance contrast, font size, letter spacing, line height and word spacing. A separate validation study demonstrates the feasibility and potential of the model (showing 87% accuracy in model prediction), which is expected to be useful in predicting usability of a web page in a more refined way. Such modeling has its obvious implications in the context of engineering interactive systems. The proposed model along with the user studies are presented in this paper.}
}
@article{NOWICKI2012324,
title = {Improving the computational efficiency of metric-based spares algorithms},
journal = {European Journal of Operational Research},
volume = {219},
number = {2},
pages = {324-334},
year = {2012},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2011.12.033},
url = {https://www.sciencedirect.com/science/article/pii/S0377221711011271},
author = {David R. Nowicki and Wesley S. Randall and Jose Emmanuel Ramirez-Marquez},
keywords = {Inventory, Performance based logistics, Logistics, Supply chain, Optimization, Outcome based contracting},
abstract = {We propose a new heuristic algorithm to improve the computational efficiency of the general class of Multi-Echelon Technique for Recoverable Item Control (METRIC) problems. The objective of a METRIC-based decision problem is to systematically determine the location and quantity of spares that either maximizes the operational availability of a system subject to a budget constraint or minimizes its cost subject to an operational availability target. This type of sparing analysis has proven essential when analyzing the sustainment policies of large-scale, complex repairable systems such as those prevalent in the defense and aerospace industries. Additionally, the frequency of these sparing studies has recently increased as the adoption of performance-based logistics (PBL) has increased. PBL represents a class of business strategies that converts the recurring cost associated with maintenance, repair, and overhaul (MRO) into cost avoidance streams. Central to a PBL contract is a requirement to perform a business case analysis (BCA) and central to a BCA is the frequent need to use METRIC-based approaches to evaluate how a supplier and customer will engage in a performance based logistics arrangement where spares decisions are critical. Due to the size and frequency of the problem there exists a need to improve the efficiency of the computationally intensive METRIC-based solutions. We develop and validate a practical algorithm for improving the computational efficiency of a METRIC-based approach. The accuracy and effectiveness of the proposed algorithm are analyzed through a numerical study. The algorithm shows a 94% improvement in computational efficiency while maintaining 99.9% accuracy.}
}
@article{MOUTOUSSIS20212025,
title = {Decision-making ability, psychopathology, and brain connectivity},
journal = {Neuron},
volume = {109},
number = {12},
pages = {2025-2040.e7},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321002853},
author = {Michael Moutoussis and Benjamín Garzón and Sharon Neufeld and Dominik R. Bach and Francesco Rigoli and Ian Goodyer and Edward Bullmore and Peter Fonagy and Peter Jones and Tobias Hauser and Rafael Romero-Garcia and Michelle {St Clair} and Petra Vértes and Kirstie Whitaker and Becky Inkster and Gita Prabhu and Cinly Ooi and Umar Toseeb and Barry Widmer and Junaid Bhatti and Laura Villis and Ayesha Alrumaithi and Sarah Birt and Aislinn Bowler and Kalia Cleridou and Hina Dadabhoy and Emma Davies and Ashlyn Firkins and Sian Granville and Elizabeth Harding and Alexandra Hopkins and Daniel Isaacs and Janchai King and Danae Kokorikou and Christina Maurice and Cleo McIntosh and Jessica Memarzia and Harriet Mills and Ciara O’Donnell and Sara Pantaleone and Jenny Scott and Pasco Fearon and John Suckling and Anne-Laura {van Harmelen} and Rogier Kievit and Marc Guitart-Masip and Raymond J. Dolan},
keywords = {decision acuity, computational psychiatry, functional connectivity, adolescence, development},
abstract = {Summary
Decision-making is a cognitive process of central importance for the quality of our lives. Here, we ask whether a common factor underpins our diverse decision-making abilities. We obtained 32 decision-making measures from 830 young people and identified a common factor that we call “decision acuity,” which was distinct from IQ and reflected a generic decision-making ability. Decision acuity was decreased in those with aberrant thinking and low general social functioning. Crucially, decision acuity and IQ had dissociable brain signatures, in terms of their associated neural networks of resting-state functional connectivity. Decision acuity was reliably measured, and its relationship with functional connectivity was also stable when measured in the same individuals 18 months later. Thus, our behavioral and brain data identify a new cognitive construct that underpins decision-making ability across multiple domains. This construct may be important for understanding mental health, particularly regarding poor social function and aberrant thought patterns.}
}
@article{KOTAGODAHETTI2024118926,
title = {Life cycle-based multi-objective model for optimal gaseous fuel generation and portfolio allocation in gas grids: A strategic decarbonization},
journal = {Energy Conversion and Management},
volume = {319},
pages = {118926},
year = {2024},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2024.118926},
url = {https://www.sciencedirect.com/science/article/pii/S0196890424008677},
author = {Ravihari Kotagodahetti and Kasun Hewage and Ezzeddin Bakhtavar and Rehan Sadiq},
keywords = {Biomethane, Hydrogen, Environmental impacts, Economic impacts, Life cycle thinking, Multi-objective optimization},
abstract = {Biomethane and hydrogen are acknowledged as transformative opportunities for decarbonizing the conventional gas grid. Essential to this transformation is the modeling of the gaseous fuel supply chain, particularly with hydrogen and biomethane, offering crucial insights for decision-makers. This study introduces a life cycle thinking-based multi-objective optimization model for the integrated design of biomethane and hydrogen gaseous fuel supply chain networks. The model determines optimal resource allocation for the production of the two fuels, integrating them into the conventional gas network. Moreover, it allocates conventional natural gas, biomethane, and hydrogen optimally across building, industry, and transport sectors, considering the life cycle environmental and economic performance of fuel integration paths. Objective functions include minimization of life cycle emissions and levelized cost of energy while maximizing revenue from fuel sales. Integrating life cycle assessment and cost analysis tools, the optimization model quantifies emissions and life cycle costs for biomethane and hydrogen paths. Results identify Pareto-optimal fuel production paths and portfolios, revealing that integrating the alternative fuels into the current gas grid can significantly reduce emissions (up to 250 tonCO2eq/year) and generate substantial carbon tax savings (up to $16,250/year). This model is useful for gaseous fuel industry stakeholders, offering a comprehensive view of supply chain costs and detailed insights into emission benefits when integrating alternative fuels into existing gas networks.}
}
@article{SLOOT2010189,
title = {Computational science: A kaleidoscopic view into science},
journal = {Journal of Computational Science},
volume = {1},
number = {4},
pages = {189},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000694},
author = {Peter M.A. Sloot}
}
@article{MANTELERO2014643,
title = {The future of consumer data protection in the E.U. Re-thinking the “notice and consent” paradigm in the new era of predictive analytics},
journal = {Computer Law & Security Review},
volume = {30},
number = {6},
pages = {643-660},
year = {2014},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2014.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S026736491400154X},
author = {Alessandro Mantelero},
keywords = {Data protection, Consent, Data protection impact assessment, Big Data, Data protection authorities},
abstract = {The new E.U. proposal for a general data protection regulation has been introduced to give an answer to the challenges of the evolving digital environment. In some cases, these expectations could be disappointed, since the proposal is still based on the traditional main pillars of the last generation of data protection laws. In the field of consumer data protection, these pillars are the purpose specification principle, the use limitation principle and the “notice and consent” model. Nevertheless, the complexity of data processing, the power of modern analytics and the “transformative” use of personal information drastically limit the awareness of consumers, their capability to evaluate the various consequences of their choices and to give a free and informed consent. To respond to the above, it is necessary to clarify the rationale of the “notice and consent” paradigm, looking back to its origins and assessing its effectiveness in a world of predictive analytics. From this perspective, the paper considers the historical evolution of data protection and how the fundamental issues coming from the technological and socio-economic contexts have been addressed by regulations. On the basis of this analysis, the author suggests a revision of the “notice and consent” model focused on the opt-in and proposes the adoption of a different approach when, such as in Big Data collection, the data subject cannot be totally aware of the tools of analysis and their potential output. For this reason, the author sustains the provision of a subset of rules for Big Data analytics, which is based on a multiple impact assessment of data processing, on a deeper level of control by data protection authorities, and on the different opt-out model.}
}
@article{HUANGHUANG2023315,
title = {Teacher educator learning to implement equitable mathematics teaching using technology through lesson study},
journal = {International Journal for Lesson and Learning Studies},
volume = {12},
number = {4},
pages = {315-329},
year = {2023},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-05-2023-0049},
url = {https://www.sciencedirect.com/science/article/pii/S2046825323000537},
author = {RongjinRongjin HuangHuang and Christopher T.Christopher T. BonnesenBonnesen and Amanda LakeAmanda Lake HeathHeath and Jennifer M.Jennifer M. SuhSuh},
keywords = {Equitable instruction, Technology, Teacher educator learning, Lesson study},
abstract = {Purpose
This paper examines how mathematics teacher educators (MTEs) learn to enact equitable mathematics instruction using technology through lesson study (LS).
Design/methodology/approach
A LS team with three MTEs conducted three iterations of LS on teaching the Pythagorean Theorem in an in-person, technology-mediated environment. Many forms of data were collected: Desmos activities, videos of research lessons (RLs), videos of MTE RL debriefings, artifacts of student learning in the Desmos Dashboard, and MTEs' written self-reflection. The authors investigate the teacher educators' learning through LS by analyzing the MTE debriefings of the RLs using Bannister’s (2015) framework for teacher learning in communities of practice.
Findings
The MTEs learned to enact equitable mathematics instruction using technology through addressing emerging issues related to intellectual authority and use of student thinking. Throughout the LS, the MTEs sought ways of promoting students' mathematical authority and using student thinking through features of the Desmos platform.
Research limitations/implications
This study focuses on MTEs' learning without examining participating preservice teachers' learning. It demonstrates the benefits of LS for MTEs' professional learning.
Practical implications
This study showcases how a research-based Desmos activity is used and refined to promote MTE learning how to implement equitable mathematics instruction.
Originality/value
The study contributes to better understanding of how LS could be used to develop MTEs' professional learning. Moreover, the dual process of participation and reification was concretized through diagnostic and prognostic frames in the LS context, which enriches the concept of community of practice.}
}
@article{PRADIPA20241213,
title = {Malang Voyage: A sustainable digital landscape in Malang City},
journal = {Procedia Computer Science},
volume = {245},
pages = {1213-1224},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.351},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031594},
author = {I Gede Cahya Pradipa and Yudhistya Ayu Kusumawati and Yongkie Angkawijaya},
keywords = {Sustainable tourism, Tourism development, Digital infrastructure, Malang City},
abstract = {In the scope of global tourism, Malang stands as a potential yet underutilized tourism city. Known as the "Paris of East Java," its captivating landscapes and pleasant climate offer a unique experience. Despite this, the city's tourism sector remains underdeveloped, evident from the low number of visitors compared to what it has to offer. Existing studies reveal the city's yet undiscovered potential, especially in city tourism, cultural experiences, and culinary. However, limited information and digital infrastructure pose significant challenges. This research addresses these gaps, proposing the development of a robust digital platform in the form of a dedicated social media travel hub for Malang's sustainable tourism. By utilizing design thinking methodology, the study aims to revolutionize how tourists access information and interact with local attractions. It hypothesizes that a well-designed digital infrastructure will enhance the city's tourism quality, attracting more visitors. Additionally, adopting sustainable tourism principles will further boost Malang's tourism industry. This research is not just a digital upgrade, it's a transformative journey, paving the way for Malang to emerge as a sustainable tourism hub. Through innovative design and a user-focused approach, this study is set to unlock Malang's full tourism potential of balanced growth with environmental and cultural preservation.}
}
@article{MARTINEZLEDESMA20203567,
title = {Computational methods for detecting cancer hotspots},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3567-3576},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304876},
author = {Emmanuel Martinez-Ledesma and David Flores and Victor Trevino},
keywords = {Mutations, Cancer, Hotspots, Recurrent mutations, Algorithms, Genomics, Sequencing, Exome, Whole genome sequencing},
abstract = {Cancer mutations that are recurrently observed among patients are known as hotspots. Hotspots are highly relevant because they are, presumably, likely functional. Known hotspots in BRAF, PIK3CA, TP53, KRAS, IDH1 support this idea. However, hundreds of hotspots have never been validated experimentally. The detection of hotspots nevertheless is challenging because background mutations obscure their statistical and computational identification. Although several algorithms have been applied to identify hotspots, they have not been reviewed before. Thus, in this mini-review, we summarize more than 40 computational methods applied to detect cancer hotspots in coding and non-coding DNA. We first organize the methods in cluster-based, 3D, position-specific, and miscellaneous to provide a general overview. Then, we describe their embed procedures, implementations, variations, and differences. Finally, we discuss some advantages, provide some ideas for future developments, and mention opportunities such as application to viral integrations, translocations, and epigenetics.}
}
@article{BULLOCK2009757,
title = {Computational perspectives on forebrain microcircuits implicated in reinforcement learning, action selection, and cognitive control},
journal = {Neural Networks},
volume = {22},
number = {5},
pages = {757-765},
year = {2009},
note = {Advances in Neural Networks Research: IJCNN2009},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2009.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608009001117},
author = {Daniel Bullock and Can Ozan Tan and Yohan J. John},
keywords = {Basal ganglia, Acetylcholine, Dopamine, Striatum, Decision making},
abstract = {Abundant new information about signaling pathways in forebrain microcircuits presents many challenges, and opportunities for discovery, to computational neuroscientists who strive to bridge from microcircuits to flexible cognition and action. Accurate treatment of microcircuit pathways is especially critical for creating models that correctly predict the outcomes of candidate neurological therapies. Recent models are trying to specify how cortical circuits that enable planning and voluntary actions interact with adaptive subcortical microcircuits in the basal ganglia. The basal ganglia are strongly implicated in reinforcement learning, and in all behavior and cognition over which the frontal lobes exert flexible control. The persisting role of the basal ganglia shows that ancient vertebrate designs for motivated action selection proved adaptable enough to support many “modern” behavioral innovations, including fluent generation of language and speech. This paper summarizes how recent models have incorporated realistic representations of microcircuit features, and have begun to trace their computational implications. Also summarized are recent empirical discoveries that provide guidance regarding how to formulate the rules for synaptic modification that govern learning in cortico-striatal pathways. Such efforts are contributing to an emerging synthesis based on an interlocking set of computational hypotheses regarding cortical interactions with basal ganglia and thalamic nuclei. These hypotheses specify how specialized microcircuits solve learning and control problems inherent to the brain’s parallel design.}
}
@article{BROM20121,
title = {A computational model of the allocentric and egocentric spatial memory by means of virtual agents, or how simple virtual agents can help to build complex computational models},
journal = {Cognitive Systems Research},
volume = {17-18},
pages = {1-24},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000404},
author = {Cyril Brom and Jan Vyhnánek and Jiří Lukavský and David Waller and Rudolf Kadlec},
keywords = {Spatial cognition, Paradigm of pointing, Disorientation effect, Intelligent virtual agent},
abstract = {The ability to acquire, remember and use information about locations of objects in one’s proximal surrounding is a fundamental aspect of human spatial cognition. In this paper, we present a computational model of this ability. The model provides a possible explanation of contradictory results from experimental psychology related to this ability, namely explanation of why some experiments have reproduced the so-called “disorientation effect” while others have failed to do so. Additionally, in contrast to other computational models of various aspects of spatial cognition, our model is integrated within an intelligent virtual agent. Thus, on a more general level, this paper also demonstrates that it is possible to use intelligent virtual agents as a powerful research tool in computational cognitive sciences.}
}
@article{RAZ2024101598,
title = {Open and closed-ended problem solving in humans and AI: The influence of question asking complexity},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101598},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101598},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001366},
author = {Tuval Raz and Roni Reiter-Palmon and Yoed N. Kenett},
keywords = {Question asking, Problem-solving, AI, Creativity},
abstract = {Question-asking, an underexplored aspect of creativity, is integral to creative problem-solving and information-seeking. Previous research reveals that lower creativity correlates with asking simpler, closed questions, while higher creativity correlates with complex, open-ended inquiries. The present study explores the relation between question asking complexity and problem-solving tasks involving open- and close-ended thinking and how these abilities generalize and compare to AI. In Study 1, participants (N = 89) completed the alternative questions task (AQT), a close-ended riddles task (Stumpers), and the alternate uses task (AUT), a creativity measure. Our results show AQT question complexity wasn't correlated with stumpers performance, although it correlated with AUT originality (r = .3). In Study 2, participants (N = 100) completed the AQT, AUT, and open-ended creative problem-solving (CPS) task. CPS responses were evaluated for originality and quality. A positive correlation was observed between CPS quality and AQT complexity (r = .29) and originality (r = .34). In study 3, AI agents (N = 100) completed the AQT, AUT, stumpers, and CPS tasks. Like humans, AI's AQT originality and complexity were related with open, but not closed problem-solving. AI questions were also significantly more creative and complex, it solved more stumpers and gave higher quality CPS solutions. Surprisingly, human and AI CPS originality didn't differ. We find significant links between question complexity and open—but not closed-ended—problem-solving in humans, which generalize to AI. Our results highlight the significance of complex and creative question-asking in everyday life and as an integral part of our problem-solving toolkit.}
}
@article{WANG2020106763,
title = {Fuzzy Linear regression based on approximate Bayesian computation},
journal = {Applied Soft Computing},
volume = {97},
pages = {106763},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106763},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620307018},
author = {Ning Wang and Marek Reformat and Wen Yao and Yong Zhao and Xiaoqian Chen},
keywords = {Fuzzy linear regression, Bayes statistics, Approximate Bayesian computation},
abstract = {Fuzzy linear regression with crisp inputs and fuzzy output data constitutes an important modeling problem. Basic strategies used to solve this problem, i.e., the possibilistic method and the least squares method, together with their extensions, have some drawbacks. The possibilistic methods put emphasis on an inclusion property while the least squares methods focus on a central tendency property. Therefore, many researchers work on combining these two methods to obtain a better performance. In this paper, in contrast to most existing techniques which treat fuzzy linear regression as an optimization problem, we set the problem of constructing a fuzzy linear regression model in Bayesian statistics and propose a new fuzzy linear regression method based on approximate Bayesian computation (ABC). The method applies the likelihood-free inference algorithm ABC to generate independent samples of unknown model coefficients from Bayesian posterior distribution. This overcomes difficulty of defining likelihood function in fuzzy environment. By adjusting a prior distribution and a threshold of the ABC algorithm, the proposed approach can flexibly balance the inclusion property of the possibilistic methods and the central tendency property of the least squares methods. The convergence property of the proposed ABC algorithm is verified by a numerical example. Two measuring criteria, i.e., a distance metric and a degree of fitting index, which indicate the central tendency property and the inclusion property, respectively, are introduced to evaluate the quality of regression results. Three numerical examples are applied to show the performances of the proposed method. The numerical results are also compared with those obtained by some classical and recently proposed approaches. Additionally, a practical engineering application example is used to illustrate effectiveness of the proposed method.}
}
@article{LI2017183,
title = {SeeMore: A kinetic parallel computer sculpture for educating broad audiences on parallel computation},
journal = {Journal of Parallel and Distributed Computing},
volume = {105},
pages = {183-199},
year = {2017},
note = {Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517300230},
author = {Bo Li and John Mooring and Sam Blanchard and Aditya Johri and Melinda Leko and Kirk W. Cameron},
keywords = {Parallel and distributed computing, Kinetic art, Computer science education},
abstract = {We discuss the design, implementation, and evaluation of a 256-node Raspberry-Pi cluster with kinetic properties. Each compute node is attached to a servo mechanism such that movement results from local computation. The result is SeeMore, a kinetic parallel computer sculpture designed to enable visualization of parallel algorithms in an effort to educate broad audiences as to the beauty, complexity, and importance of parallel computation. The algorithms and interfaces were implemented by students from various related courses at VA Tech. We describe these designs in sufficient detail to enable others to build their own kinetic computing sculptures to augment their experiential learning programs. Our evaluations at exhibitions indicate 63% and 84% of visitors enjoyed interacting with SeeMore while 69% and 87% believed SeeMore has educational value.}
}
@article{LIU20183231,
title = {Nickel catalyzed regio- and stereoselective arylation and methylation of allenamides via coupling reactions. An experimental and computational study11Electronic supplementary information (ESI) available. CCDC 1548725 and 1817608. For ESI and crystallographic data in CIF or other electronic format see DOI: 10.1039/c8qo00729b},
journal = {Organic Chemistry Frontiers},
volume = {5},
number = {22},
pages = {3231-3239},
year = {2018},
issn = {2052-4129},
doi = {https://doi.org/10.1039/c8qo00729b},
url = {https://www.sciencedirect.com/science/article/pii/S2052411022005156},
author = {Yang Liu and Alessandro Cerveri and Assunta {De Nisi} and Magda Monari and Olalla {Nieto Faza} and Carlos Silva Lopez and Marco Bandini},
abstract = {The nickel catalyzed regio- and stereoselective condensation of boronic acids to allenamides is documented as a novel synthetic route to stereochemically defined tri-substituted enamides. The protocol has been implemented into a three-component variant intercepting the in situ formed allyl-Ni intermediate with a range of aldehydes. Additionally, evidence for the effective extension of this methodology to Me2Zn is documented. Full rationale on the mechanism as well as its stereochemical outcome is provided by a synergistic experimental/computational approach.}
}
@article{TRYK2023101372,
title = {The electrochemistry of platinum-group and noble metals as it relates to fuel cells and water electrolysis: Vibrational spectroscopic and computational insights},
journal = {Current Opinion in Electrochemistry},
volume = {41},
pages = {101372},
year = {2023},
issn = {2451-9103},
doi = {https://doi.org/10.1016/j.coelec.2023.101372},
url = {https://www.sciencedirect.com/science/article/pii/S2451910323001655},
author = {Donald A. Tryk and Akiyoshi Kuzume},
abstract = {The intrinsic electrochemistry of platinum and other platinum-group metals and noble metals has been under intense investigation for over forty years but is still not fully understood. Various in situ spectroscopic techniques, particularly vibrational spectroscopies, have provided and continue to provide many insights, but challenges remain. The intrinsic electrochemistry is capable of being elucidated through the combination of electrochemistry, vibrational spectroscopy and theory and is then further able to clarify the catalytic reactions involved in H2–O2 fuel cells and water electrolysis.}
}
@article{STEPHENS2021100871,
title = {From “You have to have three numbers and a plus sign” to “It’s the exact same thing”: K–1 students learn to think relationally about equations},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100871},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100871},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000328},
author = {Ana Stephens and Ranza {Veltri Torres} and Yewon Sung and Susanne Strachota and Angela {Murphy Gardiner} and Maria Blanton and Rena Stroud and Eric Knuth},
keywords = {Equal sign, Equations, Elementary grades, Early algebra, Algebraic thinking},
abstract = {This research shares progressions in thinking about equations and the equal sign observed in ten students who took part in an early algebra classroom intervention across Kindergarten and first grade. We report on data from task-based interviews conducted prior to the intervention and at the conclusion of each school year that elicited students’ interpretations of the equal sign and equations of various forms. We found at the beginning of the intervention that most students viewed the equal sign as an operational symbol and did not accept many equations forms as valid. By the end of first grade, almost all students described the symbol as indicating the equivalence of two amounts and were much more successful interpreting and working with equations in a variety of forms. The progressions we observed align with those of other researchers and provide evidence that very young students can learn to reason flexibly about equations.}
}
@article{DEICHMANN2024105260,
title = {Contrasting philosophical and scientific views in the long history of studying the generation of form in development},
journal = {BioSystems},
volume = {242},
pages = {105260},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105260},
url = {https://www.sciencedirect.com/science/article/pii/S030326472400145X},
author = {Ute Deichmann},
keywords = {Genomic causality, Developmental gene regulatory networks, Physical-chemical selforganization in form generation, Preformation versus epigenesis, Morphogenesis, Stochastic fluctuations, Eric Davidson, Aristotle},
abstract = {Focusing on the opposing ways of thinking of philosophers and scientists to explain the generation of form in biological development, I show that today's controversies over explanations of early development bear fundamental similarities to the dichotomy of preformation theory versus epigenesis in Greek antiquity. They are related to the acceptance or rejection of the idea of a physical form of what today would be called information for the generating of the embryo as a necessary pre-requisite for specific development and heredity. As a recent example, I scrutinize the dichotomy of genomic causality versus self-organization in 20th and 21st century theories of the generation of form. On the one hand, the generation of patterns and form, as well as the constant outcome in development, are proposed to be causally related to something that is "preformed" in the germ cells, the nucleus of germ cells, or the genome. On the other hand, it is proposed that there is no pre-existing form or information, and development is seen as a process where genuinely new characters emerge from formless matter, either by immaterial "forces of life," or by physical-chemical processes of self-organization. I also argue that these different ways of thinking and the research practices associated with them are not equivalent, and maintain that it is impossible to explain the generation of form and constant outcome of development without the assumption of the transmission of pre-existing information in the form of DNA sequences in the genome. Only in this framework of "preformed" information can "epigenesis" in the form of physical and chemical processes of self-organization play an important role.}
}
@article{YEH2011794,
title = {Evaluation approach to stock trading system using evolutionary computation},
journal = {Expert Systems with Applications},
volume = {38},
number = {1},
pages = {794-803},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2010.07.035},
url = {https://www.sciencedirect.com/science/article/pii/S0957417410006639},
author = {I-Cheng Yeh and Che-hui Lien and Yi-Chen Tsai},
keywords = {Genetic algorithms, Neural networks, Decision system, Stock market, Over-learning},
abstract = {The past researches emphasize merely the avoidance of over-learning at the system level and ignore the problem of over-learning at the model level, which lead to the poor performance of the evolutionary computation based stock trading decision-making system. This study presents a new evaluation approach to focus on evaluating the generalization capability at the model level. An empirical study was provided and the results reveal four important findings. First, the decision-making system generated at the model design stage outperforms the system generated at the model validation stage, which shows over-learning at the model level. Secondly, for the decision-making system generated either at the model design stage or at the model validation stage, the investment performance in the training period is much better than that in the testing period, exhibiting over-learning at the system level. Third, employing moving timeframe approach is unable to improve the investment performance at the model validation stage. Fourth, reducing the evolution generation and input variables are unable to avoid the over-learning at the model level. The major contribution of this study is to clarify the issue of over-learning at the model and the system level. For future research, this study developed a more reliable evaluation approach in examining the generalization capability of evolutionary computation based decision-making system.}
}
@article{GIROTTO1991111,
title = {Event controllability in counterfactual thinking},
journal = {Acta Psychologica},
volume = {78},
number = {1},
pages = {111-133},
year = {1991},
issn = {0001-6918},
doi = {https://doi.org/10.1016/0001-6918(91)90007-M},
url = {https://www.sciencedirect.com/science/article/pii/000169189190007M},
author = {Vittorio Girotto and Paolo Legrenzi and Antonio Rizzo},
abstract = {The counterfactual assessment of events, i.e. is the mental construction of alternatives to factual events, is a pervasive mental process that is quite natural for people. For example, people easily make counterfactual statements when reflecting on dramatic events (‘If only I hadn't drunk alcohol the night of the car accident…’). The way in which people select the events to mutate when requested to undo a scenario outcome seems to be governed by general rules. One is that subjects tend to select exceptional (i.e. unusual or surprising) rather than normal events (Kahneman and Tversky 1982a,b; Kahneman and Miller 1986). Another is that subjects prefer to select the first rather than the subsequent events in a causal chain (Wells, Taylor and Turtle 1987). We hypothesized that events corresponding to controllable actions (i.e. voluntary decisions) by the protagonist of a scenario are more mentally mutable than events which occur in the surrounding background. In experiment 1, we manipulated the order and the controllability of four events in a scenario. Contrary to the causal order effect hypothesis, subjects preferred to change the event corresponding to a coluntary decision of the scenario actor, regardless of its relative position in the scenario. Experiment 2 showed that subjects made this choice regardless of the normal vs. exceptional status of the voluntary action event. Experiment 3 gave evidence that an unconstrained action performed by the focal actor of a story is more mutable than a constrained action performed by the same actor. The implications of these findings for the analysis of accidents involving human errors are discussed.}
}
@article{TRASMUNDI2024101615,
title = {Dialogical cognition},
journal = {Language Sciences},
volume = {103},
pages = {101615},
year = {2024},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2024.101615},
url = {https://www.sciencedirect.com/science/article/pii/S0388000124000044},
author = {Sarah Bro Trasmundi and Sune Vork Steffensen},
keywords = {Per Linell, Dialogical cognition, Distributed cognition, Cognitive ethnography, Distributed language},
abstract = {In this article we review Per Linell's work within the last five decades that led to his dialogism framework, which he defines as a general epistemology of language, cognition and communication. We critically discuss how his contribution on the one hand, altered and qualified existent models within language, communication and cognitive science, because dialogism removed language and cognition from their abstract and mental seat in the brain, and embedded them instead in situational contexts and embodied interaction. In that sense, his dialogism successfully replaced monological assumptions about the mind, action and thinking with more contextual and temporally distributed ones. On the other hand, we also question why Linell has not pursued a more rigorous empirical program for studying human cognition, when he did establish a theoretical apparatus for approaching cognition from a dialogical starting point. In going through Linell's arguments over the past five decades we suggest that this absence of an empirical program is due to his humanistic roots which both have sensitised him to appreciating the contingencies and dynamics of human sense making and cognition, and have impeded him from buying into a necessary condition for pursuing a cognitive analysis, even if he conceptually and methodologically accepts a distributed view on cognition. The outcome of this discussion leads to an empirical-based cognitive analysis of a medical interaction. Altogether, the purpose of this article is to show how Linell's conceptual framework can be put to use in ways that make a dialogical cognitive science achievable.}
}
@incollection{YONGSATIANCHOT2021651,
title = {Chapter 19 - Computational models of appraisal to understand the person-situation relation},
editor = {Dustin Wood and Stephen J. Read and P.D. Harms and Andrew Slaughter},
booktitle = {Measuring and Modeling Persons and Situations},
publisher = {Academic Press},
pages = {651-674},
year = {2021},
isbn = {978-0-12-819200-9},
doi = {https://doi.org/10.1016/B978-0-12-819200-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128192009000053},
author = {Nutchanon Yongsatianchot and Stacy Marsella},
abstract = {Appraisal theories of emotion argue that emotions arise from a process of comparing individual needs and concerns to external demands. That is, emotions cannot be explained by solely focusing on the environment or by solely focusing on the individual. Rather, they reflect an individual’s subjective assessment of their relation to the environment. Appraisal theories further posit this relationship is characterized by the individual (appraised) in terms of a set of criteria, variously called appraisal variables, checks, or dimensions; for example, Is an event congruent with a person’s goals or concerns?; Who or what caused it?; Was it unexpected?; and What control does the person have over its unfolding? The results of these appraisal checks are in turn mapped to emotion. In this chapter, we do not explore appraisal as a theory of emotion elicitation. Rather, we suggest appraisal theories, specifically the criteria that appraisal theories posit, provide a useful framework for characterizing how situations are perceived by a person and influence their behavior. We go on to suggest that computational models of appraisal can provide a clear specification of how these criteria are assessed. Furthermore, such models can help us explore the dynamics of the person-environment relation, specifically how changes in the environment as well as changes in the person’s perceptions and behavior arise and induce those dynamics.}
}
@article{TEZDUYAR20061872,
title = {Parallel finite element computations in fluid mechanics},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {195},
number = {13},
pages = {1872-1884},
year = {2006},
note = {A Tribute to Thomas J.R. Hughes on the Occasion of his 60th Birthday},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2005.05.038},
url = {https://www.sciencedirect.com/science/article/pii/S0045782505003105},
author = {Tayfun E. Tezduyar and Ahmed Sameh},
keywords = {Parallel computing, Fluid mechanics, Moving boundaries and interfaces, Mesh update, Preconditioned iterative algorithms},
abstract = {We provide an overview of the role of parallel finite element computations in fluid mechanics. We emphasize the class of flow problems involving moving boundaries and interfaces. Some of the computationally most challenging flow problems, such as fluid–object and fluid–structure interactions as well as free-surface and two-fluid flows, belong to this class. In the development of the methods targeting this class of problems, the computational challenges involved need to be addressed in such a way that 3D computation of complex applications can be carried out efficiently on parallel computers. This requirement has to be one of the key factors in designing various components of the overall solution approach, such as solution techniques for the discretized equations and mesh update methods for handling the changes in the spatial domain occupied by the fluid. This overview includes a description of how the computational challenges are addressed and how the computational schemes can be enhanced with special preconditioning techniques.}
}
@article{DIFRANCO2019386,
title = {Information-gain computation in the Fifth system},
journal = {International Journal of Approximate Reasoning},
volume = {105},
pages = {386-395},
year = {2019},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18301610},
author = {Anthony {Di Franco}},
keywords = {Declarative programming, Probabilistic logic programming, , Adaptive evaluation strategy, Multi-armed bandits},
abstract = {Despite large incentives, correctness in software remains an elusive goal. Declarative programming techniques, where algorithms are derived from a specification of the desired behavior, offer hope to address this problem, since there is a combinatorial reduction in complexity in programming in terms of specifications instead of algorithms, and arbitrary desired properties can be expressed and enforced in specifications directly. However, limitations on performance have prevented programming with declarative specifications from becoming a mainstream technique for general-purpose programming, because a strategy which is both efficient and fully general to derive algorithms from specifications does not yet exist. To address this bottleneck, I propose information-gain computation, a framework where an adaptive evaluation strategy is used to efficiently perform a search which derives algorithms that provide information about a query via the most efficient routes. Within this framework, opportunities to compress the search space present themselves, which suggest that information-theoretic bounds on the performance of such a system might be articulated and a system might be designed to achieve them. The computation of the information measures that are the basis of this strategy crucially depends on a probabilistic semantics for the relations represented by predicates, which may either already be present in a probabilistic logic language, or may be superimposed on a pure logic language. I describe a prototype implementation of Fifth, a system that implements these techniques, and a preliminary empirical study of adaptive evaluation for a simple test program. In the test, the evaluation strategy adapts successfully to efficiently evaluate a query with pathological features that would prevent its evaluation by standard general-purpose strategies.}
}
@article{ISLAM2021104757,
title = {EEG Channel Correlation Based Model for Emotion Recognition},
journal = {Computers in Biology and Medicine},
volume = {136},
pages = {104757},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104757},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521005515},
author = {Md. Rabiul Islam and Md. Milon Islam and Md. Mustafizur Rahman and Chayan Mondal and Suvojit Kumar Singha and Mohiuddin Ahmad and Abdul Awal and Md. Saiful Islam and Mohammad Ali Moni},
keywords = {Emotion, Convolutional neural network, Feature extraction, EEG, Pearson's correlation coefficient, Complexity},
abstract = {Emotion recognition using Artificial Intelligence (AI) is a fundamental prerequisite to improve Human-Computer Interaction (HCI). Recognizing emotion from Electroencephalogram (EEG) has been globally accepted in many applications such as intelligent thinking, decision-making, social communication, feeling detection, affective computing, etc. Nevertheless, due to having too low amplitude variation related to time on EEG signal, the proper recognition of emotion from this signal has become too challenging. Usually, considerable effort is required to identify the proper feature or feature set for an effective feature-based emotion recognition system. To extenuate the manual human effort of feature extraction, we proposed a deep machine-learning-based model with Convolutional Neural Network (CNN). At first, the one-dimensional EEG data were converted to Pearson's Correlation Coefficient (PCC) featured images of channel correlation of EEG sub-bands. Then the images were fed into the CNN model to recognize emotion. Two protocols were conducted, namely, protocol-1 to identify two levels and protocol-2 to recognize three levels of valence and arousal that demonstrate emotion. We investigated that only the upper triangular portion of the PCC featured images reduced the computational complexity and size of memory without hampering the model accuracy. The maximum accuracy of 78.22% on valence and 74.92% on arousal were obtained using the internationally authorized DEAP dataset.}
}
@article{ASHTIANI201618,
title = {A hesitant fuzzy model of computational trust considering hesitancy, vagueness and uncertainty},
journal = {Applied Soft Computing},
volume = {42},
pages = {18-37},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.01.023},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616300102},
author = {Mehrdad Ashtiani and Mohammad Abdollahi Azgomi},
keywords = {Trust modeling, Hesitant fuzzy sets (HFS), Comparative linguistic expressions, Vagueness, Uncertainty, Multi-criteria decision making (MCDM)},
abstract = {The aim of this work is to introduce a trust model, which is highly consistent with the social nature of trust in computational domains. To this end, we propose a hesitant fuzzy multi-criteria decision making based computational trust model capable of taking into account the fundamental building blocks corresponding to the concept of trust. The proposed model is capable of considering the contextuality property of trust and the subjective priorities of the trustor regarding the chosen goal. This is due to viewing trust not as a single label or an integrated concept, but as a collection of trustworthiness facets that may form the trust decision in various contexts and toward different goals. The main benefit of the proposed model is the consideration of the hesitancy of recommenders and the trustor in the process of trust decision making which can create a more flexible mapping between the social and computational requirements of trust. This type of formulation also allows for taking into account the vagueness of the provided opinions. In addition to the vagueness of the provided opinions, the model is capable of considering the certainty of recommendations and its effect on the aggregation process of gathered opinions. In the proposed model, the taste of the recommenders and the similarity of opinions are also considered. This will allow the model to assign more weight to recommendations that have a similar taste compared to the trustor. Finally, taking into consideration the attitudes of the trustors toward change of personality that may occur for various entities in the environment is another advantage of the proposed model. A step-by-step illustrative example and the results of several experimental evaluations, which demonstrate the benefits of the proposed model, are also presented in this paper.}
}
@article{SIETTOS20061632,
title = {A systems-based approach to multiscale computation: Equation-free detection of coarse-grained bifurcations},
journal = {Computers & Chemical Engineering},
volume = {30},
number = {10},
pages = {1632-1642},
year = {2006},
note = {Papers form Chemical Process Control VII},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2006.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0098135406001360},
author = {C.I. Siettos and R. Rico-Martinez and I.G. Kevrekidis},
keywords = {Multiscale, Equation-free, Bifurcation},
abstract = {We discuss certain basic features of the equation-free (EF) approach to modeling and computation for complex/multiscale systems. We focus on links between the equation-free approach and tools from systems and control theory (design of experiments, data analysis, estimation, identification and feedback). As our illustrative example, we choose a specific numerical task (the detection of stability boundaries in parameter space) for stochastic models of two simplified heterogeneous catalytic reaction mechanisms. In the equation-free framework the stochastic simulator is treated as an experiment (albeit a computational one). Short bursts of fine scale simulation (short computational experiments) are designed, executed, and their outputs processed and fed back to the process, in integrated protocols aimed at performing the particular coarse-grained task (the detection of a macroscopic instability). Two distinct approaches are presented; one is a direct translation of our previous protocol for adaptive detection of instabilities in laboratory experiments [Rico-Martinez, R., Krisher, K., Flatgen, G., Anderson, J. S., & Kevrekidis, I. G. (2003). Adaptive detection of instabilities: An experimental feasibility study. Physica D, 176, 1–18]; the second approach is motivated from numerical bifurcation algorithms for critical point detection. A comparison of the two approaches brings forth a key feature of equation-free computation: computational experiments can be easily initialized at will, in contrast to laboratory ones.}
}
@article{KINLEY2022105843,
title = {Pathologies of precision: A Bayesian account of goals, habits, and episodic foresight in addiction},
journal = {Brain and Cognition},
volume = {158},
pages = {105843},
year = {2022},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2022.105843},
url = {https://www.sciencedirect.com/science/article/pii/S027826262200001X},
author = {Isaac Kinley and Michael Amlung and Suzanna Becker},
keywords = {Addiction, Goals, Habits, Free energy, Bayesian statistics, Episodic future thinking},
abstract = {The brain is thought to implement two decision-making systems: a goal-directed system in which decisions are made through planning on the basis of action–outcome relationships, and a habitual system in which behaviour reflects stimulus–response associations. A prominent theory of addiction sees it as arising due to an extreme dominance of habit over goal-directed action. The balance between these systems is thought to be arbitrated by the relative precision of their separate predictions of reward. In this paper, we argue that various factors in addiction create hyper-precise reward predictions in the habitual system and hypo-precise reward predictions in the goal-directed system, shifting the balance of behavioural control in favour of habit. Based on this, we offer a theoretical account of the utility of episodic future thinking in addiction, interpreting it as increasing the precision of reward estimates in the goal-directed system, thereby enhancing the control of this system over behaviour.}
}
@article{ZHAO2015194,
title = {Bring CS2013 Recommendations into c Programming Course},
journal = {Procedia - Social and Behavioral Sciences},
volume = {176},
pages = {194-199},
year = {2015},
note = {International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.461},
url = {https://www.sciencedirect.com/science/article/pii/S187704281500498X},
author = {Lingling Zhao and Xiaohong Su and Tiantian Wang},
keywords = {CS2013, C programming course, CS curriculum planning, CS major ;},
abstract = {Computer Science Curriculum 2013 has become the guidance of computing education since it was released in 2013by the ACM/IEEE-Computer Society. This paper analyzes the CS curriculum development trend, trying to dig the programming-related core from CS2013 with respect to the knowledge areas, topics, organization of teaching, and the building of students’ capability. Considering the characteristic of our local institution and undergraduates, we present an updated teaching curriculum and lab curriculum for C Programming Language course in relation to CS2013 recommendations, which highlight the development of the students’ abilities on programming, problem-solving, self-regulated learning, and computational thinking. Finally, we present and assess the implementation of the resulting curriculum.}
}
@article{KLEINSCHMIDT2004842,
title = {Thinking Big: Many Modules or Much Cortex?},
journal = {Neuron},
volume = {41},
number = {6},
pages = {842-844},
year = {2004},
issn = {0896-6273},
doi = {https://doi.org/10.1016/S0896-6273(04)00154-0},
url = {https://www.sciencedirect.com/science/article/pii/S0896627304001540},
author = {Andreas Kleinschmidt},
abstract = {Is there a neural system dedicated to generic magnitude judgments? In this issue of Neuron, Pinel et al. report qualitative spatial overlap of fMRI responses during judgments of luminance, size, and numerical magnitude but also quantitative response differences in intraparietal cortex that mirror behavioral interference between perceptual and symbolic magnitude.}
}
@article{CARLEY2002253,
title = {Computational organizational science and organizational engineering},
journal = {Simulation Modelling Practice and Theory},
volume = {10},
number = {5},
pages = {253-269},
year = {2002},
note = {Organisational Processes},
issn = {1569-190X},
doi = {https://doi.org/10.1016/S1569-190X(02)00119-3},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X02001193},
author = {Kathleen M Carley},
keywords = {Computational modeling, Simulation, Organization science, Organizational design, Organizational learning},
abstract = {The past decade has witnessed the emergence of a new scientific discipline––computational social and organizational science. Within organization science in particular, and social science more generally, scientists and practitioners are turning to computational analysis to address fundamental socio-technical problems that are so complex and dynamic that they cannot be fully addressed by traditional techniques. Consequently, there is an explosion of computational models, computationally generated findings, interest in doing simulation, and a dearth of support for this enterprise. This paper contains discussions of the underlying fundamental perspective, the relation of models to empirical data and characteristics of necessary infrastructure.}
}
@article{HUMPHREYS1991315,
title = {Vol. 3: Thinking: edited by Daniel N. Osherson and Edward E. Smith (x + 308 pages) ISBN 0 262 65035 5},
journal = {Trends in Neurosciences},
volume = {14},
number = {7},
pages = {315},
year = {1991},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(91)90148-N},
url = {https://www.sciencedirect.com/science/article/pii/016622369190148N},
author = {Glyn W. Humphreys}
}
@article{CROLLEN2020290,
title = {How visual is the « number sense »? Insights from the blind},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {118},
pages = {290-297},
year = {2020},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2020.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S0149763420304851},
author = {Virginie Crollen and Olivier Collignon},
keywords = {Blindness, Mathematical cognition, Brain plasticity},
abstract = {Is vision a necessary building block for the foundations of mathematical cognition? A straightforward model to test the causal role visual experience plays in the development of numerical abilities is to study people born without sight. In this review we will demonstrate that congenitally blind people can develop numerical abilities that equal or even surpass those of sighted individuals, despite representing numbers using a qualitatively different representational format. We will also show that numerical thinking in blind people maps onto regions typically involved in visuo-spatial processing in the sighted, highlighting how intrinsic computational biases may constrain the reorganization of numerical networks in case of early visual deprivation. More generally, we will illustrate how the study of arithmetic abilities in congenitally blind people represents a compelling model to understand how sensory experience scaffolds the development of higher-level cognitive representations.}
}
@article{JONES2020100801,
title = {Scalar and vector line integrals: A conceptual analysis and an initial investigation of student understanding},
journal = {The Journal of Mathematical Behavior},
volume = {59},
pages = {100801},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100801},
url = {https://www.sciencedirect.com/science/article/pii/S0732312320300651},
author = {Steven R. Jones},
keywords = {Multivariable calculus, Definite integrals, Line integrals, Conceptual analysis, Student understanding},
abstract = {This paper adds to the growing body of research happening in multivariable calculus by examining scalar and vector line integrals. This paper contributes in two ways. First, this paper provides a conceptual analysis for both types of line integrals in terms of how theoretical ways of thinking about definite integrals summarized from the research literature might be applied to understanding line integrals specifically. Second, this paper provides an initial investigation of students’ understandings of line integral expressions, and connects these understanding to the theoretical ways of thinking drawn from the literature. One key finding from the empirical part is that several students appeared to understand individual pieces of the integral expression based on one way of thinking, such as adding up pieces or anti-derivatives, while trying to understand the overall integral expression through a different way of thinking, such as area under a curve.}
}
@article{GUTIERREZFINOL20253167,
title = {A call for frugal modelling: two case studies involving molecular spin dynamics†‡†Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d4gc04900d‡During the refereeing process A.G.A. was caught in the disaster zone of the 2024 Spanish floods, which were fueled by sea warming. This paper is gratefully dedicated to the autonomous volunteers that spearheaded the cleanup and relief efforts.},
journal = {Green Chemistry},
volume = {27},
number = {12},
pages = {3167-3177},
year = {2025},
issn = {1463-9262},
doi = {https://doi.org/10.1039/d4gc04900d},
url = {https://www.sciencedirect.com/science/article/pii/S1463926225001360},
author = {Gerliz M. Gutiérrez-Finol and Aman Ullah and María González-Béjar and Alejandro Gaita-Ariño},
abstract = {As scientists living through a climate emergency, we have a responsibility to lead by example, or to at least be consistent with our understanding of the problem. This common goal of reducing the carbon footprint of our work can be approached through a variety of strategies. For theoreticians, this includes not only optimizing algorithms and improving computational efficiency but also adopting a frugal approach to modeling. Here we present and critically illustrate this principle. First, we compare two models of very different level of sophistication which nevertheless yield the same qualitative agreement with an experiment involving electric manipulation of molecular spin qubits while presenting a difference in cost of >4 orders of magnitude. As a second stage, an already minimalistic model of the potential use of single-ion magnets to implement a network of probabilistic p-bits, programmed in two different programming languages, is shown to present a difference in cost of a factor of ≃50. In both examples, the computationally expensive version of the model was the one that was published. As a community, we still have a lot of room for improvement in this direction.}
}
@article{EYSENCK19921359,
title = {Thinking clearly about psychology volume 2: Personality and psychopathology: William M. Grove and Dante Cicchetti: Minneapolis: University of Minnesota Press (1991). pp. v–vi, 3–467. Cloth, ISBN 0-8166-1892-5 v. 2.$45.00.},
journal = {Personality and Individual Differences},
volume = {13},
number = {12},
pages = {1359-1360},
year = {1992},
issn = {0191-8869},
doi = {https://doi.org/10.1016/0191-8869(92)90185-R},
url = {https://www.sciencedirect.com/science/article/pii/019188699290185R},
author = {H.J. Eysenck}
}
@article{CATENACCIVOLPI20141,
title = {How active perception and attractor dynamics shape perceptual categorization: A computational model},
journal = {Neural Networks},
volume = {60},
pages = {1-16},
year = {2014},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2014.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608014001440},
author = {Nicola {Catenacci Volpi} and Jean Charles Quinton and Giovanni Pezzulo},
keywords = {Hopfield networks, Perceptual categorization, Prediction, Active vision, Dynamic choice},
abstract = {We propose a computational model of perceptual categorization that fuses elements of grounded and sensorimotor theories of cognition with dynamic models of decision-making. We assume that category information consists in anticipated patterns of agent–environment interactions that can be elicited through overt or covert (simulated) eye movements, object manipulation, etc. This information is firstly encoded when category information is acquired, and then re-enacted during perceptual categorization. The perceptual categorization consists in a dynamic competition between attractors that encode the sensorimotor patterns typical of each category; action prediction success counts as “evidence” for a given category and contributes to falling into the corresponding attractor. The evidence accumulation process is guided by an active perception loop, and the active exploration of objects (e.g., visual exploration) aims at eliciting expected sensorimotor patterns that count as evidence for the object category. We present a computational model incorporating these elements and describing action prediction, active perception, and attractor dynamics as key elements of perceptual categorizations. We test the model in three simulated perceptual categorization tasks, and we discuss its relevance for grounded and sensorimotor theories of cognition.}
}
@article{OCAMPO2024111111,
title = {An integrated three-way decision methodology for sustainability of wastewater circularity in thermal power plants},
journal = {Applied Soft Computing},
volume = {151},
pages = {111111},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.111111},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623011298},
author = {Lanndon Ocampo and Jenebyb Cabigas and Dylan Jones and Ashraf Labib},
keywords = {Water circularity, Wastewater, Water reuse, MARCOS, Three-way decision},
abstract = {The presence of multiple criteria for evaluating wastewater reuse applications indicates the potential usage of Multi-Criteria Decision-Making (MCDM) methods for this purpose. However, there is currently a scarcity of studies in the domain literature that utilize MCDM approaches in this application topic. This paper therefore advances the domain literature in two distinctive ways. Firstly, it analyzes and advances the reuse agenda of wastewater from thermal power plants, recognized as large-scale users of water, thus promoting greater water circularity. Secondly, it provides a methodological advance by integrating the notion of Three-Way Decision (3WD) into the computational structure of MCDM methods by introducing a middle reference point. Such an initiative results in a novel 3WD extension of the Measurement of Alternatives and Ranking according to COmpromise Solution (MARCOS) method. Additionally, this work provides a proof that the MARCOS method utilizes a compromise solution in identifying priority alternatives, along with the integration of a Weighted Aggregated Sum Product ASsessment (WASPAS) metric. An initial hypothetical example illustrates how the proposed approach augments the canonical MARCOS method, particularly in promoting the “thinking in threes” as a more natural information processing approach and the high degree of distinguishability of priorities between decision alternatives. An actual case study in a thermal power plant then demonstrates the contributions of this work. With the best-worst method used to determine the priorities of the decision attributes, the findings reveal that wastewater reuse applications achieving reduced costs for needed infrastructures, operational simplicity, technological compatibility, consumer safety and household savings are preferred by stakeholders. The 3WD-MARCOS approach identifies industrial and commercial use, municipal use, environmental restoration, and household use as the high-priority alternatives, with cooking and drinking as least preferred. These insights guide stakeholders in their design of initiatives that allocate resources for greater wastewater reuse. A comparative analysis yields high consistency of these findings with similar MCDM methods. In addition, the efficacy of the novel 3WD-MARCOS method highlights its potential in handling MCDM problems, including those promoting water circularity.}
}
@article{CHANG20161,
title = {COMPUTATIONAL DESIGN in the past, present and future of digital architecture},
journal = {Automation in Construction},
volume = {72},
pages = {1-2},
year = {2016},
note = {Computational and generative design for digital fabrication: Computer-Aided Architectural Design Research in Asia (CAADRIA)},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2016.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S092658051630303X},
author = {Teng-Wen Chang and Tane J. Moleta and Daekwon Park}
}
@article{DESOUZA2024100042,
title = {The generative AI revolution, cognitive mediation networks theory and the emergence of a new mode of mental functioning: Introducing the Sophotechnic Mediation scale},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100042},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100042},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000021},
author = {Bruno Campello {de Souza} and Agostinho {Serrano de Andrade Neto} and Antonio Roazzi},
keywords = {ChatGPT, Chatbots, Artificial intelligence, Cognitive mediation networks theory, Hyperculture, Sophotechnic},
abstract = {This paper examines the recent emergence of AI-powered chatbots such as ChatGPT through the lens of the Cognitive Mediation Networks Theory (CMNT), deducing that the introduction of this radically new technology will likely create a new stage of collective cognitive functioning, called “Sophotechnic Mediation”, with characteristics that can be extrapolated from the way these new tools work and the dynamics of the sociocultural structures being created around them. From that description, the Sophotechnic Mediation Scale is proposed as a means to assess the extent of an individual's internalization of the new form of thinking. A preliminary empirical investigation with 132 higher education professors and students found the instrument to be statistically consistent, yielding a unidimensional and Gaussian score that behaves as a developmental trait emerging from the interaction with generative AIs, mediated by age and mastery of previous digital technologies and their cultural elements. It is concluded that the results are suggestive of the validity of the new scale and warrant further research.}
}
@article{BENTLEY20131240,
title = {Predicting the future: Towards symbiotic computational and experimental angiogenesis research},
journal = {Experimental Cell Research},
volume = {319},
number = {9},
pages = {1240-1246},
year = {2013},
note = {Special Issue: Endothelial Biology},
issn = {0014-4827},
doi = {https://doi.org/10.1016/j.yexcr.2013.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0014482713000426},
author = {Katie Bentley and Martin Jones and Bert Cruys},
keywords = {Computational modelling, Interdisciplinary, Angiogenesis, Prediction, Simulation},
abstract = {Understanding the fundamental organisational principles underlying the complex and multilayered process of angiogenesis is the mutual aim of both the experimental and theoretical angiogenesis communities. Surprisingly, these two fields have in the past developed in near total segregation, with neither fully benefiting from the other. However, times are changing and here we report on the new direction that angiogenesis research is taking, where from well-integrated collaborations spring new surprises, experimental predictions and research avenues. We show that several successful ongoing collaborations exist in the angiogenesis field and analyse what aspects of their approaches led them to achieve novel and impactful biological insight. We conclude that there are common elements we can learn from for the future, and provide a list of guidelines to building a successful collaborative venture. Specifically, we find that a near symbiosis of computation with experimentation reaps the most impactful results by close cyclical feedback and communication between the two disciplines resulting in continual refinement of models, experimental directions and our understanding. We discuss high impact examples of predictive modelling from the wider, more established integrated scientific domains and conclude that the angiogenesis community can do nothing but benefit from joining this brave new, integrated world.}
}
@article{DASH201640,
title = {An evolutionary hybrid Fuzzy Computationally Efficient EGARCH model for volatility prediction},
journal = {Applied Soft Computing},
volume = {45},
pages = {40-60},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616301624},
author = {Rajashree Dash and P.K. Dash},
keywords = {Volatility prediction, Stock markets, GARCH model variants, Fuzzy logic based hybrids, Fuzzy inference with nonlinear functions, Multistep prediction, Differential evolution, Super predictive ability test},
abstract = {Accurate modeling for forecasting of stock market volatility is a widely interesting research area both in academia as well as financial markets. This paper proposes an innovative Fuzzy Computationally Efficient EGARCH model to forecast the volatility of three stock market indexes. The proposed model represents a joint estimation of the membership function parameters of a TSK-type fuzzy inference system along with the leverage effect, asymmetric shock by leverage effect of EGARCH model in forecasting highly nonlinear and complicated financial time series model more accurately. Further unlike the conventional TSK type fuzzy neural network the proposed model uses a functional link neural network (FLANN) in the consequent part of the fuzzy rules to provide an improved mapping. Moreover, a differential evolution (DE) algorithm is suggested to solve the parameters estimation problem of Fuzzy Computationally Efficient EGARCH model. Being a parallel direct search algorithm, DE has the strength of finding global optimal solutions regardless of the initial values of its few control parameters. Furthermore, the DE based algorithm aims to achieve an optimal solution with a rapid convergence rate. The proposed model has been compared with some GARCH family models and hybrid fuzzy systems and GARCH models based on three performance metrics: MSFE, RMSFE, and MAFE. The results indicate that the proposed method offers significant improvements in volatility forecasting performance in comparison with all other specified models.}
}
@article{WANG2014638,
title = {Computational Psychiatry},
journal = {Neuron},
volume = {84},
number = {3},
pages = {638-654},
year = {2014},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2014.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S0896627314009167},
author = {Xiao-Jing Wang and John H. Krystal},
abstract = {Psychiatric disorders such as autism and schizophrenia, arise from abnormalities in brain systems that underlie cognitive, emotional, and social functions. The brain is enormously complex and its abundant feedback loops on multiple scales preclude intuitive explication of circuit functions. In close interplay with experiments, theory and computational modeling are essential for understanding how, precisely, neural circuits generate flexible behaviors and their impairments give rise to psychiatric symptoms. This Perspective highlights recent progress in applying computational neuroscience to the study of mental disorders. We outline basic approaches, including identification of core deficits that cut across disease categories, biologically realistic modeling bridging cellular and synaptic mechanisms with behavior, and model-aided diagnosis. The need for new research strategies in psychiatry is urgent. Computational psychiatry potentially provides powerful tools for elucidating pathophysiology that may inform both diagnosis and treatment. To achieve this promise will require investment in cross-disciplinary training and research in this nascent field.}
}
@article{PRATT2023103217,
title = {Bringing advanced technology to strategic decision-making: The Decision Intelligence/Data Science (DI/DS) Integration framework},
journal = {Futures},
volume = {152},
pages = {103217},
year = {2023},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2023.103217},
url = {https://www.sciencedirect.com/science/article/pii/S0016328723001222},
author = {Lorien Pratt and Christophe Bisson and Thierry Warin},
keywords = {Strategic decision making, Decision intelligence, Corporate foresight, Artificial intelligence, Complexity, Kahneman’s systems thinking},
abstract = {There is a widespread stated desire amongst both public and private organizations worldwide to engage in more significant “evidence-based reasoning” and to be more “data-driven.” We argue that these two goals are proxies for the often-unstated goal of improving the exploration of possible futures as foresights that could lead to better strategic decisions and improved business outcomes. From this perspective, data and analytics hold great promise and are necessary—but not sufficient—for improving strategic decision-making. Something more is needed to realize this potential. We specify how to fill this gap using an integration framework between technology and decision-makers, which is especially appropriate in complex and/or volatile environments. Our solution—which comprises a methodology as well as a software architecture—therefore unifies not only human decision makers to technology but each other and also integrates several disciplines that have been hitherto unnecessarily separated. Thereby, it could help organizations to address increasing challenges better as well as improve the exploration of possible futures.}
}
@article{BAKER2023238,
title = {13Ccarbene nuclear magnetic resonance chemical shift analysis confirms CeIVC double bonding in cerium(iv)–diphosphonioalkylidene complexes††Electronic supplementary information (ESI) available: Computational details. See DOI: https://doi.org/10.1039/d3sc04449a},
journal = {Chemical Science},
volume = {15},
number = {1},
pages = {238-249},
year = {2023},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d3sc04449a},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023058364},
author = {Cameron F. Baker and John A. Seed and Ralph W. Adams and Daniel Lee and Stephen T. Liddle},
abstract = {Diphosphonioalkylidene dianions have emerged as highly effective ligands for lanthanide and actinide ions, and the resulting formal metal–carbon double bonds have challenged and developed conventional thinking about f-element bond multiplicity and covalency. However, f-element–diphosphonioalkylidene complexes can be represented by several resonance forms that render their metal–carbon double bond status unclear. Here, we report an experimentally-validated 13C Nuclear Magnetic Resonance computational assessment of two cerium(iv)–diphosphonioalkylidene complexes, [Ce(BIPMTMS)(ODipp)2] (, BIPMTMS = {C(PPh2NSiMe3)2}2−; Dipp = 2,6-diisopropylphenyl) and [Ce(BIPMTMS)2] (). Decomposing the experimental alkylidene chemical shifts into their corresponding calculated shielding (σ) tensor components verifies that these complexes exhibit CeC double bonds. Strong magnetic coupling of CeC σ/π* and π/σ* orbitals produces strongly deshielded σ11 values, a characteristic hallmark of alkylidenes, and the largest 13C chemical shift tensor spans of any alkylidene complex to date (, 801 ppm; , 810 ppm). In contrast, the phosphonium-substituent shielding contributions are much smaller than the CeC σ- and π-bond components. This study confirms significant Ce 4f-orbital contributions to the CeC bonding, provides further support for a previously proposed inverse-trans-influence in , and reveals variance in the 4f spin–orbit contributions that relate to the alkylidene hybridisation. This work thus confirms the metal–carbon double bond credentials of f-element–diphosphonioalkylidenes, providing quantified benchmarks for understanding diphosphonioalkylidene bonding generally.}
}
@article{KRZHIZHANOVSKAYA2015288,
title = {Russian-Dutch double-degree Master’s programme in computational science in the age of global education},
journal = {Journal of Computational Science},
volume = {10},
pages = {288-298},
year = {2015},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2015.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877750315000812},
author = {Valeria V. Krzhizhanovskaya and Alexey V. Dukhanov and Anna Bilyatdinova and Alexander V. Boukhanovsky and Peter M.A. Sloot},
keywords = {Computational science, Master’s programme, Graduate program, Double degree, Curriculum, Enrollment, Student research, Funding opportunities},
abstract = {We present a new double-degree graduate (Master’s) programme developed together by the ITMO University, Russia and University of Amsterdam, The Netherlands. First, we look into the global aspects of integration of different educational systems and list some funding opportunities. Then, we describe our double-degree program curriculum, suggest the timeline of enrollment and studies, and give some examples of student research topics. Finally, we discuss the issues of joint programs with Russia and suggest possible solutions, analyze the results of the first three student intakes and reflect on the lessons learnt, and share our thoughts and experiences that could be of interest to the international community expanding the educational markets to the vast countries like Russia, China or India. The paper is written for education professionals and contains useful information for potential students. This is an extended version of a conference paper (http://dx.doi.org/10.1016/j.procs.2014.05.130) invited to this special issue of the Journal of Computational Science.}
}
@article{KANIZSA198523,
title = {Seeing and thinking},
journal = {Acta Psychologica},
volume = {59},
number = {1},
pages = {23-33},
year = {1985},
issn = {0001-6918},
doi = {https://doi.org/10.1016/0001-6918(85)90040-X},
url = {https://www.sciencedirect.com/science/article/pii/000169188590040X},
author = {G. Kanizsa},
abstract = {According to ratiomorphic theories of perception every visual phenomenon would be the result of unconscious inferences through which the visual system, starting from a set of axioms and premises, reaches certain conclusions (which constitute actually the visual phenomena) by a process analogous to a reasoning process. The author presents some examples from the area of amodal completion which, according to him, hardly support a ratiomorphic theory. Instead they constitute counterexamples that rather support the hypothesis that seeing and thinking function according to different rules.}
}
@incollection{MILLER201455,
title = {Chapter 5 - Managing and Integrating Exposome Data: Maps, Models, Computation, and Systems Biology},
editor = {Gary W. Miller},
booktitle = {The Exposome},
publisher = {Academic Press},
address = {San Diego},
pages = {55-69},
year = {2014},
isbn = {978-0-12-417217-3},
doi = {https://doi.org/10.1016/B978-0-12-417217-3.00005-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780124172173000057},
author = {Gary W. Miller},
keywords = {Bioinformatics, systems biology, computational biology, machine learning, Bayesian methods},
abstract = {Exposome-related data will come from a myriad of sources. The huge amounts of data must be organized in some manner that allows appropriate interpretations and associations to be drawn. Models and maps are often used to provide organization to complex data sets. Maps are quite appropriate for exposome research as the location of the sources and exposures is a critical component, and spatial statistics could play a major role in exposome data organization. The complex types of data will undoubtedly require mathematical approaches, including bioinformatics, computational, and systems biology-based techniques. This chapter reviews some of the possible strategies that can be used to keep track of the diverse and massive data sets that will result from exposome research.}
}
@article{FARAZI2024103661,
title = {Planning electric vertical takeoff and landing aircraft (eVTOL)-based package delivery with community noise impact considerations},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {189},
pages = {103661},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103661},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524002527},
author = {Nahid Parvez Farazi and Bo Zou},
keywords = {Advanced air mobility (AAM), eVTOL, Package delivery, Community noise impact, Bi-objective integer programming model, Tailored solution algorithm},
abstract = {The rapid development of Advanced Air Mobility (AAM) in recent years suggests a promise to use electric vertical takeoff and landing aircraft (eVTOLs) for package delivery in metro areas. While eVTOL manufacturers and logistics service providers are actively developing prototype eVTOLs and exploring their potentials for moving freight, a system thinking about the suitability and ways to operate an eVTOL-based package delivery system remains scarce. A key aspect of the system thinking is the noise impact of eVTOL operations on surrounding communities. In this study, we provide an operation planning framework that aims to prepare AAM to be both economically efficient and community friendly for package delivery. We first develop a method to quantify the community noise impact of an eVTOL operation, using a “population exposure” measure which is based on the level of sound generated and accounts for both the number of people impacted and duration of the impact. Then, a bi-objective integer programming model is formulated which simultaneously optimizes total shipping cost and community noise impact of eVTOL operations. The optimization takes into consideration operational constraints including maximum distance for local delivery, latest package departure time from the warehouse, and eVTOL fleet size and carrying capacity. A tailored solution algorithm which augments non-dominated sorting genetic algorithm 2 (NSGA2) with compact solution representation, guided generation of initial population of solutions, and customized local search heuristics is devised. The model and the algorithm are implemented in a case study in the Chicago metro area. Numerical results reveal the trade-off between the minimization of shipping cost and community noise impact. Several operational insights about eVTOL-based package delivery are obtained. The computational efficiency and effectiveness of the proposed solution algorithm are also demonstrated in comparison with alternative solution methods.}
}
@article{MARRA2025102557,
title = {Bridging the gaps in sustainability assessment: A systematic literature review, 2014–2023},
journal = {Evaluation and Program Planning},
volume = {110},
pages = {102557},
year = {2025},
issn = {0149-7189},
doi = {https://doi.org/10.1016/j.evalprogplan.2025.102557},
url = {https://www.sciencedirect.com/science/article/pii/S0149718925000242},
author = {Mita Marra},
keywords = {Sustainability Assessment (SA), Sustainability, Bibliometric analysis, Evaluation Journals},
abstract = {This article highlights recurrent themes and research communities in Sustainability Assessment (SA), a rapidly growing trans-disciplinary area particularly relevant to the global evaluation community. This bibliometric analysis signals the emergence of a substantial research community based in Asia and the Middle East, whose production is distinct from North American and European-centric evaluation studies. While the latter primarily address methodological challenges related to sustainability issues in social policy, organizational capacity building, and public health, the broader SA literature centers on life-cycle assessments to integrate the analysis of environmental and socioeconomic effects in such domains as biodiversity, energy efficiency, urban planning, alternative agriculture, and supply chain management. This mapping exercise highlights the global distribution of research output and identifies existing gaps and potential future cross-fertilization. The transdisciplinary SA literature can draw from theory-based designs attuned to complexity and systems thinking. Policy analysts and evaluators can gain insights from diverse SA perspectives and policy approaches to tackle sustainability challenges more systematically.}
}
@article{VALTON2017631,
title = {Comprehensive review: Computational modelling of schizophrenia},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {83},
pages = {631-646},
year = {2017},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2017.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S0149763416307357},
author = {Vincent Valton and Liana Romaniuk and J. {Douglas Steele} and Stephen Lawrie and Peggy Seriès},
keywords = {Psychotic symptoms, Schizophrenia, Computational models, Computational psychiatry},
abstract = {Computational modelling has been used to address: (1) the variety of symptoms observed in schizophrenia using abstract models of behavior (e.g. Bayesian models – top-down descriptive models of psychopathology); (2) the causes of these symptoms using biologically realistic models involving abnormal neuromodulation and/or receptor imbalance (e.g. connectionist and neural networks – bottom-up realistic models of neural processes). These different levels of analysis have been used to answer different questions (i.e. understanding behavioral vs. neurobiological anomalies) about the nature of the disorder. As such, these computational studies have mostly supported diverging hypotheses of schizophrenia's pathophysiology, resulting in a literature that is not always expanding coherently. Some of these hypotheses are however ripe for revision using novel empirical evidence. Here we present a review that first synthesizes the literature of computational modelling for schizophrenia and psychotic symptoms into categories supporting the dopamine, glutamate, GABA, dysconnection and Bayesian inference hypotheses respectively. Secondly, we compare model predictions against the accumulated empirical evidence and finally we identify specific hypotheses that have been left relatively under-investigated.}
}
@article{MA2017144,
title = {A decomposition-based multi-objective optimization for simultaneous balance computation and transformation in signed networks},
journal = {Information Sciences},
volume = {378},
pages = {144-160},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516313883},
author = {Lijia Ma and Maoguo Gong and Jianan Yan and Fuyan Yuan and Haifeng Du},
keywords = {Structural balance computation, Balance transformation, Multi-objective optimization, Decomposition, Signed networks},
abstract = {Many social systems have a set of opposite interactions such as friend/enemy, cooperation/competition and support/opposition. In these signed systems, there exist functional imbalances from the system-level view because of the existence of unbalanced interactions. However, it is difficult to compute the unbalance degree and transform unbalanced factors to balanced ones in real signed systems. Earlier studies tackled these two issues separately and gave a unique solution, and thus cannot be well applied to real applications with constraints. In this paper, we devise a decomposition-based and network-specific multi-objective optimization algorithm to solve the balance computation and transformation of signed networks simultaneously. The devised algorithm aims at finding a set of optimal balance transformation solutions, and each of which is the trade-off between the twin objectives (i.e., the minimization of inter-cluster positive links and the minimization of intra-cluster negative links). Of these solutions, the one with the fewest unbalanced links corresponds to the solution to the balance computation. And each trade-off solution corresponds to an optimal balance transformation way under a certain transformation cost. Extensive experiments on four social networks demonstrate the effectiveness of the devised algorithm on both the computation and the transformation of structural balance. They also show that the devised algorithm can provide multiple optimal solutions at the same transformation cost.}
}
@article{YONG2024322,
title = {Students’ perception of non-placement work-integrated learning in chemical engineering: Work-related skills towards the post-pandemic future},
journal = {South African Journal of Chemical Engineering},
volume = {47},
pages = {322-332},
year = {2024},
issn = {1026-9185},
doi = {https://doi.org/10.1016/j.sajce.2023.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S1026918523001270},
author = {Su Ting Yong and Nishanth G. Chemmangattuvalappil and Dominic C.Y. Foo},
keywords = {Non-placement, Work-integrated learning, Virtual communication, Technology usage, Critical thinking, Problem solving},
abstract = {Work-integrated learning (WIL) is a pedagogical activity designed to enhance the integration of theoretical knowledge and practical skills in an authentic context. WIL is typically accomplished through work placement, but a non-placement WIL is potentially promising. In this study, a non-placement WIL programme was incorporated into chemical engineering final year projects. The students worked on industrial problems without a work placement. The purpose of the study was to investigate work-related skills learned in a non-placement WIL programme. A qualitative dominant mixed-methods research approach was adopted. Data was collected using a quantitative questionnaire (n = 69) and a qualitative interview (n = 15). Quantitative findings revealed no significant difference between students working on non-placement WIL and academic projects. However, qualitative findings revealed seven insightful work-related skills in the non-placement WIL: (1) professional relationship with industrial experts and academic supervisors, (2) virtual communication and collaboration, (3) technology skills in the latest industrial software and tools, (4) motivation to undertake novel and challenging industrial problems, (5) creative and innovative strategies, (6) application of higher order thinking skills to model authentic problems, (7) inductive and deductive reasoning. The COVID-19 pandemic has changed how engineers work. Today, it is a necessity to embrace creative problem-solving skills and adopt various types of modern technologies to work effectively and remotely.}
}
@article{BAUTISTA2023109,
title = {Acceptance and commitment therapy in parents of children with cancer at psychosocial risk: A randomized multiple baseline evaluation},
journal = {Journal of Contextual Behavioral Science},
volume = {29},
pages = {109-121},
year = {2023},
issn = {2212-1447},
doi = {https://doi.org/10.1016/j.jcbs.2023.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212144723000789},
author = {Ana B. Bautista and Francisco J. Ruiz and Juan C. Suárez-Falcón},
keywords = {Acceptance and commitment therapy, Repetitive negative thinking, Childhood cancer, Parents, Single-case experimental design, Psychosocial risk},
abstract = {Developing and testing psychological interventions for primary caregivers of children with cancer at significant psychosocial risk is still needed. One psychological factor contributing to their emotional distress is repetitive negative thinking (RNT). This study conducted a randomized, multiple-baseline evaluation of the effect of an individual, online, 2-session, RNT-focused ACT intervention in 12 parents. Participants responded to daily measures of emotional symptoms, RNT, and progress in values during baseline, intervention, and the 2-month follow-up. These measures have shown adequate psychometric properties at the individual level in this study. All 12 participants completed the intervention. A Bayesian hierarchical model indicated that most participants showed reductions in emotional symptoms and RNT (10 of 11), and 8 of 12 participants showed increases in valued living. The design-comparable standardized mean difference was computed to estimate the intervention effect overall. The effect sizes were large for all variables (PHQ-4: d = 0.83, 95% CI [0.27, 1.40]; RNTQ-3: d = 0.81, 95% CI [0.34, 1.28]; VQ-3: d = 1.07, 95% CI [0.22, 1.91]). Participants evaluated the intervention as useful at the 2-month follow-up. In conclusion, a brief and online RNT-focused intervention showed promising results in parents of children with cancer at significant psychosocial risk.}
}
@article{RICHARD2019136,
title = {CastLab: an object-oriented finite element toolbox within the Matlab environment for educational and research purposes in computational solid mechanics},
journal = {Advances in Engineering Software},
volume = {128},
pages = {136-151},
year = {2019},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2018.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0965997818301303},
author = {Benjamin Richard and Giuseppe Rastiello and Cédric Giry and Francesco Riccardi and Romili Paredes and Eliass Zafati and Santosh Kakarla and Chaymaa Lejouad},
keywords = {Matlab toolbox, Nonlinear solid mechanics, Computational mechanics, Educational tools, Finite elements},
abstract = {The Matlab environment has become widely used among the computational mechanics community, not only for research purposes but also to teach either undergraduate or graduate classes. This paper aims to present a new toolbox devoted to computational mechanics and in particular to solid mechanics. Both recent and well-established numerical formulations have been implemented in it. One of its strengths resides in the fact that it was developed within an object-oriented framework. This key feature makes the CastLab toolbox easy-to-use and with extensive capabilities for customized user developments. After a brief description of the theoretical background related to the problems that can be solved by means of the toolbox, several representative case-studies are presented. These examples have been selected to illustrate not only the numerical efficiency of the toolbox, which is of primary importance for research purposes, but also its strong educational and pedagogic potential.}
}
@article{PATAC2025101301,
title = {Using ChatGPT for academic support: Managing cognitive load and enhancing learning efficiency – A phenomenological approach},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101301},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101301},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000282},
author = {Louida P. Patac and Adriano V. Patac},
keywords = {Cognitive load theory, ChatGPT, AI in education, Academic support, Mathematics education, Phenomenology},
abstract = {This study aims to discuss the effects of ChatGPT on the management of students' cognitive load and learning outcomes. Participants used ChatGPT for answering particular questions, checking information, and solving complex problems involving equations. Results show that ChatGPT lowers intrinsic and extrinsic cognitive load with very detailed responses and efficient search for information, even though it has difficulties in entering mathematical notation. Students consider that ChatGPT is a tool able to enhance understanding, engage, and promote critical thinking. These findings underline that the level of AI assistance must be balanced against independent learning and critical evaluation.}
}
@article{MATSUMURA2023100689,
title = {Tasks and feedback: An exploration of students’ opportunity to develop adaptive expertise for analytic text-based writing},
journal = {Assessing Writing},
volume = {55},
pages = {100689},
year = {2023},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2022.100689},
url = {https://www.sciencedirect.com/science/article/pii/S107529352200085X},
author = {Lindsay Clare Matsumura and Elaine Lin Wang and Richard Correnti and Diane Litman},
keywords = {Feedback, Instruction, Tasks, Text-based writing},
abstract = {In this study, we apply a cognitive theoretical lens to investigate students’ opportunity to develop their analytic text-based writing skills (N = 35 fifth and sixth grade classrooms). Specifically, we examine the thinking demands of classroom text-based writing tasks and teachers’ written feedback on associated student work. Four text-based writing tasks with drafts of associated student work were collected from teachers across a school year. Results of qualitative analyses showed that about half of the classroom text-based writing tasks considered by teachers to be challenging guided students to express analytic thinking about what they read (n = 73). A minority of student work received written feedback focused on students’ use of evidence, expression of thinking, and text comprehension; or received feedback that provided guidance for strategies students could take to meet genre goals. Most teachers provided content-related, instructive, and/or localized feedback on at least one piece of student work. Only a small number of teachers, however, consistently provided content-related, instructive or localized feedback on their students’ essays. Overall, results suggest that students have few opportunities to practice analytic text-based writing and receive feedback that would be expected to advance their conceptual understanding and adaptive expertise for writing in this genre.}
}
@incollection{HARDIN2025519,
title = {Disinformation, Misinformation, and Fake News: The Latest Trends and Issues in Research},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {519-530},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00171-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895001711},
author = {Greg Hardin},
keywords = {Disinformation, Evaluating sources, Fake news, Information literacy, Malinformation, Misinformation},
abstract = {Information comes in many forms and there are various ways in which false or fabricated information travels throughout the information ecosystem. Fake news, disinformation, misinformation, and malinformation have similarities and differences, but all have in common that they cause harm. Understanding misinformation in all its various forms is key to minimizing the negative effects on individuals and society. While it may be impossible to eradicate misinformation in all its various forms, librarians have a history of and are poised to promote information literacy and critical thinking skills.}
}
@article{ATSALAKIS2016107,
title = {Using computational intelligence to forecast carbon prices},
journal = {Applied Soft Computing},
volume = {43},
pages = {107-116},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616300801},
author = {George S. Atsalakis},
keywords = {ANFIS forecasting, Carbon allowance, Carbon price forecasting, Computational intelligent forecasting, Neuro-fuzzy forecasting, PATSOS forecasting},
abstract = {European Union has introduced the European Trading System (ETS) as a tool for developing and implementing international treaties related to climate changes and to identify the most cost-effective methods for reducing greenhouse gas emissions, in particular carbon dioxide (CO2), which is the most substantial. Companies producing carbon emissions must effectively manage associated costs by buying or selling carbon emission futures. Viewed from this perspective, this paper provides a model for managing the risk by buying and selling carbon emission futures by implementing techniques that leverage computational intelligence. Three computational intelligence techniques are proposed to provide accurate and timely forecasts for changes in the price of carbon: a novel hybrid neuro-fuzzy controller that forms a closed-loop feedback mechanism called PATSOS; an artificial neural network (ANN) based system; an adaptive neuro-fuzzy inference system (ANFIS). Results are based on 1074 daily carbon price observations collected to comprise a useful time-series dataset and for evaluation of the proposed techniques. The extra-sample performance of the proposed techniques is calculated. Analysis results are compared with those produced by other models. Comparison studies reveal that PATSOS is the most accurate and promising methodology for predicting the price of carbon. It is stated that this paper registers a first attempt to apply a hybrid neuro-fuzzy controller to forecasting carbon prices.}
}
@article{SHARMA20221,
title = {The design and evaluation of an AR-based serious game to teach programming},
journal = {Computers & Graphics},
volume = {103},
pages = {1-18},
year = {2022},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2022.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0097849322000024},
author = {Vandit Sharma and Kaushal Kumar Bhagat and Huai-Hsuan Huang and Nian-Shing Chen},
keywords = {Augmented Reality, Computational thinking, Learning Analytics, Gamification, Feedback design, System usability},
abstract = {The ubiquity of smartphone and tablet devices, combined with the increasing availability of serious games, has enabled students to learn various abstract concepts in an appealing and convenient manner. While several researchers have explored the use of Augmented Reality (AR) in serious games, many of these games have not been critically explained or evaluated. To that end, we employed game-based learning methodologies and Game Learning Analytics (GLA) to systematize the design and evaluation of an AR-based serious game to teach programming. We evaluated our game for usability and effectiveness by conducting a user study on twenty-seven undergraduate students. The evaluation primarily consisted of a learning test conducted twice – before and after playing the game – along with a usability questionnaire that players completed after playing the game. Our results showed that players made significant progress after playing the game. The game helped players improve their basic programming skills, especially for the group having lower prior programming skills. The results highlighted various ways in which GLA can be used to benefit different stakeholders in the game. Based on players’ qualitative responses, we also identified several areas of improvement, most prominently the trade-off between ease of use and game complexity. We provide suggestions and discuss implications for future work.}
}
@article{SINGH20212537,
title = {Resources and computational strategies to advance small molecule SARS-CoV-2 discovery: Lessons from the pandemic and preparing for future health crises},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {2537-2548},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.04.059},
url = {https://www.sciencedirect.com/science/article/pii/S2001037021001719},
author = {Natesh Singh and Bruno O. Villoutreix},
abstract = {There is an urgent need to identify new therapies that prevent SARS-CoV-2 infection and improve the outcome of COVID-19 patients. This pandemic has thus spurred intensive research in most scientific areas and in a short period of time, several vaccines have been developed. But, while the race to find vaccines for COVID-19 has dominated the headlines, other types of therapeutic agents are being developed. In this mini-review, we report several databases and online tools that could assist the discovery of anti-SARS-CoV-2 small chemical compounds and peptides. We then give examples of studies that combined in silico and in vitro screening, either for drug repositioning purposes or to search for novel bioactive compounds. Finally, we question the overall lack of discussion and plan observed in academic research in many countries during this crisis and suggest that there is room for improvement.}
}
@article{VAIGLOVA2025106220,
title = {How can we improve statistical training in archaeological science?},
journal = {Journal of Archaeological Science},
volume = {179},
pages = {106220},
year = {2025},
issn = {0305-4403},
doi = {https://doi.org/10.1016/j.jas.2025.106220},
url = {https://www.sciencedirect.com/science/article/pii/S030544032500069X},
author = {Petra Vaiglova},
abstract = {The aim of this paper is to shine light on fundamental statistical concepts that archaeologists do not talk about enough. I argue that more deliberate discussion of these statistical ‘elephants in the room’ can have a positive impact on improving statistical training and on steering us away from perpetuation of poor research practices. 1) Statistical thinking should come first. This will help us break down some of the stigma around numbers and statistics, and set us up for building analytical frameworks that will provide the most informative answers to our research questions. 2) Descriptive and inferential statistics have different interpretative potential. This will clarify how we can move from using tools that only allow us to talk about our studied samples to using tools that enable us to draw inferences about the underlying populations from which the samples derived. 3) p values can be extremely variable. This will help spread awareness about the misuses and misconceptions of Null Hypothesis Significance Testing (NHST) and demonstrate the dangers of using significance thresholds to interpret data. 4) Statistical precision is not the same as measurement precision. This will bring attention to the many different types of uncertainties that are built into archaeological datasets (e.g., statistical precision, instrument measurement error, natural variation),.Recognising this is key for drawing reliable inferences from our data. 5) Meta-analyses and forest plots can be useful for synthesising previous research. This will help spread awareness about the benefit of meta-analyses for creating evidence-driven summaries of previous findings. The discussion draws on examples from isotope archaeology, bioarchaeology, and organic residue analysis to illustrate how switching from a reliance on significance testing to a reliance on effect sizes can improve methodological rigour and the representativeness of our findings. The paper ends with a discussion of the roles and responsibilities of supervisors for creating an effective learning environment for statistical training. This includes, but is not limited to, acknowledging the problems of NHST and advocating for adherence to Open Science principles. Ultimately, the changes suggested in this paper will help us raise discipline-wide standards for quantitative training and improve both the breadth and the depth of archaeological research.}
}
@article{LASO2018428,
title = {Finding an economic and environmental balance in value chains based on circular economy thinking: An eco-efficiency methodology applied to the fish canning industry},
journal = {Resources, Conservation and Recycling},
volume = {133},
pages = {428-437},
year = {2018},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2018.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0921344918300429},
author = {Jara Laso and Isabel García-Herrero and María Margallo and Ian Vázquez-Rowe and Pére Fullana and Alba Bala and Cristina Gazulla and Ángel Irabien and Rubén Aldaco},
keywords = {Life cycle assessment, Life cycle costing, Eco-efficiency, Engraulis encrasicolus, Linear programming},
abstract = {The production of food that is environmentally friendly and presents a high economic return is one of the current concerns for the food industry. Eco-efficiency links the environmental performance of a product to its economic value. In this context, this study combines Life Cycle Assessment (LCA) and Life Cycle Costing (LCC) to propose a two-step eco-efficiency methodology assessment for the fish canning industry. An eco-label rating system based on a descriptive weighting of environmental (Global Warming Potential, Acidification Potential, Eutrophication Potential and the ReCiPe Single Score Endpoint) and economic (Value Added) indicators was applied to the canned anchovy. Secondly, LCA-LCC results were coupled to linear programming (LP) tools in order to define a composite eco-efficiency index. This approach enables translation into economic terms of the environmental damage caused when a given alternative is chosen. In particular, different origins for anchovy species (South American vs. Cantabrian) and related waste management alternatives (landfill, incineration and valorization) were evaluated under this cradle to gate approach. Results indicated that substantial differences can be observed depending on the origin of the fish. Anchovies landed in Cantabria show a higher value added score at the expense of larger environmental impacts, mainly due to fuel use intensity. Moreover, its environmental scores are lowered when fish residues are valorized into marketable products, while increasing the value added. This study demonstrates the environmental and economic benefits of applying circular economy. According to this, it is possible to introduce the cradle-to-cradle concept in the fish canned industry. The methodology proposed is intended to be useful to decision-makers in the anchovy canning sector and can be applied to other regions and industrial sectors.}
}
@article{CAMACHOLIE202435,
title = {Development of basic thermodynamics workshops integrating a cubic equations of state simulator and MATLAB Grader courses},
journal = {Education for Chemical Engineers},
volume = {49},
pages = {35-54},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000228},
author = {Mariola Camacho-Lie and Rodrigo Alberto Hernández-Ochoa and Adriana Palacios},
keywords = {Teaching of thermodynamics, Digital tools in education, Deep learning, Constructive Alignment, Preparation for Future Learning, Productive Failure},
abstract = {This paper describes the development of EoS Simulator, a cubic equations of state simulator created in the MATLAB R2022b App Designer platform, which aims to be a practical digital tool for chemical engineering students that facilitates the solution, analysis, and critical thinking about thermodynamic problems. In the simulator, numerical algorithms were implemented based on a theoretical framework, such as fugacity test, bracketing methods, and the calculation of residual properties. EoS Simulator can estimate two-phase envelopes, isobars, isotherms, and surfaces related to PTVHS properties. MATLAB Grader courses were proposed to test student learning using the software in two different workshops. The evaluation was based on the achievement of tasks related to intended learning outcomes. Survey responses about the simulator and learning environment were collected, concluding that most students improved their skills in understanding thermodynamics phenomena, but some improvements are necessary for future versions of the software and online courses.}
}
@article{ANGELAKI2009452,
title = {Multisensory integration: psychophysics, neurophysiology, and computation},
journal = {Current Opinion in Neurobiology},
volume = {19},
number = {4},
pages = {452-458},
year = {2009},
note = {Sensory systems},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2009.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0959438809000725},
author = {Dora E Angelaki and Yong Gu and Gregory C DeAngelis},
abstract = {Fundamental observations and principles derived from traditional physiological studies of multisensory integration have been difficult to reconcile with computational and psychophysical studies that share the foundation of probabilistic (Bayesian) inference. We review recent work on multisensory integration, focusing on experiments that bridge single-cell electrophysiology, psychophysics, and computational principles. These studies show that multisensory (visual–vestibular) neurons can account for near-optimal cue integration during the perception of self-motion. Unlike the nonlinear (superadditive) interactions emphasized in some previous studies, visual–vestibular neurons accomplish near-optimal cue integration through subadditive linear summation of their inputs, consistent with recent computational theories. Important issues remain to be resolved, including the observation that variations in cue reliability appear to change the weights that neurons apply to their different sensory inputs.}
}
@article{DELOERA20161,
title = {Random sampling in computational algebra: Helly numbers and violator spaces},
journal = {Journal of Symbolic Computation},
volume = {77},
pages = {1-15},
year = {2016},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2016.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S074771711600002X},
author = {Jesús A. {De Loera} and Sonja Petrović and Despina Stasi},
keywords = {Violator spaces, Ideal generators, Solving polynomial systems, Randomized algorithm in algebra, Large sparse systems of equations},
abstract = {This paper transfers a randomized algorithm, originally used in geometric optimization, to computational problems in commutative algebra. We show that Clarkson's sampling algorithm can be applied to two problems in computational algebra: solving large-scale polynomial systems and finding small generating sets of graded ideals. The cornerstone of our work is showing that the theory of violator spaces of Gärtner et al. applies to polynomial ideal problems. To show this, one utilizes a Helly-type result for algebraic varieties. The resulting algorithms have expected runtime linear in the number of input polynomials, making the ideas interesting for handling systems with very large numbers of polynomials, but whose rank in the vector space of polynomials is small (e.g., when the number of variables and degree is constant).}
}
@incollection{THIEL2005559,
title = {Chapter 21 - Semiempirical quantum-chemical methods in computational chemistry},
editor = {Clifford E. Dykstra and Gernot Frenking and Kwang S. Kim and Gustavo E. Scuseria},
booktitle = {Theory and Applications of Computational Chemistry},
publisher = {Elsevier},
address = {Amsterdam},
pages = {559-580},
year = {2005},
isbn = {978-0-444-51719-7},
doi = {https://doi.org/10.1016/B978-044451719-7/50064-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517197500640},
author = {Walter Thiel},
abstract = {Publisher Summary
This chapter focuses on semiempirical quantum-chemical methods describing their development over the past 40 years. One of the first semiempirical approaches in quantum chemistry was the p-electron method proposed by Hǖckel (1931) that generates molecular orbitals (MOs) essentially from the connectivity matrix of a molecule and provides valuable qualitative insights into the structure, stability, and spectroscopy of unsaturated molecules. Hoffmann extended this approach to include all valence electrons and applied in many qualitative studies of inorganic and organometallic compounds. These early semiempirical methods had a lasting impact on chemical thinking as they guided the development of qualitative MO theory that is commonly employed for rationalizing chemical phenomena in terms of orbitals interactions. They are normally not used any longer as computational tools. After a survey of the established methods such as MNDO, AM1, and PM3, recent methodological advances are described including the development of improved semiempirical models, new general-purpose and special-purpose parametrizations, and linear scaling approaches.}
}