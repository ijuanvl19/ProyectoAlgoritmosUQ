@article{SUO2024109268,
title = {A review of three-way decision: Triadic understanding, organization, and perspectives},
journal = {International Journal of Approximate Reasoning},
volume = {173},
pages = {109268},
year = {2024},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109268},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24001555},
author = {Langwangqing Suo and Han Yang and Qiaoyi Li and Hai-Long Yang and Yiyu Yao},
keywords = {Three-way decision, Triadic thinking, Three-way literature review,  method, Three-way bibliometrics analytics},
abstract = {A theory of three-way decision is about thinking, problem-solving, and computing in threes or through triads. In this paper, we review fifteen years of research on three-way decision by using the philosophy-theory-application triad and the who-what-when triad. First, we discuss the philosophy, theory, and application of three-way decision. At the philosophy level, we delve into the philosophical roots and fundamental nature of three-way decision to reveal the underlying philosophical thinking. At the theory level, we provide an insightful analysis of the theory and methodology of three-way decision. At the application level, we examine the integration of three-way decision with other theories and their applications and effectiveness in real-world scenarios. Second, we focus on bibliometrics analytics by using the who-what-when triad, which attempts to answer a fundamental question of “who did what when”. We propose a 3×3 model by applying the 3×3 method of three-way decision. The first 3 is the author-topic-time triad. The second 3 represents a three-level analysis for each of the first three: (1) categorizing authors into the three levels of prolific authors, frequent authors, and occasional authors, (2) classifying topics into the three levels of the core topics, emerging topics, and to-be-explored topics, and (3) dividing articles into the three levels of initial investigations, further developments, and most recent studies. Finally, we perform a bibliometrics analysis of three-way decision articles by using the 3×3 model of three-way decision. The results not only reveal the current status and trend of three-way decision research but also provide a road map for future research.}
}
@article{BOERS2025100095,
title = {Exploring cognitive strategies in human-AI interaction: ChatGPT's role in creative tasks},
journal = {Journal of Creativity},
volume = {35},
number = {1},
pages = {100095},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2025.100095},
url = {https://www.sciencedirect.com/science/article/pii/S2713374525000020},
author = {Jelle Boers and Terra Etty and Martine Baars and Kim {van Boekhoven}},
keywords = {Human-AI interaction, Cognitive strategies, Creativity, Higher education},
abstract = {This study investigated the cognitive strategies employed by dyads when utilizing ChatGPT's examples to generate ideas in creative tasks. Fourteen university students generated ideas for both function-first and form-first creative tasks in interaction with ChatGPT. Their 591 turns were analyzed using both self-reports and coded transcripts to categorize cognitive strategies such as conceptual combination, inspiration, improvement, and repetition. The results indicated that students less frequently employ cognitive strategies focusing on human-AI interaction (e.g., inspiration, improve, combine), but that most of the ideas were produced by repeating ChatGPT's idea. This tendency suggests that, when given freedom, students may rely heavily on AI-generated suggestions rather than actively engaging in more complex cognitive processes. A key practical implication of these findings is the importance of educating students on different cognitive strategies they can adopt in collaboration with AI tools. By guiding students to employ more diverse and active cognitive strategies, ChatGPT has the potential to become a more effective tool for enhancing creative thinking in higher education.}
}
@incollection{JUDD2006881,
title = {Chapter 17 Computationally Intensive Analyses in Economics},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {881-893},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02017-4},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020174},
author = {Kenneth L. Judd},
keywords = {computational economics, economic methodology},
abstract = {Computer technology presents economists with new tools, but also raises novel methodological issues. This essay discusses the challenges faced by computational researchers, and proposes some solutions.}
}
@article{LIU2024100642,
title = {A systematic review on how educators teach AI in K-12 education},
journal = {Educational Research Review},
volume = {45},
pages = {100642},
year = {2024},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2024.100642},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X24000514},
author = {Xiaofan Liu and Baichang Zhong},
keywords = {K-12 education, AI education, AI literacy, Research design, Teaching practice},
abstract = {Developing Artificial Intelligence (AI) education in K-12 contexts, i.e., teaching students about AI, is critical to promote students' AI literacy. However, the state-of-the-art of AI education is not clear enough. To this end, this study reviewed 45 high-quality empirical studies on K-12 AI education over the past decade from both research and instruction perspectives. Regarding the research design, this study revealed the relationship between publication year, sample size, learning stage, educational setting, research method, research focus and duration. Regarding the instruction design, this study revealed the relationship between learning stage, pedagogical strategy, learning tool, learning activity, learning content, assessment method and learning effect. Besides, this study also derived recommendations for research (i.e., time allocation, samples selection, longitudinal design, rigorous methodology and technical democracy) and instruction (i.e., group learning, authentic context, teacher involvement, triangular evidence and learning scaffolding). Overall, the main findings indicate that K-12 AI education has the potential to develop students’ AI literacy, which contains AI knowledge, AI affectivity, and AI thinking. However, deficiencies in research and instructional design still remain, including short durations, small sample sizes, non-standardized research methods, lack of long-term and cross-age AI curriculum, etc. This study also discussed several critical topics for future research and instruction.}
}
@article{LAWNICZAK20102227,
title = {Computational intelligence based architecture for cognitive agents},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {2227-2235},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.249},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910002504},
author = {Anna T. Lawniczak and Bruno N. {Di Stefano}},
keywords = {Agent, Agent modeling, Cognitive agent, Computational intelligence},
abstract = {We discuss some limitations of reflexive agents to motivate the need to develop cognitive agents and propose a hierarchical, layered, architecture for cognitive agents. Our examples often involve the discussion of cognitive agents in highway traffic models. A cognitive agent is an agent capable of performing cognitive acts, i.e. a sequence of the following activities: “Perceiving” information in the environment and provided by other agents, “Reasoning” about this information using existing knowledge, “Judging” the obtained information using existing knowledge, “Responding” to other cognitive agents or to the external environment, as it may be required, and “Learning”, i.e. changing (and, hopefully augmenting) the existing knowledge if the newly acquired information allows it. We describe how computational intelligence techniques (e.g., fuzzy logic, neural networks, genetic algorithms, etc) allow mimicking to a certain extent the cognitive acts performed by human beings. The order with which the cognitive actions take place is important and so is the order with which the various computational intelligence techniques are applied. We believe that a hierarchical layered model should be defined for the generic cognitive agents in a style akin to the hierarchical OSI 7 layer model used in data communication. We outline in broad sense such a reference model.}
}
@article{REN201310351,
title = {Challenges in the assignment of relative and absolute configurations of complex molecules: computation can resolve conflicts between theory and experiment},
journal = {Tetrahedron},
volume = {69},
number = {48},
pages = {10351-10356},
year = {2013},
issn = {0040-4020},
doi = {https://doi.org/10.1016/j.tet.2013.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S004040201301538X},
author = {Jie Ren and Guo-You Li and Lan Shen and Guo-Lin Zhang and Laurance A. Nafie and Hua-Jie Zhu},
keywords = {Absolute configuration reassignment, DFT, Chiroptical spectroscopy, Transition state, X-ray},
abstract = {The configuration of (−)-brevianamides was assigned as (2S,13S) based on X-ray structure analysis and hydrolysis experiments. However, our theoretical investigation of its chiroptical properties strongly implied that the correct configuration should be (2R,13R). The reasons for the incorrect earlier assignment are analyzed by calculations of conversion energy barriers among different intermediates, starting materials and final products. This study demonstrates that conflicting theoretical and, experimental results suggest that it is premature to assign the configuration of a natural product.}
}
@article{PSYCHARIS2011547,
title = {The computational experiment and its effects on approach to learning and beliefs on physics},
journal = {Computers & Education},
volume = {56},
number = {3},
pages = {547-555},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2010.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0360131510002642},
author = {Sarantos Psycharis},
keywords = {ICT, Programming, Interactive learning environments, Physics learning, Computational experiment},
abstract = {Contemporary instructional approaches expect students to be active producers of knowledge. This leads to the need for creation of instructional tools and tasks that can offer students opportunities for active learning. This study examines the effect of a computational experiment as an instructional tool-for Grade 12 students, using a computer simulation environment created in Java for the domain of “linear oscillations without damping”. In this study we use the computational experiment as an integration of the computational science with the discovery learning method. The computational experiment supports both types of research, the exploratory as well as the inventive research, helping the learners to develop not only exploratory but also expressive models. The aim of the paper is threefold. At first we want to examine the influence of the computational experiment on students’ learning performance. The other two aims are related to the investigation of the experiment’s influence on students’ approach to learning and their beliefs on physics. Our results indicate that there is a strong shift on students’ conceptual understanding and to the consideration of the coherence of physics, as well as to the realization that physics is strongly connected to mathematics. Finally students realized that mathematics, physics and information theory are strongly connected cognitive disciplines.}
}
@incollection{MOORE2013200,
title = {Gene Interaction},
editor = {Stanley Maloy and Kelly Hughes},
booktitle = {Brenner's Encyclopedia of Genetics (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {200-201},
year = {2013},
isbn = {978-0-08-096156-9},
doi = {https://doi.org/10.1016/B978-0-12-374984-0.00592-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123749840005921},
author = {J.H. Moore},
keywords = {Epistasis, Synergy, Systems genetics},
abstract = {Gene interaction is a broad term used to describe the joint role of multiple genes in determining phenotypic variability. It is often studied from the molecular point of view as biomolecular interactions or from a more genetic point of view as phenotypic effects due to the role of DNA sequence variations and their influence on biological processes. We are now moving from an era of thinking about interactions among several genes to interacting networks or systems of many genes in a genome-wide scale. The study of gene interactions using systems genetics approaches is being made possible by advances in DNA sequencing technology and more powerful experimental, statistical, and computational methods.}
}
@article{XU2011331,
title = {New Recursive Construction of Magic Squares Using Kronecker Compositional Operations and Its Application in Engineering Computation},
journal = {Systems Engineering Procedia},
volume = {2},
pages = {331-337},
year = {2011},
note = {Complexity System and Engineering Management},
issn = {2211-3819},
doi = {https://doi.org/10.1016/j.sepro.2011.10.046},
url = {https://www.sciencedirect.com/science/article/pii/S2211381911001354},
author = {Dandan Xu and Zisen Mao and Bei Chen and Ping Huang},
keywords = {Magic squares, symmetrical, pandiagonal, construction, engineering computation},
abstract = {Owing to the depth research on the remarkable properties of magic squares, a new recursive method for constructing high order magic squares will be firstly presented, based on the matrix operations, we refer to as the Kronecker compositional operations. Furthermore, popularizing this method,, we successfully demonstrate that large size magic squares of odd order with symmetrical and pandiagonal features can be generated by lower order initiators,which leads to the impressive application in engineering computation. Finally, we enumerate two small symmetrical and pandiagonal magic squares.}
}
@article{MOHAMMADIZIABARI2018376,
title = {Computational Analysis of Gender Differences in Coping with Extreme Stressful Emotions},
journal = {Procedia Computer Science},
volume = {145},
pages = {376-385},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.088},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323767},
author = {S. Sahand {Mohammadi Ziabari} and Jan Treur},
keywords = {Adaptive Network, Rumination, Extreme Emotion, Gender},
abstract = {In this paper a computational analysis is presented of differences between men and women in coping with extreme emotions. This analysis is based on an adaptive temporal-causal network model. It takes into account the suppression of connections between preparation states and sensory representations of action effects due to an extreme stressful emotion. It is shown how this model can be used to represent the difference between males and females facing an extreme emotion, thereby performing their own methods in coping with the extreme emotion, for males fight or flight and for females tend-and-befriend.}
}
@article{DAYAN2011661,
title = {Networks, circuits and computation},
journal = {Current Opinion in Neurobiology},
volume = {21},
number = {5},
pages = {661-663},
year = {2011},
note = {Networks, circuits and computation},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2011.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438811001267},
author = {Peter Dayan and Marla Feller and Dan Feldman}
}
@article{WESTERA201732,
title = {How people learn while playing serious games: A computational modelling approach},
journal = {Journal of Computational Science},
volume = {18},
pages = {32-45},
year = {2017},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2016.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877750316304483},
author = {Wim Westera},
keywords = {Serious gaming, Learning, Simulation, Modelling, Flow theory, Methodology},
abstract = {This paper proposes a computational modelling approach for investigating the interplay of learning and playing in serious games. A formal model is introduced that allows for studying the details of playing a serious game under diverse conditions. The dynamics of player action and motivation is based on cognitive flow theory, which is expressed in quantitative terms for this purpose. Seven extensive simulation studies involving over 100,000 iterations have demonstrated the stability of the model and its potential as a research instrument for serious gaming. The model allows researchers to deeply investigate quantitative dependences between relevant game variables, gain deeper understanding of how people learn from games, and develop approaches to improving serious game design.}
}
@article{ZAROUALI2024108024,
title = {Personality and susceptibility to political microtargeting: A comparison between a machine-learning and self-report approach},
journal = {Computers in Human Behavior},
volume = {151},
pages = {108024},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.108024},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003758},
author = {Brahim Zarouali and Tom Dobber and Jurrian Schreuder},
keywords = {Political microtargeting, Persuasion, Personality, Social media, Algorithms},
abstract = {Based on recent technological advances, campaigners and political actors can use psychographic-based political marketing. Yet, empirical evidence about its effectiveness is still very limited. Based on self-congruity theory, a pre-registered experiment (N = 280) investigated the persuasion effects of personality-congruent political microtargeting on the attitude toward the political party and voting intentions of citizens. More precisely, the focus was on the thinking vs feeling personality dimension (MBTI), and it was tested whether this personality “interacts” with exposure to a matching advertising appeal: rational vs. emotional political ad. To do so, two different methodological approaches were used: 1) a machine learning approach; 2) a self-report survey measure of personality. Results revealed significant “congruence effects” between personality and ad appeal, and showed that perceived ad relevance was serving as the underlying mechanism (mediator). However, these results were only found when the self-report measure of personality was used. When the algorithmic approach was used, no significant results were found. These findings feed into timely societal, methodological, and theoretical contributions.}
}
@article{YANG2012852,
title = {Computational Optimization, Modelling and Simulation: Smart Algorithms and Better Models},
journal = {Procedia Computer Science},
volume = {9},
pages = {852-856},
year = {2012},
note = {Proceedings of the International Conference on Computational Science, ICCS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.04.091},
url = {https://www.sciencedirect.com/science/article/pii/S1877050912002128},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, derivative-free method, optimization algorithm, modelling, nonlinear optimization, surragate-based optimization, simulation},
abstract = {Computational optimization is becoming a standard tool that is widely used in engineering design and industrial applications. Products and services are often concerned with the maximization of profits and reduction of cost, but also aim at being more energy-efficient, environment-friendly and safety-ensured; at the same time they are limited by resources, time and money. Despite of increasing computer power and availability of better simulation packages, there are a number of challenges remaining when applying numerical optimization methods for real-world engineering problems. Also, new challenges emerge when attempting to attack problems whose solution by means of simulation-based optimization was not even possible in the past. This third workshop on Computational Optimization, Modelling and Simulation (COMS 2012) at ICCS 2012 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry.}
}
@article{CARUSI20171,
title = {Validation and models in computational biomedical sciences: Philosophy, science, engineering},
journal = {Progress in Biophysics and Molecular Biology},
volume = {129},
pages = {1-2},
year = {2017},
note = {Validation of Computer Modelling},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S007961071730192X},
author = {Annamaria Carusi and Blanca Rodriguez and Kevin Burrage}
}
@article{OZKAYA2006381,
title = {Requirement-driven design: assistance for information traceability in design computing},
journal = {Design Studies},
volume = {27},
number = {3},
pages = {381-398},
year = {2006},
note = {Digital Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2005.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X0500089X},
author = {Ipek Ozkaya and Ömer Akin},
keywords = {requirement-driven design, information processing, design knowledge, design process, design methods},
abstract = {We describe requirement-driven computational design thinking as an approach to leverage the distinctive characteristics of the digital design process. We primarily focus on information continuity and traceability in the digital medium. Requirement-driven design is an information-based approach facilitating consistent design rationale tracking and evaluation, verification, and validation of design. We present the characteristics of requirement-driven design, which leverage the pervasive nature of digital design thinking. We demonstrate a requirement–design coupling approach, modeling a continuous and interactive design process for integrating problem formulation and form exploration.}
}
@article{ZHU2006287,
title = {Children can solve Bayesian problems: the role of representation in mental computation},
journal = {Cognition},
volume = {98},
number = {3},
pages = {287-308},
year = {2006},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2004.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0010027705000132},
author = {Liqi Zhu and Gerd Gigerenzer},
keywords = {Bayesian problems, Computation, Binary hypothesis},
abstract = {Can children reason the Bayesian way? We argue that the answer to this question depends on how numbers are represented, because a representation can do part of the computation. We test, for the first time, whether Bayesian reasoning can be elicited in children by means of natural frequencies. We show that when information was presented to fourth, fifth, and sixth graders in terms of probabilities, their ability to estimate the Bayesian posterior probability was zero. Yet when the same information was presented in natural frequencies, Bayesian reasoning showed a steady increase from fourth to sixth grade, reaching an average level of 19, 39, and 53%, respectively, in two studies. Sixth graders' performance with natural frequencies matched the performance of adults with probabilities. But this general increase was accompanied by striking individual differences. More than half of the sixth graders solved most or all problems, whereas one third could not solve a single one. An analysis of the children's responses provides evidence for the use of three non-Bayesian strategies. These follow an overlapping wave model of development and continue to be observed in the minds of adults. More so than adults' probabilistic reasoning, children's reasoning depends on a proper representation of information.}
}
@article{COOPER201442,
title = {Implementations are not specifications: Specification, replication and experimentation in computational cognitive modeling},
journal = {Cognitive Systems Research},
volume = {27},
pages = {42-49},
year = {2014},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2013.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041713000314},
author = {Richard P. Cooper and Olivia Guest},
keywords = {Theory specification, Implementation detail, Replication, Sensitivity analysis, Computational experimentation},
abstract = {Contemporary methods of computational cognitive modeling have recently been criticized by Addyman and French (2012) on the grounds that they have not kept up with developments in computer technology and human–computer interaction. They present a manifesto for change according to which, it is argued, modelers should devote more effort to making their models accessible, both to non-modelers (with an appropriate easy-to-use user interface) and modelers alike. We agree that models, like data, should be freely available according to the normal standards of science, but caution against confusing implementations with specifications. Models may embody theories, but they generally also include implementation assumptions. Cognitive modeling methodology needs to be sensitive to this. We argue that specification, replication and experimentation are methodological approaches that can address this issue.}
}
@article{DHAYAKA20241238,
title = {BeKarsa: A strategic approach to alleviate unemployment challenges in Malang City},
journal = {Procedia Computer Science},
volume = {245},
pages = {1238-1248},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.353},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031612},
author = {Pricillia Yohana Dhayaka and Yudhistya Ayu Kusumawati and Rudi Yulio Arindiono},
keywords = {Unemployment, Malang city, Work},
abstract = {Creating decent work and economic growth is not an easy thing. Decent work and economic growth aim to create a decent work environment and financial stability. Malang City, known as the City of Education, has a relatively high unemployment rate, although it has decreased since it spiked during the COVID-19 pandemic. This figure is also still higher than the unemployment rate in East Java. One of the problems contributing to this unemployment rate is the ineffective dissemination of skills training and job vacancies, so this needs to be improved. To overcome this problem and find the most effective solution to reduce the unemployment rate in Malang City, this research is being conducted. The purpose of this research is to determine the most effective solution to the problem using the design thinking method to help decrease the high unemployment rates. To assist the audience in obtaining information related to certified training and job vacancies, the researcher aims to design a platform in the form of a website so that the audience can access information effectively. The semantical differential method is also used in this research to assess the audience's impression of the solution and determine whether the solution is acceptable to the target audience and can help with the problem of information dissemination. This solution is expected to help people obtain information related to certified training and job openings. In addition, this research will improve certified training information services in Malang City to be more effective and easily accessible to the public.}
}
@article{JONCZYK2024120752,
title = {Operating in a second language lowers cognitive interference during creative idea generation: Evidence from brain oscillations in bilinguals},
journal = {NeuroImage},
volume = {297},
pages = {120752},
year = {2024},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2024.120752},
url = {https://www.sciencedirect.com/science/article/pii/S1053811924002490},
author = {Rafał Jończyk and Iga Krzysik and Olga Witczak and Katarzyna Bromberek-Dyzman and Guillaume Thierry},
keywords = {Creativity, Bilingualism, EEG, Alternate uses task, Alpha frequency, Beta frequency},
abstract = {Tasks measuring human creativity overwhelmingly rely on both language comprehension and production. Although most of the world's population is bilingual, few studies have investigated the effects of language of operation on creative output. This is surprising given that fluent bilinguals master inhibitory control, a mechanism also at play in creative idea evaluation. Here, we compared creative output in the two languages of Polish(L1)-English(L2) bilinguals engaged in a cyclic adaptation of the Alternative Uses Task increasing the contribution of idea evaluation (convergent thinking). We show that Polish-English bilinguals suffer less cognitive interference when generating unusual uses for common objects in the L2 than the L1, without incurring a significant drop in idea originality. Right posterior alpha oscillation power, known to reflect creative thinking, increased over cycles. This effect paralleled the increase in originality ratings over cycles, and lower alpha power (8–10 Hz) was significantly greater in the L1 than the L2. Unexpectedly, we found greater beta (16.5–28 Hz) desynchronization in the L2 than the L1, suggesting that bilingual participants suffered less interference from competing mental representations when performing the task in the L2. Whereas creative output seems unaffected by language of operation overall, the drop in beta power in the L2 suggests that bilinguals are not subjected to the same level of semantic flooding in the second language as they naturally experience in their native language.}
}
@incollection{RAMOS2018720,
title = {8.36 - Bioinformatics and Computational Biology in Toxicology: Gateways for Precision Medicine☆},
editor = {Charlene A. McQueen},
booktitle = {Comprehensive Toxicology (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {720-728},
year = {2018},
isbn = {978-0-08-100601-6},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.99176-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383991761},
author = {K.S. Ramos and M. Martin and I.N. Ramos and G.A. Rempala},
keywords = {Bioinformatics, Computational biology, Precision medicine, Systems biology},
abstract = {The National Center for Biotechnology Information (NCBI) defines bioinformatics as “… the field of science in which biology, computer science, and information technology merge to form a single discipline”. As such, the field of bioinformatics includes computer scientists who develop algorithms for sequence analysis, biostatisticians who develop and implement methods of analyses for large clinical datasets, mathematicians or physical scientists who develop models to describe the interactions of genes, proteins, and small molecules within cells, and all those engaged in the development of software and databases for manipulation, storage, and retrieval of information in support of their research. This chapter focuses on how computational biology has been enabled by molecular informatics to provide the basis for in silico studies that facilitate the collection, organization, and analysis of datasets that explain biological phenomena and that help to drive biological discovery with applications in precision medicine.}
}
@incollection{SEDERBERG2010145,
title = {Learning and Memory: Computational Models},
editor = {George F. Koob and Michel Le Moal and Richard F. Thompson},
booktitle = {Encyclopedia of Behavioral Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {145-153},
year = {2010},
isbn = {978-0-08-045396-5},
doi = {https://doi.org/10.1016/B978-0-08-045396-5.00140-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780080453965001408},
author = {P.B. Sederberg and K.A. Norman},
keywords = {Computational models, Context, Cortex, Episodic memory, Hippocampus, Learning, Memory, Neural networks, Recognition, Recall, Semantic memory, Synaptic plasticity},
abstract = {The goal of learning and memory research is to understand how we store and retrieve information based on our experiences. Computational models provide formal implementations of memory theories that attempt to predict both behavior and neural data. This article describes computational models of declarative memory, including episodic memory (memory for specific events) and semantic memory (memory for meanings), with a particular focus on the role of context in supporting both types of memory.}
}
@article{DUAN2025127718,
title = {LSBT-Net: A lightweight framework for fault diagnosis of bearings based on an interpretable spatial-temporal model},
journal = {Expert Systems with Applications},
volume = {281},
pages = {127718},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127718},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425013405},
author = {Yicheng Duan and Tongguang Yang and Chenlin Wang and Yongjian Zhang and Qingkai Han and Shuangping Guo},
keywords = {Intelligent Diagnosis, Insulated Bearings, LSBT-Net Framework, Interpretability},
abstract = {Intelligent fault diagnosis based on deep learning has emerged as a research focus in mechanical equipment due to its adaptive feature extraction capability. However, current models struggle with low accuracy, high computational costs, and poor interpretability when detecting faults in insulated bearings. To address these challenges, this paper proposes a novel lightweight spatiotemporal model-based intelligent diagnostic framework, named LSBT-Net, which aims to identify motor insulating bearing faults in practical engineering applications more accurately. Specifically, this research breaks the conventional thinking of “learning fault data feature information” by innovatively developing a spatiotemporal information fusion module. This module is cleverly integrated into the LSBT-Net framework, enabling the extraction of both local and global high-dimensional fault feature information from insulating bearings. At the same time, based on a lightweight design, it significantly reduces the total number of parameters and computational resources required by the framework, thus lowering its computational complexity. The t-SNE algorithm is introduced into the LSBT-Net framework to achieve local or global interpretability. Furthermore, by calculating the gradient information of the LSBT-Net framework on the fault types of insulating bearings through backpropagation, the interpretability of the framework with respect to the physical information is enhanced. Using insulating bearings and typical fault experiments as examples, the LSBT-Net framework demonstrates excellent diagnostic capability and generalization performance compared to other advanced methods.}
}
@article{JUNG201787,
title = {Computational Collective Intelligence with Big Data: Challenges and Opportunities},
journal = {Future Generation Computer Systems},
volume = {66},
pages = {87-88},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16302837},
author = {Jason J. Jung},
keywords = {Computational collective intelligence, Computer-supported collaboration, Big data},
abstract = {Collective intelligence has been an important research topic in many AI communities. With The big data phenomenon, we have been facing on many research problems on how to integrate the big data with collective intelligence. This special issue has selected 9 high quality papers covering various research issues.}
}
@article{VALENTINOV2015491,
title = {Nonprofit organizations, institutional economics, and systems thinking},
journal = {Economic Systems},
volume = {39},
number = {3},
pages = {491-501},
year = {2015},
note = {Symposium: Financial System and Development in China},
issn = {0939-3625},
doi = {https://doi.org/10.1016/j.ecosys.2014.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0939362515000278},
author = {Vladislav Valentinov and Stefan Hielscher and Ingo Pies},
keywords = {Nonprofit organizations, John Kenneth Galbraith, Countervailing power, Niklas Luhmann},
abstract = {The present paper applies the logic of John Kenneth Gailbraith's institutional economics analysis of corporate power to inquiring into the societal role of the nonprofit sector. Building on Galbraith's insight that corporations cause subtle but pervasive societal imbalances, the paper locates the role of nonprofit organizations in compensating for these imbalances, thus showing corporations and nonprofit organizations to be mutually complementary rather than antagonistic actors. This argument is supported by Niklas Luhmann's vision of the precarious relationship between the complexity and sustainability of social systems as well as by Kenneth Boulding's analysis of the farmer and labor movement. Luhmann's and Boulding's perspectives show profit-seeking corporations to be social systems developing high technological complexity at the cost of sacrificing their societal sustainability, while the improvement of the latter constitutes the rationale of many nonprofit organizations. The same systems-theoretic logic suggests, however, that nonprofit organizations may tend to underestimate the technological complexity of implementing their mission-related activities, thereby undermining their own effectiveness.}
}
@incollection{ALEKSANDER200777,
title = {Computational studies of consciousness},
editor = {Rahul Banerjee and Bikas K. Chakrabarti},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {168},
pages = {77-93},
year = {2007},
booktitle = {Models of Brain and Mind},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(07)68007-8},
url = {https://www.sciencedirect.com/science/article/pii/S0079612307680078},
author = {Igor Aleksander and Helen Morton},
keywords = {brain modelling, consciousness, neural architectures},
abstract = {In this chapter we present a computational architecture intended to add clarity to the concept of consciousness. We briefly review some of the motivations of work done in this area in various institutes around the world and looks closely at our own work which specifically includes phenomenology, the sense of a self in a perceptual world. This breaks consciousness into five axioms: presence, imagination, attention, volition and emotions. It develops plausible mechanisms of each and how they interact to give a single sensation. An abstract architecture, the kernel architecture, is introduced as a starting point for building computational models. It is shown that through this architecture it is possible to discuss puzzling aspects of consciousness, for example are animals conscious? What happens when we dream? What goes on when we experience an illusion? This paper is intended to elucidate and update some concepts introduced in Aleksander (2005).}
}
@article{LEE2023101274,
title = {Storytelling as a learning tool in creative education: A case study in an architecture design studio},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101274},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101274},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000445},
author = {Keunhye Lee and Eunki Kang and Eun Joo Park},
keywords = {Storytelling, Creative thinking, Architecture design studio, Creative education, Communicative representation},
abstract = {This paper investigates the significant aspects of storytelling, when used as a pedagogical method to enhance students critical and creative thinking and communicative technique, by applying it to first-year students in the architecture design studio. Creativity is a substantial part of architectural education as it improves students’ design processes in innovative ways. This paper considers how the architecture design studio can form a creative design solution that can be learned and developed by learner-centred activity; it concentrates on aspects of storytelling, which many scholars have begun to discuss its significance in creative education. Thus, this paper aims to develop a creative learning strategy for use in the architecture design studio and suggest a new learning method by engaging storytelling in the design process. This paper starts with discussions about storytelling and its usages in the architecture design studio, referring to several theorists and educators, particularly focusing on McDrury and Alterio (2003); it helps to create a framework and develop a curriculum for the architecture design studio. The overall results suggest that using storytelling as a learning method in an architecture design studio is important in contextualising and articulating design work, from ideas to analysis, visualisation and expression, in a coherent context. It helps students gain better design skills and a greater understanding of the design process across the disciplines of the design studio, improving students creative thinking during the unique design process.}
}
@article{SU2022100049,
title = {Artificial intelligence in early childhood education: A scoping review},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100049},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100049},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000042},
author = {Jiahong Su and Weipeng Yang},
keywords = {Artificial intelligence, Early childhood education, Teaching and learning, Machine learning, Computer science},
abstract = {Artificial intelligence (AI) tools are increasingly being used in the field of early childhood education (ECE) to enhance learning and development among young children. Previous proof-of-concept studies have demonstrated that AI can effectively improve teaching and learning in ECE; however, there is a scarcity of knowledge about how these studies are conducted and how AI is used across these studies. We conducted this scoping review to evaluate, synthesize and display the latest literature on AI in ECE. This review analyzed 17 eligible studies conducted in different countries from 1995 to 2021. Although few studies on this critical issue have been found, the existing references provide up-to-date insights into different aspects (knowledge, tools, activities, and impacts) of AI for children. Most studies have shown that AI has significantly improved children's concepts regarding AI, machine learning, computer science, and robotics and other skills such as creativity, emotion control, collaborative inquiry, literacy skills, and computational thinking. Future directions are also discussed for researching AI in ECE.}
}
@article{WHALLEY2001743,
title = {Reliability and uncertainty in flow measurement techniques - some current thinking},
journal = {Physics and Chemistry of the Earth, Part C: Solar, Terrestrial & Planetary Science},
volume = {26},
number = {10},
pages = {743-749},
year = {2001},
issn = {1464-1917},
doi = {https://doi.org/10.1016/S1464-1917(01)95019-6},
url = {https://www.sciencedirect.com/science/article/pii/S1464191701950196},
author = {N. Whalley and R.S. Iredale and A.F. Clare},
keywords = {flow measurement, current meter gauging, flow measurement structures, calibration, stage-discharge relationship},
abstract = {Improvements in the quality and availability of flow measurement equipment are undoubtedly capable of enhancing the reliability and accuracy of the hydrometric data that we require. However much of the UK's hydrometric data is acquired by the tried and trusted methods that have remained the mainstay of flow monitoring for many years. Should the results provided by these established techniques always be so readily accepted given the range of assumptions on which they are based? Current meter gauging is the principle technique used for the establishment of stage discharge relationships in the UK. Either directly for the establishment of stage-discharge relationships in open channels, indirectly for calibration of flow measurement equipment (e.g. ultrasonic Doppler velocity meters) or as a means of verification of existing flow measurement structures. Recent projects involving current meter gauging techniques have provoked much thought as to the validity of established techniques and in particular the assumptions on which they are based. The chosen case studies highlight a number of projects where there have been questions regarding the reliability and uncertainty of the flow measurement techniques employed. The alternative approaches required to deal with such problems are also discussed.}
}
@article{LISSACK2024389,
title = {Responsible Use of Large Language Models: An Analogy with the Oxford Tutorial System},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {389-413},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000959},
author = {Michael Lissack and Brenden Meagher},
keywords = {responsible AI, Oxford Tutorial, large language models (LLMs), human-AI collaboration, critical thinking},
abstract = {In the rapidly evolving landscape of artificial intelligence, large language models (LLMs) have emerged as powerful tools with the potential to revolutionize how we process information, generate content, and solve complex problems. However, integrating these sophisticated AI systems into academic and professional practices raises critical questions about responsible use, ethical considerations, and the preservation of human expertise. This article introduces a novel framework for understanding and implementing responsible AI use by drawing an analogy between the optimal use of LLMs and the role of the second student in an Oxford Tutorial. Through an in-depth exploration of the Oxford Tutorial system and its parallels with LLM interaction, we propose a nuanced approach to leveraging AI language models while maintaining human agency, fostering critical thinking, and upholding ethical standards. The article examines the implications of this analogy, discusses potential risks of misuse, and provides detailed practical scenarios across various fields. By grounding the use of cutting-edge AI technology in a well-established and respected educational model, this research contributes to the ongoing discourse on AI ethics. It offers valuable insights for academics, professionals, and policymakers grappling with the challenges and opportunities presented by LLMs.}
}
@article{BILORIA2012259,
title = {Interactive morphologies: An investigation into integrated nodal networks and embedded computation processes for developing real-time responsive spatial systems},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {3},
pages = {259-271},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000465},
author = {Nimish Biloria},
keywords = {Real-time interaction, Sensing and actuation, Performance, Adaptation, Emergence},
abstract = {The design-research illustrated in this research article focus on the emerging field of interactive architecture focusing on developing real-time information exchanging architectural bodies. These interactive bodies demonstrate a fusion between the material, the electronic and the digital domains. This fusion is explicitly attained through a synergistic merger between the fields of ambient sensing, control systems, ubiquitous computing, architectural design, pneumatic systems and computation. The resultant spatial bodies are thus visualised as complex adaptive systems, continually engaged in activities of data-exchange resulting in physical and ambient adaptations of their constituting components in response to contextual variations. Interdependent nodal networks, where every node/junction of a spatial prototype becomes a potential information hub by means of its ability to collect, process and communicate contextual data apart from working as an actuated detail owing to its ability to kinetically re-position itself in three-dimensional space is thus a critical outcome of this inter-disciplinary way of working. A strategy apt for binding material logistics with the digital to materialize dynamic spatial behaviours owing to real time data exchange between the prototypes and their context is thus embarked upon via three research and design projects, namely: Electronic Media Augmented Spatial Skins, The InteractiveWall and the Muscle Re-configured.}
}
@article{KLIEMANN20181,
title = {The social neuroscience of mentalizing: challenges and recommendations},
journal = {Current Opinion in Psychology},
volume = {24},
pages = {1-6},
year = {2018},
note = {Social Neuroscience},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X17302786},
author = {Dorit Kliemann and Ralph Adolphs},
abstract = {Our ability to understand and think about the mental states of other people is referred to as ‘mentalizing’ or ‘theory of mind’. It features prominently in all social behavior, is essential for maintaining relationships, and shows pronounced individual differences. Here we review new approaches to study the underlying psychological mechanisms and discuss how they could best be investigated using modern tools from social neuroscience. We list key desiderata for the field, such as validity, specificity, and reproducibility, and link them to specific recommendations for the future. We also discuss new computational modeling approaches, and the application to psychopathology.}
}
@article{LI2025126039,
title = {Correct like humans: Progressive learning framework for Chinese text error correction},
journal = {Expert Systems with Applications},
volume = {265},
pages = {126039},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.126039},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424029063},
author = {Yinghui Li and Shirong Ma and Shaoshen Chen and Haojing Huang and Shulin Huang and Yangning Li and Hai-Tao Zheng and Ying Shen},
keywords = {Chinese text error correction, Progressive learning, Natural language processing, Computational linguistics},
abstract = {Chinese Text Error Correction (CTEC) aims to detect and correct errors in the input text, which benefits human daily life and various downstream tasks. With the extensive research on Pre-trained Language Models (PLMs), Chinese Spelling Correction (CSC) and Chinese Grammatical Error Correction (CGEC), two subtasks of CTEC, have achieved good results. However, researchers usually study these two tasks separately. In addition, we argue that previous studies still overlook the importance of human thinking patterns. To enhance the development of PLMs for CTEC, inspired by humans’ daily error-correcting behavior, we propose a novel model-agnostic progressive learning framework, named ProTEC, which guides PLMs-based CTEC models to learn to correct like humans and can be applied to various existing CTEC models in both CSC and CGEC. During the training process, ProTEC guides the model to learn text error correction by incorporating these sub-tasks into a progressive paradigm. During the inference process, the model completes these sub-tasks in turn to generate the correction results. Extensive experiments and detailed analyses demonstrate the effectiveness and efficiency of our proposed model-agnostic ProTEC framework.}
}
@article{LADLEY20152412,
title = {The impact of individual versus group rewards on work group performance and cooperation: A computational social science approach},
journal = {Journal of Business Research},
volume = {68},
number = {11},
pages = {2412-2425},
year = {2015},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2015.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S0148296315001022},
author = {Daniel Ladley and Ian Wilkinson and Louise Young},
keywords = {Cooperation, Work groups, Incentive, Iterated, Group versus individual reward systems, Complex systems, Agent based models, Computational social science},
abstract = {Purpose
To examine the effect of individual versus group evaluation and reward systems on work group behavior and performance under different task conditions.
Methodology
Uses computational social methods using Agent Based Models to simulate work group interactions as different forms of iterated games.
Findings
Group based systems outperform individual based and mixed systems, producing more cooperative behavior, the best performing groups and individuals in most types of interaction games. A new role emerges, the self-sacrificer, who plays a critical role in enabling other group members and the group, to perform better at their own expense.
Research Implications
Suggest opportunities for model development and guidelines for designing real world experiments.
Practical Implications
Helps firms engineer better performing work groups as well as the design of other business systems.
Social Implications
Identifies mechanisms by which cooperation can be developed in social systems.
Originality/Value
Demonstrates the role and value of computational social science methods and agent based models to business research.}
}
@article{YANG2018242,
title = {Multi-disciplinary and multi-objective optimization problem re-formulation in computational design exploration: A case of conceptual sports building design},
journal = {Automation in Construction},
volume = {92},
pages = {242-269},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.03.023},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517309317},
author = {Ding Yang and Shibo Ren and Michela Turrin and Sevil Sariyildiz and Yimin Sun},
keywords = {Multi-disciplinary optimization, Multi-objective optimization, Computational design exploration, Knowledge extraction, Statistical analysis techniques, Optimization problem re-formulation, Sports buildings, Architectural performance, Climate performance, Structural performance},
abstract = {The benefits of applying multi-objective optimization (MOO) in building design have been increasingly recognized in recent decades. The existing or traditional computational design optimization (CDO) approaches mostly focus on optimization problem solving (OPS), as they often conduct optimizations directly by assuming the optimization problems in question are good enough. In contrast, the computational design exploration (CDE) approaches defined in this research mainly focus on optimization problem formulation (OPF), which are considered more essential and aim to achieve or ensure appropriate optimization problems before conducting optimizations. However, the application of the CDE is very limited especially in conceptual architectural design. The necessity of re-formulating original optimization problems and its potential impacts on optimization results are often overlooked or not emphasized enough. This paper proposes a new CDE approach that highlights the knowledge-supported re-formulation of a changeable initial optimization problem. It improves upon the traditional CDO approach by introducing a changeable initial OPF and inserting a CDE module. The changeable initial OPF allows expanding the dimensionality of an objective space and design space being investigated, and the CDE module can re-formulate the changeable optimization problem using the information and knowledge extracted from statistical analyses. To facilitate designers in achieving the proposed approach, an improved computational platform is used which combines parametric modeling software (including simulation plug-ins) and design optimization software. Assisted by the platform, the proposed approach is applied to the conceptual design of an indoor sports building that considers multi-disciplinary performance criteria (including architecture-, climate- and structure-related criteria) and a wide range of geometric variations. Through the case study, this paper demonstrates the use of the proposed approach, verifies its benefits over the traditional method, and unveils the factors that may affect the behaviour of the proposed approach. Besides, it also shows the suitability of the computational platform used.}
}
@article{CONSTABLE201760,
title = {The practice of chemistry still needs to change},
journal = {Current Opinion in Green and Sustainable Chemistry},
volume = {7},
pages = {60-62},
year = {2017},
note = {New Synthetic Methods 2017},
issn = {2452-2236},
doi = {https://doi.org/10.1016/j.cogsc.2017.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2452223617300755},
author = {David J.C. Constable},
abstract = {There is now over a 20-year history of green and sustainable chemistry efforts in the US, but for a majority of chemicals that have been synthesized, chemists and chemical engineers lack key information about what it takes to commercialize them, their toxicity to humans or the environment, their degradability (biological or otherwise), their ability to be recycled or reused, or their ability to be source renewably. While the depth, breadth, and variety of innovations in chemistry gives one hope that chemists and chemical engineers will make many significant advances in the next 20 years, there is still a need to incorporate systems and life cycle thinking into chemistry. This is especially true as one considers limitations in the supply of key elements chemists rely on very heavily. Recent advances in computational chemistry and machine learning show great promise for moving chemistry toward a more sustainable practice of chemistry.}
}
@article{CROLLEN2019549,
title = {Recruitment of the occipital cortex by arithmetic processing follows computational bias in the congenitally blind},
journal = {NeuroImage},
volume = {186},
pages = {549-556},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.11.034},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918321153},
author = {Virginie Crollen and Latifa Lazzouni and Mohamed Rezk and Antoine Bellemare and Franco Lepore and Marie-Pascale Noël and Xavier Seron and Olivier Collignon},
keywords = {Blindness, Mental arithmetic, Multiplication, Neural correlates, Subtraction},
abstract = {Arithmetic reasoning activates the occipital cortex of congenitally blind people (CB). This activation of visual areas may highlight the functional flexibility of occipital regions deprived of their dominant inputs or relate to the intrinsic computational role of specific occipital regions. We contrasted these competing hypotheses by characterizing the brain activity of CB and sighted participants while performing subtraction, multiplication and a control letter task. In both groups, subtraction selectively activated a bilateral dorsal network commonly activated during spatial processing. Multiplication triggered activity in temporal regions thought to participate in memory retrieval. No between-group difference was observed for the multiplication task whereas subtraction induced enhanced activity in the right dorsal occipital cortex of the blind individuals only. As this area overlaps with regions showing selective tuning to auditory spatial processing and exhibits increased functional connectivity with a dorsal “spatial” network, our results suggest that the recruitment of occipital regions during high-level cognition in the blind actually relates to the intrinsic computational role of the activated regions.}
}
@article{MOGHADDAM2020112879,
title = {A neuro-inspired computational model for adaptive fault diagnosis},
journal = {Expert Systems with Applications},
volume = {140},
pages = {112879},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.112879},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419305895},
author = {Mohsen Moghaddam and Qiliang Chen and Abhijit V. Deshmukh},
keywords = {Machine consciousness, Deep learning, Convolutional neural networks, Transfer learning},
abstract = {Fault diagnosis is a key process to ensure reliable and cost-effective performance of time-critical engineered systems. This article develops a data-driven computational model for adaptive fault diagnosis by drawing an analogy with the neurobiological process of conscious attention—a dynamic process that brings only the most novel 0.01% of the signals we receive with our five senses to our conscious experience. A model of conscious attention based on the theory of dynamic core hypothesis is first outlined, followed by a computational model that mimics key stages of the conscious attention process. Convolutional neural networks serve as a basis for modeling perceptual categorization and concept formation through automatic feature extraction, due to their analogy with the processes of neural group selection and reentry in the brain. Further, the process of incremental learning and its impact on signal novelty are modeled via transfer learning. The model is tested on the NASA C-MAPSS turbofan engine model, which indicated 95–99% fault diagnosis accuracy. This study aims at familiarizing the engineering community with the neurobiological process of conscious attention and its applications for adaptive process monitoring and improvement in engineered systems.}
}
@article{VARTIAINEN2020100182,
title = {Learning machine learning with very young children: Who is teaching whom?},
journal = {International Journal of Child-Computer Interaction},
volume = {25},
pages = {100182},
year = {2020},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2020.100182},
url = {https://www.sciencedirect.com/science/article/pii/S2212868920300155},
author = {Henriikka Vartiainen and Matti Tedre and Teemu Valtonen},
keywords = {Machine learning, Computational thinking, K-12, Participatory learning, Early childhood, Participatory research, Artificial intelligence},
abstract = {While artificial intelligence and machine learning is becoming a commonplace feature of people’s everyday lives, so far few theoretical or empirical studies have focused on investigating it in K-12​ education. Drawing on the sociocultural theory of learning and participation, this case study explored how six very young children taught and explored Google’s Teachable Machine in nonschool settings. Through fine-grained analysis of video recordings and interviews with the children, the article illustrates the content and the process of teaching where 3–9 year old children were producing machine learning data sets and models as well as observing, exploring, and explaining their own interaction with machine learning systems. The results illustrate the quick-paced and embodied nature of the child-computer interaction that also supported children to reason about the relationship between their own bodily expressions and the output of an interactive ML-based tool. The article concludes with discussions on the emergent process of teaching and learning as well as on ways of promoting children’s participation and sense of agency in the age of machine learning.}
}
@article{NIGHTINGALE2016558,
title = {Impact responses of the cervical spine: A computational study of the effects of muscle activity, torso constraint, and pre-flexion},
journal = {Journal of Biomechanics},
volume = {49},
number = {4},
pages = {558-564},
year = {2016},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2016.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0021929016000154},
author = {Roger W. Nightingale and Jake Sganga and Hattie Cutcliffe and Cameron R. ‘Dale’ Bass},
keywords = {Biomechanics, Cervical spine, Bilateral facet Dislocation, Buckling, Muscle, Initial conditions, Compression, Pre-flexion, Preflexion, Alignment},
abstract = {Cervical spine injuries continue to be a costly societal problem. Future advancements in injury prevention depend on improved physical and computational models, which are predicated on a better understanding of the neck response during dynamic loading. Previous studies have shown that the tolerance of the neck is dependent on its initial position and its buckling behavior. This study uses a computational model to examine three important factors hypothesized to influence the loads experienced by vertebrae in the neck under compressive impact: muscle activation, torso constraints, and pre-flexion angle of the cervical spine. Since cadaver testing is not practical for large scale parametric analyses, these factors were studied using a previously validated computational model. On average, simulations with active muscles had 32% larger compressive forces and 25% larger shear forces—well in excess of what was expected from the muscle forces alone. In the short period of time required for neck injury, constraints on torso motion increased the average neck compression by less than 250N. The pre-flexion hypothesis was tested by examining pre-flexion angles from neutral (0°) to 64°. Increases in pre-flexion resulted in the largest increases in peak loads and the expression of higher-order buckling modes. Peak force and buckling modality were both very sensitive to pre-flexion angle. These results validate the relevance of prior cadaver models for neck injury and help explain the wide variety of cervical spine fractures that can result from ostensibly similar compressive loadings. They also give insight into the mechanistic differences between burst fractures and lower cervical spine dislocations.}
}
@article{HERAS2011685,
title = {fKenzo: A user interface for computations in Algebraic Topology},
journal = {Journal of Symbolic Computation},
volume = {46},
number = {6},
pages = {685-698},
year = {2011},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2011.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0747717111000174},
author = {J. Heras and V. Pascual and J. Rubio and F. Sergeraert},
keywords = {Symbolic computation systems, User interface, Constructive Algebraic Topology},
abstract = {fKenzo (= friendly Kenzo) is a graphical user interface providing a user-friendly front-end for the Kenzo system, a Common Lisp program devoted to Algebraic Topology. The fKenzo system provides the user interface itself, an XML intermediary generator-translator and, finally the Kenzo kernel. We describe in this paper the main points of fKenzo, and we explain also the advantages and limitations of fKenzo with respect to Kenzo itself. The text is separated into two parts, trying to cover both the user and the developer perspectives.}
}
@article{ARSLAN2024340,
title = {Computational analysis of linguistic features in speech samples of first-episode bipolar disorder and psychosis},
journal = {Journal of Affective Disorders},
volume = {363},
pages = {340-347},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.07.102},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724011595},
author = {Berat Arslan and Elif Kizilay and Burcu Verim and Cemal Demirlek and Muhammed Demir and Ezgi Cesim and Merve S. Eyuboglu and Simge Uzman Ozbek and Ekin Sut and Berna Yalincetin and Emre Bora},
keywords = {Psychosis, Bipolar, First-episode, Natural language processing, Semantic similarity},
abstract = {Background
In recent years, automated analyses using novel NLP methods have been used to investigate language abnormalities in schizophrenia. In contrast, only a few studies used automated language analyses in bipolar disorder. To our knowledge, no previous research compared automated language characteristics of first-episode psychosis (FEP) and bipolar disorder (FEBD) using NLP methods.
Methods
Our study included 53 FEP, 40 FEBD and 50 healthy control participants who are native Turkish speakers. Speech samples of the participants in the Thematic Apperception Test (TAT) underwent automated generic and part-of-speech analyses, as well as sentence-level semantic similarity analysis based on SBERT.
Results
Both FEBD and FEP were associated with the use of shorter sentences and increased sentence-level semantic similarity but less semantic alignment with the TAT pictures. FEP also demonstrated reduced verbosity and syntactic complexity. FEP differed from FEBD in reduced verbosity, decreased first-person singular pronouns, fewer conjunctions, increased semantic similarity as well as shorter sentence and word length. The mean classification accuracy was 82.45 % in FEP vs HC, 71.1 % in FEBD vs HC, and 73 % in FEP vs FEBD. After Bonferroni correction, the severity of negative symptoms in FEP was associated with reduced verbal output and increased 5th percentile of semantic similarity.
Limitations
The main limitation of this study was the cross-sectional nature.
Conclusion
Our findings demonstrate that both patient groups showed language abnormalities, which were more severe and widespread in FEP compared to FEBD. Our results suggest that NLP methods reveal transdiagnostic linguistic abnormalities in FEP and FEBD.}
}
@article{ROLLS2007962,
title = {A computational neuroscience approach to consciousness},
journal = {Neural Networks},
volume = {20},
number = {9},
pages = {962-982},
year = {2007},
note = {Brain and Consciousness},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2007.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S089360800700189X},
author = {Edmund T. Rolls},
keywords = {Consciousness, Higher order thought, Synchrony, Oscillations, Backward masking, Binding},
abstract = {Simultaneous recordings from populations of neurons in the inferior temporal visual cortex show that most of the information about which stimulus was shown is available in the number of spikes (or firing rate) of each neuron, and not from stimulus-dependent synchrony, so that it is unlikely that stimulus-dependent synchrony (or indeed oscillations) is an essential aspect of visual object perception. Neurophysiological investigations of backward masking show that the threshold for conscious visual perception may be set to be higher than the level at which small but significant information is present in neuronal firing and which allows humans to guess which stimulus was shown without conscious awareness. The adaptive value of this may be that the systems in the brain that implement the type of information processing involved in conscious thoughts are not interrupted by small signals that could be noise in sensory pathways. I then consider what computational processes are closely related to conscious processing, and describe a higher order syntactic thought (HOST) computational theory of consciousness. It is argued that the adaptive value of higher order thoughts is to solve the credit assignment problem that arises if a multistep syntactic plan needs to be corrected. It is then suggested that it feels like something to be an organism that can think about its own linguistic, and semantically-based thoughts. It is suggested that qualia, raw sensory and emotional feels, arise secondarily to having evolved such a higher order thought system, and that sensory and emotional processing feels like something because it would be unparsimonious for it to enter the planning, higher order thought, system and not feel like something.}
}
@article{COX2005104,
title = {Metacognition in computation: A selected research review},
journal = {Artificial Intelligence},
volume = {169},
number = {2},
pages = {104-141},
year = {2005},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2005.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0004370205001530},
author = {Michael T. Cox},
keywords = {Cognitive monitoring, Computational introspection, Limited rationality, Metacognition, Meta-explanation, Metaknowledge, Meta-level architecture, Metareasoning, Self-reference, Reflection},
abstract = {Various disciplines have examined the many phenomena of metacognition and have produced numerous results, both positive and negative. I discuss some of these aspects of cognition about cognition and the results concerning them from the point of view of the psychologist and the computer scientist, and I attempt to place them in the context of computational theories. I examine metacognition with respect to both problem solving (e.g., planning) and to comprehension (e.g., story understanding) processes of cognition.}
}
@article{PAPAVLASOPOULOU201850,
title = {How do you feel about learning to code? Investigating the effect of children’s attitudes towards coding using eye-tracking},
journal = {International Journal of Child-Computer Interaction},
volume = {17},
pages = {50-60},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2018.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300259},
author = {Sofia Papavlasopoulou and Kshitij Sharma and Michail N. Giannakos},
keywords = {Children’s attitudes, Eye-tracking, Coding, Computational thinking, Constructionism},
abstract = {Computational thinking and coding for children are attracting increasing attention. There are several efforts around the globe to implement coding frameworks for children, and there is a need to develop an empirical knowledge base of methods and tools. One major problem for integrating study results into a common body of knowledge is the relatively limited measurements applied, and the relation of the widely used self-reporting methods with more objective measurements, such as biophysical ones. In this study, eye-tracking activity was used to measure children’s learning and activity indicators. The goal of the study is to utilize eye-tracking to understand children’s activity while they learn how to code and to investigate any potential association between children’s attitudes and their gaze. In this contribution, we designed an experiment with 44 children (between 8 and 17 years old) who participated in a full-day construction-based coding activity. We recorded their gaze while they were working and captured their attitudes in relation to their learning, excitement and intention. The results showed a significant relation between children’s attitudes (what they think about coding) and their gaze patterns (how they behaved during coding). Eye-tracking data provide initial insights into the behaviour of children, for example if children have difficulty in extracting information or fail to accomplish an expected task. Therefore, further studies need to be conducted to shed additional light on children’s experience and learning duringcoding.}
}
@incollection{SEJNOWSKI200919,
title = {Computational Methods},
editor = {Larry R. Squire},
booktitle = {Encyclopedia of Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {19-22},
year = {2009},
isbn = {978-0-08-045046-9},
doi = {https://doi.org/10.1016/B978-008045046-9.01396-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080450469013966},
author = {T.J. Sejnowski},
keywords = {Brain theory, Computational models, Mathematical analysis},
abstract = {Computational neuroscience is a relatively recent approach to understanding how nervous systems develop and interact with a changing and uncertain world. Computational models can be used to interpret experimental data in new ways, to confirm and extend existing hypotheses, and to generate new hypotheses for the function of neural systems. These hypotheses provide links between levels of description, from the molecular level to the systems level. Hypotheses that are tested and validated provide a conceptual framework that can lead to more abstract theories. The ultimate aim of theoretical and computational neuroscience is to provide linking principles from neural mechanisms to behavior.}
}
@article{YANG20111230,
title = {Computational optimization, modelling and simulation: Recent advances and overview},
journal = {Procedia Computer Science},
volume = {4},
pages = {1230-1233},
year = {2011},
note = {Proceedings of the International Conference on Computational Science, ICCS 2011},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.04.132},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911001906},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, derivative-free method, optimization algorithm, modelling, nonlinear optimization, surragate-based optimization, simulation},
abstract = {Computational optimization is becoming increasingly important in engineering design and industrial applications. Products and services are often concerned with the maximization of profits and reduction of cost, but also aim at being more energy-efficient, environment-friendly and safety-ensured; at the same time they are limited by resources, time and money. This second workshop on Computational Optimization, Modelling and Simulation (COMS 2011) at ICCS 2011 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry.}
}
@incollection{CHOE2005187,
title = {Thinking about Visual Behavior; Learning about Photoreceptor Function},
series = {Current Topics in Developmental Biology},
publisher = {Academic Press},
volume = {69},
pages = {187-213},
year = {2005},
booktitle = {Neural Development},
issn = {0070-2153},
doi = {https://doi.org/10.1016/S0070-2153(05)69007-2},
url = {https://www.sciencedirect.com/science/article/pii/S0070215305690072},
author = {Kwang‐Min Choe and Thomas R. Clandinin},
abstract = {Visual behavioral assays in Drosophila melanogaster were initially developed to explore the genetic control of behavior, but have a rich history of providing conceptual openings into diverse questions in cell and developmental biology. Here, we briefly summarize the early efforts to employ three of these behaviors: phototaxis, the UV‐visible light choice, and the optomotor response. We then discuss how each of these assays has expanded our understanding of neuronal connection specificity and synaptic function. All of these studies have contributed to the development of sophisticated tools for manipulating gene expression, assessing cell fate specification, and visualizing neuronal development. With these tools in hand, the field is now poised to return to the original goal of understanding visual behavior using genetic approaches.}
}
@article{TROGER201953,
title = {Exploitation vs. exploration—computational temporal and semantic analysis explains semantic verbal fluency impairment in Alzheimer's disease},
journal = {Neuropsychologia},
volume = {131},
pages = {53-61},
year = {2019},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2019.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0028393218305116},
author = {Johannes Tröger and Nicklas Linz and Alexandra König and Philippe Robert and Jan Alexandersson and Jessica Peter and Jutta Kray},
keywords = {Alzheimer's disease, MCI (mild cognitive impairment), Semantic speech analysis, Temporal analysis},
abstract = {Impaired Semantic Verbal Fluency (SVF) in dementia due to Alzheimer's Disease (AD) and its precursor Mild Cognitive Impairment (MCI) is well known. Yet, it remains open whether this impairment mirrors the breakdown of semantic memory retrieval processes or executive control processes. Therefore, qualitative analysis of the SVF has been proposed but is limited in terms of methodology and feasibility in clinical practice. Consequently, research draws no conclusive picture which of these afore-mentioned processes drives the SVF impairment in AD and MCI. This study uses a qualitative computational approach—combining temporal and semantic information—to investigate exploitation and exploration patterns as indicators for semantic memory retrieval and executive control processes. Audio SVF recordings of 20 controls (C, 66–81 years), 55 MCI (57–94 years) and 20 AD subjects (66–82 years) were assessed while groups were matched according to age and education. All groups produced, on average, the same amount of semantically related items in rapid succession within word clusters. Conversely, towards AD, there was a clear decline in semantic as well as temporal exploration patterns between clusters. Results strongly point towards preserved exploitation—semantic memory retrieval processes—and hampered exploration—executive control processes—in AD and potentially in MCI.}
}
@article{LISOWSKI2014634,
title = {Computational Intelligence Methods of a Safe Ship Control},
journal = {Procedia Computer Science},
volume = {35},
pages = {634-643},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.08.145},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914011107},
author = {Józef Lisowski},
keywords = {Game Control, Optimal Control, Neural Networks, Safety of Navigation, Computer-Aided Decision, Computer Simulation},
abstract = {The paper describes the application of selected methods of optimal control theory, game theory and artificial neural networks with the aim of computer support for a safe ship control in collision situations. It shows the structure of the control system and defines the task of safe control. Also presented are methodologies and models for collision avoidance strategies. Using Matlab software, positional game, risk game and dynamic optimal trajectory algorithms have been developed to provide computer support of navigator for collision avoidance at sea. A computer simulations showing safe trajectory through eighteen met ships at sea illustrates this.}
}
@article{FILOMENA201914,
title = {A computational approach to ‘The Image of the City’},
journal = {Cities},
volume = {89},
pages = {14-25},
year = {2019},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2019.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118309776},
author = {Gabriele Filomena and Judith A. Verstegen and Ed Manley},
keywords = {Image of the City, Cognitive maps, Kevin Lynch, Street network, GIScience},
abstract = {In The Image of the City Lynch describes how individuals perceive and recall features in urban spaces. The most distinctive elements in the urban landscape - categorised in paths, nodes, edges, districts and landmarks - give shape to individuals' mental representation of the city. Lynch’s approach has stimulated research into spatial cognition, urban design and artificial intelligence, and it still represents an essential pillar in the analysis of urban dynamics. Nevertheless, an explicit link between The Image of the City and GIScience has not been completely explored yet. In this paper, a computational approach to The Image of the City is proposed. Different perspectives in spatial cognition and GIS research are integrated to obtain a complete Image of the City, in which the most salient elements are shared by a large part of citizens. Nodes, paths and districts were identified through network science techniques. Methods drawn from the information approach to The Image of the City are used to detect landmarks, integrating the complexity of points of reference in their visual, structural and semantic components, as conceptualised by Lynch and successive research. The methods were applied to the central area of Boston and built using freely available spatial datasets. Results were compared to Lynch’s maps to evaluate the methodology: besides a considerable discrepancy with regard to landmarks, a good correspondence for paths, nodes, edges and districts was found.}
}
@incollection{READMONTAGUE2018273,
title = {Chapter 11 - Computational Phenotypes Revealed by Interactive Economic Games},
editor = {Alan Anticevic and John D. Murray},
booktitle = {Computational Psychiatry},
publisher = {Academic Press},
pages = {273-292},
year = {2018},
isbn = {978-0-12-809825-7},
doi = {https://doi.org/10.1016/B978-0-12-809825-7.00011-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128098257000110},
author = {P. {Read Montague}},
keywords = {Approach and avoidance, Computational phenotyping, Computational psychiatry, Decision-making models, Economic games, Psychopathology, Reinforcement learning, Trust game},
abstract = {Reinforcement learning models provide an excellent example of how a computational process approach can help organize ideas and understanding of underlying neurobiology. In a strong sense, this is the assumption behind computational neuroscience. Computational psychiatry, as a translational arm of computational neuroscience, can also profit from the computational process approach but applied at many levels ranging from low-level neurobiology through characterization of mental states and even up to the level of multiple interacting humans. Here, we review some of the early evidence for why reinforcement learning in its modern versions moves well beyond behaviorist accounts and provides an excellent “computational paradigm” for framing value-dependent decision-making; something that goes awry in a number of psychiatry conditions. We focus in particular on how social exchange between humans can engage reward systems and can be used as a computational device good for parsing subjects into categories that relate in interesting ways to traditional depictions of psychopathology.}
}
@article{TOZZI2018133,
title = {Syntax meets semantics during brain logical computations},
journal = {Progress in Biophysics and Molecular Biology},
volume = {140},
pages = {133-141},
year = {2018},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2018.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717303140},
author = {Arturo Tozzi and James F. Peters and Andrew A. Fingelkurts and Alexander A. Fingelkurts and Leonid Perlovsky},
keywords = {Borsuk-ulam, Brouwer, Computation, Meaning, Truth, Syntactic},
abstract = {The discrepancy between syntax and semantics is a painstaking issue that hinders a better comprehension of the underlying neuronal processes in the human brain. In order to tackle the issue, we at first describe a striking correlation between Wittgenstein's Tractatus, that assesses the syntactic relationships between language and world, and Perlovsky's joint language-cognitive computational model, that assesses the semantic relationships between emotions and “knowledge instinct”. Once established a correlation between a purely logical approach to the language and computable psychological activities, we aim to find the neural correlates of syntax and semantics in the human brain. Starting from topological arguments, we suggest that the semantic properties of a proposition are processed in higher brain's functional dimensions than the syntactic ones. In a fully reversible process, the syntactic elements embedded in Broca's area project into multiple scattered semantic cortical zones. The presence of higher functional dimensions gives rise to the increase in informational content that takes place in semantic expressions. Therefore, diverse features of human language and cognitive world can be assessed in terms of both the logic armor described by the Tractatus, and the neurocomputational techniques at hand. One of our motivations is to build a neuro-computational framework able to provide a feasible explanation for brain's semantic processing, in preparation for novel computers with nodes built into higher dimensions.}
}
@article{KUGEL1986137,
title = {Thinking may be more than computing},
journal = {Cognition},
volume = {22},
number = {2},
pages = {137-198},
year = {1986},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(86)90057-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027786900570},
author = {Peter Kugel},
abstract = {The uncomputable parts of thinking (if there are any) can be studied in much the same spirit that Turing (1950) suggested for the study of its computable parts. We can develop precise accounts of cognitive processes that, although they involve more than computing, can still be modelled on the machines we call ‘computers’. In this paper, I want to suggest some ways that this might be done, using ideas from the mathematical theory of uncomputability (or Recursion Theory). And I want to suggest some uses to which the resulting models might be put. (The reader more interested in the models and their uses than the mathematics and its theorems, might want to skim or skip the mathematical parts.)
Résumé
Les éléments du raisonnement ne relevant pas du calculable (uncomputable), (s'il en existe), peuvent s'etudier dans I'optique suggérée par Turing (1950) pour l'étude des éléments calculables (computable). On peut rendre compte avec précision des processus cognitifs qui, bien qu'impliquant plus que des calculs, peuvent cependant être modélisés sur ordinateurs. Dans cet article l'auteur propose des modalités pour arriver à ces résultats en utilisant les idées de la théorie mathdmatique de la Récursion (uncomputability). L'auteur suggère aussi des utilisations pour les modéles que en découlent (Il est possible au lecteur plus intéressé par les modèles et leurs utilisations que par les mathématiques et les théorèmes de passer rapidement sur la partie mathématique ou d'omettre de la lire.)}
}
@incollection{BLACK2021105,
title = {10 - Mutual benefit from library collaboration with computational biologists: the cropPAL project at the University of Western Australia},
editor = {Jeremy Atkinson},
booktitle = {Technology, Change and the Academic Library},
publisher = {Chandos Publishing},
pages = {105-114},
year = {2021},
series = {Chandos Information Professional Series},
isbn = {978-0-12-822807-4},
doi = {https://doi.org/10.1016/B978-0-12-822807-4.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128228074000105},
author = {Kylie Black},
keywords = {cropPAL, partnerships, collaboration, commercialisation, market research, DeweyFish, ON Prime},
abstract = {In 2016–17, the University of Western Australia (UWA) Library partnered with researchers in the Australian Research Council’s Centre of Excellence in Plant Energy Biology to produce cropPAL2, a database providing the subcellular locations for proteins in crops significant for food production. The project team consisted of computational biologists, software engineers and a librarian, in which the Library contributed expertise in developing search strategies, research data management and enhancing discoverability of cropPAL2 and its dataset. The Library continues to be a key player in this collaboration, a first for UWA, both in the innovative process and as a key driver in directing the development of commercial software for the wider benefit of researchers at UWA and beyond.}
}
@article{MOLINSRUANO2018428,
title = {Phogo: A low cost, free and “maker” revisit to Logo},
journal = {Computers in Human Behavior},
volume = {80},
pages = {428-440},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217305551},
author = {Pablo Molins-Ruano and Carlos Gonzalez-Sacristan and Carlos Garcia-Saura},
keywords = {Computational thinking, Technology education, Educational robots, LOGO, Pre-university education},
abstract = {Today it is almost impossible to spend a single day without depending on an information system, a computer or any other form of computation. Though the starting barrier is low, fundamental concepts are still required in order to manage the technicalities of the engineering environment and everyday computational systems. In 1967, Logo proposed to teach abstract programming concepts by providing a set of functions that had intuitive, visible effects over a robotic Turtle. LOGO was a success, but the robots quickly migrated into computer simulations. From LOGO, many followed. Scratch and Lego Mindstorm are some of the most notorious examples. Both introduced graphical block-based programming interfaces. We propose to bring back the powerful ideas behind LOGO by updating it with state of the art technologies. Phogo combines Python, Arduino and 3D printing into a low cost robot that is easy to build and control. The robot has a pen to draw shapes and can be commanded from a computer via a wireless link that is transparent to the students. The use of a physical robot can make programming more accessible for students with disabilities. The open and maker philosophies behind Phogo makes it more interesting as students will be able to access and study the electronic components. The textual programing language can be a long life companion for the students. In this work we discuss LOGO and other projects inspired by it, and we also share the methodology and design decisions behind Phogo, the results of its application in a workshop and the improvements we are currently developing.}
}
@article{CHEN2016222,
title = {Constraint local principal curve: Concept, algorithms and applications},
journal = {Journal of Computational and Applied Mathematics},
volume = {298},
pages = {222-235},
year = {2016},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2015.11.041},
url = {https://www.sciencedirect.com/science/article/pii/S0377042715005956},
author = {Dewang Chen and Jiateng Yin and Shiying Yang and Lingxi Li and Peter Pudney},
keywords = {Constraint local principal curve (CLPC), GPS, Local optimization, Adaptive radius, Principal of nearest neighbor},
abstract = {Existing principal curve algorithms have some drawbacks such as time consuming and narrow application scope in practice, since these algorithms are mainly based on global optimization. In this paper, we present the concept of Constraint Local Principal Curve (CLPC), which uses local optimization methods and restricts the principal curve with two fixed endpoints to reduce the computational complexity. In addition, we propose three CLPC algorithms by Local Optimization and Adaptive Radius to expand the range of applications and increase the solution quality. The first algorithm, i.e., CLPCg is based on greedy thinking. The second algorithm, i.e., CLPCs uses one dimensional search and the last algorithm CLPCc combines the greedy thinking and one dimensional search. Then, we define six performance indices to evaluate the performance of the CLPC algorithms. Finally, we present some numerical experiments with three simulation data sets and two GPS measured data sets in both highway and railway. The results indicate that all of the three CLPC algorithms can obtain high-accuracy data from multiple low-accuracy data efficiently. The CLPC algorithms can improve the accuracy and computational speed compared with the existing K-segment principal curve (KPC) algorithm. In addition, CLPCc outperforms CLPCg and CLPCs according to the comprehensive experiments while CLPCg runs much faster than other ones.}
}
@article{MAIA2017382,
title = {Theory-Based Computational Psychiatry},
journal = {Biological Psychiatry},
volume = {82},
number = {6},
pages = {382-384},
year = {2017},
note = {Computational Psychiatry},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2017.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0006322317318164},
author = {Tiago V. Maia and Quentin J.M. Huys and Michael J. Frank}
}
@article{STOLPE2024100159,
title = {Artificial intelligence literacy for technology education},
journal = {Computers and Education Open},
volume = {6},
pages = {100159},
year = {2024},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2024.100159},
url = {https://www.sciencedirect.com/science/article/pii/S2666557324000016},
author = {Karin Stolpe and Jonas Hallström},
keywords = {AI literacy, Ethical issues, AI in education},
abstract = {The interest in artificial intelligence (AI) in education has erupted during the last few years, primarily due to technological advances in AI. It is therefore argued that students should learn about AI, although it is debated exactly how it should be applied in education. AI literacy has been suggested as a way of defining competencies for students to acquire to meet a future everyday- and working life with AI. This study argues that researchers and educators need a framework for integrating AI literacy into technological literacy, where the latter is viewed as a multiliteracy. This study thus aims to critically analyse and discuss different components of AI literacy found in the literature in relation to technological literacy. The data consists of five AI literacy frameworks related to three traditions of technological knowledge: technical skills, technological scientific knowledge, and socio-ethical technical understanding. The results show that AI literacy for technology education emphasises technological scientific knowledge (e.g., knowledge about what AI is, how to recognise AI, and systems thinking) and socio-ethical technical understanding (e.g., AI ethics and the role of humans in AI). Technical skills such as programming competencies also appear but are less emphasised. Implications for technology education are also discussed, and a framework for AI literacy for technology education is suggested.}
}
@article{JARMAN2022225,
title = {Critical measurement issues in the assessment of social media influence on body image},
journal = {Body Image},
volume = {40},
pages = {225-236},
year = {2022},
issn = {1740-1445},
doi = {https://doi.org/10.1016/j.bodyim.2021.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S1740144521001583},
author = {Hannah K. Jarman and Siân A. McLean and Scott Griffiths and Samantha J. Teague and Rachel F. Rodgers and Susan J. Paxton and Emma Austen and Emily Harris and Trevor Steward and Adrian Shatte and Long {Khanh-Dao Le} and Tarique Anwar and Cathrine Mihalopoulos and Alexandra G. Parker and Zali Yager and Matthew Fuller-Tyszkiewicz},
keywords = {Social media, Body image, Qualitative, Survey, Experimental, Momentary assessment, Web scraping, Computational modelling, Measurement, Assessment},
abstract = {Progress towards understanding how social media impacts body image hinges on the use of appropriate measurement tools and methodologies. This review provides an overview of common (qualitative, self-report survey, lab-based experiments) and emerging (momentary assessment, computational) methodological approaches to the exploration of the impact of social media on body image. The potential of these methodologies is detailed, with examples illustrating current use as well as opportunities for expansion. A key theme from our review is that each methodology has provided insights for the body image research field, yet is insufficient in isolation to fully capture the nuance and complexity of social media experiences. Thus, in consideration of gaps in methodology, we emphasise the need for big picture thinking that leverages and combines the strengths of each of these methodologies to yield a more comprehensive, nuanced, and robust picture of the positive and negative impacts of social media.}
}
@article{FIGUEIRASAMPAIO2009484,
title = {A constructivist computational tool to assist in learning primary school mathematical equations},
journal = {Computers & Education},
volume = {53},
number = {2},
pages = {484-492},
year = {2009},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2009.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S036013150900075X},
author = {Aleandra da Silva Figueira-Sampaio and Eliane Elias Ferreira {dos Santos} and Gilberto Arantes Carrijo},
keywords = {Elementary education, Improving classroom teaching, Interactive learning environments, Virtual reality},
abstract = {In constructivist principles, learning is a process in which individuals construct knowledge. Research in Mathematics Education looks for ways to make mathematics education less dry and more attractive. When solving polynomial equations of the first degree, it is very common for teachers to work with the mistaken idea of “changing the sign” when “moving” the member. To minimize this problem, a balance can be used to illustrate the idea of equilibrium and also properties of equality. The objectives of this study were (1) develop a computational tool to replace a conventional balance in practical mathematics exercises thereby solving two material challenges for Brazilian teachers: verifying the accuracy of balances and the lack of student physical and social activity through direct participation; (2) determine how substituting the conventional balance with a computational tool for the solution of first degree polynomial equations affected the aspects inherent in the learning process like motivation, cooperation, dialogue, discussion, reflection, reciprocity, negotiation and responsibility. The results indicate that the cognitive computational tool met the challenges of Brazilian teachers. First, because it lacks mechanisms that need to be verified for accuracy in order to demonstrate equilibrium. Second, because it allows the direct participation of students (physical experience) and the use of the tool in small groups (social experience). The hands on completion of the activity, realistic appearance, the interaction with the tool, visual feedback on the panel, and two students using the same tool awakened motivation, responsibility for completing the activity, dialogue, cooperation, discussion and reflection. Doing the experiment with others aroused concern about the learning of others and reciprocity of knowledge for the improvement of the procedure to be constructed for solving 1st degree equations.}
}
@article{DENHAAN2011175,
title = {Computational suite of models with heterogeneous agents II: Multi-country real business cycle models},
journal = {Journal of Economic Dynamics and Control},
volume = {35},
number = {2},
pages = {175-177},
year = {2011},
note = {Computational Suite of Models with Heterogeneous Agents II: Multi-Country Real Business Cycle Models},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2010.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0165188910002149},
author = {Wouter J. {Den Haan} and Kenneth L. Judd and Michel Juillard},
keywords = {Numerical solutions, Simulations, Approximations},
abstract = {This paper describes the second model considered in the computational suite project that compares the performance of different numerical algorithms. It is a multi-country model in which countries face different productivity shocks. Solving such models is a challenging numerical problem unless the number of countries is small. The solutions are functions of a large set of arguments and the functional forms are unknown. Moreover, the solution procedures have to deal with high-dimensional integration problems.}
}
@article{BRODLAND201562,
title = {How computational models can help unlock biological systems},
journal = {Seminars in Cell & Developmental Biology},
volume = {47-48},
pages = {62-73},
year = {2015},
note = {Coding and non-coding RNAs & Mammalian development},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2015.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1084952115001287},
author = {G. Wayne Brodland},
keywords = {Review, Models, Computational modelling, Cell mechanics, Tissue mechanics, Embryo mechanics, Embryogenesis, Morphogenetic movements, Developmental mechanisms, Biological systems},
abstract = {With computation models playing an ever increasing role in the advancement of science, it is important that researchers understand what it means to model something; recognize the implications of the conceptual, mathematical and algorithmic steps of model construction; and comprehend what models can and cannot do. Here, we use examples to show that models can serve a wide variety of roles, including hypothesis testing, generating new insights, deepening understanding, suggesting and interpreting experiments, tracing chains of causation, doing sensitivity analyses, integrating knowledge, and inspiring new approaches. We show that models can bring together information of different kinds and do so across a range of length scales, as they do in multi-scale, multi-faceted embryogenesis models, some of which connect gene expression, the cytoskeleton, cell properties, tissue mechanics, morphogenetic movements and phenotypes. Models cannot replace experiments nor can they prove that particular mechanisms are at work in a given situation. But they can demonstrate whether or not a proposed mechanism is sufficient to produce an observed phenomenon. Although the examples in this article are taken primarily from the field of embryo mechanics, most of the arguments and discussion are applicable to any form of computational modelling.}
}
@article{LEE2012579,
title = {Developing an efficient computational method that estimates the ability of students in a Web-based learning environment},
journal = {Computers & Education},
volume = {58},
number = {1},
pages = {579-589},
year = {2012},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511002259},
author = {Young-Jin Lee},
keywords = {Ability estimation, Educational data mining, Item response theory, Log file analysis, Web-based learning environment},
abstract = {This paper presents a computational method that can efficiently estimate the ability of students from the log files of a Web-based learning environment capturing their problem solving processes. The computational method developed in this study approximates the posterior distribution of the student’s ability obtained from the conventional Bayes Modal Estimation (BME) approach to a simple Gaussian function in order to reduce the amount of computations required in the subsequent ability update processes. To verify the correctness and usefulness of this method, the abilities of 407 college students who solved 61 physics problems in a Web-based learning environment were estimated from the log files of the learning environment. The reduced chi-squared statistic and Pearson’s chi-square test for the goodness of fit indicate that the estimated abilities were able to successfully explain the observed problem solving performance of students within error. The educational implications of estimating the ability of students in Web-based learning environments were also discussed.}
}
@article{KLIMOVA20171,
title = {Where Youth strives in Computational Science: retrospective Analysis of Young Scientist Conference in HPC and Simulation},
journal = {Procedia Computer Science},
volume = {119},
pages = {1-7},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.153},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323633},
author = {Alexandra Klimova and Anna Bilyatdinova and Jari Kortelainen and Peter M.A. Sloot and Alexander Boukhanovsky},
keywords = {computational science, high-performance computing, leading scientists program, international conference},
abstract = {This volume presents the selected papers of young computational scientists – participants of YSC-2017. Annual Young Scientist Conferences (YSC) in high performance computing, modeling and simulation are traditionally held since 2012 by the University of Amsterdam (the Netherlands) and ITMO University (St. Petersburg, Russia) as the open international events which aim to develop a dialogue about the present and future of computational science with a focus on applications of modeling and simulation solving a wide range of problems of science, industry, and business. The conference has already been organized for six times, which gives us an opportunity for retrospective analysis of conference’ results and trends in high performance computing (HPC). The results are presented in this editorial.}
}
@article{SWANSON2020100961,
title = {The relationship between executive processing and computational growth among monolingual and english learners with and without math difficulties: Does it help to be bilingual?},
journal = {Cognitive Development},
volume = {56},
pages = {100961},
year = {2020},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2020.100961},
url = {https://www.sciencedirect.com/science/article/pii/S0885201420301155},
author = {H. Lee Swanson},
keywords = {Math difficulties, English learner, Bilingual, Working memory, Cognition, Math computation},
abstract = {Does the commonly reported math achievement gap among elementary school monolingual and English learners (ELs) with and without math difficulties reflect variations in executive processing? This cohort-sequential study (N = 841) explored the cognitive processes that underlie in elementary school children’s math computational growth who are monolingual (English-only) or English learners with Spanish as a first language. Three language subgroups (proficient ELs [relatively proficient in both English and Spanish vocabulary], less proficient ELs [more proficient in English when compared to Spanish vocabulary] and monolingual [English-only]) children with and without math difficulties (MD) were compared on measures of math computation and cognitive growth. As expected, children with MD identified at wave 1 underperformed children without MD in their rate of growth and their level of computational and working memory (WM) performance in the final testing wave. However, two additional findings occurred. First, executive processing measures (working memory and inhibition) were significantly related to computational growth even when measures of reading, fluid intelligence, STM, naming speed and SES were partialed in the analysis. Second, no statistical advantages in executive processing or computation emerged in favor of EL children relative to monolingual children. Taken together, the results support the notion that (a) growth in math computation is tied to growth in the executive system and (b) EL children relatively proficient in English and Spanish experience no growth advantages in WM or computation compared to monolingual children.}
}
@article{GONDOCS2024102769,
title = {AI in medical diagnosis: AI prediction & human judgment},
journal = {Artificial Intelligence in Medicine},
volume = {149},
pages = {102769},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102769},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000113},
author = {Dóra Göndöcs and Viktor Dörfler},
keywords = {Medical diagnosis, Melanoma, Human-computer interaction, Augmented intelligence, Explainability, Responsible AI},
abstract = {AI has long been regarded as a panacea for decision-making and many other aspects of knowledge work; as something that will help humans get rid of their shortcomings. We believe that AI can be a useful asset to support decision-makers, but not that it should replace decision-makers. Decision-making uses algorithmic analysis, but it is not solely algorithmic analysis; it also involves other factors, many of which are very human, such as creativity, intuition, emotions, feelings, and value judgments. We have conducted semi-structured open-ended research interviews with 17 dermatologists to understand what they expect from an AI application to deliver to medical diagnosis. We have found four aggregate dimensions along which the thinking of dermatologists can be described: the ways in which our participants chose to interact with AI, responsibility, ‘explainability’, and the new way of thinking (mindset) needed for working with AI. We believe that our findings will help physicians who might consider using AI in their diagnosis to understand how to use AI beneficially. It will also be useful for AI vendors in improving their understanding of how medics want to use AI in diagnosis. Further research will be needed to examine if our findings have relevance in the wider medical field and beyond.}
}
@article{LEE2023121253,
title = {Artificial intelligence enabled energy-efficient heating, ventilation and air conditioning system: Design, analysis and necessary hardware upgrades},
journal = {Applied Thermal Engineering},
volume = {235},
pages = {121253},
year = {2023},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2023.121253},
url = {https://www.sciencedirect.com/science/article/pii/S1359431123012826},
author = {Dasheng Lee and Shang-Tse Lee},
keywords = {Artificial intelligence (AI), Heating, ventilation and air conditioning (HVAC), Energy saving, Design thinking, Hardware upgrade},
abstract = {Literature search across different databases showed that the application of artificial intelligence (AI) in heating, ventilation and air conditioning (HVAC) equipment has been extensively studied. On the commercial front, Internet search suggested that numerous AI-equipped HVAC products have been launched. These products apply AI in very different ways, and their energy-saving effects are also different. Such divergence and uncertain energy-saving effects may hinder AI application. To overcome this difference and accelerate the development of AI applications, the present study proposed a double diamond preferred reporting items for systematic reviews and meta-analysis (PRISMA) method—an analysis method that combined literature review with design thinking. Through a process of divergence-convergence-re-divergence, this study described how to design AI functions for energy-efficient HVAC systems, taking into account more than 1,700 research papers it had reviewed. However, there was a limitation on the part re-divergence. Because the vast majority of research papers only published results of successful AI applications, no cases of failed applications were available for review, making it impossible to re-think profoundly. Instead, this study collected raw data from 88 research papers and used these data to analyze the effectiveness and ineffectiveness of AI in depth. It was concluded that AI application must be accompanied by necessary hardware improvements to achieve effective energy savings. AI-enabled energy-saving effects for chillers, air-handing units, heating systems, and air conditioners, as well as corresponding hardware upgrades, were discussed.}
}
@article{TOIVONEN202052,
title = {Computational creativity beyond machine learning},
journal = {Physics of Life Reviews},
volume = {34-35},
pages = {52-53},
year = {2020},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300373},
author = {Hannu Toivonen}
}
@article{TURKHEIMER2015211,
title = {The brain's code and its canonical computational motifs. From sensory cortex to the default mode network: A multi-scale model of brain function in health and disease},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {211-222},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001189},
author = {Federico E. Turkheimer and Robert Leech and Paul Expert and Louis-David Lord and Anthony C. Vernon},
keywords = {Brain networks, Functional connectivity, Interneurons, Gamma-oscillations, NMDA, GABA, Lateral inhibition, Feedback inhibition, Feed-forward inhibition, Canonical neural computation, Motifs, Default mode network, fMRI, Schizophrenia},
abstract = {A variety of anatomical and physiological evidence suggests that the brain performs computations using motifs that are repeated across species, brain areas, and modalities. The computational architecture of cortex, for example, is very similar from one area to another and the types, arrangements, and connections of cortical neurons are highly stereotyped. This supports the idea that each cortical area conducts calculations using similarly structured neuronal modules: what we term canonical computational motifs. In addition, the remarkable self-similarity of the brain observables at the micro-, meso- and macro-scale further suggests that these motifs are repeated at increasing spatial and temporal scales supporting brain activity from primary motor and sensory processing to higher-level behaviour and cognition. Here, we briefly review the biological bases of canonical brain circuits and the role of inhibitory interneurons in these computational elements. We then elucidate how canonical computational motifs can be repeated across spatial and temporal scales to build a multiplexing information system able to encode and transmit information of increasing complexity. We point to the similarities between the patterns of activation observed in primary sensory cortices by use of electrophysiology and those observed in large scale networks measured with fMRI. We then employ the canonical model of brain function to unify seemingly disparate evidence on the pathophysiology of schizophrenia in a single explanatory framework. We hypothesise that such a framework may also be extended to cover multiple brain disorders which are grounded in dysfunction of GABA interneurons and/or these computational motifs.}
}
@article{ISMAILOVA2018183,
title = {Basic Constructions of the Computational Model of Support for Access Operations to the Semantic Network},
journal = {Procedia Computer Science},
volume = {123},
pages = {183-188},
year = {2018},
note = {8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.01.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918300310},
author = {Larisa Yu. Ismailova and Viacheslav E. Wolfengagen and Sergey V. Kosikov},
keywords = {informational objects, semantics, computational model, semantic network, intensional logic, access operation},
abstract = {The paper considers the approach to solving the task of storing data in the Web environment using semantic networks (SN). The control over the access to SN is identified as a critical task. An approach to the solution based on the use of the controlling SN is proposed. The rationale for the approach involves developing a computational model for supporting the access operations. The construction of a model based on intensional logic is proposed. The basic logical constructions, necessary for building a model, are considered. The testing of the model’s constructions was performed when building the tools of semantic support for the implementation of the best available technologies (BAT).}
}
@article{VANDENAMEELE2014334,
title = {Thinking out of the dish: what to learn about cortical development using pluripotent stem cells},
journal = {Trends in Neurosciences},
volume = {37},
number = {6},
pages = {334-342},
year = {2014},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2014.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0166223614000447},
author = {Jelle {van den Ameele} and Luca Tiberi and Pierre Vanderhaeghen and Ira Espuny-Camacho},
abstract = {The development of the cerebral cortex requires the tightly coordinated generation of dozens of neuronal subtypes that will populate specific layers and areas. Recent studies have revealed how pluripotent stem cells (PSC), whether of mouse or human origin, can differentiate into a wide range of cortical neurons in vitro, which can integrate appropriately into the brain following in vivo transplantation. These models are largely artificial but recapitulate a substantial fraction of the complex temporal and regional patterning events that occur during in vivo corticogenesis. Here, we review these findings with emphasis on the new perspectives that they have brought for understanding of cortical development, evolution, and diseases.}
}
@incollection{MAERTENS2025358,
title = {Regrettable Substitutions},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {358-364},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00099-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157424000995},
author = {Alexandra Maertens and Thomas Hartung},
keywords = {Alternative assessments, Chemical policy, Environmental justice, Exposure science, Green toxicology, Hazard, Life cycle analysis, Toxicity mechanisms},
abstract = {Regrettable substitutions refer to the unintended consequences that arise when replacing one substance with another, often resulting in new problems or uncertainties. Regrettable substitutions have been observed in various functional classes, such as flame retardants, where initial solutions aimed at enhancing fire safety but have raised concerns about persistent environmental pollution and potential health risks. Regrettable substitutions are often caused by a lack of data about hazard or exposure, life-cycle considerations or a failure to consider other functionality more broadly. Initial solutions aimed at enhancing fire safety, product performance or crop protection have ended up raising new concerns about persistent environmental pollution, ecosystem effects, occupational hazards and long-term health risks. To avoid future regrettable substitutions, a more holistic, data-driven approach to chemical alternatives assessment is needed. This should incorporate human-relevant mechanistic toxicity testing, quantitative exposure modeling, life cycle thinking, and consideration of safer chemistry solutions that maintain product functionality. Enhanced cross-sector collaboration, data sharing, and clear risk communication to consumers is also critical. Integrating these green toxicology principles into chemical design and evaluation can help achieve sustainable substitutions that maximize benefits and minimize risks.}
}
@article{MIRIANNA2025112353,
title = {Opportunities and challenges for people-centered multi-hazard early warning systems: Perspectives from the Global South},
journal = {iScience},
volume = {28},
number = {5},
pages = {112353},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.112353},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225006145},
author = {Budimir Mirianna and Šakić Trogrlić Robert and Almeida Cinthia and Arestegui Miguel and Chuquisengo Vásquez Orlando and Cisneros Abel and Cuba Iriarte Monica and Dia Adama and Lizon Leon and Madueño Giorgio and Ndiaye Alioune and Ordoñez Caldas Miluska and Rahman Tamanna and RanaTharu Bikram and Sall Alpha and Uprety Dharam and Anderson Chris and McQuistan Colin},
keywords = {Earth sciences, Human geography, Social sciences},
abstract = {Summary
This perspective critically examines the challenges and opportunities of implementing people-centered multi-hazard early warning systems (MHEWS) in the Global South. Despite global initiatives, such as the Early Warnings for All initiative, operational realities lag behind. By exploring the needs of the most vulnerable and how core concepts of multi-hazard thinking (e.g., hazard interrelationships and vulnerability dynamics) integrate into different pillars and cross-cutting components of an MHEWS, the perspective highlights a mismatch between current ambitions and realities on the ground. Drawing on extensive experience from Practical Action, we identify opportunities to move toward MHEWS through outlining potential entry points in research, policy, and practice. We emphasize a need for localized, inclusive strategies that genuinely address the needs of the most vulnerable populations and fully encompass the meaning of multi-hazards, including hazard interrelationships, the dynamics of risk components, and the complexity of multi-hazard impacts.}
}
@article{CUI2022104203,
title = {Pore-network modeling of flow in shale nanopores: Network structure, flow principles, and computational algorithms},
journal = {Earth-Science Reviews},
volume = {234},
pages = {104203},
year = {2022},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2022.104203},
url = {https://www.sciencedirect.com/science/article/pii/S0012825222002872},
author = {Ronghao Cui and S. Majid Hassanizadeh and Shuyu Sun},
keywords = {Pore-network modeling, Shale rock, Nanoporous media, Flow theory, Thermodynamics},
abstract = {Hydrocarbons in subsurface nanoporous media, such as shale, are promising energy resources to compensate for the shortage of conventional reservoirs. Pore-network modeling serves as a valuable tool for simulating microscale fluid transport and elucidating flow physics in porous media. However, traditional pore-network models have failed to capture features of spatial structure and fluid flow in unconventional shale rock. This work presents a critical review of pore-network modeling of single-phase and two-phase flow in shale rock. Pore-network modeling advances of shale are reviewed based on three major parts: network morphology and geometries, flow principles in nanocapillaries, and pore-network computational algorithms. First, based on key geological features of shale rock, we analyze network topology, multiscale network, pore geometries, and network representativeness of shale pore-network models. Then, we discuss four important aspects that may influence flow principles of fluids in nanocapillaries: gas and liquid slippage, sorption and diffusion behavior, hydrocarbon thermodynamics, and the presence of water. Finally, we present pore-network modeling methods used for flow simulations in shale rock, including quasi-static and dynamic algorithms. We hope that this review could shed light on fundamentals of pore-network modeling of shale rock.}
}
@article{ATANCE2010297,
title = {Thinking about false belief: It’s not just what children say, but how long it takes them to say it},
journal = {Cognition},
volume = {116},
number = {2},
pages = {297-301},
year = {2010},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2010.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0010027710001101},
author = {Cristina M. Atance and Daniel M. Bernstein and Andrew N. Meltzoff},
keywords = {Theory of mind, False-belief reasoning, Conceptual development, Response latencies},
abstract = {We examined 240 children’s (3.5-, 4.5-, and 5.5-year-olds) latency to respond to questions on a battery of false-belief tasks. Response latencies exhibited a significant cross-over interaction as a function of age and response type (correct vs. incorrect). 3.5-year-olds’ incorrect latencies were faster than their correct latencies, whereas the opposite pattern emerged for 4.5- and 5.5-year-olds. Although these results are most consistent with conceptual change theories of false-belief reasoning, no extant theory fully accounts for our data pattern. We argue that response latency data provide new information about underlying cognitive processes in theory of mind reasoning, and can shed light on concept acquisition more broadly.}
}
@article{BRASCH2012299,
title = {Thinking outside the cell: how cadherins drive adhesion},
journal = {Trends in Cell Biology},
volume = {22},
number = {6},
pages = {299-310},
year = {2012},
issn = {0962-8924},
doi = {https://doi.org/10.1016/j.tcb.2012.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0962892412000529},
author = {Julia Brasch and Oliver J. Harrison and Barry Honig and Lawrence Shapiro},
abstract = {Cadherins are a superfamily of cell surface glycoproteins whose ectodomains contain multiple repeats of β-sandwich extracellular cadherin (EC) domains that adopt a similar fold to immunoglobulin domains. The best characterized cadherins are the vertebrate ‘classical’ cadherins, which mediate adhesion via trans homodimerization between their membrane-distal EC1 domains that extend from apposed cells, and assemble intercellular adherens junctions through cis clustering. To form mature trans adhesive dimers, cadherin domains from apposed cells dimerize in a ‘strand-swapped’ conformation. This occurs in a two-step binding process involving a fast-binding intermediate called the ‘X-dimer’. Trans dimers are less flexible than cadherin monomers, a factor that drives junction assembly following cell–cell contact by reducing the entropic cost associated with the formation of lateral cis oligomers. Cadherins outside the classical subfamily appear to have evolved distinct adhesive mechanisms that are only now beginning to be understood.}
}
@article{ROSSITER202473,
title = {A MATLAB virtual laboratory to support learning of auto-tuning PID approaches},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {7},
pages = {73-78},
year = {2024},
note = {4th IFAC Conference on Advances in Proportional-Integral-Derivate Control PID 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324007250},
author = {J.A. Rossiter and A. Visioli and S. Dormido and R. Bars},
keywords = {Control101 toolbox, PID compensation, virtual laboratories, independent learning},
abstract = {This paper presents a small number of MATLAB APPs and livescript files designed to help students both understand and implement PID tuning. The paper presents the thinking behind the use of MATLAB and the topic itself before then describing the proposed resources in detail. The resources split into files with detailed mathematical and coding background students can use for self-study and assignments, and a virtual laboratory which is more intuitive and interactive and useful for familiarisation with core concepts. The files were recently added to the control101 toolbox (Rossiter, 2023).}
}
@article{DOIRON2019iii,
title = {Editorial overview: Computational neuroscience},
journal = {Current Opinion in Neurobiology},
volume = {58},
pages = {iii-vii},
year = {2019},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959438819300728},
author = {Brent Doiron and Máté Lengyel}
}
@article{HAO20231,
title = {A Commentary on Towards autonomous artificial agents with an active self: Modeling sense of control in situated action},
journal = {Cognitive Systems Research},
volume = {79},
pages = {1-3},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722001085},
author = {Chenxu Hao and Nele Russwinkel and Daniel F.B. Haeufle and Philipp Beckerle},
keywords = {Human–robot interaction, Unified models of HRI, Anticipatory thinking},
abstract = {Kahl et al., (2022) present a computational model of an autonomous agent implemented with an active self. With ideas based on the Free Energy Principle (Friston and Kiebel, 2009), their model tackles the challenge to unify higher-level cognitive activities and lower-level sensorimotor control as the autonomous agent maintains situational awareness while interacting with the environment. While Kahl et al., (2022) focus on modeling a single agent, we argue that this challenge similarly appears in modeling human–robot interaction (HRI). In this commentary, we discuss how the conceptual framework from Kahl et al., (2022) could inspire unified models of physical and cognitive HRI and how the modeling approach from Kahl et al., (2022) can potentially be applied to anticipatory thinking in robotics to support the human in daily life.}
}
@article{DOUKAS2013227,
title = {Modelling of linguistic variables in multicriteria energy policy support},
journal = {European Journal of Operational Research},
volume = {227},
number = {2},
pages = {227-238},
year = {2013},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2012.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0377221712008740},
author = {Haris Doukas},
keywords = {Decision support, Multicriteria analysis, Linguistic variables, Energy policy, Sustainable development},
abstract = {The climate change and the increasing complexity of the energy sector along with the prerequisite for sustainability have broadened the energy policy shaping field by bringing out new challenges. Decision support tools and methods, such as Multicriteria Decision Aid (MCDA), are necessary for energy policy, in the pursuit of appropriate approaches necessary to support the restructuring of the energy sector, concerning patterns of energy extraction, generation, transformation and use, from unsustainable to sustainable forms of development. Papers devoted to the investigation of MCDA models using linguistic variables for energy policy support seem to be not available in the international literature. The scope of this paper is to explore different linguistic representation and computational models in MCDA that are or can be applied to energy policy support and to establish a clear linkage between them. This paper argues that MCDA methodologies with direct computation on linguistic variables can support energy policy frameworks, bridging the gap between energy policy makers thinking, reasoning, representation and computing. Finally, current trends, open questions and prospects in this topic are pointed out.}
}
@article{SHARP2025118,
title = {Anxiety involves altered planning},
journal = {Trends in Cognitive Sciences},
volume = {29},
number = {2},
pages = {118-121},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324002924},
author = {Paul B. Sharp},
keywords = {planning, anxiety, reinforcement learning},
abstract = {Clinicians have suggested but not shown how anxiety involves altered planning. Here, I synthesize and extend computational models of planning in a framework that can be used to explain planning biases in anxiety. To spur its development, I spotlight two of its promising areas: task construal and meta-control.}
}
@article{TREMOLIERE2012379,
title = {Mortality salience and morality: Thinking about death makes people less utilitarian},
journal = {Cognition},
volume = {124},
number = {3},
pages = {379-384},
year = {2012},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2012.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0010027712001035},
author = {Bastien Trémolière and Wim De Neys and Jean-François Bonnefon},
keywords = {Mortality salience, Moral judgment, Utilitarian responses, Cognitive resources},
abstract = {According to the dual-process model of moral judgment, utilitarian responses to moral conflict draw on limited cognitive resources. Terror Management Theory, in parallel, postulates that mortality salience mobilizes these resources to suppress thoughts of death out of focal attention. Consequently, we predicted that individuals under mortality salience would be less likely to give utilitarian responses to moral conflicts. Two experiments corroborated this hypothesis. Experiment 1 showed that utilitarian responses to non-lethal harm conflicts were less frequent when participants were reminded of their mortality. Experiment 2 showed that the detrimental effect of mortality salience on utilitarian conflict judgments was comparable to that of an extreme concurrent cognitive load. These findings raise the question of whether private judgment and public debate about controversial moral issues might be shaped by mortality salience effects, since these issues (e.g., assisted suicide) often involve matters of life and death.}
}
@article{DUGGAN2024101426,
title = {ChatGPT performance on radiation technologist and therapist entry to practice exams},
journal = {Journal of Medical Imaging and Radiation Sciences},
volume = {55},
number = {4},
pages = {101426},
year = {2024},
issn = {1939-8654},
doi = {https://doi.org/10.1016/j.jmir.2024.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S193986542400122X},
author = {Ryan Duggan and Kaitlyn M. Tsuruda},
keywords = {Radiography, Radiotherapy, Nuclear Medicine, Magnetic Resonance Imaging, AI (Artificial Intelligence), Natural Language Processing, Teaching, Educational Measurement},
abstract = {Background
The aim of this study was to describe the proficiency of ChatGPT (GPT-4) on certification style exams from the Canadian Association of Medical Radiation Technologists (CAMRT), and describe its performance across multiple exam attempts.
Methods
ChatGPT was prompted with questions from CAMRT practice exams in the disciplines of radiological technology, magnetic resonance (MRI), nuclear medicine and radiation therapy (87-98 questions each). ChatGPT attempted each exam five times. Exam performance was evaluated using descriptive statistics, stratified by discipline and question type (knowledge, application, critical thinking). Light's Kappa was used to assess agreement in answers across attempts.
Results
Using a passing grade of 65 %, ChatGPT passed the radiological technology exam only once (20 %), MRI all five times (100 %), nuclear medicine three times (60 %), and radiation therapy all five times (100 %). ChatGPT's performance was best on knowledge questions across all disciplines except radiation therapy. It performed worst on critical thinking questions. Agreement in ChatGPT's responses across attempts was substantial within the disciplines of radiological technology, MRI, and nuclear medicine, and almost perfect for radiation therapy.
Conclusion
ChatGPT (GPT-4) was able to pass certification style exams for radiation technologists and therapists, but its performance varied between disciplines. The algorithm demonstrated substantial to almost perfect agreement in the responses it provided across multiple exam attempts. Future research evaluating ChatGPT's performance on standardized tests should consider using repeated measures.
RÉSUMÉ
Contexte
L'objectif de cette étude était de décrire la compétence du ChatGPT (GPT-4) dans les examens d'agrément de l'Association canadienne des technologues en radiation médicale (ACTRM), et de décrire sa performance à travers plusieurs tentatives d'examen.
Méthodes
ChatGPT a été invité à répondre à des questions provenant des examens pratiques de l'ACTRM dans les disciplines de la technologie de radiologie, de la résonance magnétique (IRM), de la médecine nucléaire et de la radiothérapie (87-98 questions pour chaque discipline). ChatGPT a tenté chaque examen cinq fois. La performance à l'examen a été évaluée à l'aide de statistiques descriptives, stratifiées par discipline et par type de question (connaissances, application, réflexion critique). Le Kappa de Light a été utilisé pour évaluer la concordance des réponses entre les tentatives.
Résultats
En utilisant une note de passage de 65 %, ChatGPT a réussi l'examen de technologie de radiologie une seule fois (20 %), l'IRM les cinq fois (100 %), la médecine nucléaire trois fois (60 %), et la radiothérapie les cinq fois (100 %). Les performances de ChatGPT ont été les meilleures pour les questions de connaissances dans toutes les disciplines, à l'exception de la radiothérapie. Il a été le moins performant pour les questions de réflexion critique. La concordance des réponses du ChatGPT entre les tentatives était substantielle dans les disciplines de la technologie de radiologie, de l'IRM et de la médecine nucléaire, et presque parfaite pour la radiothérapie.
Conclusion
ChatGPT (GPT-4) a été capable de réussir les examens d'agrément pour les technologues en radiation médicale et les radiothérapeutes, mais ses performances ont varié selon les disciplines. L'algorithme a démontré une concordance substantielle à presque parfaite dans les réponses qu'il a fournies à travers de multiples tentatives d'examen. Les futures recherches évaluant les performances de ChatGPT sur des tests standardisés devraient envisager l'utilisation de mesures répétées.}
}
@article{BELLO2025100031,
title = {Cloud computing for chatbot in the construction industry: An implementation framework for conversational-BIM voice assistant},
journal = {Digital Engineering},
volume = {5},
pages = {100031},
year = {2025},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000311},
author = {Sururah A. Bello and Lukumon O. Oyedele and Lukman A. Akanbi and Abdul-Lateef Bello},
keywords = {Software project management, Amazon web services, Cloud computing, Building information modelling (BIM), Conversational AI, Construction industry, Framework implementation, Chatbot, construction workers, Design thinking methodology, Focus group, Stakeholders management},
abstract = {This study presents a structural framework for selecting cloud services for the Conversational AI system implementation in the construction industry using Design Thinking Methodology. A focus group discussion approach was used to obtain user requirements from construction workers to implement the Conversational AI for BIM. This resulted in five factors: finance, speed of operation, privacy, estimation, and interface. The user specifications were mapped into technical modules, which were used to select cloud services employed to implement the virtual assistant for the construction industry. The study thus presented the comprehensive requirements for the different categories of construction workers to implement the Conversational-BIM Chatbot (Conversational-BIM) system. Furthermore, the study presented the architecture of Conversational-BIM using Amazon Web Services. The study is useful to researchers and IT developers in implementing chatbots for the construction industry as it presents the relevant considerations for conversational AI applications in the industry.}
}
@article{LEONARDI2018824,
title = {A Method for the computation of entropy in the Recurrence Quantification Analysis of categorical time series},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {512},
pages = {824-836},
year = {2018},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2018.08.058},
url = {https://www.sciencedirect.com/science/article/pii/S0378437118309981},
author = {Giuseppe Leonardi},
keywords = {Recurrence Quantification Analysis, Entropy, Categorical time series, Dynamical measures, Recurrence Plot},
abstract = {In this work, I propose a new method for the computation of informational entropy from Recurrence Plots when the analyzed time series are categorical in nature. In such cases, there is typically a simplification in choosing the parameters of the analysis, in the sense that no embedding in multidimensional space is usually assumed and that recurrence is restricted to exact matching (equivalence) of the numerically coded categories. However, such a simplified parameterization brings about some notable changes in the appearance of the obtained Recurrence Plots, which has consequences for the extraction of the standard dynamical measures. Specifically, a categorical Recurrence Plot is often composed of rectangular structures rather than line structures (diagonal and horizontal/vertical), over which the recurrence quantification measures were originally proposed. Starting from this observation, I consider alternative computational procedures to extract a non-biased measure of entropy for the categorical case, showing the viability of such a choice with simulated data}
}
@article{GEORGAKARAKOS2017291.e15,
title = {Custom-Made Conical Endograft in the Treatment of Saccular Abdominal Aortic Aneurysms with Tight and Calcified Distal Neck: Thinking Out of the Box},
journal = {Annals of Vascular Surgery},
volume = {39},
pages = {291.e15-291.e19},
year = {2017},
issn = {0890-5096},
doi = {https://doi.org/10.1016/j.avsg.2016.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0890509616312419},
author = {Efstratios Georgakarakos and Christos Argyriou and Nikolaos Schoretsanitis and George S. Georgiadis},
abstract = {Background
To describe the use of the combination of a conical custom-made TREO® (TREO CM) stent graft in the treatment of a saccular abdominal aortic endograft (AAA) with long but tight and calcified distal neck.
Materials and Methods
A 65-year-female patient was treated for a saccular 5.2 cm AAA with a 3-cm long but calcified and tight (16 mm) distal neck, precluding the safe use of a bifurcated endograft. Because the patient refused an open surgery, a conical TREO CM endograft was manufactured with 20% proximal oversizing, whereas the 3-cm caudal sealing segment demonstrated a conical configuration comprising a 2-cm and 1-cm nitinol-supported zones of 20% and 10% oversizing, respectively, to avoid excessive strain and incomplete expand at the most distal calcified area, leading ultimately to an insidious infolding and consequent type Ib endoleak. A 24 × 40 mm Treovance aortic cuff was centrally deployed resulting in a 30 mm overlap with the main endograft.
Results
After 6 months, there was complete sealing, and the AAA sac has been shrunk to 45 mm.
Conclusions
The use of a conical TREO CM endograft with a proximal cuff provides a firm fixation centrally and a sufficient distal sealing design in AAAs with calcified and tight distal aorta, constituting a reliable alternative to bifurcated endografts or aortouniliac configurations followed by crossover adjuncts.}
}
@article{YANG2013855,
title = {Computational Optimization, Modelling and Simulation: Recent Trends and Challenges},
journal = {Procedia Computer Science},
volume = {18},
pages = {855-860},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.250},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913003931},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, optimization algorithm, modelling, metaheursitics, nonlinear optimization, stochastic optimization, surragate-based optimization, simulation ;},
abstract = {Modelling, simulation and optimization form an integrated part of modern design practice in engineering and industry. Tremendous progress has been observed for all three components over the last few decades. However, many challenging issues remain unresolved, and the current trends tend to use nature-inspired algorithms and surrogate-based techniques for modelling and optimization. This 4th workshop on Computational Optimization, Modelling and Simulation (COMS 2013) at ICCS 2013 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry. In this review paper, we will analyse the recent trends in modelling and optimization, and their associated challenges. We will discuss important topics for further research, including parameter-tuning, large-scale problems, and the gaps between theory and applications.}
}
@article{JIANG2025100583,
title = {DeepSeek vs. ChatGPT vs. Claude: A comparative study for scientific computing and scientific machine learning tasks},
journal = {Theoretical and Applied Mechanics Letters},
volume = {15},
number = {3},
pages = {100583},
year = {2025},
issn = {2095-0349},
doi = {https://doi.org/10.1016/j.taml.2025.100583},
url = {https://www.sciencedirect.com/science/article/pii/S2095034925000157},
author = {Qile Jiang and Zhiwei Gao and George Em Karniadakis},
keywords = {Large language models (LLM), Scientific computing, Scientific machine learning, Physics-informed neural network},
abstract = {Large language models (LLMs) have emerged as powerful tools for addressing a wide range of problems, including those in scientific computing, particularly in solving partial differential equations (PDEs). However, different models exhibit distinct strengths and preferences, resulting in varying levels of performance. In this paper, we compare the capabilities of the most advanced LLMs-DeepSeek, ChatGPT, and Claude-along with their reasoning-optimized versions in addressing computational challenges. Specifically, we evaluate their proficiency in solving traditional numerical problems in scientific computing as well as leveraging scientific machine learning techniques for PDE-based problems. We designed all our experiments so that a nontrivial decision is required, e.g, defining the proper space of input functions for neural operator learning. Our findings show that reasoning and hybrid-reasoning models consistently and significantly outperform non-reasoning ones in solving challenging problems, with ChatGPT o3-mini-high generally offering the fastest reasoning speed.}
}
@article{MASELLI20235395,
title = {Computational analysis of five neurodegenerative diseases reveals shared and specific genetic loci},
journal = {Computational and Structural Biotechnology Journal},
volume = {21},
pages = {5395-5407},
year = {2023},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2023.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S2001037023003835},
author = {Francesca Maselli and Salvatore D’Antona and Mattia Utichi and Matteo Arnaudi and Isabella Castiglioni and Danilo Porro and Elena Papaleo and Paolo Gandellini and Claudia Cava},
keywords = {Neurodegenerative diseases, Bioinformatics, GWAS, SNPs},
abstract = {Neurodegenerative diseases (ND) are heterogeneous disorders of the central nervous system that share a chronic and selective process of neuronal cell death. A computational approach to investigate shared genetic and specific loci was applied to 5 different ND: Amyotrophic lateral sclerosis (ALS), Alzheimer's disease (AD), Parkinson's disease (PD), Multiple sclerosis (MS), and Lewy body dementia (LBD). The datasets were analyzed separately, and then we compared the obtained results. For this purpose, we applied a genetic correlation analysis to genome-wide association datasets and revealed different genetic correlations with several human traits and diseases. In addition, a clumping analysis was carried out to identify SNPs genetically associated with each disease. We found 27 SNPs in AD, 6 SNPs in ALS, 10 SNPs in PD, 17 SNPs in MS, and 3 SNPs in LBD. Most of them are located in non-coding regions, with the exception of 5 SNPs on which a protein structure and stability prediction was performed to verify their impact on disease. Furthermore, an analysis of the differentially expressed miRNAs of the 5 examined pathologies was performed to reveal regulatory mechanisms that could involve genes associated with selected SNPs. In conclusion, the results obtained constitute an important step toward the discovery of diagnostic biomarkers and a better understanding of the diseases.}
}
@article{MISZTAL2017731,
title = {Invited review: efficient computation strategies in genomic selection},
journal = {Animal},
volume = {11},
number = {5},
pages = {731-736},
year = {2017},
issn = {1751-7311},
doi = {https://doi.org/10.1017/S1751731116002366},
url = {https://www.sciencedirect.com/science/article/pii/S1751731116002366},
author = {I. Misztal and A. Legarra},
keywords = {genomic selection, single-step, genomic relationship matrix, inverse, REML},
abstract = {The purpose of this study is review and evaluation of computing methods used in genomic selection for animal breeding. Commonly used models include SNP BLUP with extensions (BayesA, etc), genomic BLUP (GBLUP) and single-step GBLUP (ssGBLUP). These models are applied for genomewide association studies (GWAS), genomic prediction and parameter estimation. Solving methods include finite Cholesky decomposition possibly with a sparse implementation, and iterative Gauss–Seidel (GS) or preconditioned conjugate gradient (PCG), the last two methods possibly with iteration on data. Details are provided that can drastically decrease some computations. For SNP BLUP especially with sampling and large number of SNP, the only choice is GS with iteration on data and adjustment of residuals. If only solutions are required, PCG by iteration on data is a clear choice. A genomic relationship matrix (GRM) has limited dimensionality due to small effective population size, resulting in infinite number of generalized inverses of GRM for large genotyped populations. A specific inverse called APY requires only a small fraction of GRM, is sparse and can be computed and stored at a low cost for millions of animals. With APY inverse and PCG iteration, GBLUP and ssGBLUP can be applied to any population. Both tools can be applied to GWAS. When the system of equations is sparse but contains dense blocks, a recently developed package for sparse Cholesky decomposition and sparse inversion called YAMS has greatly improved performance over packages where such blocks were treated as sparse. With YAMS, GREML and possibly single-step GREML can be applied to populations with >50 000 genotyped animals. From a computational perspective, genomic selection is becoming a mature methodology.}
}
@article{VANDENBOS201842,
title = {Computational neuroscience across the lifespan: Promises and pitfalls},
journal = {Developmental Cognitive Neuroscience},
volume = {33},
pages = {42-53},
year = {2018},
note = {Methodological Challenges in Developmental Neuroimaging: Contemporary Approaches and Solutions},
issn = {1878-9293},
doi = {https://doi.org/10.1016/j.dcn.2017.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1878929317301068},
author = {Wouter {van den Bos} and Rasmus Bruckner and Matthew R. Nassar and Rui Mata and Ben Eppinger},
keywords = {Computational neuroscience, Reinforcement learning, Risk-taking, Decision-making, Brain development, Identification, Strategies},
abstract = {In recent years, the application of computational modeling in studies on age-related changes in decision making and learning has gained in popularity. One advantage of computational models is that they provide access to latent variables that cannot be directly observed from behavior. In combination with experimental manipulations, these latent variables can help to test hypotheses about age-related changes in behavioral and neurobiological measures at a level of specificity that is not achievable with descriptive analysis approaches alone. This level of specificity can in turn be beneficial to establish the identity of the corresponding behavioral and neurobiological mechanisms. In this paper, we will illustrate applications of computational methods using examples of lifespan research on risk taking, strategy selection and reinforcement learning. We will elaborate on problems that can occur when computational neuroscience methods are applied to data of different age groups. Finally, we will discuss potential targets for future applications and outline general shortcomings of computational neuroscience methods for research on human lifespan development.}
}
@article{LIU2021110585,
title = {Computational insights into electronic characteristics of 2D PtSe2 nanomaterials: Effects of vacancy defects and strain engineering},
journal = {Vacuum},
volume = {194},
pages = {110585},
year = {2021},
issn = {0042-207X},
doi = {https://doi.org/10.1016/j.vacuum.2021.110585},
url = {https://www.sciencedirect.com/science/article/pii/S0042207X21005340},
author = {Guogang Liu and Tong Chen and Zhonghui Xu and Guanghui Zhou and Xianbo Xiao},
keywords = {PtSe, Electronic structure, Defects, Strain engineering},
abstract = {The epitaxial growth of PtSe2 monolayer has brings new opportunities for the application and development of materials science. Using first-principles calculations, the effect of vacancy defects, and strain engineering on the electronic properties of PtSe2 monolayer are systematically investigated. The results show that the Pt single vacancy induces a large magnetic moment of 4.0 μB on PtSe2 monolayer and transforms it from semiconductor to metal. However, the Se single vacancy systems are nonmagnetic and realize the PtSe2 from an indirect semiconductor to a direct one. Moreover, the band gap of PtSe2 monolayer can be prominently modulated within a appreciable uniaxial strain range, and the band gap are monotonically increase/decrease as decrease/increase the magnitude of the compressive/tensile strain. In particular, when a specific strain applied, a wide and high absorption peak across near-infrared, visible light and ultraviolet region. These findings not only enrich the fundamental understanding of PtSe2 monolayer but also provide useful guidance to design PtSe2-based spintronic, optoelectronic and gas sensing applications.}
}
@incollection{PENN2006338,
title = {Symbolic Computational Linguistics: Overview},
editor = {Keith Brown},
booktitle = {Encyclopedia of Language & Linguistics (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {338-352},
year = {2006},
isbn = {978-0-08-044854-1},
doi = {https://doi.org/10.1016/B0-08-044854-2/00875-0},
url = {https://www.sciencedirect.com/science/article/pii/B0080448542008750},
author = {G. Penn},
keywords = {computational linguistics, concept ontologies, lambda calculus, logic, phrase structure trees, typed feature structures},
abstract = {Symbolic computational linguistics is a diverse body of research that uses logical, graphical and other discrete mathematical representations to model structure and meaning at the various levels of linguistic investigation. This article provides an informal introduction to these representations, along with a discussion of their applications.}
}
@incollection{BARTHEYE2020385,
title = {Chapter 19 - Human-machine sense making in context-based computational decision},
editor = {William F. Lawless and Ranjeev Mittu and Donald A. Sofge},
booktitle = {Human-Machine Shared Contexts},
publisher = {Academic Press},
pages = {385-398},
year = {2020},
isbn = {978-0-12-820543-3},
doi = {https://doi.org/10.1016/B978-0-12-820543-3.00019-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128205433000195},
author = {Olivier Bartheye and Laurent Chaudron},
keywords = {Human/machine sense making, Knowledge processing, Decision mechanism, Causal break, Hopf algebras, Computational contexts, Continuous inference},
abstract = {In this chapter, we present what should be the inner structure of a decision algebra whose motivation is to fill a causal break induced by context invalidity to ultimately permit human-machine interactions. It turns out that such a decision structure can be qualified using the context change arrow as a disruptive process or as a phase transition according to the geometrical representation of computational contexts as double S-curves. In particular a computational context is always characterized by a shift between sense making and temporal causality. That is, once a causal break occurs, it has to be filled locally by a decision. A causal break is always continuous and never discrete; in effect, in the discrete case, combinatoric analysis causes unwanted complexity due to a lack of knowledge, whereas we need full knowledge thanks to a very precise semantic of a causal break. Intuitively, rather than separating brutally models and counter-models as a proof can do by setting a strong negation operator, we prefer to use the continuous inference as an implementation of sense making. Sense is that way taken as the rationality of the transition. Full knowledge requires a special structure, a Hopf algebra in which the continuous property we cannot implement is replaced by the computable co-continuous property in the co-algebraic component of the decision Hopf algebra. We hope that thanks to co-continuous structures and to co-dimensional exterior algebras, we’ll be able to find out a representation of the continuous inference able to compute a decision rather than admitting definitely and desperately that “such a mechanism is totally out of bounds” and will never ever concern a machine.}
}
@article{ZHOU2025100904,
title = {Exploring the development of pre-service teachers' epistemic agency in Chinese University knowledge building community},
journal = {Learning, Culture and Social Interaction},
volume = {52},
pages = {100904},
year = {2025},
issn = {2210-6561},
doi = {https://doi.org/10.1016/j.lcsi.2025.100904},
url = {https://www.sciencedirect.com/science/article/pii/S2210656125000236},
author = {Fuying Zhou and Shaoming Chai and Zhenhai He and Han Wu},
keywords = {Epistemic agency, Knowledge Building Community, Cognitive conflict, Teacher education},
abstract = {Epistemic agency, the capacity to effectively engage with knowledge and understand its nature, is crucial for successful learning and problem-solving in today's complex world. This study explores the non-linear development of epistemic agency among pre-service teachers engaged in principle-based Knowledge Building (KB) activities on the Knowledge Forum (KF) platform within a Chinese university setting. By analyzing interaction data, notes, and reflective reports from 38 participants, the findings reveal a positive correlation between the development of epistemic agency and strategies for handling cognitive conflicts. The research highlights a transition from reliance on authoritative knowledge to confidence in personal KB, and from simplistic understanding of problems to critical thinking about complex issues. These insights provide empirical support for the design of teacher education curricula, emphasizing the importance of creating opportunities for pre-service teachers to manage cognitive conflicts, thereby fostering their growth in epistemic agency.}
}
@incollection{OREILLY2019317,
title = {Chapter 17 - Computational models of motivated frontal function},
editor = {Mark D'Esposito and Jordan H. Grafman},
series = {Handbook of Clinical Neurology},
publisher = {Elsevier},
volume = {163},
pages = {317-332},
year = {2019},
booktitle = {The Frontal Lobes},
issn = {0072-9752},
doi = {https://doi.org/10.1016/B978-0-12-804281-6.00017-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042816000173},
author = {Randall C. O’Reilly and Jacob Russin and Seth A. Herd},
keywords = {Computational models, Frontal cortex, Basal ganglia, Goal-directed, Motivation, Working memory, Reinforcement learning},
abstract = {Computational models of frontal function have made important contributions to understanding how the frontal lobes support a wide range of important functions, in their interactions with other brain areas including, critically, the basal ganglia (BG). We focus here on the specific case of how different frontal areas support goal-directed, motivated decision-making, by representing three essential types of information: possible plans of action (in more dorsal and lateral frontal areas), affectively significant outcomes of those action plans (in ventral, medial frontal areas including the orbital frontal cortex), and the overall utility of a given plan compared to other possible courses of action (in anterior cingulate cortex). Computational models of goal-directed action selection at multiple different levels of analysis provide insight into the nature of learning and processing in these areas and the relative contributions of the frontal cortex versus the BG. The most common neurologic disorders implicate these areas, and understanding their precise function and modes of dysfunction can contribute to the new field of computational psychiatry, within the broader field of computational neuroscience.}
}
@article{NEWHALL2025105044,
title = {An introductory-level undergraduate CS course that introduces parallel computing},
journal = {Journal of Parallel and Distributed Computing},
volume = {199},
pages = {105044},
year = {2025},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2025.105044},
url = {https://www.sciencedirect.com/science/article/pii/S0743731525000115},
author = {Tia Newhall and Kevin C. Webb and Vasanta Chaganti and Andrew Danner},
keywords = {CS curriculum, Parallel computing, Introductory CS},
abstract = {We present the curricular design, pedagogy, and goals of an introductory-level course on computer systems that introduces parallel and distributed computing (PDC) to students who have only a CS1 background. With the ubiquity of multicore processors, cloud computing, and hardware accelerators, PDC topics have become fundamental knowledge areas in the undergraduate CS curriculum. As a result, it is increasingly important for students to learn a common core of introductory parallel and distributed computing topics and to develop parallel thinking skills early in their CS studies. Our introductory-level course focuses on three main curricular goals: 1) understanding how a computer runs a program, 2) evaluating system costs associated with running a program, and 3) taking advantage of the power of parallel computing. We elaborate on the goals and details of our course's key modules, and we discuss our pedagogical approach that includes active-learning techniques. We also include an evaluation of our course and a discussion of our experiences teaching it since Fall 2012. We find that the PDC foundation gained through early exposure in our course helps students gain confidence in their ability to expand and apply their understanding of PDC concepts throughout their CS education.}
}
@article{LEONELLI201229,
title = {Re-thinking organisms: The impact of databases on model organism biology},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {43},
number = {1},
pages = {29-36},
year = {2012},
note = {Data-Driven Research in the Biological and Biomedical Sciences On Nature and Normativity: Normativity, Teleology, and Mechanism in Biological Explanation},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2011.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1369848611000793},
author = {Sabina Leonelli and Rachel A. Ankeny},
keywords = {Database, Data, Model organism, Data-intensive science, Curator},
abstract = {Community databases have become crucial to the collection, ordering and retrieval of data gathered on model organisms, as well as to the ways in which these data are interpreted and used across a range of research contexts. This paper analyses the impact of community databases on research practices in model organism biology by focusing on the history and current use of four community databases: FlyBase, Mouse Genome Informatics, WormBase and The Arabidopsis Information Resource. We discuss the standards used by the curators of these databases for what counts as reliable evidence, acceptable terminology, appropriate experimental set-ups and adequate materials (e.g., specimens). On the one hand, these choices are informed by the collaborative research ethos characterising most model organism communities. On the other hand, the deployment of these standards in databases reinforces this ethos and gives it concrete and precise instantiations by shaping the skills, practices, values and background knowledge required of the database users. We conclude that the increasing reliance on community databases as vehicles to circulate data is having a major impact on how researchers conduct and communicate their research, which affects how they understand the biology of model organisms and its relation to the biology of other species.}
}
@article{SNIDER2021108795,
title = {Reinforcer pathology in cocaine use disorder: Temporal window determines cocaine valuation},
journal = {Drug and Alcohol Dependence},
volume = {225},
pages = {108795},
year = {2021},
issn = {0376-8716},
doi = {https://doi.org/10.1016/j.drugalcdep.2021.108795},
url = {https://www.sciencedirect.com/science/article/pii/S0376871621002908},
author = {Sarah E. Snider and Jamie K. Turner and Samuel M. McClure and Warren K. Bickel},
keywords = {Reinforcer pathology, Experimental medicine approach, Episodic future thinking, Delay discounting, Behavioral economic demand, Cocaine use disorder},
abstract = {Aims
The Experimental Medicine Approach offers a unique perspective to determine clinical behavior change by engaging a target underlying the cause of a disorder. The present work engaged a novel target of addiction, Reinforcer Pathology, in two studies to test changes in behavior among individuals with cocaine use disorder.
Methods
In Study 1, n = 44 participants engaged the temporal window with episodic future thinking (EFT), a positive prospection exercise. Changes in temporal view and cocaine valuation were tested using delay discounting and behavioral economic demand, respectively. Additionally, a computational model assessed the relative reliance on the near- and far-sighted systems during EFT. In Study 2, n = 71 engaged the temporal window with a negatively-valenced hurricane scenario to test the opposite effects on window length and cocaine valuation.
Results
Results demonstrated systematic and symmetrical engagement of the behavioral target. Study 1 robustly replicated previous work, wherein EFT lengthened the temporal window and decreased cocaine valuation. Moreover, EFT increased the weighting of the modeled far-sighted system, increasing the relative impact of long-term discounting decisions. Study 2 produced opposite outcomes, shortened temporal window and increased cocaine valuation.
Conclusions
This approximately equal and opposite reaction to the manipulations supports reinforcer pathology theory and implicates the temporal window over which rewards are valued as a target to be pushed and pulled to produce clinically meaningful behavior change. Using the Experimental Medicine Approach as a guide, future work should identify new potential interventions to engage reinforcer pathology and use the clinically relevant outcomes as a litmus test for mechanism.}
}