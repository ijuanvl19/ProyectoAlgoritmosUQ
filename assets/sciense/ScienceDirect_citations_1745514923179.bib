@article{CHEN2015247,
title = {Reinforcement learning in depression: A review of computational research},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {247-267},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001311},
author = {Chong Chen and Taiki Takahashi and Shin Nakagawa and Takeshi Inoue and Ichiro Kusumi},
keywords = {Anhedonia, Computational psychiatry, Depression, Dopamine, Incentive salience, Learning rate, ‘Liking’, Model-free, Model-based, Motivation, Prediction error, Reinforcement learning, Reward sensitivity, Stress, ‘Wanting’},
abstract = {Despite being considered primarily a mood disorder, major depressive disorder (MDD) is characterized by cognitive and decision making deficits. Recent research has employed computational models of reinforcement learning (RL) to address these deficits. The computational approach has the advantage in making explicit predictions about learning and behavior, specifying the process parameters of RL, differentiating between model-free and model-based RL, and the computational model-based functional magnetic resonance imaging and electroencephalography. With these merits there has been an emerging field of computational psychiatry and here we review specific studies that focused on MDD. Considerable evidence suggests that MDD is associated with impaired brain signals of reward prediction error and expected value (‘wanting’), decreased reward sensitivity (‘liking’) and/or learning (be it model-free or model-based), etc., although the causality remains unclear. These parameters may serve as valuable intermediate phenotypes of MDD, linking general clinical symptoms to underlying molecular dysfunctions. We believe future computational research at clinical, systems, and cellular/molecular/genetic levels will propel us toward a better understanding of the disease.}
}
@article{HUNG1997311,
title = {Meanings, contexts, and mathematical thinking: The meaning-context model},
journal = {The Journal of Mathematical Behavior},
volume = {16},
number = {4},
pages = {311-324},
year = {1997},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(97)90010-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312397900109},
author = {David Wei Loong Hung},
abstract = {The aim of this paper is to describe the meaning-context model which integrates three different levels of contextual factors that influence students' mathematical thinking and problem solving. These factors can be primarily classified according to: (1) the problem-task at hand; (2) the individual problem solver's personal epistemology of mathematics; and (3) the social and cultural influences through which the individual develops his or her mathematical disposition. We have referred to these three different contextual factors as the meaning-symbol context, meaning-interpretation context, and the meaning-intersubjectivity context respectively. The paper also discusses the implications of this model.}
}
@article{BORREGO2024101948,
title = {DPGraphJ: A Java package for the implementation of dynamic programming algorithms},
journal = {SoftwareX},
volume = {28},
pages = {101948},
year = {2024},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2024.101948},
url = {https://www.sciencedirect.com/science/article/pii/S2352711024003182},
author = {Diana Borrego and Irene Barba and Carmelo {Del Valle} and Miguel Toro},
keywords = {Dynamic programming, AND/OR graphs, Design & implementation, Software quality, Computational thinking},
abstract = {This paper introduces the DPGraphJ package, a collection of reusable Java functions to solve optimisation problems using a dynamic programming algorithm. The latter is based on a recursive schema that follows a top-down approach and uses the memoisation technique. This algorithm is a reusable software component that is generic and efficient. Moreover, it has been developed by paying special attention to good practices in the design of software. For using DPGraphJ, the problem to be solved needs to be modelled as an AND/OR graph. In the DPGraphJ package, we provide 5 academic case studies with detailed comments. We strongly believe that our proposal can be helpful for several kinds of users, such as students, researchers, and practitioners.}
}
@article{CHECIU2024127324,
title = {Reconstructing creative thoughts: Hopfield neural networks},
journal = {Neurocomputing},
volume = {575},
pages = {127324},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127324},
url = {https://www.sciencedirect.com/science/article/pii/S092523122400095X},
author = {Denisa Checiu and Mathias Bode and Radwa Khalil},
keywords = {Creative Thinking, Hopfield Neural Network, Patterns, Memory, Associative Chains, Semantic Association},
abstract = {From a brain processing perspective, the perception of creative thinking is rooted in the underlying cognitive process, which facilitates exploring and cultivating novel avenues and problem-solving strategies. However, it is challenging to emulate the intricate complexity of how the human brain presents a novel way to uncover unique solutions. One potential approach to mitigating this complexity is incorporating creative cognition into the evolving artificial intelligence systems and associated neural models. Hopfield neural network (HNN) are commonly acknowledged as a simplified neural model, renowned for their biological plausibility to store and retrieve information, specifically patterns of neurons. Our findings suggest utilizing modern HNN to emulate creative thinking by making meaningful associations between seemingly disparate concepts. This semantic link is represented as a radio knob that can be set to determine whether the network solves problems creatively or shuts down; the threshold is a parameter. We used the term "first knob of creativity" to describe a certain pattern and utilized the "second knob of creativity" to aid in the examination of alternatives within the network. By manipulating the knobs, it is possible to selectively suppress specific patterns, facilitating the creative functioning of the HNN and identifying other patterns with which input can be linked.}
}
@article{CHANG2023100529,
title = {Management accounting system: Insights from the decision making theories},
journal = {Social Sciences & Humanities Open},
volume = {8},
number = {1},
pages = {100529},
year = {2023},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2023.100529},
url = {https://www.sciencedirect.com/science/article/pii/S2590291123001341},
author = {Kirk Chang and Alhashmi Aboubaker Lasyoud and Diaeldin Osman},
keywords = {Decision making, MAS, Management account system, Pre-factor, Thinking styles},
abstract = {Management accounting system (MAS) improves business growth through quality decision making process, but scholars have mixed views about MAS and constantly debate its efficacy. Drawing on the decision-making theories, the current research deviates from the debates and adopts a ‘think-outside-the-box’ approach, aiming to advance the knowledge of MAS's efficacy. Research data are gathered from the MAS literatures and cognate studies. Following the research findings, we identify a new pre-factor (thinking style) and incorporate it into the MAS. Specifically, decision makers' cognitive process is found to affect the design and implementation of MAS, as rational thinking style, administrative thinking style, and political thinking style may affect the MAS's efficacy differently. Research findings have brought valuable insights to the MAS literatures, by highlighting the strength and weakness of different thinking styles in designing management accounting system. Moreover, decision makers, such as organizational leaders and business managers, are encouraged to monitor their thinking styles: that is, with better understanding of thinking styles, decision makers can better utilize MAS and rectify the style-driven deficits in time.}
}
@article{KALRO1998267,
title = {3D computation of unsteady flow past a sphere with a parallel finite element method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {151},
number = {1},
pages = {267-276},
year = {1998},
note = {Containing papers presented at the Symposium on Advances in Computational Mechanics},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(97)00120-5},
url = {https://www.sciencedirect.com/science/article/pii/S0045782597001205},
author = {V. Kalro and T. Tezduyar},
abstract = {We present parallel computation of 3D, unsteady, incompressible flow past a sphere. The Navier-Stokes equations of incompressible flows are solved using a stabilized finite element formulation. Equal-order interpolation functions are used for velocity and pressure. The second-order accurate time-marching within the solution process is carried out in an implicit fashion. The coupled, nonlinear equations generated at each time step are solved using an element-vector-based iteration technique. The computed value of the primary frequency associated with vortex shedding is in close agreement with experimental measurements. The computation was performed on the Thinking Machines CM-5.}
}
@article{BEATTIE2003909,
title = {Post-genomic technologies – thinking beyond the hype},
journal = {Drug Discovery Today},
volume = {8},
number = {20},
pages = {909-910},
year = {2003},
issn = {1359-6446},
doi = {https://doi.org/10.1016/S1359-6446(03)02862-9},
url = {https://www.sciencedirect.com/science/article/pii/S1359644603028629},
author = {John Beattie and Peter Ghazal},
keywords = {Post-genomic, Proteomics, Biochip, DNA chip, Bioinformatics, Microarrays}
}
@article{ZOCCA2019100,
title = {Decision-making computationally aided in the management of energy sources used in agrifood industries},
journal = {Energy Procedia},
volume = {161},
pages = {100-107},
year = {2019},
note = {Proceedings of the 2nd International Conference on Sustainable Energy and Resource Use in Food Chains including Workshop on Energy Recovery Conversion and Management;ICSEF 2018, 17 – 19 October 2018, Paphos, Cyprus},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2019.02.063},
url = {https://www.sciencedirect.com/science/article/pii/S1876610219311427},
author = {Renan Zocca and Pedro D. Gaspar and Pedro D. Silva and Fernando C. Santos and Luís P. Andrade and José Nunes},
keywords = {Energy consumption, Energy management, Computational tool, decision making},
abstract = {In an increasingly competitive society with an unfavourable economic environment, it is necessary for Small and Medium Enterprises (SMEs) to update themselves, thereby increasing their efficiency. Companies increasingly use computational tools to support the development of predictive scenarios in order to facilitate decision-making. However, the tools developed for SMEs are not always expedite and simple to use. The tool presented in this article intends to support the management of energy sources used by agro-industrial companies. It aims to facilitate and promote the implementation of a new culture of business management, in this sector so important at national level. The computational part is directed to support the decision-making on the selection of fossil or renewable energy sources to be used in a particular agroindustry, by presenting the average values of the energy consumption, cost and emissions associated with each selected energy source.}
}
@incollection{HASS202094,
title = {Measurement: Computerized Creativity Testing and Scoring},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {94-99},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23810-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245238108},
author = {Richard W. Hass},
keywords = {Creativity, Measurement, Assessment, Semantic memory, Computer algorithms, Divergent thinking, Remote association, Brainstorming, Domain-specificity, Creative problem solving},
abstract = {This entry discusses the use of computers in creativity measurement and assessment. Special emphasis is placed on the use of algorithms for scoring the responses generated during divergent thinking tasks. These algorithms are rooted in various theories of semantics, the details of which are also reviewed. In addition, advances in the use of computers for electronic brainstorming and for domain-specific creativity measurement beyond verbal divergent thinking are also reviewed. The objective is to provide readers with information on the various methods that are available, and a brief discussion of computational semantics.}
}
@article{VOYER2022101734,
title = {Symbols of class: A computational analysis of class distinction-making through etiquette, 1922-2017},
journal = {Poetics},
volume = {94},
pages = {101734},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101734},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001164},
author = {Andrea Voyer and Zachary D. Kline and Madison Danton},
keywords = {Social class, Status symbols, Word embeddings, Cultural sociology, Computational sociology},
abstract = {Social scientists of class and inequality have documented the rise of omnivorousness, informality, ordinariness, and emphasis on meritocracy. This apparent decline in class closure contrasts sharply with rising inequality and declining economic mobility. How are these competing developments reflected in everyday class distinction-making? In this article, we answer this question by applying Goffman's work on the symbols of class status to the analysis of unique data: a corpus of etiquette books published between 1922 and 2017. We use word embeddings to quantify the salience of six class concepts (affluence, cultivation, education, employment, morality, and status) in the corpus. We find that education and employment are increasingly salient while status, affluence, cultivation, and morality decline in their salience to class distinction-making. These results signal a decline of class operating as a status group through cultural closure, the rise of education and employment as the carriers of class in everyday life, and the corresponding legitimation of class position and class inequality based on supposedly meritocratic grounds. This research opens up new avenues for studies of class and the application of computational methods to investigations of social change.}
}
@article{NOORIGOODARZI2022105372,
title = {Subtractive genomic approach toward introduction of novel immunogenic targets against Clostridioides difficile: Thinking out of the box},
journal = {Microbial Pathogenesis},
volume = {162},
pages = {105372},
year = {2022},
issn = {0882-4010},
doi = {https://doi.org/10.1016/j.micpath.2021.105372},
url = {https://www.sciencedirect.com/science/article/pii/S088240102100646X},
author = {Narjes {Noori Goodarzi} and Sepideh Fereshteh and Omid Azizi and Hamzeh Rahimi and Negin Bolourchi and Farzad Badmasti},
keywords = {, Reverse vaccinology, Immunogenic target},
abstract = {Clostridioides difficile is one of the major causatives of nosocomial infections worldwide. Antibiotic-associated diarrhea, pseudomembranous colitis, and toxic megacolon are the most common forms of C. difficile infection (CDI). Considering the high antibiotic resistance of C. difficile isolates and the low efficacy of immunization with toxin-related vaccines, we suggested that surface-exposed and secreted proteins could be considered as potential immunogenic targets against CDI. Various immuninformatics databases were used to predict antigenicity, allergenicity, B-cell epitopes, MHC-II binding sites, conserved domains, prevalence and conservation of proteins among the most common sequence types, molecular docking, and immunosimulation of immunogenic targets. Finally, 16 proteins belonging to three functional groups were identified, including proteins involved in the cell wall and peptidoglycan layer (nine proteins), flagellar assembly (five proteins), spore germination (one protein), and a protein with unknown function. Molecular docking results showed that among all the mentioned proteins, WP_009892971.1 (Acd) and WP_009890599.1 (a C40 family peptidase) had the strongest interactions with human Toll-like receptor 2 (TLR-2) and TLR-4. This study proposes a combination of C. difficile toxoid (Tcd) and surface-exposed proteins such as Acd as a promising vaccine formulation for protection against circulating clinical strains of C. difficile.}
}
@article{MORTOLA201628,
title = {Thinking about breathing: Effects on respiratory sinus arrhythmia},
journal = {Respiratory Physiology & Neurobiology},
volume = {223},
pages = {28-36},
year = {2016},
issn = {1569-9048},
doi = {https://doi.org/10.1016/j.resp.2015.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1569904815300963},
author = {Jacopo P. Mortola and Domnica Marghescu and Rosemarie Siegrist-Johnstone},
keywords = {Neural control of breathing, Parasympathetic control, Vagal tone},
abstract = {Respiratory sinus arrhythmia (RSA), the increase and decrease in instantaneous heart rate (HR) with inspiration and expiration, is commonly evaluated as function of breathing frequency f. However, to the extent that RSA plays a role in the efficiency of gas exchange, it may be expected to correlate better with HR/f (‘breathing specific heart rate’) than with f, because the former is a better reflection of the cardio-respiratory coupling. We measured RSA breath-by-breath in 209 young men and women during spontaneous breathing and during volitional breathing under auditory cues at vastly different f. In either case, and for both genders, RSA correlated better with HR/f than with f. As HR/f increased so did RSA, in a linear manner. When compared on the basis of HR/f, RSA did not differ significantly between spontaneous and volitional breathing. It is proposed that RSA is a central mechanism that ameliorates the matching between the quasi-continuous pulmonary blood flow and the intermittent airflow, irrespective of the type of ventilatory drive (cortical or autonomic).}
}
@article{BAUSO20161,
title = {Strategic thinking under social influence: Scalability, stability and robustness of allocations},
journal = {European Journal of Control},
volume = {32},
pages = {1-15},
year = {2016},
issn = {0947-3580},
doi = {https://doi.org/10.1016/j.ejcon.2016.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0947358016300115},
author = {Dario Bauso and Tamer Başar},
keywords = {Mean-field games, Coalitional game theory, Differential games, Optimal control},
abstract = {This paper studies the strategic behavior of a large number of game designers and studies the scalability, stability and robustness of their allocations in a large number of homogeneous coalitional games with transferable utilities (TU). For each TU game, the characteristic function is a continuous-time stochastic process. In each game, a game designer allocates revenues based on the extra reward that a coalition has received up to the current time and the extra reward that the same coalition has received in the other games. The approach is based on the theory of mean-field games with heterogeneous groups in a multi-population regime.}
}
@article{TREUR2013449,
title = {Conceptual and Computational Analysis of the Role of Emotions and Social Influence in Learning},
journal = {Procedia - Social and Behavioral Sciences},
volume = {93},
pages = {449-467},
year = {2013},
note = {3rd World Conference on Learning, Teaching and Educational Leadership},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.09.220},
url = {https://www.sciencedirect.com/science/article/pii/S1877042813033235},
author = {Jan Treur and Arlette {van Wissen}},
keywords = {emotion, learning, social influence, reflection.},
abstract = {In this paper, it is analyzed how emotions and social environment affect people's active and reflective learning processes. First, a conceptual analysis is made using recent insights from Cognitive, Affective and Social Neuroscience on the roles of emotions and social interactions on learning. Next, a computational analysis is made using a computational model of learning processes following these insights. In this analysis, neural mechanisms for the impact of both a person's own emotions and the emotions of others are taken into account. In particular, it is considered how these impacts influence different learning types, such as active or reflective learners. The analysis shows how the impacts of emotions and social interaction strengthen the learning process. It is discussed how from these insights indicators can be obtained that can be used to design technology-enhanced learning environments able to exploit these impacts.}
}
@article{JOHNSONLAIRD1994189,
title = {Mental models and probabilistic thinking},
journal = {Cognition},
volume = {50},
number = {1},
pages = {189-209},
year = {1994},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(94)90028-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027794900280},
author = {Philip N. Johnson-Laird},
abstract = {This paper outlines the theory of reasoning based on mental models, and then shows how this theory might be extended to deal with probabilistic thinking. The same explanatory framework accommodates deduction and induction: there are both deductive and inductive inferences that yield probabilistic conclusions. The framework yields a theoretical conception of strength of inference, that is, a theory of what the strength of an inference is objectively: it equals the proportion of possible states of affairs consistent with the premises in which the conclusion is true, that is, the probability that the conclusion is true given that the premises are true. Since there are infinitely many possible states of affairs consistent with any set of premises, the paper then characterizes how individuals estimate the strength of an argument. They construct mental models, which each correspond to an infinite set of possibilities (or, in some cases, a finite set of infinite sets of possibilities). The construction of models is guided by knowledge and beliefs, including lay conceptions of such matters as the “law of large numbers”. The paper illustrates how this theory can account for phenomena of probabilistic reasoning.}
}
@article{MURILLO2020119,
title = {Confronting the Challenges of Computational and Social Perspectives of the Data Continuum},
journal = {Data and Information Management},
volume = {4},
number = {2},
pages = {119-126},
year = {2020},
issn = {2543-9251},
doi = {https://doi.org/10.2478/dim-2020-0008},
url = {https://www.sciencedirect.com/science/article/pii/S2543925122000559},
author = {Angela P. Murillo and Renata G. Curty and Wei Jeng and Daqing He},
keywords = {data acumen, data stewardship, agricultural data, biomedical data, archaeological data},
abstract = {As the availability of data is increasing everyday, the need to reflect on how to make these data meaningful and impactful becomes vital. Current data paradigms have provided data life cycles that often focus on data acumen and data stewardship approaches. In an effort to examine the convergence, tensions, and harmonies of these two approaches, a group of researchers participated in an interactive panel session at the Association of Information Science and Technology Annual meeting in 2019. The panel presenters described their various research activities in which they confront the challenges of the computational and social perspectives of the data continuum. This paper provides a summary of this interactive panel.}
}
@article{SHIN2025101771,
title = {Exploring creative problem-solving in computer-supported collaborative learning: Focusing on group cohesiveness and socially shared metacognitive regulation},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101771},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101771},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000203},
author = {Yoonhee Shin and Haengkyung Lee and Wooyoung Kim},
keywords = {Creative problem-solving, Knowledge construction, Computer-supported collaborative learning, Group cohesiveness, Socially shared metacognitive regulation},
abstract = {This study investigated the creative problem-solving (CPS) process in computer-supported collaborative learning (CSCL), examining its relationship with CPS skills and interaction patterns, with a particular focus on group cohesiveness and socially shared metacognitive regulation (SSMR). The research sought to determine how group cohesiveness within Design Thinking (DT) phases influences CPS skills and to identify the characteristics of SSMR in high- versus low-creativity groups. Participants included 108 first-year undergraduate students majoring in humanities and social sciences at a South Korean university. The study found a significant relationship between group cohesiveness and CPS skill levels across various CPS phases. Specifically, substantial differences in SSMR patterns, particularly concerning exploration and evaluation, were observed among low- and high-creativity groups. These findings suggest that the interplay of divergent and convergent thinking during CPS is crucial for devising novel and practical solutions. Employing a mixed-methods approach and collaboration analysis, the study closely examined the CPS process using CSCL tools, offering valuable insights for informing future CPS instructional strategies.}
}
@article{GIRARD202297,
title = {Computational analysis of spoken language in acute psychosis and mania},
journal = {Schizophrenia Research},
volume = {245},
pages = {97-115},
year = {2022},
note = {Computational Approaches to Understanding Psychosis},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2021.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0920996421002528},
author = {Jeffrey M. Girard and Alexandria K. Vail and Einat Liebenthal and Katrina Brown and Can Misel Kilciksiz and Luciana Pennant and Elizabeth Liebson and Dost Öngür and Louis-Philippe Morency and Justin T. Baker},
keywords = {Language, Schizophrenia, Bipolar disorder, Positive symptoms, Negative symptoms},
abstract = {Objectives
This study aimed to (1) determine the feasibility of collecting behavioral data from participants hospitalized with acute psychosis and (2) begin to evaluate the clinical information that can be computationally derived from such data.
Methods
Behavioral data was collected across 99 sessions from 38 participants recruited from an inpatient psychiatric unit. Each session started with a semi-structured interview modeled on a typical “clinical rounds” encounter and included administration of the Positive and Negative Syndrome Scale (PANSS).
Analysis
We quantified aspects of participants' verbal behavior during the interview using lexical, coherence, and disfluency features. We then used two complementary approaches to explore our second objective. The first approach used predictive models to estimate participants' PANSS scores from their language features. Our second approach used inferential models to quantify the relationships between individual language features and symptom measures.
Results
Our predictive models showed promise but lacked sufficient data to achieve clinically useful accuracy. Our inferential models identified statistically significant relationships between numerous language features and symptom domains.
Conclusion
Our interview recording procedures were well-tolerated and produced adequate data for transcription and analysis. The results of our inferential modeling suggest that automatic measurements of expressive language contain signals highly relevant to the assessment of psychosis. These findings establish the potential of measuring language during a clinical interview in a naturalistic setting and generate specific hypotheses that can be tested in future studies. This, in turn, will lead to more accurate modeling and better understanding of the relationships between expressive language and psychosis.}
}
@article{POULOVA20151996,
title = {Education in Computational Sciences},
journal = {Procedia Computer Science},
volume = {51},
pages = {1996-2005},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.464},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915012727},
author = {Petra Poulova and Blanka Klimova},
keywords = {Computational education, Key competences, Study programmes},
abstract = {The last two decades have witnessed an enormously rapid development of computational technologies which have undoubtedly affected all the fields of human activities, including education. In fact, computational science is one of the most evolving profile study programmes at technical universities nowadays. This article thus focuses on the description of the key content courses, curricula and degrees offered within the study programmes at the Faculty of Informatics and Management of the University of Hradec Kralove, Czech Republic. Moreover, this study characterizes teaching and learning of university undergraduate computational professionals with a special focus on core competences such as an ability to identify and solve problems, knowledge of analytical methods, or operating systems, but also on active and passive knowledge of English since English as lingua franca can help these professionals together with other core competences succeed in the job market after their graduation.}
}
@article{POON2006177,
title = {Lay personality knowledge and dispositionist thinking: A knowledge-activation framework},
journal = {Journal of Experimental Social Psychology},
volume = {42},
number = {2},
pages = {177-191},
year = {2006},
issn = {0022-1031},
doi = {https://doi.org/10.1016/j.jesp.2005.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S002210310500051X},
author = {Connie S.K. Poon and Derek J. Koehler},
keywords = {Lay theories, Dispositional inferences, Knowledge activation},
abstract = {We explicate a knowledge-activation framework depicting the link between lay personality knowledge and dispositional judgments, building on work by Dweck et al., 1995a, Dweck et al., 1995b. According to this framework, most people possess knowledge consistent with an entity theory (personality is fixed) and incremental theory (personality is malleable), which operates according to knowledge-activation principles. Consistent with this claim, we find that people render more confident dispositional judgments when their entity knowledge is made relatively more accessible through priming manipulations that activate aspects of their existing knowledge. Findings also illustrate the usefulness of incorporating both specific and general knowledge in our analysis. The present framework enhances and complements the individual-differences approach to the study of person theories prevalent in the literature.}
}
@article{KELLOGG2023255,
title = {Merging cultures and disciplines to create a drug discovery ecosystem at Virginia commonwealth university: Medicinal chemistry, structural biology, molecular and behavioral pharmacology and computational chemistry},
journal = {SLAS Discovery},
volume = {28},
number = {6},
pages = {255-269},
year = {2023},
note = {Emerging Drug Discovery Ecosystems},
issn = {2472-5552},
doi = {https://doi.org/10.1016/j.slasd.2023.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S2472555223000175},
author = {Glen E. Kellogg and Yana Cen and Malgorzata Dukat and Keith C. Ellis and Youzhong Guo and Jiong Li and Aaron E. May and Martin K. Safo and Shijun Zhang and Yan Zhang and Umesh R. Desai},
keywords = {Drug discovery ecosystem, Structure-based drug discovery, Quantitative structure-activity relationships, Computational glycomics, Drug Discrimination, Allosteric effectors of hemoglobin, G protein-coupled receptors, Experimental structural biology, High-throughput screening},
abstract = {The Department of Medicinal Chemistry, together with the Institute for Structural Biology, Drug Discovery and Development, at Virginia Commonwealth University (VCU) has evolved, organically with quite a bit of bootstrapping, into a unique drug discovery ecosystem in response to the environment and culture of the university and the wider research enterprise. Each faculty member that joined the department and/or institute added a layer of expertise, technology and most importantly, innovation, that fertilized numerous collaborations within the University and with outside partners. Despite moderate institutional support with respect to a typical drug discovery enterprise, the VCU drug discovery ecosystem has built and maintained an impressive array of facilities and instrumentation for drug synthesis, drug characterization, biomolecular structural analysis and biophysical analysis, and pharmacological studies. Altogether, this ecosystem has had major impacts on numerous therapeutic areas, such as neurology, psychiatry, drugs of abuse, cancer, sickle cell disease, coagulopathy, inflammation, aging disorders and others. Novel tools and strategies for drug discovery, design and development have been developed at VCU in the last five decades; e.g., fundamental rational structure-activity relationship (SAR)-based drug design, structure-based drug design, orthosteric and allosteric drug design, design of multi-functional agents towards polypharmacy outcomes, principles on designing glycosaminoglycans as drugs, and computational tools and algorithms for quantitative SAR (QSAR) and understanding the roles of water and the hydrophobic effect.}
}
@article{YILDIRIM201973,
title = {An integrative computational architecture for object-driven cortex},
journal = {Current Opinion in Neurobiology},
volume = {55},
pages = {73-81},
year = {2019},
note = {Machine Learning, Big Data, and Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0959438818301995},
author = {Ilker Yildirim and Jiajun Wu and Nancy Kanwisher and Joshua Tenenbaum},
abstract = {Computational architecture for object-driven cortex Objects in motion activate multiple cortical regions in every lobe of the human brain. Do these regions represent a collection of independent systems, or is there an overarching functional architecture spanning all of object-driven cortex? Inspired by recent work in artificial intelligence (AI), machine learning, and cognitive science, we consider the hypothesis that these regions can be understood as a coherent network implementing an integrative computational system that unifies the functions needed to perceive, predict, reason about, and plan with physical objects—as in the paradigmatic case of using or making tools. Our proposal draws on a modeling framework that combines multiple AI methods, including causal generative models, hybrid symbolic-continuous planning algorithms, and neural recognition networks, with object-centric, physics-based representations. We review evidence relating specific components of our proposal to the specific regions that comprise object-driven cortex, and lay out future research directions with the goal of building a complete functional and mechanistic account of this system.}
}
@article{SHEARER1996465,
title = {Computational optimization of finite difference methods on the CM5},
journal = {Parallel Computing},
volume = {22},
number = {3},
pages = {465-481},
year = {1996},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(95)00009-7},
url = {https://www.sciencedirect.com/science/article/pii/0167819195000097},
author = {M.M. Shearer},
keywords = {Finite-difference method, Partial differential equation, CM5, Distributed memory multiprocessor, Optimization, Data partitioning, Performance},
abstract = {Techniques used to optimize a finite-difference program on a Thinking Machines' CM5 parallel processing system are presented. These techniques are discussed within several categories: vector unit optimization, separation of communications and computations, and optimal data partitioning. A simplified model is employed to illustrate these concepts. The results of applying these techniques to a more complicated finite-difference calculation are also reported.}
}
@article{SHENHAV2022,
title = {Using Community Ecology Theory and Computational Microbiome Methods To Study Human Milk as a Biological System},
journal = {mSystems},
volume = {7},
number = {1},
year = {2022},
issn = {2379-5077},
doi = {https://doi.org/10.1128/msystems.01132-21},
url = {https://www.sciencedirect.com/science/article/pii/S2379507722000873},
author = {Liat Shenhav and Meghan B. Azad and Jack A. Gilbert},
keywords = {computational methods, human microbiome, human milk, chronobiology, community ecology theory, system biology, lactation, breastfeeding},
abstract = {Human milk is a complex and dynamic biological system that has evolved to optimally nourish and protect human infants. Yet, according to a recent priority-setting review, “our current understanding of human milk composition and its individual components and their functions fails to fully recognize the importance of the chronobiology and systems biology of human milk in the context of milk synthesis, optimal timing and duration of feeding, and period of lactation.” We attribute this critical knowledge gap to three major reasons as follows. (i) Studies have typically examined each subsystem of the mother-milk-infant “triad” in isolation and often focus on a single element or component (e.g., maternal lactation physiology or milk microbiome or milk oligosaccharides or infant microbiome or infant gut physiology).
ABSTRACT
Human milk is a complex and dynamic biological system that has evolved to optimally nourish and protect human infants. Yet, according to a recent priority-setting review, “our current understanding of human milk composition and its individual components and their functions fails to fully recognize the importance of the chronobiology and systems biology of human milk in the context of milk synthesis, optimal timing and duration of feeding, and period of lactation” (P. Christian et al., Am J Clin Nutr 113:1063–1072, 2021, https://doi.org/10.1093/ajcn/nqab075). We attribute this critical knowledge gap to three major reasons as follows. (i) Studies have typically examined each subsystem of the mother-milk-infant “triad” in isolation and often focus on a single element or component (e.g., maternal lactation physiology or milk microbiome or milk oligosaccharides or infant microbiome or infant gut physiology). This undermines our ability to develop comprehensive representations of the interactions between these elements and study their response to external perturbations. (ii) Multiomics studies are often cross-sectional, presenting a snapshot of milk composition, largely ignoring the temporal variability during lactation. The lack of temporal resolution precludes the characterization and inference of robust interactions between the dynamic subsystems of the triad. (iii) We lack computational methods to represent and decipher the complex ecosystem of the mother-milk-infant triad and its environment. In this review, we advocate for longitudinal multiomics data collection and demonstrate how incorporating knowledge gleaned from microbial community ecology and computational methods developed for microbiome research can serve as an anchor to advance the study of human milk and its many components as a “system within a system.”}
}
@article{CAKIROGLU2021100888,
title = {Understanding students’ abstractions in block-based programming environments: A performance based evaluation},
journal = {Thinking Skills and Creativity},
volume = {41},
pages = {100888},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100888},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001036},
author = {Ünal Çakıroğlu and İsak Çevik and Engin Köşeli and Merve Aydın},
keywords = {Abstraction, Block-based programming, Computational thinking, Computer science education},
abstract = {Providing computational problems for enhancing students’ abstraction skills and monitoring how students make abstractions is difficult in block-based programming environments (BBPEs). Thus, concrete examples and principles are needed to guide computer science teachers about understanding and enhancing students’ abstractions. This study aims to examine the effect of using block-based coding environments on enhancing secondary school students’ abstraction skills. Referring to the programming knowledge, a rubric was created to analyze the data from screen recordings, observation and interviews were used together to reveal the students’ abstraction performances. The results suggested that students performed high in elimination, focusing and generalization; however, students’ performances were relatively low in customization. Students’ explanations were mostly related the nature of the problems, affordances of BBPE and the programming constructs used in coding. We hope the study will provide insights for the efforts on instructional designs for successful abstraction experiences for young students.}
}
@article{IGLESIAS2011744,
title = {Re-thinking water policy priorities in the Mediterranean region in view of climate change},
journal = {Environmental Science & Policy},
volume = {14},
number = {7},
pages = {744-757},
year = {2011},
note = {Adapting to Climate Change: Reducing Water-related Risks in Europe},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2011.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1462901111000207},
author = {Ana Iglesias and Luis Garrote and Agustin Diz and Jeremy Schlickenrieder and Francisco Martin-Carrasco},
keywords = {Mediterranean, Climate change, Water policy, Adaptation and assessment},
abstract = {Water is scarce in Mediterranean countries: cities are crowded with increasing demand; food is produced with large amounts of water; ecosystems demand more water that is often available; drought affects all. As climate change impacts become more noticeable and costlier, some current water management strategies will not be useful. According to the findings of CIRCE, the areas with limited water resources will increase in the coming decades with major consequences for the way we produce food and we protect ecosystems. Based on these projections this paper discusses water policy priorities for climate change adaptation in the Mediterranean. We first summarise the main challenges to water resources in Mediterranean countries and outline the risks and opportunities for water under climate change based on previous studies. Recognising the difficulty to go from precipitation to water policy, we then present a framework to evaluate water availability in response to natural and management conditions, with an example of application in the Ebro basin that exemplifies other Mediterranean areas. Then we evaluate adaptive capacity to understand the ability of Mediterranean countries to face, respond and recover from climate change impacts on water resources. Social and economic factors are key drivers of inequality in the adaptive capacity across the region. Based on the assessment of impacts and adaptive capacity we suggest thresholds for water policy to respond to climate change and link water scarcity indicators to relevant potential adaptation strategies. Our results suggest the need to further prioritise socially and economically sensitive policies.}
}
@article{LI2024127497,
title = {Fully automated diagnosis of thyroid nodule ultrasound using brain-inspired inference},
journal = {Neurocomputing},
volume = {582},
pages = {127497},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127497},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224002686},
author = {Guanghui Li and Qinghua Huang and Chunying Liu and Guanying Wang and Lingli Guo and Ruonan Liu and Longzhong Liu},
keywords = {Brain-inspired inference, TI-RADS, Deep learning, Knowledge tensor, Thyroid ultrasound},
abstract = {The interpretability of artificial intelligence (AI) based medical diagnostic systems is crucial to make the diagnosis adequately convincible. Deep learning has been extensively investigated and utilized in the area of medical assistance diagnosis in recent decades due to its outstanding performance and objective prediction. However, a huge semantic chasm dividing clinicians and unexplainable deep models emerges. Here we design a brain-inspired inference framework from medical images to explainable features, then to the final diagnostic conclusions. The fast thinking module is responsible for recognizing medical features in ultrasound (US) images, and the slow-thinking module builds a model for inferring from medical features to diagnostic results by constructing a knowledge graph of medical features with tensor decomposition. The whole model infers through intuition and thinking like a human being, and gives the recognized medical image features while inferring the diagnosis, which greatly improves the interpretability of the model. We conducted studies on thyroid cancer diagnoses using US images. The American College of Radiology (ACR) Thyroid Imaging Reporting and Data System (TI-RADS) characteristics are employed as medical features describing thyroid nodules. Our brain-inspired medical inference framework outperforms commonly used deep learning algorithms, with an AUC score of 0.963 (95% confidential interval (CI)=0.923–1.000) for thyroid US image diagnosis. Results indicate that our framework improves diagnostic objectivity and interpretability while providing performance that is better than deep models. Our proposed brain-inspired medical inference framework could improve the efficiency of diagnosis and our technique is performant, objective and interpretable.}
}
@article{GREEN20214139,
title = {Computational biology: Turing’s lessons in simplicity},
journal = {Biophysical Journal},
volume = {120},
number = {19},
pages = {4139-4141},
year = {2021},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2021.08.041},
url = {https://www.sciencedirect.com/science/article/pii/S000634952100727X},
author = {Jeremy B.A. Green},
abstract = {Biophysical modeling of development started with Alan Turing. His two-morphogen reaction-diffusion model was a radical but powerful simplification. Despite its apparent limitations, the model captured real developmental processes that only recently have been validated at the molecular level in many systems. The precision and robustness of reaction-diffusion patterning, despite boundary condition-dependence, remain active areas of investigation in developmental biology.}
}
@article{HSU2021100012,
title = {Behavioral-pattern exploration and development of an instructional tool for young children to learn AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100012},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100012},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X21000060},
author = {Ting-Chia Hsu and Hal Abelson and Natalie Lao and Yu-Han Tseng and Yi-Ting Lin},
keywords = {Artificial intelligence education, Interdisciplinary instructional tool, Behavioral patterns},
abstract = {This study aimed at developing an instructional tool for the artificial intelligence education of young students, and used learning analytics to identify the sequential learning behavioral patterns of students during the process of learning with the instructional tool. The instructional experiment took 9 weeks. The first stage of the course was 5 weeks spent on individual learning of MIT App Inventor and Personal Image Classifier. The second stage was 4 weeks spent on cooperative learning to make a robot car and play a computational thinking board game. In the second stage, the students worked in pairs to make the robot car. Finally, they played the computational thinking board game with the personal image classification application they developed in the first stage and the robot car they made in the second stage. The innovative studies found meaningful behavioral patterns when the young students learned the application of artificial intelligence with the instructional tool developed and proposed in the study.}
}
@article{MELHAM2013129,
title = {Modelling, abstraction, and computation in systems biology: A view from computer science},
journal = {Progress in Biophysics and Molecular Biology},
volume = {111},
number = {2},
pages = {129-136},
year = {2013},
note = {Conceptual Foundations of Systems Biology},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2012.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S0079610712000892},
author = {Tom Melham},
keywords = {Algorithmic biological modelling, Abstraction, Multi-scale modelling, Biological computation},
abstract = {Systems biology is centrally engaged with computational modelling across multiple scales and at many levels of abstraction. Formal modelling, precise and formalised abstraction relationships, and computation also lie at the heart of computer science—and over the past decade a growing number of computer scientists have been bringing their discipline's core intellectual and computational tools to bear on biology in fascinating new ways. This paper explores some of the apparent points of contact between the two fields, in the context of a multi-disciplinary discussion on conceptual foundations of systems biology.}
}
@article{ELLIS2022581,
title = {Comparison of apnoeic oxygen techniques in term pregnant subjects: a computational modelling study},
journal = {British Journal of Anaesthesia},
volume = {129},
number = {4},
pages = {581-587},
year = {2022},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2022.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0007091222003221},
author = {Reena Ellis and Marianna Laviola and Daniel Stolady and Rebecca L. Valentine and Arani Pillai and Jonathan G. Hardman},
keywords = {apnoea, computer simulation, high-flow nasal oxygenation, low-flow nasal oxygenation, obesity in pregnancy, obstetrics},
abstract = {Background
Hypoxaemia during general anaesthesia can cause harm. Apnoeic oxygenation extends safe apnoea time, reducing risk during airway management. We hypothesised that low-flow nasal oxygenation (LFNO) would extend safe apnoea time similarly to high-flow nasal oxygenation (HFNO), whilst allowing face-mask preoxygenation and rescue.
Methods
A high-fidelity, computational, physiological model was used to examine the progression of hypoxaemia during apnoea in virtual models of pregnant women in and out of labour, with BMI of 24–50 kg m−2. Subjects were preoxygenated with oxygen 100% to reach end-tidal oxygen fraction (FE'O2) of 60%, 70%, 80%, or 90%. When apnoea started, HFNO or LFNO was commenced. To simulate varying degrees of effectiveness of LFNO, periglottic oxygen fraction (FgO2) of 21%, 60%, or 100% was configured. HFNO provided FgO2 100% and oscillating positive pharyngeal pressure.
Results
Application of LFNO (FgO2 100%) after optimal preoxygenation (FE'O2 90%) resulted in similar or longer safe apnoea times than HFNO FE'O2 80% in all subjects in labour. For BMI of 24, the time to reach SaO2 90% with LFNO was 25.4 min (FE'O2 90%/FgO2 100%) vs 25.4 min with HFNO (FE'O2 80%). For BMI of 50, the time was 9.9 min with LFNO (FE'O2 90%/FgO2 100%) vs 4.3 min with HFNO (FE'O2 80%). A similar finding was seen in subjects with BMI ≥40 kg m−2 not in labour.
Conclusions
There is likely to be clinical benefit to using LFNO, given that LFNO and HFNO extend safe apnoea time similarly, particularly when BMI ≥40 kg m−2. Additional benefits to LFNO include the facilitation of rescue face-mask ventilation and ability to monitor FE'O2 during preoxygenation.}
}
@article{MCANDREW2020300,
title = {Re-Thinking the Role of Statistics in Informing Heart Team Decisions: A Consensus Distribution Approach},
journal = {Structural Heart},
volume = {4},
number = {4},
pages = {300-301},
year = {2020},
issn = {2474-8706},
doi = {https://doi.org/10.1080/24748706.2020.1782550},
url = {https://www.sciencedirect.com/science/article/pii/S2474870622004997},
author = {Thomas McAndrew and Bjorn Redfors}
}
@article{SHAFIR1994403,
title = {Uncertainty and the difficulty of thinking through disjunctions},
journal = {Cognition},
volume = {50},
number = {1},
pages = {403-430},
year = {1994},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(94)90038-8},
url = {https://www.sciencedirect.com/science/article/pii/0010027794900388},
author = {Eldar Shafir},
abstract = {This paper considers the relationship between decision under uncertainty and thinking through disjunctions. Decision situations that lead to violations of Savage's sure-thing principle are examined, and a variety of simple reasoning problems that often generate confusion and error are reviewed. The common difficulty is attributed to people's reluctance to think through disjunctions. Instead of hypothetically traveling through the branches of a decision tree, it is suggested, people suspend judgement and remain at the node. This interpretation is applied to instances of decision making, information search, deductive and inductive reasoning, probabilistic judgement, games, puzzles and paradoxes. Some implications of the reluctance to think through disjunctions, as well as potential corrective procedures, are discussed.}
}
@article{VAEVER2005137,
title = {Thinking within the spectrum: schizophrenic thought disorder in six Danish pedigrees},
journal = {Schizophrenia Research},
volume = {72},
number = {2},
pages = {137-149},
year = {2005},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2004.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S092099640400132X},
author = {Mette S. Væver and Deborah M. Licht and Lise Møller and Dorthe Perlt and Åge Jørgensen and Peter Handest and Josef Parnas},
keywords = {Formal thought disorder, TDI, Schizophrenia spectrum, Pedigree},
abstract = {Formal thought disorder (FTD), a major symptom of schizophrenia, is known to aggregate in families. Our aim was to examine the specificity of FTD in the schizophrenia spectrum disorders and the hypothesized linear aggregation of FTD within pedigrees. Six individuals with a diagnosis of schizophrenia were identified in the Copenhagen High-Risk study and each pedigree was centered on one of the six original schizophrenic probands' nuclear families. The 329 pedigree members in the study were considered at risk for schizophrenia spectrum disorders because most were genetically related to the originating schizophrenic probands. The participants were administered the Copenhagen Interview of Functional Illness to determine diagnoses and the Thought Disorder Index (TDI) was used to assess FTD. Individuals with a schizophrenia diagnosis had higher global levels of FTD, exhibited more severe types of FTD, and had a qualitatively different type of FTD than did participants with other diagnoses or no mental illness. Individuals with Cluster A diagnoses exhibited more FTD and FTD similar in quality to participants with schizophrenia. These results support the construct of a spectrum of schizophrenia conditions. There was a generally high level of FTD in the pedigrees, in part due to assortative mating in this sample. However, there was no apparent pattern of linear aggregation of FTD within the families.}
}
@article{CAETANO2020287,
title = {Computational design in architecture: Defining parametric, generative, and algorithmic design},
journal = {Frontiers of Architectural Research},
volume = {9},
number = {2},
pages = {287-300},
year = {2020},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2019.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S2095263520300029},
author = {Inês Caetano and Luís Santos and António Leitão},
keywords = {Algorithmic design, Computer-aided design, Computational design, Generative design, Parametric design},
abstract = {Computation-based approaches in design have emerged in the last decades and rapidly became popular among architects and other designers. Design professionals and researchers adopted different terminologies to address these approaches. However, some terms are used ambiguously and inconsistently, and different terms are commonly used to express the same concept. This paper discusses computational design (CD) and proposes an improved and sound taxonomy for a set of key CD terms, namely, parametric, generative, and algorithmic design, based on an extensive literature review from which different definitions by various authors were collected, analyzed, and compared.}
}
@article{BERNAL2015163,
title = {On the role of computational support for designers in action},
journal = {Design Studies},
volume = {41},
pages = {163-182},
year = {2015},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000551},
author = {Marcelo Bernal and John R. Haymaker and Charles Eastman},
keywords = {design knowledge, computer aided design, design automation, computer supported design, design technology},
abstract = {Designers' actions are high-level mechanisms based on heuristics and assumptions learned from professional experience. Significant research has been devoted to understanding these actions as well as finding ways to aid, automate, or augment them with computational support. However, representing and manipulating such tacit knowledge in computational environments remains an open area of research. In this paper, we map designers' actions and relationships to compare them with computational approaches for the generation, evaluation, and selection of design alternatives, and attempt to integrate all of the above. The analysis provides a more thorough understanding of the role of computational approaches in supporting designer actions and identifies challenges and areas of future research.}
}
@article{NOORIGOODARZI2023105449,
title = {Reverse vaccinology approaches to introduce promising immunogenic and drug targets against antibiotic-resistant Neisseria gonorrhoeae: Thinking outside the box in current prevention and treatment},
journal = {Infection, Genetics and Evolution},
volume = {112},
pages = {105449},
year = {2023},
issn = {1567-1348},
doi = {https://doi.org/10.1016/j.meegid.2023.105449},
url = {https://www.sciencedirect.com/science/article/pii/S1567134823000473},
author = {Narjes {Noori Goodarzi} and Soheila Ajdary and Mir Saeed Yekaninejad and Sepideh Fereshteh and Mohammad Reza Pourmand and Farzad Badmasti},
keywords = {Gonorrhea, Reverse vaccinology, Comparative genomics, Essential proteins, Immunogenic targets},
abstract = {Gonorrhea is an urgent antimicrobial resistance threat and its therapeutic options are continuously getting restricted. Moreover, no vaccine has been approved against it so far. Hence, the present study aimed to introduce novel immunogenic and drug targets against antibiotic-resistant Neisseria gonorrhoeae strains. In the first step, the core proteins of 79 complete genomes of N. gonorrhoeae were retrieved. Next, the surface-exposed proteins were evaluated from different aspects such as antigenicity, allergenicity, conservancy, and B-cell and T-cell epitopes to introduce promising immunogenic candidates. Then, the interactions with human Toll-like receptors (TLR-1, 2, and 4), and immunoreactivity to elicit humoral and cellular immune responses were simulated. On the other hand, to identify novel broad-spectrum drug targets, the cytoplasmic and essential proteins were detected. Then, the N. gonorrhoeae metabolome-specific proteins were compared to the drug targets of the DrugBank, and novel drug targets were retrieved. Finally, the protein data bank (PDB) file availability and prevalence among the ESKAPE group and common sexually transmitted infection (STI) agents were assessed. Our analyses resulted in the recognition of ten novel and putative immunogenic targets including murein transglycosylase A, PBP1A, Opa, NlpD, Azurin, MtrE, RmpM, LptD, NspA, and TamA. Moreover, four potential and broad-spectrum drug targets were identified including UMP kinase, GlyQ, HU family DNA-binding protein, and IF-1. Some of the shortlisted immunogenic and drug targets have confirmed roles in adhesion, immune evasion, and antibiotic resistance that can induce bactericidal antibodies. Other immunogenic and drug targets might be associated with the virulence of N. gonorrhoeae as well. Thus, further experimental studies and site-directed mutations are recommended to investigate the role of potential vaccine and drug targets in the pathogenesis of N. gonorrhoeae. It seems that the efforts for proposing novel vaccines and drug targets appear to be paving the way for a prevention-treatment strategy against this bacterium. Additionally, a combination of bactericidal monoclonal antibodies and antibiotics is a promising approach to curing N. gonorrhoeae.}
}
@article{JOSHI2018740,
title = {Are you thinking what I'm thinking? Synchronization of resting fMRI time-series across subjects},
journal = {NeuroImage},
volume = {172},
pages = {740-752},
year = {2018},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.01.058},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918300582},
author = {Anand A. Joshi and Minqi Chong and Jian Li and Soyoung Choi and Richard M. Leahy},
abstract = {We describe BrainSync, an orthogonal transform that allows direct comparison of resting fMRI (rfMRI) time-series across subjects. For this purpose, we exploit the geometry of the rfMRI signal space to propose a novel orthogonal transformation that synchronizes rfMRI time-series across sessions and subjects. When synchronized, rfMRI signals become approximately equal at homologous locations across subjects. The method is based on the observation that rfMRI data exhibit similar connectivity patterns across subjects, as reflected in the pairwise correlations between different brain regions. We show that if the data for two subjects have similar correlation patterns then their time courses can be approximately synchronized by an orthogonal transformation. This transform is unique, invertible, efficient to compute, and preserves the connectivity structure of the original data for all subjects. Analogously to image registration, where we spatially align structural brain images, this temporal synchronization of brain signals across a population, or within-subject across sessions, facilitates cross-sectional and longitudinal studies of rfMRI data. The utility of the BrainSync transform is illustrated through demonstrative simulations and applications including quantification of rfMRI variability across subjects and sessions, cortical functional parcellation across a population, timing recovery in task fMRI data, comparison of task and resting state data, and an application to complex naturalistic stimuli for annotation prediction.}
}
@article{ALONSOSANCHEZ202397,
title = {Language network self-inhibition and semantic similarity in first-episode schizophrenia: A computational-linguistic and effective connectivity approach},
journal = {Schizophrenia Research},
volume = {259},
pages = {97-103},
year = {2023},
note = {Language and Speech Analysis in Schizophrenia and Related Psychoses},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422001608},
author = {María Francisca Alonso-Sánchez and Roberto Limongi and Joseph Gati and Lena Palaniyappan},
keywords = {Psychosis, Lexical access, fMRI, Spectral dynamic causal modelling, Broca's area, Disorganization, Formal thought disorder},
abstract = {Introduction
A central feature of schizophrenia is the disorganization and impoverishment of language. Recently, we observed higher semantic similarity in first-episode-schizophrenia (FES) patients. In this study, we investigate if this aberrant similarity relates to the ‘causal’ connectivity between two key nodes of the word production system: inferior frontal gyrus (IFG) and the semantic-hub at the ventral anterior temporal lobe (vATL).
Methods
Resting-state fMRI scans were collected from 60 participants (30 untreated FES and 30 healthy controls). The semantic distance was measured with the CoVec semantic tool based on GloVe. A spectral dynamic causal model with Parametrical Empirical Bayes was constructed modelling the intrinsic self-inhibitory and extrinsic-excitatory connections within the brain regions. We estimated the parameters of a fully connected model with the semantic distance as a covariate.
Results
FES patients chose words with higher semantic similarity when describing the pictures compared to the HC group. Among patients, an increased semantic similarity was related with an increase in intrinsic connections within both the vATL and IFG, suggesting that reduced ‘synaptic gain’ in these regions likely contribute to aberrant sampling of the semantic space during discourse in schizophrenia.
Conclusions
Lexical impoverishment relates to increased self-inhibition in both the IFG and vATL. The associated reduction in synaptic gain may relate to reduced precision of locally generated neural activity, forcing the choice of words that are already ‘activated’ in a lexical network. One approach to improve word sampling may be via promoting synaptic gain via supra-physiological stimulation within the Broca's-vATL network; this proposal needs verification.}
}
@incollection{BAXTER20033,
title = {On the Foundations of Computational Mathematics},
series = {Handbook of Numerical Analysis},
publisher = {Elsevier},
volume = {11},
pages = {3-34},
year = {2003},
booktitle = {Handbook of Numerical Analysis},
issn = {1570-8659},
doi = {https://doi.org/10.1016/S1570-8659(02)11001-5},
url = {https://www.sciencedirect.com/science/article/pii/S1570865902110015},
author = {B.J.C. Baxter and A. Iserles},
abstract = {Publisher Summary
This chapter discusses the interaction of computational numerical with pure mathematics.. As far as computer scientists are concerned, their genuine “interface of interaction” with numerical thinking is in two distinct areas: complexity theory and high-performance computing. While complexity theory has always been a glamourous activity in theoretical computer science, it has only recently emerged as a focus of concerted activity in numerical circles, occasionally leading to a measure of acrimony. It is to be hoped that, eventually, computer scientists will find complexity issues involving real-number computations to be challenging, worthwhile, and central to the understanding of theoretical computation. Likewise, the ongoing development of parallel computer architectures and the computational grid is likely to lead to considerably better numerical/computational interaction at the more practical, engineering-oriented end.}
}
@article{BOOKER2004331,
title = {Solving black box computation problems using expert knowledge theory and methods},
journal = {Reliability Engineering & System Safety},
volume = {85},
number = {1},
pages = {331-340},
year = {2004},
note = {Alternative Representations of Epistemic Uncertainty},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2004.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0951832004000705},
author = {Jane M Booker and Laura A McNamara},
keywords = {Expert judgment, Elicitation, Probability theory, Epistemic uncertainty},
abstract = {The challenge problems for the Epistemic Uncertainty Workshop at Sandia National Laboratories provide common ground for comparing different mathematical theories of uncertainty, referred to as General Information Theories (GITs). These problems also present the opportunity to discuss the use of expert knowledge as an important constituent of uncertainty quantification. More specifically, how do the principles and methods of eliciting and analyzing expert knowledge apply to these problems and similar ones encountered in complex technical problem solving and decision making? We will address this question, demonstrating how the elicitation issues and the knowledge that experts provide can be used to assess the uncertainty in outputs that emerge from a black box model or computational code represented by the challenge problems. In our experience, the rich collection of GITs provides an opportunity to capture the experts' knowledge and associated uncertainties consistent with their thinking, problem solving, and problem representation. The elicitation process is rightly treated as part of an overall analytical approach, and the information elicited is not simply a source of data. In this paper, we detail how the elicitation process itself impacts the analyst's ability to represent, aggregate, and propagate uncertainty, as well as how to interpret uncertainties in outputs. While this approach does not advocate a specific GIT, answers under uncertainty do result from the elicitation.}
}
@article{LAMPRECHT20151927,
title = {Scientific Workflows with XMDD: A Way to Use Process Modeling in Computational Science Education},
journal = {Procedia Computer Science},
volume = {51},
pages = {1927-1936},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.457},
url = {https://www.sciencedirect.com/science/article/pii/S187705091501265X},
author = {Anna-Lena Lamprecht and Tiziana Margaria},
keywords = {Process modeling, Scientific workflows, Computational science, Model-driven development},
abstract = {Process models are well suited to describe in a formal but still intuitive fashion what a system should do. They can thus play a central role in problem-based computational science education with regard to qualifying students for the design and implementation of software applications for their specific needs without putting the focus on the technical part of coding. eXtreme Model Driven Design (XMDD) is a software development paradigm that explicitly focuses on the What (solving problems) rather than on the How (the technical skills of writing code). In this paper we describe how we apply an XMDD-based process modeling and execution framework for scientific workflow projects in the scope of a computer science course for students with a background in natural sciences.}
}
@incollection{SCHLESINGER2020337,
title = {Computational Models of Development},
editor = {Janette B. Benson},
booktitle = {Encyclopedia of Infant and Early Childhood Development (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {337-346},
year = {2020},
isbn = {978-0-12-816511-9},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23615-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245236158},
author = {Matthew Schlesinger},
keywords = {Computational model, Connectionist model, Artificial neural network, Learning algorithm, Symbolic versus sub-symbolic representations, Adaptive versus static, Learning mechanism, Rule-based model, Dynamic field theory model, Bayesian model, Developmental pattern},
abstract = {Conventional research methods for investigating development are powerful and diverse, but they also have their limits. Many of these limitations can be overcome or addressed through computer modeling. To help make this argument, the current chapter provides a broad, accessible overview to the study of computational models of learning and development. First, we explore the technical vocabulary of computational modeling research by reviewing a set of basic concepts, including the different kinds of representations that are employed by computational models, as well as the array of learning algorithms that are typically used. Next, we review four major types of models: connectionist models, dynamic field theory models, rule-based models, and Bayesian models. In the final section, we put these concepts and approaches into practice by surveying findings from models that simulate the development of object knowledge, language learning, and motor-skill acquisition.}
}
@article{WOLFENGAGEN2016306,
title = {Computational Model of the Tangled Web},
journal = {Procedia Computer Science},
volume = {88},
pages = {306-311},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.440},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916316969},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey Kosikov},
keywords = {event-driven computations, scripts, vulnerability, information security, computational model, tangled web},
abstract = {In this paper we attempt to build computational models of entanglement among the event-driven computations. The proposed model operates on the notion of dynamics of the events. This allows selection of entanglement zone that characterizes the area of risks where possible vulnerability and, as a consequence, security violations of web application arise. All constructions for objects are treated as virtual objects. The stated range of issues focuses on computational technologies used scripts, though other explanatory systems are admissible as well but within other appropriate contexts.}
}
@article{ROLLWAGE2019820,
title = {What Underlies Political Polarization? A Manifesto for Computational Political Psychology},
journal = {Trends in Cognitive Sciences},
volume = {23},
number = {10},
pages = {820-822},
year = {2019},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2019.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661319301810},
author = {Max Rollwage and Leor Zmigrod and Lee de-Wit and Raymond J. Dolan and Stephen M. Fleming},
keywords = {political psychology, computational modeling, cognitive styles, behavioral tasks, radicalism, polarization},
abstract = {Polarization is one of the biggest societal challenges of our time, yet its drivers are poorly understood. Here we propose a novel approach – computational political psychology – which uses behavioral tasks in combination with formal computational models to identify candidate cognitive processes underpinning susceptibility to polarized beliefs about political and societal issues.}
}
@incollection{COUCLELIS2020357,
title = {Computational Human Geography},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {357-363},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10619-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955106195},
author = {Helen Couclelis},
keywords = {Agent-based models, Ambient computing, Cellular automata, Computer modeling, Data revolution, GIS, Geocomputation, Simulation, Urban informatics, Visualization},
abstract = {Computational human geography refers to the use of computational methods and techniques to solve problems in human geography research and applications. The approach goes back to the beginnings of the quantitative revolution in geography and is philosophically related though methodologically distinct from it. Geographic information systems (GIS) and science are a big part of computational human geography, but the latter notion is considerably broader, encompassing spatial process modeling and simulation, the modeling of spatial decision and behavior, visualization techniques, spatial analysis, and an increasing number of new research areas and methods enabled by the most recent technological developments. The latter are discussed under the rubrics of The Data Revolution, Urban (Spatial) Informatics, and Ambient Computing. Two major thrusts have persisted throughout the years: the use of numerical techniques to solve large, complex quantitative problems; the development of models of complex spatial processes expressed directly in computational terms. Both have evolved with the times and continue to be central to computational human geography. Critiques originate from both within the field and from the humanities and social theory perspectives. These address epistemological and methodological problems as well as issues of ontology and representation.}
}
@article{SERIES202466,
title = {Can computational models help elucidate the link between complex trauma and hallucinations?},
journal = {Schizophrenia Research},
volume = {265},
pages = {66-73},
year = {2024},
note = {Hallucinations: Neurobiology and Patient Experience},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2023.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0920996423001834},
author = {Peggy Seriès and Emilie Veerapa and Renaud Jardri},
keywords = {Trauma, Voice hearing, Belief, Inference, Predictive coding, Bayesian models},
abstract = {Recently, a number of predictive coding models have been proposed to account for post-traumatic stress disorder (PTSD)'s symptomatology, including intrusions, flashbacks and hallucinations. These models were usually developed to account for traditional/type-1 PTSD. We here discuss whether these models also apply or can be translated to the case of complex/type-2 PTSD and childhood trauma (cPTSD). The distinction between PTSD and cPTSD is important because the disorders differ in terms of symptomatology and potential mechanisms, how they relate to developmental stages, but also in terms of illness trajectory and treatment. Models of complex trauma could give us insights on hallucinations in physiological/pathological conditions or more generally on the development of intrusive experiences across diagnostic classes.}
}
@incollection{JUNG2023198,
title = {Design-based education in STEM: for learners of the 21st century},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {198-206},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.13077-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305130775},
author = {Yong Ju Jung and Gi Woong Choi and Soo Hyeon Kim},
keywords = {Design-based education, Design thinking, Digital media creation, Engineering design, Makerspaces, STEM+C education, STEM education, 21st century learning},
abstract = {This article aims to conceptualize design-based education (DBE) in STEM educational settings and provide examples of current DBE practices followed by discussing the gaps of current DBE. We define DBE as educational theory and practice that integrate and transform design processes and design thinking into learning experiences. DBE is well-aligned with the 21st century STEM education because it can enhance learner-centered pedagogy, learners' critical thinking, collaboration, interest-driven learning, and integrative STEM learning. More attention to concrete strategies for the integrative STEM education in DBE and systems of preparing educators for DBE is needed for better learning experiences.}
}
@article{DRUKARCH2018172,
title = {Thinking about the nerve impulse: A critical analysis of the electricity-centered conception of nerve excitability},
journal = {Progress in Neurobiology},
volume = {169},
pages = {172-185},
year = {2018},
issn = {0301-0082},
doi = {https://doi.org/10.1016/j.pneurobio.2018.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0301008218300509},
author = {Benjamin Drukarch and Hanna A. Holland and Martin Velichkov and Jeroen J.G. Geurts and Pieter Voorn and Gerrit Glas and Henk W. {de Regt}},
keywords = {Nerve impulse, Action potential, Electromechanical pulse, Signal propagation, Hodgkin-Huxley model, Neuroscientific models},
abstract = {Nerve impulse generation and propagation are often thought of as solely electrical events. The prevalence of this view is the result of long and intense study of nerve impulses in electrophysiology culminating in the introduction of the Hodgkin-Huxley model of the action potential in the 1950s. To this day, this model forms the physiological foundation for a broad area of neuroscientific research. However, the Hodgkin-Huxley model cannot account for non-electrical phenomena that accompany nerve impulse propagation, for which there is nevertheless ample evidence. This raises the question whether the Hodgkin-Huxley model is a complete model of the nerve impulse. Several alternative models have been proposed that do take into account non-electrical aspects of the nerve impulse and emphasize their importance in gaining a more complete understanding of the nature of the nerve impulse. In our opinion, these models deserve more attention in neuroscientific research, since, together with the Hodgkin-Huxley model, they will help in addressing and solving a number of questions in basic and applied neuroscience which thus far have remained outside our grasp. Here we provide a historico-scientific overview of the developments that have led to the current conception of the action potential as an electrical phenomenon, discuss some major objections against this conception, and suggest a number of scientific factors which have likely contributed to the enduring success of the Hodgkin-Huxley model and should be taken into consideration whilst contemplating the formulation of a more extensive and complete conception of the nerve impulse.}
}
@article{PETERS2022104903,
title = {Towards characterizing the canonical computations generating phenomenal experience},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {142},
pages = {104903},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104903},
url = {https://www.sciencedirect.com/science/article/pii/S014976342200392X},
author = {Megan A.K. Peters},
keywords = {Metacognition, Consciousness, Computational modeling, Phenomenology, Qualia},
abstract = {Science and philosophy have long struggled with how to even begin studying the neural or computational basis of qualitative experience. Here I review psychological, neuroscience, and philosophical literature to reveal how perceptual metacognition possesses five unique properties that provide a powerful opportunity for studying the neural and computational correlates of subjective experience: (1) Metacognition leads to subjective experiences (we “feel” confident); (2) Metacognition is “about” internal representations, formalizing introspection; (3) Metacognitive computations are “recursive” (applying to meta-cognition and meta-meta-cognition), so we might discover “canonical computations” preserved across processing levels and implementations; (4) Metacognition is anchored to observable behavior; and (5) Metacognitive computations are unobservable yet hierarchically dependent, requiring development of sensitive, specific models. Given these properties, computational models of metacognition provide an empirically-tractable early step in characterizing the generative process that constructs qualitative experience. I also present practical ways to make progress in this vein, applying decades of developments in nearby fields to perceptual metacognition to reveal new and exciting insights about how the brain constructs subjective conscious experiences.}
}
@article{CHUNG200896,
title = {Revealing dimensions of thinking in open-ended self-descriptions: An automated meaning extraction method for natural language},
journal = {Journal of Research in Personality},
volume = {42},
number = {1},
pages = {96-132},
year = {2008},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2007.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0092656607000451},
author = {Cindy K. Chung and James W. Pennebaker},
keywords = {LIWC, Meaning extraction method, Natural language, Self-descriptions},
abstract = {A new method for extracting common themes from written text is introduced and applied to 1165 open-ended self-descriptive narratives. Drawing on a lexical approach to personality, the most commonly-used adjectives within narratives written by college students were identified using computerized text analytic tools. A factor analysis on the use of these adjectives in the self-descriptions produced a 7-factor solution consisting of psychologically meaningful dimensions. Some dimensions were unipolar (e.g., Negativity factor, wherein most loaded items were negatively valenced adjectives); others were dimensional in that semantically opposite words clustered together (e.g., Sociability factor, wherein terms such as shy, outgoing, reserved, and loud all loaded in the same direction). The factors exhibited modest reliability across different types of writing samples and were correlated with self-reports and behaviors consistent with the dimensions. Similar analyses with additional content words (adjectives, adverbs, nouns, and verbs) yielded additional psychological dimensions associated with physical appearance, school, relationships, etc. in which people contextualize their self-concepts. The results suggest that the meaning extraction method is a promising strategy that determines the dimensions along which people think about themselves.}
}
@article{AUGELLO201674,
title = {Artwork creation by a cognitive architecture integrating computational creativity and dual process approaches},
journal = {Biologically Inspired Cognitive Architectures},
volume = {15},
pages = {74-86},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2015.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X1500050X},
author = {Agnese Augello and Ignazio Infantino and Antonio Lieto and Giovanni Pilato and Riccardo Rizzo and Filippo Vella},
keywords = {Computational creativity, Cognitive architecture, Dual process theory, PSI model},
abstract = {The paper proposes a novel cognitive architecture (CA) for computational creativity based on the Psi model and on the mechanisms inspired by dual process theories of reasoning and rationality. In recent years, many cognitive models have focused on dual process theories to better describe and implement complex cognitive skills in artificial agents, but creativity has been approached only at a descriptive level. In previous works we have described various modules of the cognitive architecture that allows a robot to execute creative paintings. By means of dual process theories we refine some relevant mechanisms to obtain artworks, and in particular we explain details about resolution level of the CA dealing with different strategies of access to the Long Term Memory (LTM) and managing the interaction between S1 and S2 processes of the dual process theory. The creative process involves both divergent and convergent processes in either implicit or explicit manner. This leads to four activities (exploratory, reflective, tacit, and analytic) that, triggered by urges and motivations, generate creative acts. These creative acts exploit both the LTM and the WM in order to make novel substitutions to a perceived image by properly mixing parts of pictures coming from different domains. The paper highlights the role of the interaction between S1 and S2 processes, modulated by the resolution level which focuses the attention of the creative agent by broadening or narrowing the exploration of novel solutions, or even drawing the solution from a set of already made associations. An example of artificial painter is described in some experimentations by using a robotic platform.}
}
@article{BACELARALMEIDA2022100736,
title = {A formal treatment of the role of verified compilers in secure computation},
journal = {Journal of Logical and Algebraic Methods in Programming},
volume = {125},
pages = {100736},
year = {2022},
issn = {2352-2208},
doi = {https://doi.org/10.1016/j.jlamp.2021.100736},
url = {https://www.sciencedirect.com/science/article/pii/S2352220821000997},
author = {José Carlos {Bacelar Almeida} and Manuel Barbosa and Gilles Barthe and Hugo Pacheco and Vitor Pereira and Bernardo Portela},
keywords = {Secure multiparty computation, Secure compilation, Certified compilation, Formal verification, EasyCrypt, Computer-aided cryptography},
abstract = {Secure multiparty computation (SMC) allows for complex computations over encrypted data. Privacy concerns for cloud applications makes this a highly desired technology and recent performance improvements show that it is practical. To make SMC accessible to non-experts and empower its use in varied applications, many domain-specific compilers are being proposed. We review the role of these compilers and provide a formal treatment of the core steps that they perform to bridge the abstraction gap between high-level ideal specifications and efficient SMC protocols. Our abstract framework bridges this secure compilation problem across two dimensions: 1) language-based source- to target-level semantic and efficiency gaps, and 2) cryptographic ideal- to real-world security gaps. We link the former to the setting of certified compilation, paving the way to leverage long-run efforts such as CompCert in future SMC compilers. Security is framed in the standard cryptographic sense. Our results are supported by a machine-checked formalisation carried out in EasyCrypt.}
}
@article{CHRISTOU2001321,
title = {Mapping and development of intuitive proportional thinking},
journal = {The Journal of Mathematical Behavior},
volume = {20},
number = {3},
pages = {321-336},
year = {2001},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00077-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302000779},
author = {Constantinos Christou and George Philippou},
keywords = {Multiplicative problems, Conceptual field, Cardinalities},
abstract = {The purpose of this study was two-fold. First, to find out students’ informal understanding of proportional problems, and discuss their solution strategies. Second, to investigate how the intuitions developed by students influence their strategies to solve proportional problems. To this end, we interviewed 16 students in Grades 4 and 5, while they were solving proportional problems. It was found that students intuitively used the unit-rate strategy indicating an attempt to transfer the knowledge resulted by their experience with solving simple multiplicative problems. Fourth and fifth graders tended to shift from the unit-rate strategy to other strategies if there was no easy way to calculate the unit-value directly from the context of the problems. Since fifth graders were more comfortable than fourth graders in calculating the unit-value, they felt less the need to invent other solution strategies.}
}
@article{CUI2021412,
title = {Artificial intelligence and computational pathology},
journal = {Laboratory Investigation},
volume = {101},
number = {4},
pages = {412-422},
year = {2021},
issn = {0023-6837},
doi = {https://doi.org/10.1038/s41374-020-00514-0},
url = {https://www.sciencedirect.com/science/article/pii/S0023683722006468},
author = {Miao Cui and David Y. Zhang},
abstract = {Data processing and learning has become a spearhead for the advancement of medicine, with pathology and laboratory medicine has no exception. The incorporation of scientific research through clinical informatics, including genomics, proteomics, bioinformatics, and biostatistics, into clinical practice unlocks innovative approaches for patient care. Computational pathology is burgeoning subspecialty in pathology that promises a better-integrated solution to whole-slide images, multi-omics data, and clinical informatics. However, computational pathology faces several challenges, including the ability to integrate raw data from different sources, limitation of hardware processing capacity, and a lack of specific training programs, as well as issues on ethics and larger societal acceptable practices that are still solidifying. The establishment of the entire industry of computational pathology requires far-reaching changes of the three essential elements connecting patients and doctors: the local laboratory, the scan center, and the central cloud hub/portal for data processing and retrieval. Computational pathology, unlocked through information integration and advanced digital communication networks, has the potential to improve clinical workflow efficiency, diagnostic quality, and ultimately create personalized diagnosis and treatment plans for patients. This review describes clinical perspectives and discusses the statistical methods, clinical applications, potential obstacles, and future directions of computational pathology.}
}
@article{VUQUOC20231069,
title = {Deep Learning Applied to Computational Mechanics: A Comprehensive Review, State of the Art, and the Classics},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {137},
number = {2},
pages = {1069-1343},
year = {2023},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.028130},
url = {https://www.sciencedirect.com/science/article/pii/S1526149223002412},
author = {Loc Vu-Quoc and Alexander Humer},
keywords = {, breakthroughs, network architectures, backpropagation, stochastic optimization methods from classic to modern, recurrent neural networks, long short-term memory, gated recurrent unit, attention, transformer, kernel machines, Gaussian processes, libraries, Physics-Informed Neural Networks, state-of-the-art, history, limitations, challenges, , Finite-element matrix integration, improved Gauss quadrature, Multiscale geomechanics, fluid-filled porous media, Fluid mechanics, turbulence, proper orthogonal decomposition, , autoencoder, hyper-reduction using gappy data, control of large deformable beam},
abstract = {Three recent breakthroughs due to AI in arts and science serve as motivation: An award winning digital image, protein folding, fast matrix multiplication. Many recent developments in artificial neural networks, particularly deep learning (DL), applied and relevant to computational mechanics (solid, fluids, finite-element technology) are reviewed in detail. Both hybrid and pure machine learning (ML) methods are discussed. Hybrid methods combine traditional PDE discretizations with ML methods either (1) to help model complex nonlinear constitutive relations, (2) to nonlinearly reduce the model order for efficient simulation (turbulence), or (3) to accelerate the simulation by predicting certain components in the traditional integration methods. Here, methods (1) and (2) relied on Long-Short-Term Memory (LSTM) architecture, with method (3) relying on convolutional neural networks. Pure ML methods to solve (nonlinear) PDEs are represented by Physics-Informed Neural network (PINN) methods, which could be combined with attention mechanism to address discontinuous solutions. Both LSTM and attention architectures, together with modern and generalized classic optimizers to include stochasticity for DL networks, are extensively reviewed. Kernel machines, including Gaussian processes, are provided to sufficient depth for more advanced works such as shallow networks with infinite width. Not only addressing experts, readers are assumed familiar with computational mechanics, but not with DL, whose concepts and applications are built up from the basics, aiming at bringing first-time learners quickly to the forefront of research. History and limitations of AI are recounted and discussed, with particular attention at pointing out misstatements or misconceptions of the classics, even in well-known references. Positioning and pointing control of a large-deformable beam is given as an example.}
}
@article{STUPURIENE2024104939,
title = {Teachers’ perceptions of the barriers and drivers for the integration of Informatics in primary education},
journal = {Computers & Education},
volume = {208},
pages = {104939},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104939},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002166},
author = {Gabrielė Stupurienė and Margarida Lucas and Pedro Bem-Haja},
keywords = {Primary education, Teacher professional development, Thematic analysis, Network analysis, Informatics education},
abstract = {A growing trend of integrating and teaching Informatics and Computational Thinking (CT) skills at primary education levels poses different challenges for teachers. Research demonstrates that it is challenging to introduce Informatics in schools without well-prepared teachers. In this paper, we examine Lithuanian teachers' perceptions of the barriers and drivers to integrate the renewed Informatics curricula in primary education and the relation between them. Fifteen semi-structured interviews were conducted with primary school teachers, and a mixed-methods approach was employed to analyze them. The results show that explicit guidelines for renewed curricula and motivation to learn Informatics are both identified as the main barriers and drivers for integrating Informatics. The study further highlights the critical role of resources, appropriate tools, and guidelines in facilitating the successful implementation of Informatics. The study provides knowledge that could, for instance, benefit teacher training programmes and help better understand how teachers can be better supported to meet current and future challenges.}
}
@article{CHAKRABORTY2021113486,
title = {Conformations and tautomerisation between (Z)-4-(hydroxyethyl) isochroman-1, 3-dione and and 4-acetyl-3-hydroxyisochroman-1-one: A computational study through Energy, electron Distribution, vibrational analysis and hardness profiles},
journal = {Computational and Theoretical Chemistry},
volume = {1206},
pages = {113486},
year = {2021},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2021.113486},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X21003443},
author = {Abhijit Chakraborty and Goutam Dey},
keywords = {, , (Z)-4-(hydroxyethyl) isochroman-1, 3-dione, , , },
abstract = {The saturated and unsaturated rings in the tautomers of (Z)-4-(hydroxyethyl) isochroman-1, 3-dione (EIC) and 4-acetyl-3-hydroxyisochroman-1-one (AOC) are found to be nonplanar. All the DFT and ab-initio computational methods with various basis sets identify EIC as the global minimum in S0. IRC and frequency computations locate the transition states (TS). AOC and TS are located about 3.5 ± 0.5 kcal/mole and 4.5 ± 0.8 kcal/mole higher in energy than EIC. The transition region is clearly marked with the evaluation of reaction force and force constants. CIS and TDDFT computations show inconsistent results. MHP is obeyed by the EIC tautomer, while MEP is obeyed by the TS structure. Frontier molecular orbitals confirms the S0 → S1 transition as π-π* in nature. The vibrational signatures in the tautomers corresponding to CO stretching modes and ring modes are identified. The earlier observed 1740 cm-1C = O stretching mode is computed to appear at 1763 cm−1 in EIC.}
}
@article{ARBELAEZOSSA2023102458,
title = {A smarter perspective: Learning with and from AI-cases},
journal = {Artificial Intelligence in Medicine},
volume = {135},
pages = {102458},
year = {2023},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2022.102458},
url = {https://www.sciencedirect.com/science/article/pii/S093336572200210X},
author = {Laura {Arbelaez Ossa} and Michael Rost and Giorgia Lorenzini and David M. Shaw and Bernice Simone Elger},
keywords = {Medical education, Artificial intelligence, Case-based learning, Critical thinking, Ethics},
abstract = {Artificial intelligence (AI) has only partially (or not at all) been integrated into medical education, leading to growing concerns regarding how to train healthcare practitioners to handle the changes brought about by the introduction of AI. Programming lessons and other technical information into healthcare curricula has been proposed as a solution to support healthcare personnel in using AI or other future technology. However, integrating these core elements of computer science knowledge might not meet the observed need that students will benefit from gaining practical experience with AI in the direct application area. Therefore, this paper proposes a dynamic approach to case-based learning that utilizes the scenarios where AI is currently used in clinical practice as examples. This approach will support students' understanding of technical aspects. Case-based learning with AI as an example provides additional benefits: (1) it allows doctors to compare their thought processes to the AI suggestions and critically reflect on the assumptions and biases of AI and clinical practice; (2) it incentivizes doctors to discuss and address ethical issues inherent to technology and those already existing in current clinical practice; (3) it serves as a foundation for fostering interdisciplinary collaboration via discussion of different views between technologists, multidisciplinary experts, and healthcare professionals. The proposed knowledge shift from AI as a technical focus to AI as an example for case-based learning aims to encourage a different perspective on educational needs. Technical education does not need to compete with other essential clinical skills as it could serve as a basis for supporting them, which leads to better medical education and practice, ultimately benefiting patients.}
}
@article{SPREVAK2010260,
title = {Computation, individuation, and the received view on representation},
journal = {Studies in History and Philosophy of Science Part A},
volume = {41},
number = {3},
pages = {260-270},
year = {2010},
note = {Computation and cognitive science},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2010.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0039368110000403},
author = {Mark Sprevak},
keywords = {Computation, Representation, Computational identity, Explanation, Narrow content, Physical computation},
abstract = {The ‘received view’ about computation is that all computations must involve representational content. Egan and Piccinini argue against the received view. In this paper, I focus on Egan’s arguments, claiming that they fall short of establishing that computations do not involve representational content. I provide positive arguments explaining why computation has to involve representational content, and how that representational content may be of any type (distal, broad, etc.). I also argue (contra Egan and Fodor) that there is no need for computational psychology to be individualistic. Finally, I draw out a number of consequences for computational individuation, proposing necessary conditions on computational identity and necessary and sufficient conditions on computational I/O equivalence of physical systems.}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{TUTHILL2020R739,
title = {What we think about when we think about thinking},
journal = {Current Biology},
volume = {30},
number = {13},
pages = {R739-R740},
year = {2020},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2020.05.034},
url = {https://www.sciencedirect.com/science/article/pii/S0960982220306734},
author = {John Tuthill}
}
@article{WOLFRAM2020101132,
title = {What We’ve built Is a computational language (and that’s very important!)},
journal = {Journal of Computational Science},
volume = {46},
pages = {101132},
year = {2020},
note = {20 years of computational science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101132},
url = {https://www.sciencedirect.com/science/article/pii/S1877750320304336},
author = {Stephen Wolfram}
}
@article{MUKHERJEE2025111865,
title = {Empowering through mentorship: The journey of women in interdisciplinary science},
journal = {iScience},
volume = {28},
number = {3},
pages = {111865},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.111865},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225001257},
author = {Uttama Mukherjee and Ramya Kormath Madam Raghupathy and Minal Sachin Pednekar and Sradha Jayan},
abstract = {In this backstory, we feature four remarkable women in science who have collaborated with Prof. Arun Venkatnathan (referred to in this piece as Prof. Arun) from Indian Institute of Science Education and Research (IISER)-Pune at various stages of their careers and reflect on the importance of mentorship to foster interdisciplinary thinking. In his career, Prof. Arun has advocated for the importance of gender diversity and women empowerment and has incorporated this work into the development of his research program. This piece highlights the pivotal role of skilled mentorship as the cornerstone of a successful scientific career. The interview delves into how mentorship is essential in building scientists’ confidence and fostering an environment of mutual respect. This supportive atmosphere encourages collaboration and interdisciplinary thinking, helping researchers navigate the challenges of cross-disciplinary communication and acquire new skills. Ultimately, success in interdisciplinary research demands motivation, continuous learning, unwavering passion, and encouragement.}
}
@article{PREISIG201259,
title = {Thinking Towards Synergistic Green Refineries},
journal = {Energy Procedia},
volume = {20},
pages = {59-67},
year = {2012},
note = {Technoport 2012 - Sharing Possibilities and 2nd Renewable Energy Research Conference (RERC2012)},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2012.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S1876610212007382},
author = {Heinz A. Preisig and Bernd Wittgens},
keywords = {Bioreﬁnery, Green reﬁnery, Biobased Economy},
abstract = {The switch from a mined-carbon-based society to a bio-carbon based society requires a major shift not only of the resources,but alsoin the typeof processes that produce the products on which ourcivilizationbuilds;a richer approach to handling and production is required. Natural products from renewable sources will substitute today'spurely synthetic products from fossil resources, associated waste streams will have to be utilized for the production of usable materials, with chemical processing being one of the main options.Fuel represents a main class of chemicals that we increasingly rely on. They have to be substituted as quick as possible as they represent the largest use of mined carbon. The paper presents some of the stumbling blocks which prohibit the transfer and high lights the most needed research objectives.}
}
@article{DINOV2008284,
title = {Pedagogical utilization and assessment of the statistic online computational resource in introductory probability and statistics courses},
journal = {Computers & Education},
volume = {50},
number = {1},
pages = {284-300},
year = {2008},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2006.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0360131506001059},
author = {Ivo D. Dinov and Juana Sanchez and Nicolas Christou},
keywords = {Education research, Teaching with technology, Java applets, Online course materials, Probability and statistics},
abstract = {Technology-based instruction represents a new recent pedagogical paradigm that is rooted in the realization that new generations are much more comfortable with, and excited about, new technologies. The rapid technological advancement over the past decade has fueled an enormous demand for the integration of modern networking, informational and computational tools with classical pedagogical instruments. Consequently, teaching with technology typically involves utilizing a variety of IT and multimedia resources for online learning, course management, electronic course materials, and novel tools of communication, engagement, experimental, critical thinking, and assessment. The NSF-funded Statistics Online Computational Resource (SOCR) provides a number of interactive tools for enhancing instruction in various undergraduate and graduate courses in probability and statistics. These resources include online instructional materials, statistical calculators, interactive graphical user interfaces, computational and simulation applets, tools for data analysis and visualization. The tools provided as part of SOCR include conceptual simulations and statistical computing interfaces, which are designed to bridge between the introductory and the more advanced computational and applied probability and statistics courses. In this manuscript, we describe our designs for utilizing SOCR technology in instruction in a recent study. In addition, present the results of the effectiveness of using SOCR tools at two different course intensity levels on three outcome measures: exam scores, student satisfaction and choice of technology to complete assignments. Learning styles assessment was completed at baseline. We have used three very different designs for three different undergraduate classes. Each course included a treatment group, using the SOCR resources, and a control group, using classical instruction techniques. Our findings include marginal effects of the SOCR treatment per individual classes; however, pooling the results across all courses and sections, SOCR effects on the treatment groups were exceptionally robust and significant. Coupling these findings with a clear decrease in the variance of the quantitative examination measures in the treatment groups indicates that employing technology, like SOCR, in a sound pedagogical and scientific manner enhances overall the students’ understanding and suggests better long-term knowledge retention.}
}
@article{PATON199363,
title = {Some computational models at the cellular level},
journal = {Biosystems},
volume = {29},
number = {2},
pages = {63-75},
year = {1993},
issn = {0303-2647},
doi = {https://doi.org/10.1016/0303-2647(93)90084-P},
url = {https://www.sciencedirect.com/science/article/pii/030326479390084P},
author = {Ray C. Paton},
keywords = {Computational models of the cell, Levels of organisation, Systemic metaphors},
abstract = {A number of viewpoints on how a cell can be modelled are discussed in this paper in light of the ability it has to process information. The paper begins with a very brief summary of four general types of computation: sequential, parallel, distributed, and emergent. These form the general framework from which a number of comparisons are made. Several metaphors are introduced to enable reflections to be made about cellular computational properties. The most important metaphor, namely the cell as a machine, is discussed, and then a number of other ideas are introduced that complement much current thinking in this area. The idea of networks or circuits in the cell is then developed, as this provides a means of describing the mechanisms within a machine. Following on from this, three further metaphors are applied in order to overcome certain limitations in current machine thinking, cell-as-society, cell-as-text, and cell-as-field.}
}
@article{COTTAM2022104671,
title = {Chaos, complexity and computation in the evolution of biological systems},
journal = {Biosystems},
volume = {217},
pages = {104671},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104671},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722000612},
author = {Ron Cottam and Roger Vounckx},
abstract = {Chaos, complexity and computation are especially important concepts with respect to both the Evolution of biological systems and the evolution of the Universe. We consider each of these five entities separately, and then view their combination in an overall consideration of both evolution and Evolution. The concept of computation can be directly derived from processes characteristic of the Evolution of biology or the evolution of the Universe, rather than presumed from our own mathematical ideas. We advocate the inclusion of meaning in science's deliberations, and support this by insisting that physically embodied abstractions should be considered part concrete in character. Combination of our initial five conceptual entities indicates that biological Evolution follows the same developmental criteria as the evolution of the Universe, albeit with an intermediate change in strategy. We conclude that evolutionarily derived computation is the prime driver of evolution/Evolutions' implications.}
}
@incollection{SNYDER2011467,
title = {The Complex Dyanmics of the Climate System: Constraints on our Knowledge, Policy Implications and the Necessity of Systems Thinking},
editor = {Cliff Hooker},
booktitle = {Philosophy of Complex Systems},
publisher = {North-Holland},
address = {Amsterdam},
pages = {467-505},
year = {2011},
volume = {10},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-52076-0.50017-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780444520760500171},
author = {Carolyn W. Snyder and Michael D. Mastrandrea and Stephen H. Schneider},
abstract = {Publisher Summary
This chapter describes the contribution of complexity science to understanding of the climate system and the unique challenges its complex properties pose to climate predictions and policy analysis. First, it presents a brief exploration of the Earth's climate system through the lens of complexity science. Then, it introduces the data sources and modeling strategies that climate science uses to understand past behavior, to fingerprint causes of current climate changes, and to project future climate. The complex dynamics of the climate system constrain ability to gain knowledge about the climate system and add uncertainty to predictions of the impacts of human-induced climate change. It also investigates six case studies that illustrate the importance and development of key complexity themes in climate science: glacial-interglacial cycles, thermohaline ocean circulation, ice sheets, vegetation cover changes, extinction, and overshoot scenarios. In addition, it investigates the implications of the complexity of the Earth system for climate policy analysis. Assessments of the impacts of climate change are often disciplinary-based and not sufficiently integrative across important disciplinary subcomponents, producing misleading results that have potentially dangerous environmental consequences. The current framework of cost-benefit optimization is particularly flawed. Further, it describes how one should restructure climate policy analysis as an integrated assessment process, combining data and relationships from the physical, biological and social sciences, that includes robust assessments of potential risks within a vulnerability framework.}
}
@article{ZELENY1992563,
title = {An essay into a philosophy of MCDM: A way of thinking or another algorithm?},
journal = {Computers & Operations Research},
volume = {19},
number = {7},
pages = {563-566},
year = {1992},
note = {Implementing Multiobjective Optimization Methods: Behavioral and Computational Issues},
issn = {0305-0548},
doi = {https://doi.org/10.1016/0305-0548(92)90027-3},
url = {https://www.sciencedirect.com/science/article/pii/0305054892900273},
author = {Milan Zeleny},
abstract = {We have become accustomed to viewing MCDM as another OR/MS algorithm, characterized by a mere shift from k = 1 to k = n with respect to number k of objective functions or criteria. MCDM research and applications has therefore neglected the search for organizational embedding of MCDM: what types of organizations and under what conditions have the propensity to operate under multiple and which under single criteria? Organizations which derive their structure, strategy and motivation from the singleness of purpose will not and can not be conducive to the notions of multiple critera, no matter how skillfully or forcefully presented, or mathematically complete and computationally user-friendly. The organization, its structure and motivational culture have to change first. In short, traditional hierarchy of command, based on extreme specialization and little autonomy of employees and their departments will not be as open to the multiplicity of criteria as the self-managing teams of non-hierarchical companies which integrate task, labor and knowledge and which are only now starting to dominate certain business and management cultures.}
}
@article{HASSANNEZHAD2022116338,
title = {Virtual Net Propagator: A cloud-based computational tool for systemic decision propagation analysis},
journal = {Expert Systems with Applications},
volume = {191},
pages = {116338},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116338},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421016365},
author = {Mohammad Hassannezhad and Behzad Farahany and Fatemeh Barzegar},
keywords = {Change propagation, Complex networks, Computational intelligence, Systems design and analysis, Socio-technical systems, Web-based decision support system},
abstract = {Today’s organizations are witnessing a growing complexity in making interconnected decisions. Where individuals have a wider range of decisions to influence, the consequence of decisions far more propagate across the system, and the business environment continually influences the status of the system. Predicting the cascading effects of decisions in such situations would be very problematic yet can have several implications for managers and executives to think beyond organizational silos and make local decision with a bigger picture of emergent consequences in mind. A prominent challenge within this realm is the ever-increasing complexity of decision propagations, especially when incorporating the role and influence of people involved in decision-making. This paper tackles this challenge from an engineering change perspective, with the focus on computing the compound risk of decisions when their consequences concurrently propagate across the system. We introduce an interactive tool called Virtual Net Propagator, which incorporates organizational dynamics into decision analysis, with the aim to identify change opportunities and effective set of interventions. Illustrated by a field engineering case study, it is demonstrated that the proposed tool can provide detailed knowledge on how decisions are interconnected and how systemic (cascading) effects of a decision propagate through causal pathways, so highlighting key influencers along with role and influence of interfacing (hidden) players.}
}
@article{MARUYAMA20181037,
title = {Investigation into Parents’ Concerns about the Introduction of Programming Education into Japanese Primary School},
journal = {Procedia Computer Science},
volume = {126},
pages = {1037-1045},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918313188},
author = {Yukiko Maruyama},
keywords = {Programming education, primary school, parents’ concerns, computing thinking},
abstract = {The introduction of computational thinking into primary/secondary or K-12 education has been widely attempted. In Japan, programming education will be introduced into primary school in 2020. The role of parents in primary education is highly important, and their attitude towards education has a considerable influence on children’s attitudes. To investigate parents’ concerns regarding programming education in primary school, a preliminary questionnaire survey has been conducted as a first step of the study.}
}
@article{GUTIERREZBELTRAN2025103198,
title = {Mi Superpoder es la Programación: A tool for teaching programming to children and youth},
journal = {Science of Computer Programming},
volume = {240},
pages = {103198},
year = {2025},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2024.103198},
url = {https://www.sciencedirect.com/science/article/pii/S0167642324001217},
author = {Erika J. {Gutiérrez Beltrán} and Juan C. {Martínez Arias}},
keywords = {Programming for children, STEAM education, Digital educational tools, Game-based learning, Software engineering},
abstract = {Mi Superpoder es la Programación is a web tool designed to teach programming to children and young people. It focuses on developing logical thinking through interactive exercises that cover computer parts recognition, sequences, patterns, and flowcharts. The tool was developed to address the educational needs identified in the social project of the same name, where modern technologies and a serverless-based architecture were used to create an accessible and effective solution for teaching programming. Initial results indicate that students found the tool useful and demonstrated improvements in their understanding of computational logic. This analysis is framed within the global challenge of teaching programming to children and youth, demonstrating the potential of gamified tools across diverse educational contexts. Future plans include expanding the tool to incorporate more modules, allowing customization by teachers, and conducting broader evaluations in different educational environments.}
}
@article{TIKHONOV199898,
title = {The Sensing and Control Strategies of Thin-Film Growth Process Based on Visual Thinking Prototyping Cellular Neural Network},
journal = {IFAC Proceedings Volumes},
volume = {31},
number = {29, Supplement 1},
pages = {98-99},
year = {1998},
note = {7th IFAC Symposium on Artificial Intelligence in Real Time Control 1998. Extended Abstracts, Grand Canyon National Park, USA, 5-8 October},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)38368-4},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017383684},
author = {Nikolai I. Tikhonov}
}
@article{SUN2022102991,
title = {Lake algal bloom monitoring via remote sensing with biomimetic and computational intelligence},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {113},
pages = {102991},
year = {2022},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2022.102991},
url = {https://www.sciencedirect.com/science/article/pii/S1569843222001820},
author = {Zhibin Sun and Ni-Bin Chang and Chi-Farn Chen and Wei Gao},
keywords = {Eutrophication, Biomimetic intelligence, Computational intelligence, Ensemble learning, Food-water nexus, Decision level fusion, Water quality monitoring},
abstract = {Traditional supervised classifications for remote sensing-based water quality monitoring count on a set of classifiers to retrieve features and improve their prediction accuracies based on ground truth samples. However, many existing feature extraction methods in remote sensing are unable to exhibit multiple-instance nonlinear spatial pattern recognition at scales via ensemble learning. This paper designed for lake algal bloom monitoring presents intelligent feature extraction for harmonizing local and global features via tensor flow-based ensemble learning with integrated biomimetic and computational intelligence. To explore such complexity, an Integrated Biomimetic and Ensemble Learning Algorithm (IBELA) was developed to synthesize the contribution from different classifiers associated with the biomimetic philosophy of integrated bands. It leads to strengthened multiple-instance spatial pattern recognition in lake algal bloom monitoring via image fusion at the decision level. With the implementation of IBELA, a case study of a eutrophic freshwater lake, Lake Managua, for water quality monitoring leads to demonstrate six input visual senses showing different impacts on retrieving Chl-a concentrations in the dry and wet season, respectively. The input of total nitrogen from the watershed plays the most important role in water quality variations in both seasons in a watershed-based food–water nexus. Although ultraviolet and microwave bands are important in the dry season, Secchi disk depth is critical in the wet season for water quality monitoring.}
}
@incollection{SHAW2004295,
title = {Chapter 22 - The Spatial-Temporal Thinking Machine},
editor = {Gordon L. Shaw},
booktitle = {Keeping Mozart in Mind (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {295-299},
year = {2004},
isbn = {978-0-12-639061-2},
doi = {https://doi.org/10.1016/B978-012639061-2/50026-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780126390612500264},
author = {Gordon L. Shaw},
abstract = {Publisher Summary
This chapter discusses ideas and dreams of building a computer that can think and reason based on the spatial-temporal reasoning methods used in the brain. The enormous impact that electronic computers have had on our lives is well known. If one could combine the speed of the present computer with the ability of the brain to think using families of symmetry patterns developing in space and time, a whole new era would be here. Moreover, cortical columns are organized in a very highly structured manner to form a cortical area. It is this higher-level architecture that has been examined in order to explore the further consequences of the concepts concerning computation by symmetry operations. It is suggested that a hardware analog-digital implementation of this higher-level cortical area architecture of trion cortical columns should be “straightforward” owing to the localized and structured connectivity, and the discreteness of the firing levels. It is noted that, high-speed parallel computations would allow one to look for symmetry operations in a cortical area.}
}
@article{CSIZMADIA2024108765,
title = {Exploring the role of working memory gate opening process in creativity: An ERP study using the reference-back paradigm},
journal = {Biological Psychology},
volume = {187},
pages = {108765},
year = {2024},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2024.108765},
url = {https://www.sciencedirect.com/science/article/pii/S0301051124000243},
author = {Petra Csizmadia and Boglárka Nagy and Lili Kővári and Zsófia Anna Gaál},
keywords = {Divergent/convergent thinking, Working memory, Reference-back paradigm, Gate opening, ERP},
abstract = {We investigated the relationship between the gate opening process of working memory and an individual's proficiency in divergent (DT) and convergent thinking (CT) using the reference-back paradigm. Event-related potentials and reaction times were measured across groups with varying DT (N = 40, 27.35 ± 5.05 years) and CT levels (N = 40, 27.88 ± 4.95 years). Based on the role of striatal dopamine in supporting cognitive flexibility, which facilitates DT, and considering the significance of phasic dopamine activity as the gate opening signal originating from the basal ganglia, we assumed that the gate opening process may contribute differently to DT and CT. Despite the absence of behavioural differences in gate opening costs, distinct neural patterns emerged. In the early time windows (P1, N1), gate opening effects were detected in both DT and CT groups, with a notable interaction influenced by the level of DT, resulting in significant effects within the lower DT group. The P2 component showed a gate opening effect only in the higher DT group. In the P3 time window, the process unfolded comparably in all groups. Our results suggest that groups with different levels of convergent thinking (based on Matrix reasoning) and those with lower DT (based on Creativity Index) tend to select and activate the prefrontal cortex representation containing the required task information at an earlier stage, compared to those with better DT. This could be beneficial especially in the early phase of idea generation, as more elements become available to create associations and original ideas.}
}
@article{AHMADI201627,
title = {Computational cognitive assistants for futures studies: Toward vision based simulation},
journal = {Futures},
volume = {81},
pages = {27-39},
year = {2016},
note = {Modelling and Simulation in Futures Studies},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2016.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0016328716300829},
author = {Meisam Ahmadi and Mohammadreza {Jahed Motlagh} and Adel Torkaman Rahmani and Mohammad Mahdi Zolfagharzadeh and Peyman Shariatpanahi},
keywords = {Futures studies, Quantitative and qualitative methods, HCI design, Cognitive architecture, Artificial intelligent agents},
abstract = {Many foresight researchers believe that quantitative simulations have a very restricted contribution in futures studies due to their simplicity and lack of creativity. While qualitative methods, taking advantage of the human cognitive system, have a great potential in addressing a wide range of problems in futures studies, this potential is mostly due to the human visual logic that can handle the task of imagining future scenarios much better than mathematical logic. On the other hand, computational methods benefit from the advantages of silicon-based systems namely speed, large memory, rapid networking, and communication. Hence, it would be extremely beneficial to come up with a solution that combines the positive sides of both qualitative and computational approaches. Cognitive artificial agents are computational units that make use of the human cognitive system. Their interaction with foresight and futures researchers can result in promising solutions for the problems addressed in futures studies. In addition, these agents can serve as a great source of inspiration for taking the first step towards vision based computers that can simulate humans’ imaginations of the future. This paper reviews some of the previous attempts in this field and finally sheds light on the main issues where methods in futures studies can play a key role in the future of Human Computer Interaction systems. Our suggested architecture for a future studies interactions-based system along with its justifications and specifications is provided in the form of a request for proposal.}
}
@article{CHIARAMONTI2013101,
title = {Review of energy balance in raceway ponds for microalgae cultivation: Re-thinking a traditional system is possible},
journal = {Applied Energy},
volume = {102},
pages = {101-111},
year = {2013},
note = {Special Issue on Advances in sustainable biofuel production and use - XIX International Symposium on Alcohol Fuels - ISAF},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2012.07.040},
url = {https://www.sciencedirect.com/science/article/pii/S0306261912005624},
author = {David Chiaramonti and Matteo Prussi and David Casini and Mario R. Tredici and Liliana Rodolfi and Niccolò Bassi and Graziella Chini Zittelli and Paolo Bondioli},
keywords = {Microalgae, Biofuel, Raceway ponds, Head losses, Energy, Mixing},
abstract = {The present work addresses energy consumption in raceway ponds (RWPs). This kind of systems are today the most utilized industrial plant for outdoor algae cultivation. The problem has been addressed combining theoretical correlations and experimental data. Head losses for conventional raceway ponds were evaluated, and the results were compared with data available in literature. Computational fluid dynamics was used to support the theoretical analysis. This study suggested possible improvements to the traditional RWP design: an Innovative Raceway Pond (IRP II) was therefore designed, built and operated in parallel with a reference pilot RWP in a test site. Several modifications to traditional RWP design were implemented in the IRP II: the paddle wheel was substituted by a propeller, the water head was reduced and baffle boards were installed in the curves. To validate the new design, head losses and therefore energy consumption in the different systems were evaluated, during cultivation experiments, with two microalgae strains. The theoretical and experimental study allowed a validated calculation, which showed the importance of concentrated head losses towards distributed ones. The analysis highlighted how these losses weight at different pond scales, suggesting possible improvements of the RWP energy performance – as achieved in the IRP II – through revised design for optimized mixing.}
}
@article{HANI2023102968,
title = {Computational intelligence modeling of nanomedicine preparation using advanced processing: Solubility of fludrocortisone acetate in supercritical carbon dioxide},
journal = {Case Studies in Thermal Engineering},
volume = {45},
pages = {102968},
year = {2023},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2023.102968},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X23002745},
author = {Umme Hani and Zainab {Ali Bu sinnah} and Ahmad J. Obaidullah and Bader Huwaimel and Muteb Alanazi and Tareq {Nafea Alharby} and Ahmed A. Lahiq and Abdullah {Ali Alshehri}},
keywords = {Nanomedicine, Multilayer perceptron, Support vector machine, Multi linear regression, Drug solubility},
abstract = {The method of green technology which is based on supercritical solvent has been studied in this work for analysis of nanomedicine preparation of solid dosage oral medications. Given that the poor drug solubility in aqueous media is a big challenge in pharmaceutical industry, nanomedicines would help improve the drug solubility in aqueous media. The solubility of fludrocortisone acetate in supercritical carbon dioxide is modelled in this research using various machine learning methods because it is a crucial aspect of the expansion of the pharmaceutical business. For this purpose, the accessible data have two input features: a pressure range of 120–300 (bar) and a temperature range of 308–338 (K). MLP, v-SVR and MLR are the basic models used in this research, but not their raw versions. They are improved for modeling drug solubility and coupled with the grey wolf optimization (GWO) in order to optimize the models. The models optimized by GWO showed acceptable results, but among these models, MLP regression has shown better results when coupled with this optimization algorithm. This model has the RMSE error rate of 2.98 × 10−2 and its R2 score is 0.9797 in correlating the solubility data of the medicine.}
}
@article{WALTERS199115,
title = {Critical thinking, rationality, and the vulcanization of students},
journal = {Journal of Accounting Education},
volume = {9},
number = {1},
pages = {15-31},
year = {1991},
issn = {0748-5751},
doi = {https://doi.org/10.1016/0748-5751(91)90020-R},
url = {https://www.sciencedirect.com/science/article/pii/074857519190020R},
author = {Kerry S. Walters}
}
@article{LIU1996435,
title = {Is designing one search or two? A model of design thinking involving symbolism and connectionism},
journal = {Design Studies},
volume = {17},
number = {4},
pages = {435-449},
year = {1996},
note = {Special Issue: Design Cognition and Computation},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(96)00018-X},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X9600018X},
author = {Yu-Tung Liu},
keywords = {design cognition, design process, symbolism, connectionism},
abstract = {In this paper, designing is interpreted as a combination of two searches: a shape restructuring search and a knowledge transforming search. During the first phase, designers or computer-aided design systems search for alternative ways to interpret for the current design state by restructuring shapes in terms of emergent subshapes; it is close to the connectionist processing which we can only slightly sense. During the second phase, designers or computer systems search for alternative rule applications in order to transform the interpreted current state into the next one that matches the formal and functional requirements; it is close to symbolic processing which we can sense, clearly and cognitively.}
}
@article{ZENGAFFINEN2023100159,
title = {“Computational analysis on verbal fluency reveals heterogeneity in subjective language interests and brain structure”},
journal = {Neuroimage: Reports},
volume = {3},
number = {1},
pages = {100159},
year = {2023},
issn = {2666-9560},
doi = {https://doi.org/10.1016/j.ynirp.2023.100159},
url = {https://www.sciencedirect.com/science/article/pii/S2666956023000041},
author = {Francilia Zengaffinen and Antje Stahnke and Stephan Furger and Roland Wiest and Thomas Dierks and Werner Strik and Yosuke Morishima},
keywords = {Language, SyNoPsis, Computational analysis, LSA, VBM, Healthy cohort, Psychosis},
abstract = {Language is an essential higher cognitive function in humans and is often affected by psychiatric and neurological disorders. Objective measures like the verbal fluency test are often used to determine language dysfunction. Recent applications of computational approaches broaden insights into language-related functions. In addition, individuals diagnosed with a psychiatric or neurological disorder also often report subjective difficulties in language-related functions. Therefore, we investigated the association between objective and subjective measures of language functioning, on the one hand, and inter-individual structural variations in language-related brain areas, on the other hand. We performed a Latent Semantic analysis (LSA) on a semantic verbal fluency task in 101 healthy adult participants. To investigate if these objective measures are associated with a subjective one, we examined assessed subjective natural tendency of interest in language-related activity with a study-specific questionnaire. Lastly, a voxel-based brain morphometry (VBM) was conducted to reveal associations between objective (LSA) measures and structural changes in language-related brain areas. We found a positive correlation between the LSA measure cosine similarity and the subjective interest in language. Furthermore, we found that higher cosine similarity corresponds to higher gray matter volume in the right cerebellum. The results suggest that people with higher interests in language access semantic knowledge in a more organized way exhibited by higher cosine similarity and have larger gray matter volume in the right cerebellum, when compared to people with lower interests. In conclusion, we demonstrate that there is inter-individual diverseness of accessing the semantic knowledge space and that it is associated with subjective language interests as well as structural differences in the right cerebellum.}
}
@article{CHEN2009191,
title = {Towards an explanatory and computational theory of scientific discovery},
journal = {Journal of Informetrics},
volume = {3},
number = {3},
pages = {191-209},
year = {2009},
note = {Science of Science: Conceptualizations and Models of Science},
issn = {1751-1577},
doi = {https://doi.org/10.1016/j.joi.2009.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S1751157709000236},
author = {Chaomei Chen and Yue Chen and Mark Horowitz and Haiyan Hou and Zeyuan Liu and Donald Pellegrino},
keywords = {Theory of scientific discovery, Transformative scientific discoveries, Theory of structural holes, Intellectual brokerage, Knowledge diffusion, Information foraging},
abstract = {We propose an explanatory and computational theory of transformative discoveries in science. The theory is derived from a recurring theme found in a diverse range of scientific change, scientific discovery, and knowledge diffusion theories in philosophy of science, sociology of science, social network analysis, and information science. The theory extends the concept of structural holes from social networks to a broader range of associative networks found in science studies, especially including networks that reflect underlying intellectual structures such as co-citation networks and collaboration networks. The central premise is that connecting otherwise disparate patches of knowledge is a valuable mechanism of creative thinking in general and transformative scientific discovery in particular. In addition, the premise consistently explains the value of connecting people from different disciplinary specialties. The theory not only explains the nature of transformative discoveries in terms of the brokerage mechanism but also characterizes the subsequent diffusion process as optimal information foraging in a problem space. Complementary to epidemiological models of diffusion, foraging-based conceptualizations offer a unified framework for arriving at insightful discoveries and optimizing subsequent pathways of search in a problem space. Structural and temporal properties of potentially high-impact scientific discoveries are derived from the theory to characterize the emergence and evolution of intellectual networks of a field. Two Nobel Prize winning discoveries, the discovery of Helicobacter pylori and gene targeting techniques, and a discovery in string theory demonstrated such properties. Connections to and differences from existing approaches are discussed. The primary value of the theory is that it provides not only a computational model of intellectual growth, but also concrete and constructive explanations of where one may find insightful inspirations for transformative scientific discoveries.}
}
@article{KVISTBORG2015591,
title = {Thinking Outside the Gate: Single-Cell Assessments in Multiple Dimensions},
journal = {Immunity},
volume = {42},
number = {4},
pages = {591-592},
year = {2015},
issn = {1074-7613},
doi = {https://doi.org/10.1016/j.immuni.2015.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1074761315001351},
author = {Pia Kvistborg and Cécile Gouttefangeas and Nima Aghaeepour and Angelica Cazaly and Pratip K. Chattopadhyay and Cliburn Chan and Judith Eckl and Greg Finak and Sine Reker Hadrup and Holden T. Maecker and Dominik Maurer and Tim Mosmann and Peng Qiu and Richard H. Scheuermann and Marij J.P. Welters and Guido Ferrari and Ryan R. Brinkman and Cedrik M. Britten}
}
@article{CASALI2022105,
title = {Role of Anion in Determining the Stereoselectivity of Mg-Ph-BOX-Catalyzed Diels–Alder Reactions: A Computational Study},
journal = {Organometallics},
volume = {41},
number = {2},
pages = {105-114},
year = {2022},
issn = {0276-7333},
doi = {https://doi.org/10.1021/acs.organomet.1c00550},
url = {https://www.sciencedirect.com/science/article/pii/S0276733322004502},
author = {Emanuele Casali and Giuseppe Faita and Lucio Toma},
abstract = {ABSTRACT
In the realm of enantioselective Diels–Alder reactions, a role of primary importance is held by Mg-BOX catalysis. The main features of both catalysts and ligand in directing the stereoselective outcome have been extensively studied in several papers mainly through 1H NMR and X-ray diffraction (XRD) techniques. However, over the years, no computational studies have been reported to support the models proposed to rationalize the observed stereoselectivity for the reaction between 3-acryloyl-1,3-oxazolidin-2-one and cyclopentadiene catalyzed by the BOX ligand (R,R)-(+)-2,2′-isopropylidenebis­(4-phenyl-2-oxazoline) and Mg­(II) salts. To approach the problem, we performed a density functional theory (DFT) computational study, aiming to locate the preferred transitions states deriving from these proposed models, but we only found a correspondence in selectivities for the reaction catalyzed by Mg­(OTf)2, where the model suggests an octahedral complex with the two triflate anions coordinating magnesium. For the other cases [i.e., Mg­(ClO4)2, Mg­(ClO4)2·2H2O, and MgI2·I2], the commonly accepted tetrahedral or octahedral models suggest no involvement of the perchlorate or iodide anions, but the corresponding calculations did not reproduce the experimental selectivities. Only when we considered also in these cases coordination complexes involving their presence, the observed selectivities were reproduced, thus opening new insights to better understand the role and the action of the counterion to determine the stereochemical outcome of these reactions.}
}
@article{LOCKWOOD2020100783,
title = {A case for combinatorics: A research commentary},
journal = {The Journal of Mathematical Behavior},
volume = {59},
pages = {100783},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100783},
url = {https://www.sciencedirect.com/science/article/pii/S073231232030047X},
author = {Elise Lockwood and Nicholas H. Wasserman and Erik S. Tillema},
keywords = {Research commentary, Combinatorics, Discrete mathematics, Curricula},
abstract = {In this commentary, we make a case for the explicit inclusion of combinatorial topics in mathematics curricula, where it is currently essentially absent. We suggest ways in which researchers might inform the field’s understanding of combinatorics and its potential role in curricula. We reflect on five decades of research that has been conducted since a call by Kapur (1970) for a greater focus on combinatorics in mathematics education. Specifically, we discuss the following five assertions: 1) Combinatorics is accessible, 2) Combinatorics problems provide opportunities for rich mathematical thinking, 3) Combinatorics fosters desirable mathematical practices, 4) Combinatorics can contribute positively to issues of equity in mathematics education, and 5) Combinatorics is a natural domain in which to examine and develop computational thinking and activity. Ultimately, we make a case for the valuable and unique ways in which combinatorics might effectively be leveraged within K-16 curricula.}
}
@article{JOSWICK2025104908,
title = {Opportunities to collectively reason about numbers while building connections to key conceptual ideas in mathematics: Examining the questions used by teachers studying and implementing Number Talks},
journal = {Teaching and Teacher Education},
volume = {155},
pages = {104908},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104908},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24004414},
author = {Candace Joswick and Brandon G. McMillan and Kimberly A. Conner},
keywords = {Number Talks, Questioning},
abstract = {Teachers' questioning practices play a pivotal role in shaping classroom discussions. Analysis of 30 Number Talks from classrooms across the US reveals the majority of teachers' questions helped to surface student strategies (confirm, elaborate, invite questions), but did not provide opportunities for students to collectively reason about numbers while building connections to key conceptual ideas in mathematics (connect, justify, orient questions). Data excerpts illustrate how questions can be used to support this reasoning. Implications include the need to focus on pedagogical and content knowledge centered in student mathematical thinking within professional development to develop teachers’ ability to support this reasoning.}
}
@article{PSYCHARIS201490,
title = {The impact of the computational inquiry based experiment on metacognitive experiences, modelling indicators and learning performance},
journal = {Computers & Education},
volume = {72},
pages = {90-99},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0360131513002789},
author = {Sarantos Psycharis and Evi Botsari and Panagiotis Mantas and Dionisios Loukeris},
keywords = {Metacognition, Modelling, Computational experiment, Inquiry based science education},
abstract = {Computational experiment approach considers modelling as the essential feature of Inquiry Based Science Education (IBSE), where the model and the computer take the place of the “classical” experimental set-up and simulation replaces the experiment (Landau, Pαez, & Bordeianu, 2008). Modelling, as a pedagogical tool, involves the model construction, the exploration of model characteristics and the model application to a specific problem, resembling authentic activities of scientists and mathematicians (Herbert, 2003). Recent developments in strategy instruction research suggest that learning in a particular discipline is enhanced by guiding students through the development of content-relevant metacognitive strategies (Wosnitza & Volet, 2009). Problem-solving is a complex process, which involves several cognitive operations such as collecting and selecting information, heuristic strategy and metacognition (De Corte, 2003, Garofalo and Lester, 1985, Schoenfeld, 1994). The purpose of this study was to explore the impact of the Computational Experiment Methodology on learners' cognitive performance, use of modelling indicators and shift of the metacognitive experiences during problem solving using computational models. Sixty prospective primary school teachers volunteered to participate in the study. Students were exposed by the Instructor to a number of computational experiments, while during the course they developed their own models of simulation. The results of the experiment show that the use of the computational experiment approach has a substantial effect on the metacognitive experiences and the use of modelling indicators.}
}
@article{PANSKYI2019100593,
title = {Out-of-school assistance in the teaching of visual creative programming in the game-based environment – Case study: Poland},
journal = {Thinking Skills and Creativity},
volume = {34},
pages = {100593},
year = {2019},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2019.100593},
url = {https://www.sciencedirect.com/science/article/pii/S187118711930104X},
author = {Taras Panskyi and Zdzislawa Rowinska and Sebastian Biedron},
keywords = {Out-of-school education, Creative programming, Game-based learning, ICT},
abstract = {The paper presents effects of out-of-school teaching of computer science in a visual creative programming course (Scratch) for children aged 9–14, held at the Lodz University of Technology. The research was carrying out during 2016–2018 school years. The study sample consists of 265 primary and secondary students from Lodz Voivodeship (province) in central Poland. The results were obtained from anonymous questionnaires completed by 221 course participants and their parents. The answers confirm that this type of course becomes a new fascinating manner of spending spare time by children. Moreover, quantitative analysis of student’s finals projects also has been performed. In the process of creative programming in the game-based environment, children develop the computational thinking skills, problem-solving strategies, and abstract thinking. Moreover, children are supported by their parents, who notice how important these competences are and how great opportunities they will present for children in future. Authors continue to grow Scratch programming course to democratize access to new technologies and education, preparing future generation for a world in which computational and algorithmic thinking is a central part of problem-solving. Perhaps some of the course participants will continue their study of programming and make it a career for their life.}
}
@article{FENG2025100831,
title = {Construction of teaching game evaluation model based on ISSA-BPNN},
journal = {Entertainment Computing},
volume = {52},
pages = {100831},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100831},
url = {https://www.sciencedirect.com/science/article/pii/S187595212400199X},
author = {Bibo Feng and Lingli Zhang and Jing Yin and Rong Wang},
keywords = {Sparrow search algorithm, Back propagation neural network, Teaching games, Evaluating indicator},
abstract = {Teaching games are an effective teaching organization activity. In response to the evaluation and prediction problem of teaching games, a teaching game evaluation model based on improved sparrow search algorithm and back propagation neural network was studied and constructed. Firstly, a situational teaching game was designed and an evaluation index system was constructed. Then, a teaching game evaluation prediction model based on the improved method was established. Finally, the expert consultation method is adopted to collect opinions from experts in the field of education and construct an evaluation index system for teaching games. And based on the evaluation index system of teaching games, evaluate students’ mathematical thinking ability before and after experiencing teaching games to verify the application effect of teaching games. The scenario based teaching game designed in this study has a certain effect on improving students’ mathematical thinking ability. Students’ mathematical thinking has significantly improved (P<0.05), and the teaching effect is the same for students of different genders (P>0.1). The improved sparrow search algorithm has a faster convergence rate than other algorithms, and tends to be stable when iteration is about 100 when solving the single peak benchmark function. When solving the multimodal benchmark test function, it tends to stabilize when iteration is around 20. The teaching game evaluation prediction price model based on the improved method shows a trend of first increasing and then decreasing with hidden units increasing. When the hidden unit is 16, the area index under model curve is the highest, around 0.962, and its prediction accuracy is relatively high. In summary, the model constructed in this study is applicating good in teaching game evaluation prediction, and can promote education industry developing.}
}
@article{DEGELDER2021744,
title = {A computational neuroethology perspective on body and expression perception},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {9},
pages = {744-756},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321001479},
author = {Beatrice {de Gelder} and Marta {Poyo Solanas}},
keywords = {body, emotion, movement, ethology, computational features},
abstract = {Survival prompts organisms to prepare adaptive behavior in response to environmental and social threat. However, what are the specific features of the appearance of a conspecific that trigger such adaptive behaviors? For social species, the prime candidates for triggering defense systems are the visual features of the face and the body. We propose a novel approach for studying the ability of the brain to gather survival-relevant information from seeing conspecific body features. Specifically, we propose that behaviorally relevant information from bodies and body expressions is coded at the levels of midlevel features in the brain. These levels are relatively independent from higher-order cognitive and conscious perception of bodies and emotions. Instead, our approach is embedded in an ethological framework and mobilizes computational models for feature discovery.}
}
@article{BIAN2019136,
title = {Statistical thinking, machine learning},
journal = {Journal of Clinical Epidemiology},
volume = {116},
pages = {136-137},
year = {2019},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2019.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0895435619304950},
author = {Jiang Bian and Iain Buchan and Yi Guo and Mattia Prosperi}
}
@article{GOOD201778,
title = {Programming language, natural language? Supporting the diverse computational activities of novice programmers},
journal = {Journal of Visual Languages & Computing},
volume = {39},
pages = {78-92},
year = {2017},
note = {Special Issue on Programming and Modelling Tools},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2016.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X16301963},
author = {Judith Good and Kate Howland},
keywords = {Novice programming languages, Natural language, Design, Empirical evaluation},
abstract = {Given the current focus on teaching computational concepts to all from an early age, combined with the growing trend to empower end users to become producers of technology rather than mere consumers, we consider the issue of “computational notation”. Specifically, where the goal is to help individuals develop their understanding of computation and/or use computation in real world settings, we question whether natural language might be a preferred notation to traditional programming languages, given its familiarity and ubiquity. We describe three empirical studies investigating the use of natural language for computation in which we found that although natural language provides support for understanding computational concepts, it introduces additional difficulties when used for coding. We distilled our findings into a set of design guidelines for novice programming environments which consider the ways in which different notations, including natural language, can best support the various activities that comprise programming. These guidelines were embodied in Flip, a bi-modal programming language used in conjunction with the Electron toolset, which allows young people to create their own commercial quality, narrative based role- playing games. Two empirical studies on the use of Flip in three different real world contexts considered the extent to which the design guidelines support ease of use and an understanding of computation. The guidelines have potential to be of use both in analysing the use of natural language in existing novice programming environments, and in the design of new ones.}
}
@article{HAO2024102662,
title = {Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction},
journal = {Technology in Society},
volume = {78},
pages = {102662},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102662},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002100},
author = {Xinyue Hao and Emrah Demir and Daniel Eyers},
keywords = {ChatGPT, Artificial intelligence, Human intuition, Decision-making, Cognitive biases},
abstract = {This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making processes within organizations, employing a quasi-experimental pretest-posttest design. The study examines the synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios within three global organizations renowned for their cutting-edge operational techniques. The research progresses through several phases: identifying research problems, collecting baseline data on decision-making, implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in performance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is particularly valuable in complex situations characterized by unfamiliarity and information overload, where intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI integration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box’ thinking without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.}
}
@article{WEISS2025101836,
title = {Introducing the inventory of creative activities for young adolescents: An adaption and validation study},
journal = {Thinking Skills and Creativity},
volume = {57},
pages = {101836},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101836},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000859},
author = {S. Weiss and A.-K. Jaggy and B. Goecke},
keywords = {Adolescents, Creative activities, Creative achievements, Divergent Thinking, Giftedness},
abstract = {The measurement of everyday creative activities has been a widely applied measure of creativity in adult samples in order to investigate the relationship with creative potential and creative achievements. Despite the importance of creative activities for the development of achievements the assessment mostly focuses on adults. In the study at hand, we develop a questionnaire for adolescents and provide results regarding its structural, convergent, and predictive validity in a sample of n = 423 talented students from sixth and seventh grade. We show structural validity of the theoretically derived factor structure including six content domains (literature, handicrafts, fine arts, performing arts, music, and technology). Furthermore, we provide proof of convergent validity given the correlation of creative activities with divergent thinking as well as predictive validity regarding creative achievements. We discuss the findings in the light of previous studies including adult samples and summarize recommendations for the application of the measurement of creative activities in gifted students as well as in more general student populations.}
}
@article{TUHKALA201954,
title = {Technology Comprehension — Combining computing, design, and societal reflection as a national subject},
journal = {International Journal of Child-Computer Interaction},
volume = {20},
pages = {54-63},
year = {2019},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2019.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212868918301016},
author = {Ari Tuhkala and Marie-Louise Wagner and Ole Sejer Iversen and Tommi Kärkkäinen},
keywords = {Technology comprehension, Digital fabrication, Making, Design, Computing, Computational thinking, Education, Teachers, National, Scaling, Subject},
abstract = {This article considers the implementation of a new learning subject ”Technology Comprehension” into lower secondary schools in Denmark, as part of an initiative by the Danish Ministry of Education. The subject consists of learning objectives related to computing, design, and societal reflection and was first introduced as an elective course in 13 schools to investigate how it could be integrated into the Danish education system. We present four key findings based on school visits, interviews, an electronical survey, two questionnaires, and workshops including theme discussions: (1) teachers did not perceive Technology Comprehension as a distinct subject, but rather as a set of skills that can be integrated into other subjects; (2) teachers pointed out that Technology Comprehension opens up for interdisciplinary and engaging learning activities, but they need more scaffolding and support; (3) Technology Comprehension challenges teachers’ existing competencies and there is a need for a framework that takes into account computing, design, and societal reflection as a whole; (4) Technology Comprehension appealed to various kind of students, not only those who are enthusiastic about technical matters. This study contributes to the previous research on making and digital fabrication by addressing how these endeavours are implemented on a national level through engaging with local teachers. We call for more research on scaffolding and supporting teachers to orchestrate meaningful learning activities to successfully integrate Technology Comprehension into the Danish national education.}
}
@article{FUGELSANG20051204,
title = {Brain-based mechanisms underlying complex causal thinking},
journal = {Neuropsychologia},
volume = {43},
number = {8},
pages = {1204-1213},
year = {2005},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2004.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S002839320400274X},
author = {Jonathan A. Fugelsang and Kevin N. Dunbar},
keywords = {Scientific reasoning, Learning, Error detection, Conflict monitoring, fMRI},
abstract = {We use functional magnetic resonance imaging (fMRI) and behavioral analyses to study the neural roots of biases in causal reasoning. Fourteen participants were given a task requiring them to interpret data relative to plausible and implausible causal theories. Encountering covariation-based data during the evaluation of a plausible theory as opposed to an implausible theory selectively recruited neural tissue in the prefrontal and occipital cortices. In addition, the plausibility of a causal theory modulated the recruitment of distinct neural tissue depending on the extent to which the data were consistent versus inconsistent with the theory provided. Specifically, evaluation of data consistent with a plausible causal theory recruited neural tissue in the parahippocampal gyrus, whereas evaluating data inconsistent with a plausible theory recruited neural tissue in the anterior cingulate, left dorsolateral prefrontal cortex, and precuneus. We suggest that these findings provide a neural instantiation of the mechanisms by which working hypotheses and evidence are integrated in the brain.}
}
@article{HADAS2024101549,
title = {Using large language models to evaluate alternative uses task flexibility score},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101549},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101549},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000877},
author = {Eran Hadas and Arnon Hershkovitz},
keywords = {Creativity, Divergent thinking, Alternative uses task, Flexibility, Large language models},
abstract = {In the Alternative Uses Task (AUT) test, a group of participants is asked to list as many uses as possible for a simple object. The test measures Divergent Thinking (DT), which involves exploring possible solutions in various semantic domains. In this study we employ a Machine Learning approach to automatically generate suitable categories for object uses and classify given responses into them. We show that the results yielded by this automated approach are correlated with results given by humans and can be used to predict expected behavior in the field. Educators and researchers may utilize this approach to address the limitations of subjective scoring, save time, and use the AUT as a tool for cultivating creativity.}
}
@article{OMER2024100308,
title = {Computational studies of a series of closely related acenaphthopyrazine derivative},
journal = {Results in Surfaces and Interfaces},
volume = {17},
pages = {100308},
year = {2024},
issn = {2666-8459},
doi = {https://doi.org/10.1016/j.rsurfi.2024.100308},
url = {https://www.sciencedirect.com/science/article/pii/S2666845924001284},
author = {Rebaz Anwar Omer and Rebaz Obaid Kareem and Yousif Hussein Azeez and Lana Omer Ahmed and Damir A. Safin and karukh Ali Babakr},
keywords = {Gaussian software, DFT, NLO, Thermal properties, Monte Carlo simulations},
abstract = {The novelty of the study is in the use of quantum computing analysis of acenaphthopyrazine derivatives using Density Functional Theory (DFT) with the B3LYP/6-31G(d,p) basis set. The research focused on intramolecular charge transfer (ICT) and its influence on non-linear optical (NLO) properties. The NLO analysis revealed that the protonated forms of these compounds exhibit higher dipole moments, indicating their potential for NLO applications. Natural Bond Orbital (NBO) analysis identified molecule 5 as having the highest E(2) value of 509.41 kcal/mol, signifying strong electron donation from nitrogen to hydrogen atoms. The study also evaluated the thermal properties, showing that the Gibbs free energy remained positive across a wide temperature range, suggesting that none of the compounds are spontaneously formed in either neutral or protonated states. Additionally, Monte Carlo simulations indicated favorable adsorption energies for these derivatives on the Fe (110) surface, with compound 5 demonstrating the most significant inhibitory potential. We conduced of that, lower negative adsorption energy (−216.729) compound 1 are confirm with highest energy gap (3.396 eV), and smaller refractive index, and electrical conductivityof compound 1 indicates a small metal-inhibitor molecule interaction, as well as are agreement with Monte Carlo simulation for adsorption on Fe (110) non protonated case.}
}