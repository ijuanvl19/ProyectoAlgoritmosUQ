@article{RASUL2024101041,
title = {Enhancing academic integrity among students in GenAI Era:A holistic framework},
journal = {The International Journal of Management Education},
volume = {22},
number = {3},
pages = {101041},
year = {2024},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101041},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001125},
author = {Tareq Rasul and Sumesh Nair and Diane Kalendra and M.S. Balaji and Fernando de Oliveira Santini and Wagner Junior Ladeira and Raouf Ahmad Rather and Naveed Yasin and Raul V. Rodriguez and Panagiotis Kokkalis and Md Wahid Murad and Md Uzir Hossain},
keywords = {Generative AI, Academic integrity, Higher education, Students, Stakeholders},
abstract = {The introduction of Artificial Intelligence (AI), specifically Generative AI (GenAI), has significantly transformed the higher education landscape. Despite the opportunities GenAI offers to students, they pose significant challenges for academic integrity. Thus, it is crucial for higher education institutions (HEI) to balance the use of GenAI for enhancing the learning experience of students with its ethical and responsible use in their educational journey. The present study proposes a comprehensive academic integrity framework focusing on three key stakeholders: students, educators, and institutions. We propose eight strategies ranging from collaborative learning for students to developing a comprehensive GenAI policy for institutions in maintaining academic integrity among students in HEI. Furthermore, we identified four challenges, namely financial, strategic, operational, and cultural, in the implementing a comprehensive academic integrity framework in the GenAI era. This study offers significant insights for HEI to maintain academic integrity among students in the GenAI era.}
}
@article{KHOONG2024124091,
title = {Evaluating the growth of Singapore's solar electricity capacity towards Green Plan 2030 targets and beyond using system dynamics modelling approach},
journal = {Applied Energy},
volume = {376},
pages = {124091},
year = {2024},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2024.124091},
url = {https://www.sciencedirect.com/science/article/pii/S0306261924014740},
author = {Wei Kit Khoong and Sreenivasulu Bellam},
keywords = {Solar electricity capacity, Singapore's energy mix, Systems thinking, System dynamics modelling, Carbon savings, Singapore Green Plan 2030},
abstract = {Having no native energy resources of fossil fuels, with poor wind resource and scarcity of land, the Solar Photovoltaic (PV) roadmap identified solar electricity as the most feasible source of renewable energy for Singapore's energy mix and supply. Moving towards net-zero emissions and to combat climate change, the Singapore government is aiming to achieve 2-Gigawatt-peak (GWp) of solar electricity target by 2030. Accordingly, the share of solar energy in the national grid is targeted to be between ∼2–6% in 2030 and ∼ 3.5–8% in 2040, and carbon emission savings to be ∼0.5–1.4 and ∼ 0.8–2.1 million tonnes per annum in 2030 and 2040 respectively. Although these ambitious targets align with the government's plans for mitigating emissions, Singapore faces great challenge in terms of land availability to install ground-mounted solar PV panels. In this paper, a system dynamics model is developed to study- to what extent can Singapore achieve the targeted solar electricity goals by 2030 or even beyond based on Green Plan 2030, what policies can be identified to achieve these targets, and how much carbon savings can be achieved through Solar electricity deployment. Accordingly, this paper presents systems thinking and system dynamics (ST&SD) methodology to model the growth of Singapore's solar capacity, carbon emission savings and share of electricity demand met by solar electricity while focusing on key complex factors such as area utilisation, subsidies, PV panel efficiency etc. Results of our model simulations and projections, based on the key data and assumptions, and policy scenarios show that Singapore's solar capacity can be accelerated by the implementation of the proposed policies to reach 2GWp goal towards 2030 or even slightly ahead of this timeline. However, should the government revise its solar capacity targets higher for the years past 2030 i.e. to achieve 8% share of total electricity generation, perhaps by 2040, policies such as an increased area utilisation, subsidies and higher panel efficiency need to be introduced. Our model simulations incorporating and evaluating these policy scenarios yielded the results aligning with the projections mentioned above. The results and insights presented in this paper offer useful recommendations to the researchers and policy makers in the field of solar electricity system in Singapore, and to study further for better policy making.}
}
@article{SANKARANARAYANAN20151,
title = {Genome-based, mechanism-driven computational modeling of risks of ionizing radiation: The next frontier in genetic risk estimation?},
journal = {Mutation Research/Reviews in Mutation Research},
volume = {764},
pages = {1-15},
year = {2015},
issn = {1383-5742},
doi = {https://doi.org/10.1016/j.mrrev.2014.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S138357421400091X},
author = {K. Sankaranarayanan and H. Nikjoo},
keywords = {Radiation risk, DNA damage, DNA repair, Biophysical models},
abstract = {Research activity in the field of estimation of genetic risks of ionizing radiation to human populations started in the late 1940s and now appears to be passing through a plateau phase. This paper provides a background to the concepts, findings and methods of risk estimation that guided the field through the period of its growth to the beginning of the 21st century. It draws attention to several key facts: (a) thus far, genetic risk estimates have been made indirectly using mutation data collected in mouse radiation studies; (b) important uncertainties and unsolved problems remain, one notable example being that we still do not know the sensitivity of human female germ cells to radiation-induced mutations; and (c) the concept that dominated the field thus far, namely, that radiation exposures to germ cells can result in single gene diseases in the descendants of those exposed has been replaced by the concept that radiation exposure can cause DNA deletions, often involving more than one gene. Genetic risk estimation now encompasses work devoted to studies on DNA deletions induced in human germ cells, their expected frequencies, and phenotypes and associated clinical consequences in the progeny. We argue that the time is ripe to embark on a human genome-based, mechanism-driven, computational modeling of genetic risks of ionizing radiation, and we present a provisional framework for catalyzing research in the field in the 21st century.}
}
@article{ANDRADE2017111,
title = {Exact posterior computation in non-conjugate Gaussian location-scale parameters models},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {53},
pages = {111-129},
year = {2017},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2017.04.036},
url = {https://www.sciencedirect.com/science/article/pii/S100757041730151X},
author = {J.A.A. Andrade and P.N. Rathie},
keywords = {Bayesian computation, Exact posterior distribution, Non-conjugate models, Special functions, H-function},
abstract = {In Bayesian analysis the class of conjugate models allows to obtain exact posterior distributions, however this class quite restrictive in the sense that it involves only a few distributions. In fact, most of the practical applications involves non-conjugate models, thus approximate methods, such as the MCMC algorithms, are required. Although these methods can deal with quite complex structures, some practical problems can make their applications quite time demanding, for example, when we use heavy-tailed distributions, convergence may be difficult, also the Metropolis-Hastings algorithm can become very slow, in addition to the extra work inevitably required on choosing efficient candidate generator distributions. In this work, we draw attention to the special functions as a tools for Bayesian computation, we propose an alternative method for obtaining the posterior distribution in Gaussian non-conjugate models in an exact form. We use complex integration methods based on the H-function in order to obtain the posterior distribution and some of its posterior quantities in an explicit computable form. Two examples are provided in order to illustrate the theory.}
}
@article{PHANG2019100837,
title = {How to derive causal insights for digital commerce in China? A research commentary on computational social science methods},
journal = {Electronic Commerce Research and Applications},
volume = {35},
pages = {100837},
year = {2019},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2019.100837},
url = {https://www.sciencedirect.com/science/article/pii/S1567422319300146},
author = {David C.W. Phang and Kanliang Wang and Qiuhong Wang and Robert J. Kauffman and Maurizio Naldi},
keywords = {Big data, Business insights, Causal inference, Causal methods, Computational social science (CSS), Consumer behavior, China, Data analytics, Digital economy, E-commerce, Emerging markets, Empirical research, Information systems (IS) research, Machine learning (ML), M-commerce, Policy analytics, Research design, Secondary data, Sensor data, Streaming data, Social insights, Theory testing},
abstract = {The transformation of empirical research due to the arrival of big data analytics and data science, as well as the new availability of methods that emphasize causal inference, are moving forward at full speed. In this Research Commentary, we examine the extent to which this has the potential to influence how e-commerce research is conducted. China offers the ultimate in data-at-scale settings, and the construction of real-world natural experiments. Chinese e-commerce includes some of the largest firms involved in e-commerce, mobile commerce, social media and social networks. This article was written to encourage young faculty and doctoral students to engage in research that can be carried out in near real-time, with truly experimental or quasi-experimental research designs, and with the clear intention of establishing causal inferences that relate the precursors and drivers of observable outcomes through various kinds of processes. We discuss: the relevant data sources and research contexts; the methods perspectives that are appropriate which blend Computer Science, Statistics and Econometrics, how the research can be made relevant for China; and what kinds of findings and research directions are available. This article is not a tutorial on big data analytics methods in general though, nor does it cover just those published works that demonstrate big data methods and empirical causality in other disciplines. Instead, the empirical research covered is mostly taken from Electronic Commerce Research and Applications, which has published many articles on Chinese e-commerce. This Research Commentary invites researchers in China and the Asia Pacific region to expand their coverage to bring into their empirical work the new methods and philosophy of causal data science.}
}
@article{ALANZI201713,
title = {Inferring rooted species trees from unrooted gene trees using approximate Bayesian computation},
journal = {Molecular Phylogenetics and Evolution},
volume = {116},
pages = {13-24},
year = {2017},
issn = {1055-7903},
doi = {https://doi.org/10.1016/j.ympev.2017.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S1055790317305390},
author = {Ayed R.A. Alanzi and James H. Degnan},
keywords = {Multispecies coalescent, Outgroup, Midpoint rooting, Molecular clock, Identifiability, Sufficiency},
abstract = {Methods for inferring species trees from gene trees motivated by incomplete lineage sorting typically use either rooted gene trees to infer a rooted species tree, or use unrooted gene trees to infer an unrooted species tree, which is then typically rooted using one or more outgroups. Theoretically, however, it has been known since 2011 that it is possible to consistently infer the root of the species tree directly from unrooted gene trees without assuming an outgroup. Here, we use approximate Bayesian computation to infer the root of the species tree from unrooted gene trees assuming the multispecies coalescent model. It is hoped that this approach will be useful in cases where an appropriate outgroup is difficult to find and gene trees do not follow a molecular clock. We use approximate Bayesian computation to infer the root of the species tree from unrooted gene trees. This approach could also be useful when there is prior information that makes a small number of root locations plausible in an unrooted species tree.}
}
@article{YOUSIF201880,
title = {Fuzzy logic computational model for performance evaluation of Sudanese Universities and academic staff},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {30},
number = {1},
pages = {80-119},
year = {2018},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2016.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1319157816300556},
author = {Mohamed Khalid Yousif and Adnan Shaout},
keywords = {Evaluation criteria, Performance evaluation, Sudanese universities, Survey design, Fuzzy computational model, Consistency checking},
abstract = {The excellence of a Sudanese universities and academic staff member can be effectively classified by systematic and objective design criteria, which participates in developing the learning outcomes in Sudan. In the first phase of this study, we reviewed the literatures, determined and defined the suitable quantitative and qualitative criteria and then designed & exploited pairwise comparison and evaluation forms through a survey to get experts opinions/preference on the evaluation criteria that are used to measure the universities and academic staff performance. This paper presents a fuzzy logic computational model based on this survey to measure and classify the performance of Sudanese universities and academic staff, which includes computation of criteria weights and overall evaluation of Sudanese universities and academic staff using AHP and TOPSIS techniques.}
}
@article{PUPKOV2021489,
title = {Dynamic and Information Properties of Intelligent Control Systems},
journal = {Procedia Computer Science},
volume = {186},
pages = {489-494},
year = {2021},
note = {14th International Symposium "Intelligent Systems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.169},
url = {https://www.sciencedirect.com/science/article/pii/S187705092101005X},
author = {K.A. Pupkov and Y.K. Brovarskaya},
keywords = {traffic flow model, optimal control, evolutionary computations, uncertainties},
abstract = {The paper considers the dynamic and informational properties of intelligent systems. The relationship is established between control quality and stability in such systems. The method was developed and a study was conducted of the dependence of the control quality and the time spent by the human operator on the evaluation of the test image. The influence of the clean delay time on the stability margin and the quality of the setting process is studied. The study shows that in intelligent systems that work in connection with a human-operator (a group of people) or independently, the time spent (a latent period) to implement thinking forms affects on the one hand the control quality, on the other the system stability. The desired value clean delay time is set. The research results are presented. The new parameter of information properties of intelligent systems has been introduced – the control quality.}
}
@article{KANAMORI2024103319,
title = {Kunen the expositor},
journal = {Annals of Pure and Applied Logic},
volume = {175},
number = {1, Part B},
pages = {103319},
year = {2024},
note = {Kenneth Kunen (1943-2020)},
issn = {0168-0072},
doi = {https://doi.org/10.1016/j.apal.2023.103319},
url = {https://www.sciencedirect.com/science/article/pii/S0168007223000763},
author = {Akihiro Kanamori},
keywords = {Handbook chapters, Set theory text, Late texts},
abstract = {Kunen's expository work is described, bringing out both his way of assimilating and thinking about set theory and how it had a meaningful hand in its promulgation into the next generations.}
}
@article{VALLEETOURANGEAU2020100812,
title = {Mapping systemic resources in problem solving},
journal = {New Ideas in Psychology},
volume = {59},
pages = {100812},
year = {2020},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2020.100812},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X17300272},
author = {Frédéric Vallée-Tourangeau and Gaëlle Vallée-Tourangeau},
abstract = {In the wild, thinking demonstrably uses interactive processes that draw on a wide range of external resources, spanning multiple time scales. As Malafouris (2015, p. 361) puts it, “cognition is not a within property; it is an in-between process”. Interactive processes configure extended systems within which each human agent is embedded. Yet much research on higher cognition, such as problem solving, reflects an implicit but deep commitment to methodological individualism that casts the agent as the ontological locus of cognition, and largely dictates the nature of the research enterprise. Thus, tasks to measure capacities and gauge reasoning performance are designed in a manner that reduces or eliminates the possibility of interacting with the problem presentation; if thinking takes place in the head, there is no need or reason to engineer procedures wherein agents can interact with the task's physical constituents. Conversely, a methodological interactivism forces one to acknowledge the participative yet not all-encompassing role of capacities such as working memory and thinking dispositions; it also encourages the granular mapping of the cognitive ecosystem from which new ideas emerge. To adopt an interactivist perspective is thus to focus on the cognitive resources of the extended system inviting a careful description of how these resources are dynamically configured over time and space to promote the development of new ideas in problem solving. In turn, a systemic perspective encourages the development of interventions that promote cognitive performance through the optimisation of systemic rather than individualist cognitive resources.}
}
@article{SILAGHI20121303,
title = {A time-constrained SLA negotiation strategy in competitive computational grids},
journal = {Future Generation Computer Systems},
volume = {28},
number = {8},
pages = {1303-1315},
year = {2012},
note = {Including Special sections SS: Trusting Software Behavior and SS: Economics of Computing Services},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2011.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X11002251},
author = {Gheorghe Cosmin Silaghi and Liviu Dan Şerban and Cristian Marius Litan},
keywords = {SLA negotiation, Intelligent strategies, Bayesian learning, Time constraints},
abstract = {Automated and intelligent negotiation solutions for reaching service level agreements (SLA) represent a hot research topic in computational grids. Previous work regarding SLA negotiation in grids focuses on devising bargaining models where service providers and consumers can meet and exchange SLA offers and counteroffers. Recent developments in agent research introduce strategies based on opponent learning for contract negotiation. In this paper we design a generic framework for strategical negotiation of service level values under time constraints and exemplify the usage of our framework by extending the Bayesian learning agent to cope with the limited duration of a negotiation session. We prove that opponent learning strategies are worth for consideration in open competitive computational grids, leading towards an optimal allocation of resources and fair satisfaction of participants.}
}
@article{GAAR202167,
title = {Towards a computational proof of Vizing's conjecture using semidefinite programming and sums-of-squares},
journal = {Journal of Symbolic Computation},
volume = {107},
pages = {67-105},
year = {2021},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2021.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747717121000092},
author = {Elisabeth Gaar and Daniel Krenn and Susan Margulies and Angelika Wiegele},
keywords = {Vizing's conjecture, Algebraic model, Gröbner basis, Sum-of-squares problems, Semidefinite programming},
abstract = {Vizing's conjecture (open since 1968) relates the product of the domination numbers of two graphs to the domination number of their Cartesian product graph. In this paper, we formulate Vizing's conjecture as a Positivstellensatz existence question. In particular, we select classes of graphs according to their number of vertices and their domination number and encode the conjecture as an ideal/polynomial pair such that the polynomial is non-negative on the variety associated with the ideal if and only if the conjecture is true for this graph class. Using semidefinite programming we obtain numeric sum-of-squares certificates, which we then manage to transform into symbolic certificates confirming non-negativity of our polynomials. Specifically, we obtain exact low-degree sparse sum-of-squares certificates for particular classes of graphs. The obtained certificates allow generalizations for larger graph classes. Besides computational verification of these more general certificates, we also present theoretical proofs as well as conjectures and questions for further investigations.}
}
@article{LOHSE2012236,
title = {Thinking about muscles: The neuromuscular effects of attentional focus on accuracy and fatigue},
journal = {Acta Psychologica},
volume = {140},
number = {3},
pages = {236-245},
year = {2012},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2012.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0001691812000807},
author = {Keith R. Lohse and David E. Sherwood},
keywords = {Attention, Force production, Motor control, Fatigue},
abstract = {Although the effects of attention on movement execution are well documented behaviorally, much less research has been done on the neurophysiological changes that underlie attentional focus effects. This study presents two experiments exploring effects of attention during an isometric plantar-flexion task using surface electromyography (sEMG). Participants' attention was directed either externally (towards the force plate they were pushing against) or internally (towards their own leg, specifically the agonist muscle). Experiment 1 tested the effects of attention on accuracy and efficiency of force produced at three target forces (30, 60, and 100% of the maximum voluntary contraction; MVC). An internal focus of attention reduced the accuracy of force being produced and increased cocontraction of the antagonist muscle. Error on a given trial was positively correlated with the magnitude of cocontraction on that trial. Experiment 2 tested the effects of attention on muscular fatigue at 30, 60 and 100%MVC. An internal focus of attention led to less efficient intermuscular coordination, especially early in the contraction. These results suggest that an internal focus of attention disrupts efficient motor control in force production resulting in increased cocontraction, which potentially explains other neuromechanical findings (e.g. reduced functional variability with an internal focus).}
}
@article{PAN2006448,
title = {Human and social behavior in computational modeling and analysis of egress},
journal = {Automation in Construction},
volume = {15},
number = {4},
pages = {448-461},
year = {2006},
note = {The first conference on the Future of the AEC Industry (BFC05)},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2005.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0926580505000737},
author = {Xiaoshan Pan and Charles S. Han and Ken Dauber and Kincho H. Law},
keywords = {Human and social behavior, Decision-making, Egress, Emergency, Computational modeling, Multi-agent system},
abstract = {Safe egress is one of the key design issues identified by facility planners, manager and inspectors. Computational tools are now available for the simulation and design of emergency evacuation and egress. However, these tools rely heavily on assumptions about individual human and social behaviors, which have been found to be oversimplified, inconsistent and even incorrect. Furthermore, the behaviors are usually incorporated into the computational model in an ad hoc manner. This paper presents a framework for studying human and social behavior, from the perspectives of human decision-making and social interaction, and for incorporating such behavior systematically in a dynamic computational model suitable for emergency egress analysis.}
}
@article{WELLS1998269,
title = {Turing's analysis of computation and theories of cognitive architecture},
journal = {Cognitive Science},
volume = {22},
number = {3},
pages = {269-294},
year = {1998},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(99)80041-X},
url = {https://www.sciencedirect.com/science/article/pii/S036402139980041X},
author = {A.J. Wells},
abstract = {Turing's analysis of computation is a fundamental part of the background of cognitive science. In this paper it is argued that a re-interpretation of Turing's work is required to underpin theorizing about cognitive architecture. It is claimed that the symbol systems view of the mind, which is the conventional way of understanding how Turing's work impacts on cognitive science, is deeply flawed. There is an alternative interpretation that is more faithful to Turing's original insights, avoids the criticisms made of the symbol systems approach and is compatible with the growing interest in agent-environment interaction. It is argued that this interpretation should form the basis for theories of cognitive architecture.}
}
@article{GOLDSMITH198815,
title = {Idiots savants — Thinking about remembering: A response to White},
journal = {New Ideas in Psychology},
volume = {6},
number = {1},
pages = {15-23},
year = {1988},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(88)90020-7},
url = {https://www.sciencedirect.com/science/article/pii/0732118X88900207},
author = {Lynn T. Goldsmith and David Henry Feldman}
}
@article{OXMAN1999105,
title = {Educating the designerly thinker},
journal = {Design Studies},
volume = {20},
number = {2},
pages = {105-122},
year = {1999},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(98)00029-5},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X98000295},
author = {Rivka Oxman},
keywords = {design education, design cognition, design knowledge, conceptual design, computational models},
abstract = {This paper presents a hypothesis about design education that is framed within and derived from cognitive theories of learning. The relevance of design thinking and cognitive approaches to the development of pedagogical approaches in design education is presented and discussed. A conceptual model for design education that emphasizes the acquisition of explicit knowledge of design is proposed. The acquisition of knowledge is achieved through the explication of cognitive structures and strategies of design thinking. The explication process is constructed by exploiting a representational formalism, and a computational medium which supports both the learning process as well as the potential re-use of this knowledge. Finally, an argument is presented that the measure of learning, generally equated with the evaluation of the product of designing, can instead be based upon evaluating learning increments of acquired knowledge.}
}
@article{GUPTA2024102882,
title = {“Wayfinding” through the AI wilderness: Mapping rhetorics of ChatGPT prompt writing on X (formerly Twitter) to promote critical AI literacies},
journal = {Computers and Composition},
volume = {74},
pages = {102882},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102882},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000586},
author = {Anuj Gupta and Ann Shivers-McNair},
keywords = {AI, ChatGPT, Prompt writing, Prompt engineering, Machine learning, Computational methods, Algorithms, Critical AI literacy, Digital rhetoric},
abstract = {In this paper, we demonstrate how studying the rhetorics of ChatGPT prompt writing on social media can promote critical AI literacies. Prompt writing is the process of writing instructions for generative AI tools like ChatGPT to elicit desired outputs and there has been an upsurge of conversations about it on social media. To study this rhetorical activity, we build on four overlapping traditions of digital writing research in computers and composition that inform how we frame literacies, how we study social media rhetorics, how we engage iteratively and reflexively with methodologies and technologies, and how we blend computational methods with qualitative methods. Drawing on these four traditions, our paper shows our iterative research process through which we gathered and analyzed a dataset of 32,000 posts (formerly known as tweets) from X (formerly Twitter) about prompt writing posted between November 2022 to May 2023. We present five themes about these emerging AI literacy practices: (1) areas of communication impacted by prompt writing, (2) micro-literacy resources shared for prompt writing, (3) market rhetoric shaping prompt writing, (4) rhetorical characteristics of prompts, and (5) definitions of prompt writing. In discussing these themes and our methodologies, we highlight takeaways for digital writing teachers and researchers who are teaching and analyzing critical AI literacies.}
}
@article{ZETTERLUND2023104508,
title = {Computational modelling to advise and inform optimization for aeration and nutrient-dosing in wastewater treatment: Case study from pulp and paper mill in south-central Sweden},
journal = {Journal of Water Process Engineering},
volume = {56},
pages = {104508},
year = {2023},
issn = {2214-7144},
doi = {https://doi.org/10.1016/j.jwpe.2023.104508},
url = {https://www.sciencedirect.com/science/article/pii/S2214714423010280},
author = {Selma Zetterlund and Olivia Schwartz and Maria Sandberg and G. Venkatesh},
keywords = {Aeration, Biological wastewater treatment, Energy use optimisation, Nutrients, Pulp and paper mills},
abstract = {Sweden's pulp and paper sector accounts for a significant proportion of national energy usage, besides generating wastewater that causes eutrophication of nearby sinks. In this paper, the possibility of optimizing biological wastewater treatment at the Stora Enso Skoghall mill south of the city of Karlstad in central Sweden, with respect to electricity usage and the addition of nutrients, has been investigated. A computational model of the treatment process was developed, based on process data obtained from the said mill, and nine different scenarios were compared subsequently, with energy use, environmental impacts and operational expenses, as criteria. The most energy-efficient and cost-effective alternative was a combination of measures such as lowering the oxygen level in the MBBR (Moving Bed Bio-Reactor) from 3 mg/l to 2 mg/l and using the Hyperclassic aerator in the aerated lagoon. This arrangement yielded a 48.5 % reduction in operational expenses, and a 60 % decrease in the energy use, vis-à-vis the reference case, without affecting the efficiency of the treatment process. This also uncovered an opportunity to mitigate the annual global warming and eutrophication impacts, by approximately 100 tons CO2-eq. and 140 kg PO43−-eq. respectively. All attempts to optimise the use of resources and decrease the anthropogenic environmental footprint ought to be made to come closer to the targets set by the United Nations' sustainable development goals (SDGs). The authors' conclusion predicated on the results of the modelling and analysis done in this study is that the potential of seemingly small process modifications, such as lowering the oxygen level in the MBBR, and applying a more optimal dosage of nutrient salts, must not be overlooked by wastewater treatment plants in general (and those in pulp and paper mills in particular).}
}
@article{KHANUM2022131890,
title = {Synthesis, single crystal, characterization and computational study of 2-amino-N-cyclopropyl-5-ethyl-thiophene-3-carboxamide},
journal = {Journal of Molecular Structure},
volume = {1250},
pages = {131890},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2021.131890},
url = {https://www.sciencedirect.com/science/article/pii/S0022286021020123},
author = {Ghazala Khanum and Aysha Fatima and Nazia Siddiqui and D.D. Agarwal and R.J. Butcher and Sanjay Kumar Srivastava and Saleem Javed},
keywords = {DFT studies, Fukui function, MEP, ELF, Hirshfeld, Molecular docking},
abstract = {2-amino-N-cyclopropyl-5-ethylthiophene-3-carboxamide (ACPETC) (C10H14N2OS) has been synthesized, characterized via single-crystal X-ray diffraction at 296 K and studied theoretically via DFT approach. The compound crystallizes in tetragonal crystal system, space group I-4 with Z = 8 and the following unit cell dimensions: a = 16.0892(4) Å, b = 16.0892(4) Å, c = 8.4059(2) Å. ACPETC was experimentally characterized by 1H, 13C NMR, FT-IR, UV–Vis and ESI-MS analysis. The molecular structure, vibrational spectra, MEP, ELF, NLO, NBO, NHO, and FMO analysis of ACPETC (C10H14N2OS) in the ground state were estimated using HF, MP2, DFT/B3LYP using the 6–311++G(d,p) basis set. Computed NMR chemical shifts (1H and 13C), as well as discrete regions in IR active vibrations, are in good concurrence with their experimental counterparts. FT-IR spectra of ACPETC were obtained in the ranges of 4000−450 cm−1. The UV–vis spectrum as well as the effects of solvents has been studied. The estimated HOMO and LUMO energies reveal that charge transfer happens within the molecule and MEP surface to be a chemically reactive region suitable for drug action. The O1-atom appears to be more vulnerable to electrophilic assault. The NBO analysis was also performed. It indicates that the greatest second order perturbation energy E(2) = 50.11 kcal/mol associated with electron delocalization from the donor (N15) → π* (C10-O14) acceptor interaction. On the atomic charges of the title chemical, the Fukui function and Mulliken analysis have been calculated. 3-D and 2-D interactions in crystals were studies and Hirshfeld surface analysis was used. To discover the optimum ligand-protein interactions, molecular docking was used using eight protein receptors.}
}
@article{MCLEAN2023104019,
title = {From Anti-doping-I to Anti-doping-II: Toward a paradigm shift for doping prevention in sport},
journal = {International Journal of Drug Policy},
volume = {115},
pages = {104019},
year = {2023},
issn = {0955-3959},
doi = {https://doi.org/10.1016/j.drugpo.2023.104019},
url = {https://www.sciencedirect.com/science/article/pii/S0955395923000683},
author = {Scott McLean and Mitchell Naughton and Hugo Kerhervé and Paul M. Salmon},
keywords = {Sport, Doping, World anti-doping agency, Systems thinking, Systems analysis},
abstract = {Doping remains an intractable issue in sport and occurs in a complex and dynamic environment comprising interactions between individual, situational, and environmental factors. Anti-doping efforts have previously predominantly focused on athlete behaviours and sophisticated detection methods, however, doping issues remain. As such, there is merit in exploring an alternative approach. The aim of this study was to apply a systems thinking approach to model the current anti-doping system for four football codes in Australia, using the Systems Theoretic Accident Model and Processes (STAMP). The STAMP control structure was developed and validated by eighteen subject matter experts across a five-phase validation process. Within the developed model, education was identified as a prominent approach anti-doping authorities use to combat doping. Further, the model suggests that a majority of existing controls are reactive, and hence that there is potential to employ leading indicators to proactively prevent doping and that new incident reporting systems could be developed to capture such information. It is our contention that anti-doping research and practice should consider a shift away from the current reactive and reductionist approach of detection and enforcement to a proactive and systemic approach focused on leading indicators. This will provide anti-doping agencies a new lens to look at doping in sport.}
}
@article{MARSIK2021108,
title = {Introducing ⦇ λ ⦈, a λ-calculus for effectful computation},
journal = {Theoretical Computer Science},
volume = {869},
pages = {108-155},
year = {2021},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2021.02.038},
url = {https://www.sciencedirect.com/science/article/pii/S0304397521001225},
author = {Jirka Maršík and Maxime Amblard and Philippe {de Groote}},
keywords = {Side effects, Monads, -calculus, Handlers, CRS, IDTS},
abstract = {We present ⦇λ⦈, a calculus with special constructions for dealing with effects and handlers. This is an extension of the simply-typed λ-calculus (STLC). We enrich STLC with a type for representing effectful computations alongside with operations to create and process values of this type. The calculus is motivated by natural language modelling, and especially semantic representation. Traditionally, the meaning of a sentence is calculated using λ-terms, but some semantic phenomena need more flexibility. In this article we introduce the calculus and show that the calculus respects the laws of algebraic structures and it enjoys strong normalisation. To do so, confluence is proven using the Combinatory Reduction Systems (CRSs) of Klop and termination using the Inductive Data Type Systems (IDTSs) of Blanqui.}
}
@article{TIBURU201836,
title = {Investigating the Conformation of S100β Protein Under Physiological Parameters Using Computational Modeling: A Clue for Rational Drug Design},
journal = {The Open Biomedical Engineering Journal},
volume = {12},
pages = {36-50},
year = {2018},
issn = {1874-1207},
doi = {https://doi.org/10.2174/1874120701812010036},
url = {https://www.sciencedirect.com/science/article/pii/S1874120718000036},
author = {Elvis K. Tiburu and Ibrahim Issah and Mabel Darko and Robert E. Armah-Sekum and Stephen O. A. Gyampo and Nadia K. Amoateng and Samuel K. Kwofie and Gordon Awandare},
keywords = {S100β Protein, Molecular Dynamics, Cofactors, Energy Minimization, Physiological Parameters, Alzheimer's},
abstract = {Background
Physiochemical factors such as temperature, pH and cofactors are well known parameters that confer conformational changes in a protein structure. With S100β protein being a metal binding brain-specific receptor for both extracellular and intracellular functions, a change in conformation due to the above-mentioned factors, can compromise their cellular functions and therefore result in several pathological conditions such as Alzheimer’s disease, Ischemic stroke, as well as Myocardial Infarction.
Objective
The studies conducted sought to elucidate the effect of these physiological factors on the conformational dynamics of S100β protein using computational modeling approaches.
Method
Temperature-dependent and protein-cofactor complexes molecular dynamics simulations were conducted by varying the temperature from 100 to 400K using GROMACS 5.0.3. Additionally, the conformational dynamics of the protein was studied by varying the pH at 5.0, 7.4 and 9.0 using Ambertools17. This was done by preparing the protein molecule, solvating and minimizing its energy level as well as heating it to the required temperature, equilibrating and simulating under desired conditions (NVT and NPT ensembles).
Results
The results show that the protein misfolds as a function of increasing temperature with alpha helical content at 100K and 400K being 57.8% and 43.3%, respectively. However, the binding sites of the protein were not appreciably affected by temperature variations. The protein displayed high conformational instability in acidic medium (pH ~5.0). The binding sites of Ca2+, Mg2+ and Zn2+ were identified and each exhibited different groupings of the secondary structural elements (binding motifs). The secondary structure analysis revealed different conformational changes with the characteristic appearance of two beta hairpins in the presence of Zn2+and Mg2+.
Conclusion
High temperatures, different cofactors and acidic pH confer conformational changes to the S100β structure and these results may indicate the design of novel drugs against the protein.}
}
@incollection{VOINOV202427,
title = {Participatory Modeling for Sustainability},
editor = {Martin A. Abraham},
booktitle = {Encyclopedia of Sustainable Technologies (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {27-35},
year = {2024},
isbn = {978-0-443-22287-0},
doi = {https://doi.org/10.1016/B978-0-323-90386-8.00020-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323903868000206},
author = {Alexey Voinov},
keywords = {Biases, Modeling process, Social media, Stakeholders, Wicked problem},
abstract = {Sustainability is a wicked problem, which is hard to define in a unique way. It cannot be solved and should be treated in a participatory approach involving as many stakeholders in the process as possible. Participatory modeling is an efficient method for dealing with wicked problems. It involves stakeholders in an open-ended process of shared learning and can be essential for developing sustainable technologies. While there may be various levels of participation, the process evolves around a model of the system at stake. The model is built in interaction with the stakeholders, it provides to formalism to synchronize stakeholder thinking and knowledge about the system and to move towards consensus about the possible decision-making.}
}
@article{MEACHAM2023103902,
title = {Fire safety of existing residential buildings: Building regulatory system gaps and needs},
journal = {Fire Safety Journal},
volume = {140},
pages = {103902},
year = {2023},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2023.103902},
url = {https://www.sciencedirect.com/science/article/pii/S0379711223001704},
author = {Brian J. Meacham},
keywords = {Regulatory system, Existing buildings, Fire risk, Systems thinking},
abstract = {Considerable cost and effort are invested in government and private-sector activities aimed at providing a societally tolerable level of fire safety of the built environment. This is particularly true with respect to fire safety of new building construction. On the government side, this includes activities associated with building and fire regulations, material performance and test standards, design guidance, competency requirements, review and approvals, and more. On the private side, activities include product development, analysis and design, construction and installation, as well as education and training of practitioners. In some cases there are overlaps (e.g., private building control). However, once buildings become occupied, the system faces several challenges. Oversight of building use and modification often gets lost. Different actors come into play. Competing objectives become more significant. Occupants often lack understanding and ability to recognize problems and make adjustments. The net result is an increase in fire safety risk over the life of a building, with less opportunities for the regulatory system to make interventions prior to an unwanted fire event. However, this can be changed if the approach to regulating existing buildings changes, and importantly, embodies whole-of-life, multi-agency, holistic, systems-based thinking.}
}
@article{KENNEDY198538,
title = {Thinking of opening your own business? Be prepared!},
journal = {Business Horizons},
volume = {28},
number = {5},
pages = {38-42},
year = {1985},
issn = {0007-6813},
doi = {https://doi.org/10.1016/0007-6813(85)90066-7},
url = {https://www.sciencedirect.com/science/article/pii/0007681385900667},
author = {Carson R. Kennedy},
abstract = {The good news is that new businesses are booming. The bad news is that many are going bust. Careful preparation prior to opening your own business is the best way to forestall failure.}
}
@article{QU2025104026,
title = {Compliance assessment oriented microcystin prediction: A Bayesian adaptive LASSO Tobit quantile regression approach},
journal = {Algal Research},
volume = {89},
pages = {104026},
year = {2025},
issn = {2211-9264},
doi = {https://doi.org/10.1016/j.algal.2025.104026},
url = {https://www.sciencedirect.com/science/article/pii/S2211926425001353},
author = {Fan Qu and Lingjing Lin and Changbo Qin and Fuli Peng and Runzi Wang and Nengwang Chen and Gang Zhao and Wentao Lu and Zhongyao Liang},
keywords = {Bayesian inference, Tobin's thinking, Left-censored response variable, Compliance assessment, Quantile regression, Microcystin management},
abstract = {Microcystin has been one of major contaminants impacting health of aquatic ecosystems and threatening human health. The development of drivers-microcystin relationship is of vital importance to microcystin management. However, current practices often focused on the mean response of microcystin concentration and cannot meet the requirement of percentile-based compliance assessment. Despite of many informative studies on the development of drivers–microcystin relationship, there remains a gap between the relationship development and the percentile-based compliance assessment of microcystin concentration. In this study, Bayesian adaptive LASSO Tobit quantile regression (BALTQR) model was introduced to environmental and ecological studies for the first time. The model is specially designed for the prediction of left-censored response variable. We applied the BALTQR model to develop the drivers–microcystin relationship of lakes across the US continent. Based on the results of parameters estimation, Chlorophyll a (CHL), pH, and water temperature (WT) were identified as key drivers to the microcystin concentration. We found that CHL was approximate the same important as pH and both of them had positive effects on the microcystin concentration at all the five regression quantiles. WT was relatively less important and had a surprisingly negative effect at the 0.7, 0.8, and 0.9 regression quantiles. We demonstrated that the BALTQR model successfully established the linkage between the development of drivers–microcystin relationship and the compliance assessment of microcystin concentration. We further revealed important implications of these findings to microcystin management. We believed that the BALTQR model has great potential of generalization to model other left-censored response variable in environmental and ecological studies.}
}
@incollection{MOLE2022367,
title = {Executive/Cognitive Control},
editor = {Sergio {Della Sala}},
booktitle = {Encyclopedia of Behavioral Neuroscience, 2nd edition (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {367-376},
year = {2022},
isbn = {978-0-12-821636-1},
doi = {https://doi.org/10.1016/B978-0-12-819641-0.00111-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128196410001110},
author = {Joseph Mole and Lisa Cipolotti},
keywords = {Frontal lobes, Active thought, Executive functioning, Fluid intelligence, Language, Focal lesions, Neuropsychology, Supervisory system, Reasoning, Lateralization of function},
abstract = {The capacity for active thought is arguably one of humanity's defining features. The frontal lobes are critically involved in active thinking. In this article we will consider what can be learned from the effects of frontal lobe lesions about: (1) the relationship between active thought and intelligence, (2) whether active thought can occur without language, and (3) the processes involved in active thinking. The evidence reviewed reveals that different forms of active thought and their essential pre-requisites can be fractionated and appear to be underpinned by different frontal areas. Hence, active thinking may be achieved by distinct, interacting cognitive processes.}
}
@article{SCHEZSOBRINO2024100648,
title = {MR-LEAP: Mixed-Reality Learning Environment for Aspirational Programmers},
journal = {Software Impacts},
volume = {20},
pages = {100648},
year = {2024},
issn = {2665-9638},
doi = {https://doi.org/10.1016/j.simpa.2024.100648},
url = {https://www.sciencedirect.com/science/article/pii/S2665963824000368},
author = {Santiago Schez-Sobrino and Francisco M. García and Javier A. Albusac and Carlos Glez-Morcillo and Jose J. Castro-Schez and David Vallejo},
keywords = {Programming learning, Mixed reality, Gamification, Computational thinking, Problem solving},
abstract = {This paper presents MR-LEAP (Mixed-Reality Learning Environment for Aspirational Programmers), a framework developed for learning programming through Mixed Reality and gamification mechanics. MR-LEAP’s architecture is designed to facilitate the understanding of basic programming concepts while allowing the gradual incorporation of more complex concepts. The framework provides a simple visual level editor. MR-LEAP is supported by the Mixed Reality Toolkit framework to promote portability to new Mixed Reality devices. Our goal is to facilitate programming education using Mixed Reality technology. MR-LEAP has already been used in both research and educational.}
}
@article{YAO2018107,
title = {Three-way decision and granular computing},
journal = {International Journal of Approximate Reasoning},
volume = {103},
pages = {107-123},
year = {2018},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18302809},
author = {Yiyu Yao},
keywords = {Three-way decision, Three-way computing, Granular computing in threes, Thinking in threes, Magical number three},
abstract = {Based on results from cognitive science, this paper examines the two fields of three-way decision and granular computing, as well as their interplay. The ideas from one field shed new light on the other field. The integration of the two gives rise to three-way granular computing, that is, thinking, problem solving, and information processing in threes. We discuss a wide sense of three-way decision and propose a trisecting–acting–outcome (TAO) model. We explain fundamental notions of granular computing based on the philosophy of three-way decision as thinking in threes. We discuss a model of three-way granular computing by making use of two particular types of granular structures represented, respectively, by three granules and three levels. We use examples across different disciplines to demonstrate the values of the two types. Our investigation suggests that, in many situations, the power of granular computing is indeed the power of three-way decision, i.e., thinking in threes.}
}
@article{AGUIRRE2024101196,
title = {Mathematizing the world: A routine to advance mathematizing in the elementary classroom},
journal = {The Journal of Mathematical Behavior},
volume = {76},
pages = {101196},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101196},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000737},
author = {Julia M. Aguirre and Erin E. Turner and Elzena McVicar and Amy Roth McDuffie and Mary Q. Foote and Erin Carll},
keywords = {Mathematizing, Elementary, Mathematical thinking, Problem posing, Culturally responsive},
abstract = {The Mathematizing-the-World routine (MWR) is an efficient culturally responsive instructional routine for mathematizing that explicitly supports problem posing using an image or object. Given the under-representation of problem-posing studies in elementary school settings, our qualitative study analyzed student responses from 56 MWR enactments in grade 3–5 classrooms in two regions of the United States. Our findings include detailed examples of the MWR in action, including how three open-ended prompts engaged younger students in mathematizing and posing problems related to authentic, real-world situations. We summarize findings across the 56 MWR classroom enactments focusing on the understandings about the context and the mathematical ideas evidenced in student responses. Our findings demonstrate the potential of the MWR as a catalyst for eliciting and communicating diverse student ideas while engaged in the problem-posing process. We discuss research and practice implications for this routine to support mathematizing, and specifically problem posing in the elementary classroom.}
}
@article{SUTHAR2023122,
title = {The integrative approach of learning chemical engineering thermodynamics by using simulation-based exercises},
journal = {Education for Chemical Engineers},
volume = {45},
pages = {122-129},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S174977282300043X},
author = {Krunal J. Suthar and Milind H. Joshipura},
keywords = {Process simulation, Thermodynamics, Teaching-learning, Fluid package},
abstract = {The active learning integrative approach of simulation-based exercises along with the core course would help undergraduate students with more engaged learning. The present study describes the simulation approach using an open-source process simulator with the help of three simulation-based exercises. The first one exemplifies the importance of the selection of an appropriate fluid package. The second exercise presented in the study shows the effect of using optimized and default values of binary interaction parameters on VLE prediction of alcohol-ester systems. The small interactive simulation-based problems with expected outcomes were presented in the third exercise which makes the learning more engaging and interesting. The current study highlights an integrative approach to inculcating critical thinking and self-learning abilities using small simulation-based exercises while learning chemical engineering thermodynamics. Finally, a survey with closed- and open-ended questions was used to gather the opinions of students on the presented exercises. A short communication is needed that sheds light on the integrative approach of learning process simulation complementing the thermodynamic theory learning.}
}
@article{JOHNSON20241037,
title = {Minds and markets as complex systems: an emerging approach to cognitive economics},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {11},
pages = {1037-1050},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001748},
author = {Samuel G.B. Johnson and Patrick R. Schotanus and J.A. Scott Kelso},
keywords = {decision-making, behavioral economics, narratives, agent-based models, extended mind, Coordination Dynamics},
abstract = {Cognitive economics is an emerging interdisciplinary field that uses the tools of cognitive science to study economic and social decision-making. Although most strains of cognitive economics share commitments to bridging levels of analysis (cognitive, behavioral, and systems) and embracing interdisciplinary approaches, we review a newer strand of cognitive economic thinking with a further commitment: conceptualizing minds and markets each as complex adaptive systems. We describe three ongoing research programs that strive toward these goals: (i) studying narratives as a cognitive and social representation used to guide decision-making; (ii) building cognitively informed agent-based models; and (iii) understanding markets as an extended mind – the Market Mind Hypothesis – analyzed using the concepts, methods, and tools of Coordination Dynamics.}
}
@article{FERNYHOUGH20231180,
title = {Inner speech as language process and cognitive tool},
journal = {Trends in Cognitive Sciences},
volume = {27},
number = {12},
pages = {1180-1193},
year = {2023},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002103},
author = {Charles Fernyhough and Anna M. Borghi},
keywords = {inner dialogue, inner monologue, verbal thinking, self-talk, self-regulation, phenomenology},
abstract = {Many people report a form of internal language known as inner speech (IS). This review examines recent growth of research interest in the phenomenon, which has broadly supported a theoretical model in which IS is a functional language process that can confer benefits for cognition in a range of domains. A key insight to have emerged in recent years is that IS is an embodied experience characterized by varied subjective qualities, which can be usefully modeled in artificial systems and whose neural signals have the potential to be decoded through advancing brain–computer interface technologies. Challenges for future research include understanding individual differences in IS and mapping form to function across IS subtypes.}
}
@article{HOGENDOORN2022128,
title = {Perception in real-time: predicting the present, reconstructing the past},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {2},
pages = {128-141},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321002886},
author = {Hinze Hogendoorn},
keywords = {perception, time, prediction, real-time, neural delays},
abstract = {We feel that we perceive events in the environment as they unfold in real-time. However, this intuitive view of perception is impossible to implement in the nervous system due to biological constraints such as neural transmission delays. I propose a new way of thinking about real-time perception: at any given moment, instead of representing a single timepoint, perceptual mechanisms represent an entire timeline. On this timeline, predictive mechanisms predict ahead to compensate for delays in incoming sensory input, and reconstruction mechanisms retroactively revise perception when those predictions do not come true. This proposal integrates and extends previous work to address a crucial gap in our understanding of a fundamental aspect of our everyday life: the experience of perceiving the present.}
}
@article{WANG2013226,
title = {A Computational Knowledge Elicitation and Sharing System for mental health case management of the social service industry},
journal = {Computers in Industry},
volume = {64},
number = {3},
pages = {226-234},
year = {2013},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2012.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0166361512001777},
author = {W.M. Wang and C.F. Cheung},
keywords = {Narratives, Knowledge management, Concept mapping, Knowledge-based system, Natural language processing},
abstract = {Narrative data provide rich information and knowledge to the workers. However, existing systems mainly served as a workflow system, a reporting system, or a database system for storing this kind of information. The massive amount of unstructured narrative data makes it extremely difficult to be shared and reused. Actual knowledge sharing and reuse among the workers is still limited. This paper presents a Computational Knowledge Elicitation and Sharing System which attempts to elicit knowledge from individuals as well as a team and converts it into a structured format and shared among the team. The proposed system accomplishes several current technologies in knowledge-based system, artificial intelligence and natural language processing, which converts the narrative knowledge of knowledge workers into a concept mapping representation. With a sufficient number of narratives, patterns are revealed and an aggregate concept map for all participating members is produced. It converts the unstructured text into a more structured format which helps to summarize and share the knowledge that can be taken in handling different case management issues. Such integration is considered to be novel. A prototype system has been implemented based on the method successfully in the mental healthcare of a social service organization for handling their case management issues. An experiment has been carried out for measuring the accuracy for converting the unstructured data into the structured format. The theoretical results are found to agree well with the experimental results.}
}
@article{RUSSO2020745,
title = {Neural Trajectories in the Supplementary Motor Area and Motor Cortex Exhibit Distinct Geometries, Compatible with Different Classes of Computation},
journal = {Neuron},
volume = {107},
number = {4},
pages = {745-758.e6},
year = {2020},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2020.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S0896627320303664},
author = {Abigail A. Russo and Ramin Khajeh and Sean R. Bittner and Sean M. Perkins and John P. Cunningham and L.F. Abbott and Mark M. Churchland},
keywords = {supplementary motor area, motor control, motor cortex, population coding, recurrent neural network, neural dynamics, neural computation, population geometry},
abstract = {Summary
The supplementary motor area (SMA) is believed to contribute to higher order aspects of motor control. We considered a key higher order role: tracking progress throughout an action. We propose that doing so requires population activity to display low "trajectory divergence": situations with different future motor outputs should be distinct, even when present motor output is identical. We examined neural activity in SMA and primary motor cortex (M1) as monkeys cycled various distances through a virtual environment. SMA exhibited multiple response features that were absent in M1. At the single-neuron level, these included ramping firing rates and cycle-specific responses. At the population level, they included a helical population-trajectory geometry with shifts in the occupied subspace as movement unfolded. These diverse features all served to reduce trajectory divergence, which was much lower in SMA versus M1. Analogous population-trajectory geometry, also with low divergence, naturally arose in networks trained to internally guide multi-cycle movement.}
}
@article{SNAIDER201259,
title = {Time production and representation in a conceptual and computational cognitive model},
journal = {Cognitive Systems Research},
volume = {13},
number = {1},
pages = {59-71},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041710000781},
author = {Javier Snaider and Ryan McCall and Stan Franklin},
keywords = {Time, Time perception, Cognitive architecture, Event, Duration},
abstract = {Time perception and inferences there from are of critical importance to many autonomous agents. But time is not perceived directly by any sensory organ. We argue that time is constructed by cognitive processes. Here we present a model for time perception that concentrates on succession and duration, and that generates these concepts and others, such as continuity, immediate present duration, and lengths of time. These concepts are grounded through the perceptual process itself. We also address event representation, event hierarchy and expectations, as issues intimately related with time. The LIDA cognitive model is used to illustrate these ideas.}
}
@article{ZBOINSKA2019675,
title = {Influence of a hybrid digital toolset on the creative behaviors of designers in early-stage design},
journal = {Journal of Computational Design and Engineering},
volume = {6},
number = {4},
pages = {675-692},
year = {2019},
issn = {2288-4300},
doi = {https://doi.org/10.1016/j.jcde.2018.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S228843001830174X},
author = {Malgorzata A. Zboinska},
keywords = {Early-stage design, Digital design, Computational design, Architectural design, Hybrid digital design systems, Intelligent human-machine integration},
abstract = {The purpose of this research was to investigate how diversification of the repertoire of digital design techniques affects the creative behaviors of designers in the early design phases. The principal results of practice-based pilot experiments on the subject indicate three key properties of the hybrid digital tooling strategy. The strategy features intelligent human-machine integration, facilitating three different types of synergies between the designer and the digital media: human-dominated, machine-dominated, and a balanced human-machine collaboration. This strategy also boosts the cognitive behaviors of the designer by triggering divergent, transformative and convergent design activities and allowing for work on various abstraction levels. In addition, the strategy stimulates the explorative behaviors of the designer by encouraging the production of and interaction with a wide range of design representations, including physical and digital, dynamic and static objects. Thus, working with a broader range of digital modeling techniques can positively influence the creativity of designers in the early conception stages.}
}
@article{PENG2025109960,
title = {LMCodec2: Ultra-low bit rate codec with causal multiple transformers},
journal = {Computers and Electrical Engineering},
volume = {122},
pages = {109960},
year = {2025},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109960},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624008851},
author = {Dingwei Peng and Qizhen Weng and Ningze Zhong and Ting Xie and Can Gong and Xiangwei Zhu and Xuelin Yuan and Mingjun Ouyang},
keywords = {End-to-end codec, VQ-VAE, GAN, Transformer model, Huffman coding},
abstract = {In recent years, the bandwidth constraints in satellite Internet of Things (IoT) applications have spurred the development of novel methods for compressing transmitted speech. For satellite voice communications, it is essential to achieve high-quality codecs with a bit rate below 1 kbps, particularly for channels such as Beidou-3, which often operate under such limitations. Neural network-based vocoders have emerged as a promising solution within the AI community, offering high-fidelity audio compression. In this paper, we propose LMCodec2, a causal speech codec designed to operate across a range of bit rates while delivering high-quality audio at extremely low bit rates, specifically tailored for satellite voice transmission. LMCodec2 utilizes a Transformer-based language model to predict tokens frame by frame, achieving a 25 % reduction in bit rate without compromising decoded audio quality. Our experimental evaluations demonstrate that LMCodec2 produces high-quality decoded audio at 0.76 kbps and 1.15 kbps. Notably, at 0.76 kbps, LMCodec2 achieves a MUSHRA (Multi-Stimulus Test with Hidden Reference and Anchor) score that surpasses Encodec's performance at 1.5 kbps. Audio demonstrations, including real-world self-recorded speech datasets, are available at https://dingweipeng.github.io/JACK.github.io. LMCodec2 provides a new way of thinking to addressing the challenges of bandwidth-limited satellite voice communications.}
}
@article{SHARIF2025101979,
title = {Innovative computation to detect stress in working people based on mode of commute},
journal = {Journal of Transport & Health},
volume = {41},
pages = {101979},
year = {2025},
issn = {2214-1405},
doi = {https://doi.org/10.1016/j.jth.2024.101979},
url = {https://www.sciencedirect.com/science/article/pii/S2214140524002251},
author = {Mhd Saeed Sharif and Madhav Raj Theeng Tamang and Cynthia Fu and Ahmed Ibrahim Alzahrani and Fahad Alblehai},
keywords = {Stress assessment, Blood pressure, Wearable sensors, Commuting, Intelligent transport system, Machine learning},
abstract = {Introduction:
Commuting is an integral part of modern life for many people, shaping daily routines and impacting overall well-being. With various transportation options, including driving, public transport, walking, and cycling, commuters encounter various experiences and challenges in their everyday journeys. Understanding how different modes of commuting affect stress levels is essential for improving public health and informing transportation planning. This study develops advanced machine-learning techniques to explore the connection between commuting methods and stress levels.
Methods:
This research examines how different commuting modes affect stress levels using machine learning methods. The study analyses data collected from 45 individuals who regularly commute to work, focusing on driving, cycling, and public transport modes. Non-invasive wearable sensors were utilised to gather electroencephalography (EEG), blood pressure (BP), and heart rate (HR) data for five consecutive days for each participant. Additionally, qualitative data was collected using the Positive and Negative Affect Schedule (PANAS) questionnaire to assess participants’ emotional responses before and after their commute. The research focuses on developing a machine learning-based model to predict the commute’s impact and monitor the stress level due to the commute mode. In research, objective and subjective factors shape the research process and outcomes. Understanding the interaction between these factors is essential for conducting thorough and reliable research that produces valid results. Our study utilises datasets incorporating qualitative and quantitative data from questionnaires and human bio-signals.
Results:
This research developed various machine learning algorithms to detect stress levels based on commuting mode. The results indicate that the Linear Discriminant Analysis technique achieved an accuracy of 88%, while Logistic Regression reached 90.66% accuracy. The Boosted Tree algorithm produced the best performance, with an accuracy of 91.11%. Furthermore, incorporating personalised parameters into the data improved the accuracy of these algorithms in detecting stress levels. Cross-validation was also utilised to mitigate the risk of overfitting, ensuring robust and reliable model performance.
Conclusion:
The findings reveal that human bio-signals tend to increase following commuting, irrespective of the mode, with driving identified as the most stressful option. Commuters using passive modes of transport experience elevated stress levels compared to those using active modes. This research underscores the importance of understanding the connection between commuting modes and stress, providing key insights into the potential health impacts of daily travel. The development of an intelligent model to predict stress levels based on commuting mode offers valuable contributions to public health and transportation planning, with the goal of enhancing well-being and improving commuters’ quality of life.}
}
@article{MANNI2016260,
title = {Numerical study of airfoil stall cells using a very wide computational domain},
journal = {Computers & Fluids},
volume = {140},
pages = {260-269},
year = {2016},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2016.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S0045793016302894},
author = {Luca Manni and Takafumi Nishino and Pierre-Luc Delafin},
keywords = {Flow separation, 2D/3D transition, High aspect ratio wing, Unsteady RANS, Delayed DES},
abstract = {The formation of stall cells over a NACA 0012 airfoil at a Reynolds number of one million has been investigated numerically, using unsteady Reynolds-averaged Navier–Stokes (URANS) and delayed detached-eddy simulation (DDES) approaches. The simulations are performed with a very wide computational domain (10 chord length) to minimize the influence of spanwise periodic boundary conditions. For the URANS simulations, four different spanwise mesh resolutions are tested to determine the minimum resolution required to capture the formation of stall cells. Both URANS and DDES results show a sudden decrease in lift and increase in drag between 16° and 17° angle of attack, accompanied by a significant change of separated flow patterns. Stall cell structures are observed clearly in the URANS solutions between 17° and 19° with a spanwise spacing of about 1.4 to 1.8 chord length, which agrees well with a theoretical prediction based on the slope of the lift curve in this angle-of-attack range. The DDES results show much more complex flow patterns over the airfoil at these high angles of attack, although the spectral analysis of wall shear stress suggests the existence of flow structures having a similar spanwise length scale to the stall cells.}
}
@article{GERSTEIN200773,
title = {An interdepartmental Ph.D. program in computational biology and bioinformatics: The Yale perspective},
journal = {Journal of Biomedical Informatics},
volume = {40},
number = {1},
pages = {73-79},
year = {2007},
note = {Bio*Medical Informatics},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2006.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S1532046406000335},
author = {Mark Gerstein and Dov Greenbaum and Kei Cheung and Perry L. Miller},
keywords = {Bioinformatics, Computational biology, Educational programs, Curriculum},
abstract = {Computational biology and bioinformatics (CBB), the terms often used interchangeably, represent a rapidly evolving biological discipline. With the clear potential for discovery and innovation, and the need to deal with the deluge of biological data, many academic institutions are committing significant resources to develop CBB research and training programs. Yale formally established an interdepartmental Ph.D. program in CBB in May 2003. This paper describes Yale’s program, discussing the scope of the field, the program’s goals and curriculum, as well as a number of issues that arose in implementing the program. (Further updated information is available from the program’s website, www.cbb.yale.edu.)}
}
@article{BEDEWY2023101299,
title = {STEAM + X - Extending the transdisciplinary of STEAM-based educational approaches: A theoretical contribution},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101299},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101299},
url = {https://www.sciencedirect.com/science/article/pii/S187118712300069X},
author = {Shereen El Bedewy and Zsolt Lavicza},
keywords = {STEAM, Design-based research, Culture, Technology, Design principles},
abstract = {This design-based research methodological paper is proposing a theoretical understanding in the form of STEAM + X framework that emerged from the empirical findings of implementing transdisciplinary STEAM practices featuring architecture, culture, and history. This paper shows how the proposed STEAM practices, involving creativities, to promote the integration of various disciplines with multiple cross-cultural iterations. These STEAM practices allow teachers to integrate cultural, architectural, environmental, or technological options into mathematics teaching and learning. These STEAM practices foster creativity and thinking skills in connecting disciplines in a transdisciplinary learning approach. Moreover, this paper introduces the study outcomes including the developed design principles and a framework that connects the underlying theoretical framework with emerging themes from our qualitative data analysis.}
}
@incollection{TOPLAK20221,
title = {1 - Defining cognitive sophistication in the development of judgment and decision-making},
editor = {Maggie E. Toplak},
booktitle = {Cognitive Sophistication and the Development of Judgment and Decision-Making},
publisher = {Academic Press},
pages = {1-22},
year = {2022},
isbn = {978-0-12-816636-9},
doi = {https://doi.org/10.1016/B978-0-12-816636-9.00010-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128166369000104},
author = {Maggie E. Toplak},
keywords = {Judgment and decision-making, Children and youth, Development, Cognitive sophistication, Critical thinking, Rationality, Stimulus equivalence, Miserly processing},
abstract = {Judgment and decision-making paradigms have been relatively well-studied in developmental samples. The measurement of these competencies in developmental samples has been of scientific interest. They have been recognized as having important implications for defining rational thinking in children and youth but also for teaching and training (such as, critical thinking in education). The origin of the theories and paradigms come from the adult literature, which has also undergone considerable progress in theoretical advancements and empirical studies over the last several years. The integration of our understanding from the work conducted in adults with consideration of developmental factors provides a way to advance our understanding of judgment and decision-making in children and youth. To accomplish this, establishing stimulus equivalence will be important given that these paradigms were first designed for adult samples. In addition, taking into account the rapid growth and change in cognitive capacities, that happen in development, are central for understanding performance on these paradigms. Using a working taxonomy of rational thinking based on adult samples, data from a longitudinal developmental study were used to empirically examine performance patterns on these paradigms.}
}
@article{SAIDI20091467,
title = {PLR-based heuristic for backup path computation in MPLS networks},
journal = {Computer Networks},
volume = {53},
number = {9},
pages = {1467-1479},
year = {2009},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2009.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1389128609000292},
author = {Mohand Yazid Saidi and Bernard Cousin and Jean-Louis {Le Roux}},
keywords = {Recovery, Local protection, Backup LSP, Failure risk, SRLG, MPLS, Bandwidth sharing, Path computation, Network},
abstract = {To ensure service continuity in networks, local protection pre-configuring the backup paths is preferred to global protection. Under the practical hypothesis of single physical failures in the network, the backup paths which protect against different logical failure risks (node, link and shared risk link group (SRLG)) cannot be active at the same time. Thus, sharing bandwidth between such backup paths is crucial to increase the bandwidth availability. In this article, we focus on the optimal on-line distributed computation of the bandwidth-guaranteed backup paths in MPLS networks. As the requests for connection establishment and release arrive dynamically without knowledge of future arrivals, we choose to use the on-line mode to avoid LSP reconfigurations. We also selected a distributed computation to offer scalability and decrease the LSP setup time. Finally, the optimization of bandwidth utilization can be achieved thanks to the flexibility of the path choice offered by MPLS and to the bandwidth sharing. For a good bandwidth sharing, the backup path computation entities (BPCEs) require the knowledge and maintenance of a great quantity of bandwidth information (e.g. non aggregated link information or per path information) which is undesirable in distributed environments. To get around this problem, we propose here a PLR (point of local repair)-based heuristic (PLRH) which aggregates and noticeably decreases the size of the bandwidth information advertised in the network while offering a high bandwidth sharing. PLRH permits an efficient computation of backup paths. It is scalable, easy to be deployed and balances equitably computations on the network nodes. Simulations show that with the transmission of a small quantity of aggregated information per link, the ratio of rejected backup paths is low and close to the optimum.}
}
@article{STARK2021571,
title = {Autistic Cognition: Charting Routes to Anxiety},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {7},
pages = {571-581},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000899},
author = {Eloise Stark and James Stacey and Will Mandy and Morten L. Kringelbach and Francesca Happé},
keywords = {autism, cognition, anxiety, predictive processing, intolerance of uncertainty, black and white thinking},
abstract = {Autism Spectrum Conditions are typified by a divergence in cognitive style from that of the non-autistic population. Cognitive differences in autism may underlie significant strengths, but also increase vulnerability to psychopathology such as anxiety, which is a major problem for many autistic people. Many autistic people also do not respond to typical psychotherapeutic interventions, suggesting that autism-specific models and interventions are needed. We advance a theoretical model explaining how three constructs, attenuated predictions, intolerance of uncertainty, and ‘black and white thinking’, may interact to lead to anxiety in autism. We hope to start a dialogue surrounding how we can best address specific autistic cognitive differences that may lead to distress by developing appropriate models, measurements, and psychotherapeutic interventions.}
}
@article{BALAHUR20141,
title = {Computational approaches to subjectivity and sentiment analysis: Present and envisaged methods and applications},
journal = {Computer Speech & Language},
volume = {28},
number = {1},
pages = {1-6},
year = {2014},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2013.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885230813000697},
author = {Alexandra Balahur and Rada Mihalcea and Andrés Montoyo},
keywords = {Subjectivity analysis, Sentiment analysis, Multilingual resources, Social Media mining, Chat analysis},
abstract = {Recent years have witnessed a surge of interest in computational methods for affect, ranging from opinion mining, to subjectivity detection, to sentiment and emotion analysis. This article presents a brief overview of the latest trends in the field and describes the manner in which the articles contained in the special issue contribute to the advancement of the area. Finally, we comment on the current challenges and envisaged developments of the subjectivity and sentiment analysis fields, as well as their application to other Natural Language Processing tasks and related domains.}
}
@article{ROLLS2024e31965,
title = {The memory systems of the human brain and generative artificial intelligence},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31965},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31965},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079969},
author = {Edmund T. Rolls},
keywords = {The brain and AI, Generative Pre-trained Transformer, Generative artificial intelligence, Episodic memory, Semantic memory, Hippocampal memory system, Chat-GPT},
abstract = {Generative Artificial Intelligence foundation models (for example Generative Pre-trained Transformer – GPT – models) can generate the next token given a sequence of tokens. How can this ‘generative AI’ be compared with the ‘real’ intelligence of the human brain, when for example a human generates a whole memory in response to an incomplete retrieval cue, and then generates further prospective thoughts? Here these two types of generative intelligence, artificial in machines and real in the human brain are compared, and it is shown how when whole memories are generated by hippocampal recall in response to an incomplete retrieval cue, what the human brain computes, and how it computes it, are very different from generative AI. Key differences are the use of local associative learning rules in the hippocampal memory system, and of non-local backpropagation of error learning in AI. Indeed, it is argued that the whole operation of the human brain is performed computationally very differently to what is implemented in generative AI. Moreover, it is emphasized that the primate including human hippocampal system includes computations about spatial view and where objects and people are in scenes, whereas in rodents the emphasis is on place cells and path integration by movements between places. This comparison with generative memory and processing in the human brain has interesting implications for the further development of generative AI and for neuroscience research.}
}
@article{KUO2010307,
title = {Conceptual study of micro-tab device in airframe noise reduction: (I) 2D computation},
journal = {Aerospace Science and Technology},
volume = {14},
number = {5},
pages = {307-315},
year = {2010},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2010.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S1270963810000210},
author = {Brian C. Kuo and Nesrin Sarigul-Klijn},
keywords = {Computational aeroacoustics, High-lift device, Micro-tab, Airframe noise},
abstract = {A two-dimensional numerical study was performed to investigate the acoustic effects of micro-tab device on airframe noise reduction. As the noise generated by leading-edge slat and trailing-edge flap rise with their increased deflection angles, it is possible to mitigate such high-lift noise by using reduced settings without sacrificing the aerodynamic performance during approach. In this paper, micro-tab device attached to the pressure side of the flap surface is envisioned as a mean to achieve this goal. Hybrid method involving Computational Fluid Dynamics and acoustic analogy was used to predict the far-field noise spectrum. Results illustrate that the micro-tab device with reduced deflection angles of the high-lift settings provides lower noise signature at far-field positions, comparing to the baseline configuration, while the aerodynamic performance is maintained. In addition, two parametric studies which investigated the effects of micro-tab location and micro-tab height on acoustic spectra were also included.}
}
@article{LOURENCO2020258,
title = {Synaptic inhibition in the neocortex: Orchestration and computation through canonical circuits and variations on the theme},
journal = {Cortex},
volume = {132},
pages = {258-280},
year = {2020},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2020.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S001094522030318X},
author = {Joana Lourenço and Fani Koukouli and Alberto Bacci},
keywords = {Neocortex, Inhibition, Interneurons, Cortical circuits, Synaptic transmission},
abstract = {The neocortex plays a crucial role in all basic and abstract cognitive functions. Conscious mental processes are achieved through a correct flow of information within and across neocortical networks, whose particular activity state results from a tight balance between excitation and inhibition. The proper equilibrium between these indissoluble forces is operated with multiscale organization: along the dendro–somatic axis of single neurons and at the network level. Fast synaptic inhibition is assured by a multitude of inhibitory interneurons. During cortical activities, these cells operate a finely tuned division of labor that is epitomized by their detailed connectivity scheme. Recent results combining the use of mouse genetics, cutting-edge optical and neurophysiological approaches have highlighted the role of fast synaptic inhibition in driving cognition-related activity through a canonical cortical circuit, involving several major interneuron subtypes and principal neurons. Here we detail the organization of this cortical blueprint and we highlight the crucial role played by different neuron types in fundamental cortical computations. In addition, we argue that this canonical circuit is prone to many variations on the theme, depending on the resolution of the classification of neuronal types, and the cortical area investigated. Finally, we discuss how specific alterations of distinct inhibitory circuits can underlie several devastating brain diseases.}
}
@article{DAW2006199,
title = {The computational neurobiology of learning and reward},
journal = {Current Opinion in Neurobiology},
volume = {16},
number = {2},
pages = {199-204},
year = {2006},
note = {Cognitive neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2006.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0959438806000316},
author = {Nathaniel D Daw and Kenji Doya},
abstract = {Following the suggestion that midbrain dopaminergic neurons encode a signal, known as a ‘reward prediction error’, used by artificial intelligence algorithms for learning to choose advantageous actions, the study of the neural substrates for reward-based learning has been strongly influenced by computational theories. In recent work, such theories have been increasingly integrated into experimental design and analysis. Such hybrid approaches have offered detailed new insights into the function of a number of brain areas, especially the cortex and basal ganglia. In part this is because these approaches enable the study of neural correlates of subjective factors (such as a participant's beliefs about the reward to be received for performing some action) that the computational theories purport to quantify.}
}
@article{ANDRILLON2025,
title = {Where is my mind? A neurocognitive investigation of mind blanking},
journal = {Trends in Cognitive Sciences},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2025.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661325000348},
author = {Thomas Andrillon and Antoine Lutz and Jennifer Windt and Athena Demertzi},
keywords = {mind blanking, mind wandering, meditation, dreaming, ongoing thinking},
abstract = {During wakefulness, our thoughts transition between different contents. However, there are moments that are seemingly devoid of reportable content, referred to as mind blanking (MB). It remains unclear what these blanks represent, highlighting the definitional and phenomenological ambiguities surrounding MB. We map out MB in terms of its reportable expressions, neurophysiology, and relationship to adjacent phenomenology, including meditative practices and sleep. We propose a mechanistic account linking MB to changes at the physiological, neural, and cognitive levels. We suggest that ongoing experiences are characterized by degrees of richness, and that contentless events represent distinct mental states with their own diversity. We encourage future research to acknowledge MB as a reportable mental category, leading to a comprehensive understanding of ongoing experience.}
}
@article{LONG201855,
title = {Data-driven decision making for supply chain networks with agent-based computational experiment},
journal = {Knowledge-Based Systems},
volume = {141},
pages = {55-66},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2017.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0950705117305294},
author = {Qingqi Long},
keywords = {Data-driven decision making, Supply chain network, Business analytics, Data-granularity model, Four-dimensional-flow model, Agent-based computational experiment},
abstract = {The complicated micro structures, macro emergences and dynamic evolutions in a supply chain network pose challenges to decision making for solving operational problems for the network's performance improvement. Most of these problems are complicated since various factors and their complicated relationships are involved. Success of this decision making relies on efficient business analytics based on the comprehensive and multi-dimensional data related to the static attributes and dynamic operations of the network. To confront the challenges, this paper proposes to explore a methodology of data-driven decision making for supply chain networks. In this methodology, a data-granularity model of a supply chain network is developed to standardize the data form for decision making. A four-dimensional-flow model of a supply chain network is proposed to satisfy the data requirements for decision making that are defined in the data-granularity model. Agent-based computational experiment is employed to support the generation of a comprehensive operational dataset of a supply chain network and to verify the solutions generated in decision making. Integrating these models, a data-driven decision-making framework for supply chain networks is proposed. In the framework, a new decision-making mode of “problem definition - business analytics - solution verification - parameter adjustment” is proposed. Oriented towards domain knowledge in supply chain networks, two approaches of business analytics—mapping analysis and correlation analysis—are presented. Finally, a case of a five-echelon manufacturing supply chain network is studied with the methodology. The findings indicate that the proposed methodology, models and framework are effective in supporting the data-centric decision making for solving complicated operational problems in supply chain networks and provide the networks’ managers or member enterprises with an effective tool to generate unbiased and efficient decisions for the networks’ performance improvement.}
}
@incollection{HOUQUN2016155,
title = {Chapter 8 - Research on parallel computation of high arch dam structure seismic motion response},
editor = {Chen Houqun and Wu Shengxin and Dang Faning},
booktitle = {Seismic Safety of High Arch Dams},
publisher = {Academic Press},
address = {Oxford},
pages = {155-205},
year = {2016},
isbn = {978-0-12-803628-0},
doi = {https://doi.org/10.1016/B978-0-12-803628-0.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128036280000082},
author = {Chen Houqun and Wu Shengxin and Dang Faning},
keywords = {seismic response analysis, high arch dam, high-performance parallel computation, component technique, technique of automatically generating programs, FEPG and PFEPG computation programs},
abstract = {The storage capacity and the computation time of dynamic analysis for seismic responses of high concrete arch dam systems are enormous. As a matter of course, the use of high-performance parallel computation for seismic analysis of high-concrete dams must be enforced. The significance and current situation of parallel computation for hydraulic structures using finite element method are briefly described. However, the more difficult task is to develop a parallel program. The EFPG is a finite element program generator using finite element language developed by Chinese Professor Liang Guoping in 1990. The program generated by FEPG can be automatically transformed to corresponding parallel program through the program PFEPG. The parallel computational program by means of FEPG and PFEPG applied in this stage to dynamic analysis for seismic responses of high concrete arch dam system is outlined. The strategy of FEPG is based on component technique and the technique of automatically generating programs. According to the characteristics of domain decomposition method, a finite element program can generally be decomposed to six modules as preprocess partition, start, bft, solv, E, and U programs, in which the subroutines of E and U component are generated by the system based on the scripts VDE or PDE of the partial differential equation describing the physical fields and the corresponding computational algorithms (NFE), other else components are fixed and provided by the FEPG Library. The structures and modules as well as the working operation of FEPG and PFEPG are briefly introduced. The parallel program developed for seismic response analysis of high arch dam by using the FEPG and PFEPG, including the corresponding treatments of dynamic explicit computation process, dynamic contact problem, artificial transmitting, and spring-viscous boundaries, are examined in slight details. The procedure of seismic analysis of arch dam includes three loading cases accomplished successively as follows:1.In case 1, the dam elements were treated as dead elements with zero degree of freedom for nodes, and only the dead load of the foundation rock is considered in the analysis. At the end of calculation, the initial normal compressive force along the contact planes was modified by adding the calculated contact force. All other states of the foundation were recovered to that before loading.2.In case 2, the dead load of dam and other static actions including water pressure, silt pressure, and temperature applied to the dam as well as the seepage pressure in the foundation are considered.3.In case 3, a three-component seismic input is applied to the base of the artificial transmitting boundaries in form of displacement ground motion, or to the spring-viscous boundaries with free field input including boundary stresses, velocities and displacements. In this loading case, the rate effect for dynamic strength and modulus of elasticity are considered.}
}
@article{FEKETE2011807,
title = {Towards a computational theory of experience},
journal = {Consciousness and Cognition},
volume = {20},
number = {3},
pages = {807-827},
year = {2011},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2011.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S1053810011000365},
author = {Tomer Fekete and Shimon Edelman},
keywords = {Representation, Experience, Qualia, Computation, State space, Trajectory, Dynamics, Brain activation, Concept, Clustering},
abstract = {A standing challenge for the science of mind is to account for the datum that every mind faces in the most immediate – that is, unmediated – fashion: its phenomenal experience. The complementary tasks of explaining what it means for a system to give rise to experience and what constitutes the content of experience (qualia) in computational terms are particularly challenging, given the multiple realizability of computation. In this paper, we identify a set of conditions that a computational theory must satisfy for it to constitute not just a sufficient but a necessary, and therefore naturalistic and intrinsic, explanation of qualia. We show that a common assumption behind many neurocomputational theories of the mind, according to which mind states can be formalized solely in terms of instantaneous vectors of activities of representational units such as neurons, does not meet the requisite conditions, in part because it relies on inactive units to shape presently experienced qualia and implies a homogeneous representation space, which is devoid of intrinsic structure. We then sketch a naturalistic computational theory of qualia, which posits that experience is realized by dynamical activity-space trajectories (rather than points) and that its richness is measured by the representational capacity of the trajectory space in which it unfolds.}
}
@article{COMPTON2018392,
title = {The aprosody of schizophrenia: Computationally derived acoustic phonetic underpinnings of monotone speech},
journal = {Schizophrenia Research},
volume = {197},
pages = {392-399},
year = {2018},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2018.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920996418300276},
author = {Michael T. Compton and Anya Lunden and Sean D. Cleary and Luca Pauselli and Yazeed Alolayan and Brooke Halpern and Beth Broussard and Anthony Crisafio and Leslie Capulong and Pierfrancesco Maria Balducci and Francesco Bernardini and Michael A. Covington},
keywords = {Acoustic resonance, Aprosody, Linguistics, Negative symptoms, Phonetics, Phonology, Psychosis, Schizophrenia},
abstract = {Objective
Acoustic phonetic methods are useful in examining some symptoms of schizophrenia; we used such methods to understand the underpinnings of aprosody. We hypothesized that, compared to controls and patients without clinically rated aprosody, patients with aprosody would exhibit reduced variability in: pitch (F0), jaw/mouth opening and tongue height (formant F1), tongue front/back position and/or lip rounding (formant F2), and intensity/loudness.
Methods
Audiorecorded speech was obtained from 98 patients (including 25 with clinically rated aprosody and 29 without) and 102 unaffected controls using five tasks: one describing a drawing, two based on spontaneous speech elicited through a question (Tasks 2 and 3), and two based on reading prose excerpts (Tasks 4 and 5). We compared groups on variation in pitch (F0), formant F1 and F2, and intensity/loudness.
Results
Regarding pitch variation, patients with aprosody differed significantly from controls in Task 5 in both unadjusted tests and those adjusted for sociodemographics. For the standard deviation (SD) of F1, no significant differences were found in adjusted tests. Regarding SD of F2, patients with aprosody had lower values than controls in Task 3, 4, and 5. For variation in intensity/loudness, patients with aprosody had lower values than patients without aprosody and controls across the five tasks.
Conclusions
Findings could represent a step toward developing new methods for measuring and tracking the severity of this specific negative symptom using acoustic phonetic parameters; such work is relevant to other psychiatric and neurological disorders.}
}
@article{RONEZRA2021100896,
title = {Engaging a third-grade student with autism spectrum disorder in an error finding activity},
journal = {The Journal of Mathematical Behavior},
volume = {63},
pages = {100896},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100896},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000572},
author = {Maya Ron-Ezra and Esther S. Levenson},
keywords = {Autism spectrum disorder, Two-digit addition, Error analysis, Mathematical explanations},
abstract = {This paper describes a case study of one mainstreamed third grade student with autism spectrum disorder (ASD) and his ability to explain his solutions for two-digit addition problems, and find and explain the mistake when presented with incorrectly solved addition problems. The study is presented as a counterexample to deficit views of ASD, views that focus on lack of communication skills, not being able to see someone else’s point of view, and poor executive functions. Each encounter with the student is analyzed in two ways, first analyzing his mathematical knowledge, and then analyzing obstacles the student faces that are associated with ASD. Some obstacles are overcome by the student on his own and others are overcome with the help of the researcher, who responds to the student’s thinking, and supports his endeavor to engage with a challenging activity.}
}
@article{KISS2020106823,
title = {Process systems engineering developments in Europe from an industrial and academic perspective},
journal = {Computers & Chemical Engineering},
volume = {138},
pages = {106823},
year = {2020},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2020.106823},
url = {https://www.sciencedirect.com/science/article/pii/S0098135420303069},
author = {Anton A. Kiss and Johan Grievink},
keywords = {Process systems engineering, Industry, Education, Research, Interface, Perspectives},
abstract = {Process Systems Engineering (PSE) is a discipline that deals with decision-making, at all levels and scales, by understanding any complex process system using a holistic view and a systems thinking framework. A closely related discipline (considered usually a part of PSE) is the Computer Aided Process Engineering (CAPE) which is a complementary field that focuses on developing methods and providing solution through systematic computer aided techniques for problems related to the design, control and operation of chemical systems. Nowadays, the ‘PSE’ term suffers from a branding issue to the point that PSE no longer gets the recognition that it deserves. In chemical engineering education the integrative systems frame for process design, control and operations is virtually absent. Its application potential in process industry lags relative to academic research progress and results. This work aims to provide an informative industrial and academic perspective on PSE (focused on the European region), arguing that the ‘systems thinking’ and ‘systems problem solving’ have to be given priority over just applications of computational problem solving methods. A multi-level view of the PSE field is provided within the academic and industrial context, and enhancements for PSE are suggested at their industrial and academic interfaces to create win-win situations.}
}
@incollection{SILVA20203,
title = {Chapter 1 - Introduction and overview of using computational fluid dynamics tools},
editor = {Valter Bruno Reis E. Silva and João Cardoso},
booktitle = {Computational Fluid Dynamics Applied to Waste-to-Energy Processes},
publisher = {Butterworth-Heinemann},
pages = {3-28},
year = {2020},
isbn = {978-0-12-817540-8},
doi = {https://doi.org/10.1016/B978-0-12-817540-8.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128175408000017},
author = {Valter Bruno Reis E. Silva and João Cardoso},
keywords = {Computer fluid dynamics, Waste-to-energy, Simulation workflow, Fluid dynamics history},
abstract = {Over the last decades, with the increasing computational power and numerical solvers efficiency, computational fluid dynamics (CFD) is broadly used to design, optimize, and predict the physical-chemical phenomena regarding energy-related processes. A set of elaborate mathematical models is governed by partial differential equations representing conservation laws for mass, momentum, and energy, alongside with theoretical and empirical correlation. Therefore, CFD simulation is a crucial asset to understand the influence of parameters of interest in these processes and related operation and optimization of the technology involved. This chapter discusses how CFD can be used advantageously over waste-to-energy processes, also outlining advantages, disadvantages, and main setbacks with such an approach.}
}
@article{TARIM2011563,
title = {An efficient computational method for a stochastic dynamic lot-sizing problem under service-level constraints},
journal = {European Journal of Operational Research},
volume = {215},
number = {3},
pages = {563-571},
year = {2011},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2011.06.034},
url = {https://www.sciencedirect.com/science/article/pii/S0377221711005637},
author = {S. Armagan Tarim and Mustafa K. Dogˇru and Ulaş Özen and Roberto Rossi},
keywords = {Inventory, Relaxation, Stochastic non-stationary demand, Mixed integer programming, Service level, Static–dynamic uncertainty},
abstract = {We provide an efficient computational approach to solve the mixed integer programming (MIP) model developed by Tarim and Kingsman [8] for solving a stochastic lot-sizing problem with service level constraints under the static–dynamic uncertainty strategy. The effectiveness of the proposed method hinges on three novelties: (i) the proposed relaxation is computationally efficient and provides an optimal solution most of the time, (ii) if the relaxation produces an infeasible solution, then this solution yields a tight lower bound for the optimal cost, and (iii) it can be modified easily to obtain a feasible solution, which yields an upper bound. In case of infeasibility, the relaxation approach is implemented at each node of the search tree in a branch-and-bound procedure to efficiently search for an optimal solution. Extensive numerical tests show that our method dominates the MIP solution approach and can handle real-life size problems in trivial time.}
}
@article{BASU2021135660,
title = {Integrative STEM education for undergraduate neuroscience: Design and implementation},
journal = {Neuroscience Letters},
volume = {746},
pages = {135660},
year = {2021},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2021.135660},
url = {https://www.sciencedirect.com/science/article/pii/S0304394021000380},
author = {Alo C. Basu and Alexis S. Hill and André K. Isaacs and Michelle A. Mondoux and Ryan E.B. Mruczek and Tomohiko Narita},
keywords = {Integrative thinking, Spiral curriculum, Active learning, Inclusive pedagogy, Inclusive excellence, Anti-deficit},
abstract = {As an integrative discipline, neuroscience can serve as a vehicle for the development of integrative thinking skills and broad-based scientific proficiency in undergraduate students. Undergraduate neuroscience curricula incorporate fundamental concepts from multiple disciplines. Deepening the explicit exploration of these connections in a neuroscience core curriculum has the potential to support more meaningful and successful undergraduate STEM learning for neuroscience students. Curriculum and faculty development activities related to an integrative core curriculum can provide opportunities for faculty across disciplines and departments to advance common goals of inclusive excellence in STEM. These efforts facilitate analysis of the institutional STEM curriculum from the student perspective, and assist in creating an internal locus of accountability for diversity, equity, and inclusion within the institution. Faculty at the College of the Holy Cross have undertaken the collaborative design and implementation of an integrative core curriculum for neuroscience that embraces principles of inclusive pedagogy, emphasizes the connections between neuroscience and other disciplines, and guides students to develop broad proficiency in fundamental STEM concepts and skills.}
}
@article{CSILLERY2010410,
title = {Approximate Bayesian Computation (ABC) in practice},
journal = {Trends in Ecology & Evolution},
volume = {25},
number = {7},
pages = {410-418},
year = {2010},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2010.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169534710000662},
author = {Katalin Csilléry and Michael G.B. Blum and Oscar E. Gaggiotti and Olivier François},
abstract = {Understanding the forces that influence natural variation within and among populations has been a major objective of evolutionary biologists for decades. Motivated by the growth in computational power and data complexity, modern approaches to this question make intensive use of simulation methods. Approximate Bayesian Computation (ABC) is one of these methods. Here we review the foundations of ABC, its recent algorithmic developments, and its applications in evolutionary biology and ecology. We argue that the use of ABC should incorporate all aspects of Bayesian data analysis: formulation, fitting, and improvement of a model. ABC can be a powerful tool to make inferences with complex models if these principles are carefully applied.}
}
@article{ARLE2014642,
title = {Mechanism of Dorsal Column Stimulation to Treat Neuropathic but not Nociceptive Pain: Analysis With a Computational Model},
journal = {Neuromodulation: Technology at the Neural Interface},
volume = {17},
number = {7},
pages = {642-655},
year = {2014},
issn = {1094-7159},
doi = {https://doi.org/10.1111/ner.12178},
url = {https://www.sciencedirect.com/science/article/pii/S1094715914601410},
author = {Jeffrey E. Arle and Kristen W. Carlson and Longzhi Mei and Nicolae Iftimia and Jay L. Shils},
keywords = {Chronic pain, dorsal column stimulation, gate control theory of pain, neural circuitry modeling, neuromodulation mechanism, neuropathic pain, spinal cord stimulation},
abstract = {Objective:
Stimulation of axons within the dorsal columns of the human spinal cord has become a widely used therapy to treat refractory neuropathic pain. The mechanisms have yet to be fully elucidated and may even be contrary to standard “gate control theory.” Our hypothesis is that a computational model provides a plausible description of the mechanism by which dorsal column stimulation (DCS) inhibits wide dynamic range (WDR) cell output in a neuropathic model but not in a nociceptive pain model.
Materials and Methods:
We created a computational model of the human spinal cord involving approximately 360,000 individual neurons and dendritic processing of some 60 million synapses—the most elaborate dynamic computational model of the human spinal cord to date. Neuropathic and nociceptive “pain” signals were created by activating topographically isolated regions of excitatory interneurons and high-threshold nociceptive fiber inputs, driving analogous regions of WDR neurons. Dorsal column fiber activity was then added at clinically relevant levels (e.g., Aβ firing rate between 0 and 110 Hz by using a 210-μsec pulse width, 50–150 Hz frequency, at 1–3 V amplitude).
Results:
Analysis of the nociceptive pain, neuropathic pain, and modulated circuits shows that, in contradiction to gate control theory, 1) nociceptive and neuropathic pain signaling must be distinct, and 2) DCS neuromodulation predominantly affects the neuropathic signal only, inhibiting centrally sensitized pathological neuron groups and ultimately the WDR pain transmission cells.
Conclusion:
We offer a different set of necessary premises than gate control theory to explain neuropathic pain inhibition and the relative lack of nociceptive pain inhibition by using retrograde DCS. Hypotheses regarding not only the pain relief mechanisms of DCS were made but also regarding the circuitry of pain itself, both nociceptive and neuropathic. These hypotheses and further use of the model may lead to novel stimulation paradigms.}
}
@article{LI2025101826,
title = {A novel approach to measuring creative analogical fluency in Chinese using advanced language models},
journal = {Thinking Skills and Creativity},
volume = {57},
pages = {101826},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101826},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000756},
author = {Shan Li and Kaixu Yi and Jie Cao and Tao Li and Yiwei He and Guozhu Ding},
keywords = {Creative analogical reasoning, Word embedding models, Vector offset method, Fluency measurement, Computational linguistics},
abstract = {This study introduces a novel approach to assessing creative analogical fluency in the Chinese language context. We developed the Creative Analogical Fluency Vector Offset Method, an algorithm to evaluate fluency in creative analogical reasoning using advanced word embedding models. A Chinese dataset of analogical reasoning questions was constructed and categorized into semantic and syntactic domains. The study involved 150 Chinese undergraduate students who completed a 60-item word analogical reasoning test. We compared the performance of three word embedding models (Word2Vec, BERT, and GPT) in assessing creative analogical fluency. Results demonstrated high accuracy across all models. Notably, our method showed comparable effectiveness in evaluating semantic and syntactic analogical reasoning questions, challenging the assumption of significant differences between these domains in the Chinese context. This research contributes to the field by providing a more efficient and culturally relevant tool for assessing creative analogical reasoning.}
}
@article{DAVIES2016617,
title = {Computational Screening of All Stoichiometric Inorganic Materials},
journal = {Chem},
volume = {1},
number = {4},
pages = {617-627},
year = {2016},
issn = {2451-9294},
doi = {https://doi.org/10.1016/j.chempr.2016.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S2451929416301553},
author = {Daniel W. Davies and Keith T. Butler and Adam J. Jackson and Andrew Morris and Jarvist M. Frost and Jonathan M. Skelton and Aron Walsh},
keywords = {functional materials, computational chemistry, materials design, solar energy, high-throughput screening, water splitting, perovskites, structure prediction, SDG7: Affordable and clean energy},
abstract = {Summary
Forming a four-component compound from the first 103 elements of the periodic table results in more than 1012 combinations. Such a materials space is intractable to high-throughput experiment or first-principle computation. We introduce a framework to address this problem and quantify how many materials can exist. We apply principles of valency and electronegativity to filter chemically implausible compositions, which reduces the inorganic quaternary space to 1010 combinations. We demonstrate that estimates of band gaps and absolute electron energies can be made simply on the basis of the chemical composition and apply this to the search for new semiconducting materials to support the photoelectrochemical splitting of water. We show the applicability to predicting crystal structure by analogy with known compounds, including exploration of the phase space for ternary combinations that form a perovskite lattice. Computer screening reproduces known perovskite materials and predicts the feasibility of thousands more. Given the simplicity of the approach, large-scale searches can be performed on a single workstation.}
}
@article{SHAHZAD2022102190,
title = {Thermal cooling process by nanofluid flowing near stagnating point of expanding surface under induced magnetism force: A computational case study},
journal = {Case Studies in Thermal Engineering},
volume = {36},
pages = {102190},
year = {2022},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2022.102190},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X22004361},
author = {Faisal Shahzad and Wasim Jamshed and Amjad Ali Pasha and Rabia Safdar and Md. Mottahir Alam and Misbah Arshad and Syed M. Hussain and Muhammad Bilal Hafeez and Marek Krawczuk},
keywords = {, , , , },
abstract = {This paper is dedicated to the exam of entropy age and research of the effect of mixing nanosolid additives over an extending sheet. In this review, Newtonian nanofluid version turned into researched at the actuated appealing field, heat radiation and variable heat conductivity results. With becoming modifications, the proven PDEs are moved into popular differential situations and paintings mathematically making use of a specific mathematical plan called the Keller box method (KBM). The ranges of different dimensionless parameters used in our study are volume fraction of nanoparticles 0.01≤φ≤0.04, magnetic parameter 0.5≤Λ≤2, thermal radiation 0.1≤Nr≤0.3, heat source/sink parameter 0.5≤Q0≤2, Prandtl number 5.7≤Pr≤6.2, variable thermal conductivity 0.1≤ε≤0.3, reciprocal magnetic Prandtl number 0.6≤λ∗≤1, Brinkman number 5≤Br≤15, Reynolds number 5≤Re≤15, which shows up during mathematical arrangement are shown as tables and charts.Positive modifications in heat radiation and heat conductivity affects increment the hotness pass coefficient of solar primarily based totally plane wings. Titanium alloy primarily based totally water (H2O) are taken into consideration for our research. We will likewise alternate the grouping of nanoparticles to pay attention on their impact on numerous dynamic barriers of the framework. We can see that because the Reynolds range and Brinkman range increment, the entropy increments. The thermodynamic exhibition of Titanium alloy-water (Ti6Al4V–H2O) nanofluid has been portrayed higher that of base nanofluid with comparable situations. Recorded hypothetical reproductions may be greater beneficial to similarly increase daylight primarily based totally nuclear strength frameworks.}
}
@article{LI20203666,
title = {The computational approaches of lncRNA identification based on coding potential: Status quo and challenges},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3666-3677},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304979},
author = {Jing Li and Xuan Zhang and Changning Liu},
keywords = {LncRNA identification, , Algorithm, Feature, Coding potential, sORF},
abstract = {Long noncoding RNAs (lncRNAs) make up a large proportion of transcriptome in eukaryotes, and have been revealed with many regulatory functions in various biological processes. When studying lncRNAs, the first step is to accurately and specifically distinguish them from the colossal transcriptome data with complicated composition, which contains mRNAs, lncRNAs, small RNAs and their primary transcripts. In the face of such a huge and progressively expanding transcriptome data, the in-silico approaches provide a practicable scheme for effectively and rapidly filtering out lncRNA targets, using machine learning and probability statistics. In this review, we mainly discussed the characteristics of algorithms and features on currently developed approaches. We also outlined the traits of some state-of-the-art tools for ease of operation. Finally, we pointed out the underlying challenges in lncRNA identification with the advent of new experimental data.}
}
@article{GANUTHULA2016216,
title = {Rationality and the reflective mind: A case for typical performance measure of cognitive ability},
journal = {Learning and Individual Differences},
volume = {49},
pages = {216-223},
year = {2016},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2016.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S1041608016301029},
author = {Venkat Ram Reddy Ganuthula and Lata Dyaram},
keywords = {Typical performance measure of cognitive ability, Thinking dispositions, Rationality, Tripartite model of mind},
abstract = {Intelligence and cognitive abilities often denoted good thinking. However, critics of intelligence tests have long pointed out that the failures of rational judgments and decision-making imperfectly correlate with intelligence. Reviewing the work of Keith Stanovich and his colleagues, paper highlights the role of individual differences in judgment and decision-making. Paper presents a case for typical performance measure of cognitive ability besides thinking dispositions to explain variations in rational thought. Specifically, we examine and model the relationship between need for cognition (a measure of thinking dispositions), absorptive capacity (typical performance measure of intelligence) and normative decision-making tasks.}
}
@article{BOTTEGONI201223,
title = {The role of fragment-based and computational methods in polypharmacology},
journal = {Drug Discovery Today},
volume = {17},
number = {1},
pages = {23-34},
year = {2012},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2011.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1359644611002534},
author = {Giovanni Bottegoni and Angelo D. Favia and Maurizio Recanatini and Andrea Cavalli},
abstract = {Polypharmacology-based strategies are gaining increased attention as a novel approach to obtaining potentially innovative medicines for multifactorial diseases. However, some within the pharmaceutical community have resisted these strategies because they can be resource-hungry in the early stages of the drug discovery process. Here, we report on fragment-based and computational methods that might accelerate and optimize the discovery of multitarget drugs. In particular, we illustrate that fragment-based approaches can be particularly suited for polypharmacology, owing to the inherent promiscuous nature of fragments. In parallel, we explain how computer-assisted protocols can provide invaluable insights into how to unveil compounds theoretically able to bind to more than one protein. Furthermore, several pragmatic aspects related to the use of these approaches are covered, thus offering the reader practical insights on multitarget-oriented drug discovery projects.}
}
@article{BOND200481,
title = {A computational model for the primate neocortex based on its functional architecture},
journal = {Journal of Theoretical Biology},
volume = {227},
number = {1},
pages = {81-102},
year = {2004},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2003.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0022519303003825},
author = {Alan H Bond},
keywords = {Brain architecture, Perception-action hierarchy, Computational model, Logic programming, Primate social behavior},
abstract = {Experimental evidence has shown that the primate neocortex consists in the main of a set of cortical regions which form a perception hierarchy, an action hierarchy and connections between them. By using a computer science analysis, we develop a computational architecture for the brain in which each cortical region is represented by a computational module with processing and storage abilities. Modules are interconnected according to the connectivity of the corresponding cortical regions. We develop computational principles for designing such a hierarchical and parallel computing system. We demonstrate this approach by proposing a causal functioning model of the brain. We report on results obtained with an implementation of this model. We conclude with a brief discussion of some consequences and predictions of our work.}
}
@article{PU2023102577,
title = {Generative adversarial one-shot diagnosis of transmission faults for industrial robots},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {83},
pages = {102577},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102577},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000534},
author = {Ziqiang Pu and Diego Cabrera and Yun Bai and Chuan Li},
keywords = {One-shot diagnosis, Bi-directional generative adversarial network, Random forest, Industrial robot, Transmission system},
abstract = {Transmission systems of industrial robots are prone to get failures due to harsh operating environments. Fault diagnosis is of great significance for realizing safe operations for industrial robots. However, it is difficult to obtain faulty data in real applications. To migrate this issue, a generative adversarial one-shot diagnosis (GAOSD) approach is proposed to diagnose robot transmission faults with only one sample per faulty pattern. Signals representing kinematical characteristics were acquired by an attitude sensor. A bidirectional generative adversarial network (Bi-GAN) was then trained using healthy signals. Inspired by way of human thinking, the trained encoder in Bi-GAN was taken out to perform information abstraction for all signals. Finally, the abstracted signals were sent to a random forest for the one-shot diagnosis. The performance of the present technique was evaluated on an industrial robot experimental setup. Experimental results show that the proposed GAOSD has promising performance on the fault diagnosis of robot transmission systems.}
}
@article{WEBB2010903,
title = {Troubleshooting assessment: an authentic problem solving activity for it education},
journal = {Procedia - Social and Behavioral Sciences},
volume = {9},
pages = {903-907},
year = {2010},
note = {World Conference on Learning, Teaching and Administration Papers},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2010.12.256},
url = {https://www.sciencedirect.com/science/article/pii/S187704281002361X},
author = {David C. Webb},
keywords = {authentic assessment, computational thinking, computer programming, game design, problem solving, STEM education, technologybased assessment},
abstract = {To evaluate the effectiveness of an instructional unit for game design and computer programming, we designed an authentic assessment with five troubleshooting scenarios. This assessment was completed by 24 middle grades students (age 12 – 14 years) after 10hours of instruction using a visual programming environment. Students successfully completed most of the tasks in 45minutes. Results from the Troubleshooting Assessment demonstrated that students developed sufficient fluency with programming to be able to apply their knowledge to new problems. These results suggest that troubleshooting scenarios can be used to assess student fluency in computer programming and computer-based problem solving.}
}
@article{ARASTOOPOURIRGENS2024100699,
title = {User experience testing and co-designing a digital game for broadening participation in computing with and for elementary school children},
journal = {International Journal of Child-Computer Interaction},
volume = {42},
pages = {100699},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100699},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000680},
author = {Golnaz {Arastoopour Irgens} and Cinamon Bailey and Tolulope Famaye and Atefeh Behboudi},
keywords = {Elementary education, User experience testing, Game-based learning, Culturally sustaining pedagogies, Intersectionality},
abstract = {Broadening participation in computing is more than providing access to computing for students; it requires reimagining and transforming teaching and learning to be more inclusive and culturally sustaining and it begins with elementary school children. In this study, we report on the fourth cycle of a participatory design-based research project in which researchers and children co-design culturally responsive-sustaining computational learning environments. We conducted user experience testing and co-design sessions with seven children on one level of a game-based learning environment in development. We model children's discourse through Epistemic Network Analysis models to investigate their feedback on character design, game narratives, and introductory activities. Our findings reveal 1) children's positive response to characters with counternarratives and visible intersectional identities in computing, 2) positive and negative experiences and feedback from children on game activities and narratives, and 3) suggestions for improvement.}
}
@incollection{REIN2013199,
title = {Chapter 16 - Re-thinking Standardization for Interagency Information Sharing},
editor = {Babak Akhgar and Simeon Yates},
booktitle = {Strategic Intelligence Management},
publisher = {Butterworth-Heinemann},
pages = {199-211},
year = {2013},
isbn = {978-0-12-407191-9},
doi = {https://doi.org/10.1016/B978-0-12-407191-9.00016-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780124071919000168},
author = {Kellyn Rein},
keywords = {agencies, analysis, data, fusion, human, intelligence, language, management, national, security, sources, text},
abstract = {Abstracts:
The collection and analysis of data for intelligence purposes is vital to national security. There are a number of hurdles including the exponentially increasing volume of available data, the need for increased cooperation between national and international agencies due to the increasingly globalized nature of threats to citizens and nations, and the need to be flexible in identifying new threats. Increasing reliance on computers is necessary, but complications arise due to such issues as incompatible data formats, multiple natural languages, and data privacy concerns. However, a potential solution to solving some of these problems for national security and law enforcement agencies is C2LG (Command and Control Lexical Grammar), which was originally developed for use within NATO, and is being adapted for use in crisis management and the fight against international organized crime.}
}
@article{OLTETEANU201615,
title = {Object replacement and object composition in a creative cognitive system. Towards a computational solver of the Alternative Uses Test},
journal = {Cognitive Systems Research},
volume = {39},
pages = {15-32},
year = {2016},
note = {From human to artificial cognition (and back): new perspectives of cognitively inspired AI systems},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2015.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S1389041716000073},
author = {Ana-Maria Olteţeanu and Zoe Falomir},
keywords = {Cognitive systems, Computational creativity, Creative object replacement, Creative object composition, Alternative uses test},
abstract = {In creative problem solving, humans perform object replacement and object composition to improvise tools in order to carry out tasks in everyday situations. In this paper, an approach to perform Object Replacement and Object Composition (OROC) inside a Creative Cognitive framework (CreaCogs) is proposed. Multi-feature correspondence is used to define similarity between objects in an everyday object domain. This enables the cognitive system OROC to perform creative replacement of objects and creative object composition. The generative properties of OROC are analysed and proof-of-concept experiments with OROC are reported. An evaluation of the results is carried out by human judges and compared to human performance in the Alternative Uses Test.}
}
@article{JAGER2014117,
title = {Thinking outside the channel: Timing pulse flows to benefit salmon via indirect pathways},
journal = {Ecological Modelling},
volume = {273},
pages = {117-127},
year = {2014},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2013.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0304380013005437},
author = {Henriette I. Jager},
keywords = {Reservoir releases, Environmental flows, Natural flow paradigm, Optimization, Quantile model, Pulse flows},
abstract = {Using models to represent relationships between flow and fishes has important practical applications for managing reservoir releases. Attempts to model such relationships often neglect indirect mechanisms by which flow influences fish. For example, growth of salmon juveniles is measurably faster when flows inundate floodplain and promote higher production of invertebrate prey, but out-of-channel flows have not yet been incorporated into models. The QUANTUS model developed here represents indirect linkages between flow and freshwater survival, mediated by temperature and prey availability, for fall Chinook salmon (Oncorhynchus tshawytscha). Quantiles of spawning time and place were used to define cohorts of salmon in a regulated Central Valley, California river. Survival of these quantile-cohorts was simulated through incubation, juvenile growth, and eventual downstream migration. A genetic algorithm was used to optimize the seasonal timing of pulse flows. Simulated survival was highest for flow regimes that provided a modest, temperature-moderating pulse flow in early summer and, for wetter years, a second, larger pulse of over-bank flow in late winter. For many rivers of the Pacific coast that support fall Chinook salmon, the thermal window of opportunity for spawning and rearing is narrow. Optimized flows made the most of this window by providing access to accelerated juvenile growth and early survival in floodplain habitat, a result that should be verified with field experiments. Timing of optimized pulse flows differed in some respects from the region's natural hydrograph, dominated by spring runoff. This suggests that understanding the mechanisms by which flow influences fishes can be important when shaping flows in the changed context of a regulated river.}
}
@article{DEOLIVEIRA2023133,
title = {Transdisciplinary competency-based development in the process engineering subjects: A case study in Brazil},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {133-154},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000246},
author = {Roger Assis {de Oliveira} and Giovanna Milena Borges Hipólito and Ricardo de Freitas Fernandes Pontes and Paulo Henrique Nascimento Ferreira and Ricardo Sanz Moreira and José Plácido and Carlos Alexandre Moreira da Silva and Laura Plazas Tovar},
keywords = {Chemical engineering education, Competency, Learning outcome, Lifelong learning, Process systems engineering, Sustainability},
abstract = {Recently, the Brazilian Ministry of Education issued New Curriculum Guidelines for engineering programs. This paper encompasses a pedagogical intervention reflecting our efforts to incorporate these new guidelines into our engineering program. Specifically, this work has led to the competency-based rework of the following subjects offered in the Chemical Engineering Undergraduate Program at the Federal University of São Paulo (Unifesp): I) Modeling and Systems Analysis; II) Synthesis and Optimization of Chemical Processes; III) Chemical Process Simulation; IV) Process Analysis and Control; V) Chemical Process Design; and VI) Chemical Installations Design. Thirteen transdisciplinary competencies are integrated throughout the six subjects. Students highlighted design thinking, lifelong knowledge/learning, openness to act autonomously, teamwork, communication, and cooperation as essential qualities. Moreover, the greater focus on the process systems engineering approach involving the analysis, synthesis, design, and control of sustainable processes helps chemical engineers to face new challenges using renewable resources.}
}
@article{DELORME2019133,
title = {When the meditating mind wanders},
journal = {Current Opinion in Psychology},
volume = {28},
pages = {133-137},
year = {2019},
note = {Mindfulness},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X1830157X},
author = {Arnaud Delorme and Tracy Brandmeyer},
abstract = {The capacity for thought and the ability to assemble and manipulate concepts are cognitive features unique to humans. Spontaneous thoughts often occur when we are engaged in attention-demanding tasks, with an increased frequency predicting negative affect. Meditation does not require thinking; however, thinking occurs naturally during meditation. We develop the hypothesis that chronic thinking associated with strong emotional arousal during meditation practice might be detrimental to meditation practice and well-being. One goal of meditation is to identify the arousal of emotions and thoughts, and remain equanimous with them. Over time, meditation may help dampen the attention-grabbing power of these thoughts both during practice and in daily life, which may consequently help deepen meditation practice. However, when meditators fail to remain equanimous, the effects of these thoughts may be deleterious. We discuss how this hypothesis may help guide future research on meditation.}
}
@article{EKINS201165,
title = {Computational databases, pathway and cheminformatics tools for tuberculosis drug discovery},
journal = {Trends in Microbiology},
volume = {19},
number = {2},
pages = {65-74},
year = {2011},
issn = {0966-842X},
doi = {https://doi.org/10.1016/j.tim.2010.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0966842X10001939},
author = {Sean Ekins and Joel S. Freundlich and Inhee Choi and Malabika Sarker and Carolyn Talcott},
abstract = {We are witnessing the growing menace of both increasing cases of drug-sensitive and drug-resistant Mycobacterium tuberculosis strains and the challenge to produce the first new tuberculosis (TB) drug in well over 40 years. The TB community, having invested in extensive high-throughput screening efforts, is faced with the question of how to optimally leverage these data to move from a hit to a lead to a clinical candidate and potentially, a new drug. Complementing this approach, yet conducted on a much smaller scale, cheminformatic techniques have been leveraged and are examined in this review. We suggest that these computational approaches should be optimally integrated within a workflow with experimental approaches to accelerate TB drug discovery.}
}
@article{FITRIANI2023e14769,
title = {The differential item functioning (DIF) testing for the WOCC (Ways of Coping Checklist) instrument based on gender},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e14769},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e14769},
url = {https://www.sciencedirect.com/science/article/pii/S240584402301976X},
author = {Arbania Fitriani and Dominikus David {Biondi Situmorang}},
keywords = {Differential item functioning, DIF, IRT, Stress, Coping stress, Psychometry},
abstract = {This study examined the Item Response Theory (IRT) method with statistical analysis to determine Differential Item Functioning (DIF) between men and women on the Ways of Coping Checklist (WOCC) Instruments revised by Vitaliano, Russo, Carr, Mauiro, and Becker (1985). Furthermore, it utilized primary data from 722 respondents with educational backgrounds ranging from senior high school, diplomas, and doctorates. The software packages QUEST, BILOG-MG, LISREL, and ITEMAN were used for analysis to address the concerns. Meanwhile, several items on the WOCC instrument indicated the presence of the DIF based on the calculation results using the IRT method with the QUEST and BILOG-MG software. According to the overall calculation for 1 PL and 2 PL using both tools, 8 items containing the DIF are distributed over the dimensions of problem solving, seeking social support, blaming self, and wishful thinking.}
}
@article{NENSA2025100014,
title = {The future of radiology: The path towards multimodal AI and superdiagnostics},
journal = {European Journal of Radiology Artificial Intelligence},
volume = {2},
pages = {100014},
year = {2025},
issn = {3050-5771},
doi = {https://doi.org/10.1016/j.ejrai.2025.100014},
url = {https://www.sciencedirect.com/science/article/pii/S305057712500012X},
author = {Felix Nensa},
keywords = {Multimodal AI, GenAI, LLM, Radiology, Superdiagnostics},
abstract = {The transformative power of artificial intelligence (AI) is reshaping radiology, medicine, and healthcare, marking radiology as a pioneering specialty in AI adoption. The digital nature of radiological data and standardized data formats positioned radiology as the ideal testing ground for clinical AI integration. While initial enthusiasm led to inflated expectations, fueled by linear thinking and the planning fallacy, AI has now matured into tools that augment, rather than replace, radiologists’ expertise. Radiologists’ role is evolving from image interpreters to diagnostic orchestrators in a multimodal era. The integration of imaging data with diverse sources such as genomics, pathology, and wearable sensors necessitates a shift to a systems-level perspective. This transformation demands not only technical literacy but also interdisciplinary collaboration to effectively synthesize AI-driven insights and mitigate cognitive overload. Radiologists must navigate uncertainty, adopt structured workflows, and communicate AI-supported findings clearly to maintain trust in diagnostics. The emergence of generative AI, particularly large language models, further streamlines AI adoption by enabling intuitive, human-centered interfaces. However, addressing the growing knowledge gap is crucial. Traditional radiology training must be overhauled to incorporate data science, bioinformatics, and systems biology, ensuring radiologists are prepared to lead multimodal diagnostics. Radiologists are uniquely positioned to spearhead this transition, leveraging AI to integrate diverse data streams, improve patient care, and foster collaboration across specialties. Proactive adaptation will secure radiologists’ central role in AI-driven medicine, safeguarding the human element in healthcare while advancing diagnostic precision.}
}
@article{HAMED2018112,
title = {Quantitative modeling of gene networks of biological systems using fuzzy Petri nets and fuzzy sets},
journal = {Journal of King Saud University - Science},
volume = {30},
number = {1},
pages = {112-119},
year = {2018},
issn = {1018-3647},
doi = {https://doi.org/10.1016/j.jksus.2017.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S1018364716307819},
author = {Raed I. Hamed},
keywords = {FPNs, Fuzzy sets, Uncertain data, GRNs, Quantitative modeling},
abstract = {Quantitative demonstrating of organic frameworks has turned into an essential computational methodology in the configuration of novel and investigation of existing natural frameworks. Be that as it may, active information that portrays the framework's elements should be known keeping in mind the end goal to get pertinent results with the routine displaying strategies. This information is frequently robust or even difficult to get. Here, we exhibit a model of quantitative fuzzy rational demonstrating approach that can adapt to obscure motor information and hence deliver applicable results despite the fact that dynamic information is fragmented or just dubiously characterized. Besides, the methodology can be utilized as a part of the blend with the current cutting edge quantitative demonstrating strategies just in specific parts of the framework, i.e., where the data are absent. The contextual analysis of the methodology suggested in this paper is performed on the model of nine-quality genes. We propose a kind of FPN model in light of fuzzy sets to manage the quantitative modeling of biological systems. The tests of our model appear that the model is practical and entirely powerful for information impersonation and thinking of fuzzy expert frameworks.}
}
@article{BLOOM2001453,
title = {Novel thinking},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {10},
pages = {453-454},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01758-7},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300017587},
author = {Paul Bloom}
}
@incollection{BOSSE2017311,
title = {Chapter 13 - On Computational Models of Emotion Regulation and Their Applications Within HCI},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {311-337},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00013-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000136},
author = {Tibor Bosse},
keywords = {emotion regulation, computational modeling, dynamics, virtual characters, simulation-based training},
abstract = {Emotion regulation, or the ability to regulate one’s own and other people’s emotions, is an important skill for human beings, enabling them to function adequately in their social environment. The development of computational models of emotion regulation opens up a range of interesting applications in human–computer interaction, varying from virtual characters to simulation-based training systems. To provide more insight in the underlying mechanisms as well as the application areas of computational emotion regulation models, the current chapter provides an overview of the state-of-the-art in this area. After briefly reviewing the psychological literature on emotion generation and regulation, I will explain how these phenomena can be formalized into computational models. Next, a computational model of emotion regulation is presented in detail, and a number of resulting simulation runs are shown. The chapter concludes with a discussion of potential applications of such models.}
}
@article{IWENDI20225016,
title = {Combined power generation and electricity storage device using deep learning and internet of things technologies},
journal = {Energy Reports},
volume = {8},
pages = {5016-5025},
year = {2022},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2022.02.304},
url = {https://www.sciencedirect.com/science/article/pii/S2352484722005510},
author = {Celestine Iwendi and Gai-Ge Wang},
keywords = {Energy storage, Machine learning, Internet of things, Fuzzy logic, Electricity storage device, Power generation},
abstract = {In microgrids, residential customers play a significant part in the operation. An alternative to client administration should be to utilize smart houses to deal with demand and implement demand responsiveness measures. A power generation and electricity storage device (PGESD) for next-generation technologies is proposed in this article. The current research provides an intelligent home load control system that promotes reaction to demand thinking about this circumstance. The technology is adapted to scenarios where users can charge fluctuating electric power and transmit microgeneration devices. The suggested system utilizes deep learning technology and a fuzzy logic model for better computation and lesser complexity. The choice process involves monitoring environmental information, power production, and battery storage. This article proposes a next-generation power generation and electricity storage device (PGESD). To create Smart Buildings and Microgrids, the proposed system employs technologies and techniques that have become increasingly important. With a precision and accuracy ratio of 89% and 92%, respectively, the proposed PGESD method yields precise numerical results.}
}
@incollection{HOUSE2018335,
title = {Chapter 14 - Comments on Computational Methods},
editor = {J.E. House},
booktitle = {Fundamentals of Quantum Mechanics (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {335-347},
year = {2018},
isbn = {978-0-12-809242-2},
doi = {https://doi.org/10.1016/B978-0-12-809242-2.00014-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092422000140},
author = {J.E. House},
keywords = {Basis set, Slater-type orbitals, Gaussian orbitals, Extended Hückel, Wolfsberg-Helmoltz approximation, Ballhausen-Gray approximation, Cusachs' approximation, Self-consistent field, Density functional theory},
abstract = {There are numerous types of molecular orbital calculations that are routinely performed. One of the early versions is the extended Hückel method that begins with the approach used in the Hückel method, but with the overlap and exchange integrals (approximated by the Wolfsberg-Helmholtz, Ballhausen-Gray, or Cusachs' method) included. A more robust type of calculation is that in which an electron is presumed to move in a field generated by the nucleus and other electrons. A trial wave function with some adjustable parameter(s) is taken, and the energy calculated. The wave function improves and the calculations continue until there is no additional improvement (i.e., a “self-consistent field” has been obtained). There are numerous variations of this approach that differ in the trial wave function chosen, extent of electron-electron interaction included, etc. Density functional theory is a newer approach that uses less computational capacity. These types of molecular orbital calculations are surveyed briefly in this chapter.}
}
@article{NEGI2022100096,
title = {A deep dive into metacognition: Insightful tool for moral reasoning and emotional maturity},
journal = {Neuroscience Informatics},
volume = {2},
number = {4},
pages = {100096},
year = {2022},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2022.100096},
url = {https://www.sciencedirect.com/science/article/pii/S2772528622000589},
author = {Sunder Kala Negi and Yaisna Rajkumari and Minakshi Rana},
keywords = {Metacognitive thinking, Moral reasoning, Emotional maturity, Artificial intelligence},
abstract = {The impact of metacognition on pupils' moral ideals and emotional development was investigated as well as it highlights on a collaborative research between metacognition and artificial intelligence that can bridge the gap (emotional, ethical, moral reasoning, common sense) existing in AI. A total of 200 pupils were selected in the study's sample. Participants (100 high metacognitive students and 100 low metacognitive students) were chosen at random and ranged in age from 17 to 21 years old. The influence of metacognition on students' moral ideals and emotional development was studied using a t-test. The outcome reveals that the mean score of moral reasoning on high metacognitive students as 66.77 and for low metacognitive students as 63.08, t value = 3.21, at the 0.01 level, statistically highly significant. The mean emotional maturity score for high metacognitive students was 29.99, while for low metacognitive students was 33.01, t value as 2.81, shows statistically significant at the 0.05 level. This demonstrates that the higher the score, the less emotionally stable the pupils are. The current findings show that metacognitive thinking has a major impact on moral reasoning and emotional maturity, and that as metacognition levels rise, so do moral reasoning and emotional maturity. Metacognition can strengthen the humanistic qualities which are majorly lacking in AI. In addition, there are new avenues being opened in the study of artificial intelligence via metacognitive study which is significant and futuristic.}
}
@article{KOUZALIS2024105312,
title = {Advanced technologies and mathematical metacognition: The present and future orientation},
journal = {BioSystems},
volume = {245},
pages = {105312},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105312},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724001977},
author = {Alexios Kouzalis and Antonios Antoniou and Nicos Rossides and Rita Panaoura and Priyanka Yadav},
keywords = {Mathematical cognition, Metacognition, Cognition, Artificial intelligence, Machine learning, Robotics, Boolean logic, Bayesian inference, Fuzzy logic, Chemical artificial intelligence},
abstract = {The intersection of mathematical cognition, metacognition, and advanced technologies presents a frontier with profound implications for human learning and artificial intelligence. This paper traces the historical roots of these concepts from the Pythagoreans and Aristotle to modern cognitive science and explores their relevance to contemporary technological applications. We examine how the Pythagoreans' view of mathematics as fundamental to understanding the universe and Aristotle's contributions to logic and categorization have shaped our current understanding of mathematical cognition and metacognition. The paper investigates the role of Boolean logic in computational processes and its relationship to human logical reasoning, as well as the significance of Bayesian inference and fuzzy logic in modelling uncertainty in human cognition and decision-making. We also explore the emerging field of Chemical Artificial Intelligence and its potential applications. We argue for unifying mathematical metacognition with advanced technologies, including artificial intelligence and robotics, while identifying the multifaceted benefits and challenges of such unification. The present paper examines essential research directions for integrating cognitive sciences and advanced technologies, discussing applications in education, healthcare, and business management. We provide suggestions for developing cognitive robots using specific cognitive tasks and explore the ethical implications of these advancements. Our analysis underscores the need for interdisciplinary collaboration to realize the full potential of this integration while mitigating potential risks.}
}
@article{CHANG2024103484,
title = {Evaluating AI's impact on self-regulated language learning: A systematic review},
journal = {System},
volume = {126},
pages = {103484},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103484},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24002665},
author = {Wenli-Li Chang and Jerry Chih-Yuan Sun},
keywords = {Self-regulated language learning, AI mediation, Learning partner, Systematic review},
abstract = {AI technology is reshaping language classrooms, prompting students to adopt flexible roles exhibiting linguistic competence and self-regulated learning (SRL) skills. Considerable studies explore the necessary integrated learning perspectives, emphasizing AI's adaptive role as a mind tool. In AI-mediated language learning, the technology's metacognitive importance enables students to learn with AI as a partner, encouraging independent critical thinking. Within Zimmerman's SRL model, AI as a mind tool is integrated for improving language students' strategic employment in a cyclical process. A systematic review, following PRISMA protocols, examines the intersection of AI and self-regulated language learning (SRLL) over 2000–2022. Findings highlight AI's evolving role, predominantly through algorithms and systems, aiming for micro and macro integration. Interactive AI has not fully engaged in two-way directions, despite a familiar process approach in reviewed studies. In the favored ESL/EFL research context, task-specific AI is utilized to encourage cyclical improvement with learner autonomy enhancement mainly among higher education students at intermediate level or above. Pedagogical values are possible when major SRL phases are fully practiced, even without highly autonomous AI. Future research is directed toward adaptive personalized technology by exploring the dynamic interplay between AI technologies and SRLL as educational practices under Education 4.0 principles.}
}
@article{AHMED20191,
title = {Computational intelligence based prediction of drilling rate of penetration: A comparative study},
journal = {Journal of Petroleum Science and Engineering},
volume = {172},
pages = {1-12},
year = {2019},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2018.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S0920410518307824},
author = {Omogbolahan S. Ahmed and Ahmed A. Adeniran and Ariffin Samsuri},
keywords = {ROP prediction, Neural network, Least square support vector regression, Specific energy, Drilling efficiency, Extreme learning machine},
abstract = {Application of artificial intelligence in the accurate prediction of the rate of penetration (ROP), an important measure of drilling performance, has lately gained significant interest in oil and gas well drilling operations. Consequently, several computational intelligence techniques (CITs) for the prediction of ROP have been explored in the literature. This study explores the predictive capabilities of four commonly used CITs in the prediction of ROP and experimentally compare their predictive performance. The CIT algorithm utilizes predictors which are easily accessible continuous drilling data that have physical but complex relationship with ROP based on hydro-mechanical specific energy ROP model. The four CITs compared are the artificial neural network (ANN), extreme learning machine, support vector Regression and least-square support vector regression (LS-SVR). Two experiments were carried out; the first experiment investigates the comparative performance of the CITs while the second investigates the effect of reduced number of predictors on the performance of the models. The results show that all the CITs perform within acceptable accuracy with testing root mean square error range (RMSE) of 18.27–28.84 and testing correlation coefficient (CC) range of 0.71–0.94. LS-SVR has the best predictive performance in terms of accuracy with RMSE of 18.27 and CC of 0.94 while ANN has the best testing execution time at 0.03 s. Also utilizing the specific energy concept in chosen drilling parameters to be included among the predictors shows improved performance with five drilling parameters showing an improvement of 3%–9% in RMSE for LS-SVR in the two well studied. The utilization of the specific energy concept in the selection of the predictors in this study has demonstrated that the easily accessible drilling parameters have immense value to provide acceptable performance in the development of ROP model with CITs.}
}
@article{KAY20231697,
title = {Tasks and their role in visual neuroscience},
journal = {Neuron},
volume = {111},
number = {11},
pages = {1697-1713},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2023.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0896627323002180},
author = {Kendrick Kay and Kathryn Bonnen and Rachel N. Denison and Mike J. Arcaro and David L. Barack},
keywords = {task, brain, behavior, visual cortex, information processing, modeling},
abstract = {Summary
Vision is widely used as a model system to gain insights into how sensory inputs are processed and interpreted by the brain. Historically, careful quantification and control of visual stimuli have served as the backbone of visual neuroscience. There has been less emphasis, however, on how an observer’s task influences the processing of sensory inputs. Motivated by diverse observations of task-dependent activity in the visual system, we propose a framework for thinking about tasks, their role in sensory processing, and how we might formally incorporate tasks into our models of vision.}
}
@article{BROCAS2021105366,
title = {Value computation and modulation: A neuroeconomic theory of self-control as constrained optimization},
journal = {Journal of Economic Theory},
volume = {198},
pages = {105366},
year = {2021},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2021.105366},
url = {https://www.sciencedirect.com/science/article/pii/S0022053121001836},
author = {Isabelle Brocas and Juan D. Carrillo},
keywords = {Neuroeconomic theory, Multiple brain systems, Self-control, Cue-triggered behavior, Self-regulation},
abstract = {We develop a theory based on the evidence reported in Hare et al. (2009) to explain consumption of goods that feature a low-order attribute (e.g., taste) and a high-order attribute (e.g., health). One brain system with access to the low-order attribute computes the goal value of consumption while another brain system can modulate this value, at a cost, by transmitting information regarding the high-order attribute. We determine the optimal modulation and consumption strategy as a function of the cost of information transmission and the environment. We show that in healthy environments, modulation is used to signal surprisingly unhealthy goods so as to trigger abstinence when consumption would ordinarily occur. Conversely, in unhealthy environments, modulation is used to signal surprisingly healthy choices so as to trigger consumption when abstinence would ordinarily occur. From an outside perspective, individuals may appear to under-regulate their choices (self-indulgence) but also to over-regulate them (self-restraint). Both modulation and decisions are affected by factors orthogonal to the decision problem. In particular, taxing executive functions results in less modulation and more inefficient behavior. Finally, the model can shed light on issues related to eating disorders, present-biased preferences, habit formation and compulsive behavior.}
}
@article{SAYHAN201714166,
title = {Computational investigation and comparison of hydrogen storage properties of B24N24 and Al24N24 nanocages},
journal = {International Journal of Hydrogen Energy},
volume = {42},
number = {20},
pages = {14166-14180},
year = {2017},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2017.04.069},
url = {https://www.sciencedirect.com/science/article/pii/S0360319917314490},
author = {Sinan Sayhan and Armağan Kinal},
keywords = {Boron nitride nanocages, Aluminum nitride nanocages, Hyrdogen storage materials, BN, AlN, The DFT methods},
abstract = {In this study, hydrogen storage properties of the B24N24 and Al24N24 nanocages have been computationally investigated by the DFT method whose suitability was determined with a thorough methodological analysis. This analysis includes comparison of the performances of a number of DFT functionals against the CCSD(T) method for the determination of the best DFT method that is able to accurately model H2-BN and H2-AlN systems. The ɷB97X-D, B3LYP-D2, PBEPBE-D2, BHandH methods produced results close to that of the reference CCSD(T) method. Of all methods studied, ɷB97X-D, showing the best performance, is found to be the most appropriate DFT method for H2-B24N24 and Al24N24 systems including dispersive interactions between hydrogen and the host molecule. The ɷB97X-D calculations result in that H2 molecule make the tightest adsorptive bond with Al atom in Al24N24 having an adsorption energy of −0.116 eV, by forming much more stable complex than the H2-B24N24 one. This indicates that Al24N24 has better exohedral hydrogen storage properties. The calculations also revealed that H2 molecules cannot pass through hexagonal rings of B24N24 instead they chemisorb on the cage atoms by breaking BN bond while they can pass through hexagonal rings of Al24N24 without making any damage in the Al–N bond, leading the fact that the Al–N bond is stronger than the B–N bond. Moreover, endohedral addition of H2 molecules up to three can form thermodynamically stable nH2@Al24N24 complexes while endohedral hydrogen addition to B24N24 destabilizes the complexes. Thus, the Al24N24 nanocage is not only structurally more stable than B24N24 nanocage, but also it can accommodate more hydrogen molecules, so it is better candidate for both endohedrally and exohedrally hydrogen storage compared to B24N24.}
}
@article{CHIN20201054,
title = {Rethinking Cancer Immunotherapy by Embracing and Engineering Complexity},
journal = {Trends in Biotechnology},
volume = {38},
number = {10},
pages = {1054-1065},
year = {2020},
note = {Special Issue: Therapeutic Biomanufacturing},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2020.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167779920301244},
author = {Matthew H.W. Chin and Eileen Gentleman and Marc-Olivier Coppens and Richard M. Day},
keywords = {bioengineering, complex systems, holism, immunotherapy, process intensification},
abstract = {The meteoric rise of cancer immunotherapy in the past decade has led to promising treatments for a number of hard-to-treat malignancies. In particular, adoptive T cell therapy has recently reached a major milestone with two products approved by the US FDA. However, the inherent complexity of cell-based immunotherapies means that their manufacturing time, cost, and controllability limit their effectiveness and geographic reach. One way to address these issues may lie in complementing the dominant, reductionistic mentality in modern medicine with complex systems thinking. In this opinion article, we identify key concepts from complexity theory to address manufacturing challenges in cell-based immunotherapies and raise the possibility of a unifying framework upon which future bioprocessing strategies may be designed.}
}
@article{NESI2024,
title = {Enactivism: A contemporary perspective of a reconceptualization of osteopathy},
journal = {Advances in Integrative Medicine},
year = {2024},
issn = {2212-9588},
doi = {https://doi.org/10.1016/j.aimed.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212958824001186},
author = {Jacson Nesi and Michele Benites and Filipe Boeira Schedler},
keywords = {Enactivism, Osteopathy, Medical rationalities, Reconceptualization},
abstract = {Enactivism is a philosophical and scientific approach that emphasizes the role of the body and its interactions with the environment in shaping cognitive processes and subjective experiences. Meanwhile, osteopathy is a person-centered health care discipline, highlighting the structure-function interrelationship of the body and its selfregulation mechanisms. Both approaches value the body and the environment in health. Several authors have been discussing the urgent need for a reconceptualization of osteopathy and also suggesting integrate biological, psychological and social aspects. Thinking osteopathy as a Therapeutic Rationality, implies recognize its fundamental dimensions: Human Morphology, Vital Dynamics, Medical Doctrine, Diagnostic System and Therapeutic System, all integrated by a philosophical Cosmology, as the original term Medical rationality states, but also embrace a broader perspective allowing an individual and unique process of each person, reflecting the transformation of contemporary medicine to a person approach. Enactivism principles can serve as a basis for a reconceptualization of osteopathy, integrating environmental, psychological, social, and spiritual factors. Osteopathic concepts can probably be updated through the convergence between enactivism and osteopathy, promoting more meaningful and evidence-based clinical practice. Advancing in this direction requires a collaborative dialogue between researchers, health professionals and interested people, seeking an integrated understanding of the relationship between body, mind, environment and health.}
}
@article{JANES200673,
title = {A biological approach to computational models of proteomic networks},
journal = {Current Opinion in Chemical Biology},
volume = {10},
number = {1},
pages = {73-80},
year = {2006},
note = {Proteomics and genomics},
issn = {1367-5931},
doi = {https://doi.org/10.1016/j.cbpa.2005.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S1367593105001687},
author = {Kevin A Janes and Douglas A Lauffenburger},
abstract = {Computational modeling is useful as a means to assemble and test what we know about proteins and networks. Models can help address key questions about the measurement, definition and function of proteomic networks. Here, we place these biological questions at the forefront in reviewing the computational strategies that are available to analyze proteomic networks. Recent examples illustrate how models can extract more information from proteomic data, test possible interactions between network proteins and link networks to cellular behavior. No single model can achieve all these goals, however, which is why it is critical to prioritize biological questions before specifying a particular modeling approach.}
}
@article{GIOT2013788,
title = {Fast computation of the performance evaluation of biometric systems: Application to multibiometrics},
journal = {Future Generation Computer Systems},
volume = {29},
number = {3},
pages = {788-799},
year = {2013},
note = {Special Section: Recent Developments in High Performance Computing and Security},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X12000362},
author = {Romain Giot and Mohamad El-Abed and Christophe Rosenberger},
keywords = {Biometrics, Authentication, Error estimation, Access control},
abstract = {The performance evaluation of biometric systems is a crucial step when designing and evaluating such systems. The evaluation process uses the Equal Error Rate (EER) metric proposed by the International Organization for Standardization (ISO/IEC). The EER metric is a powerful metric which allows easily comparing and evaluating biometric systems. However, the computation time of the EER is, most of the time, very intensive. In this paper, we propose a fast method which computes an approximated value of the EER. We illustrate the benefit of the proposed method on two applications: the computing of non parametric confidence intervals and the use of genetic algorithms to compute the parameters of fusion functions. Experimental results show the superiority of the proposed EER approximation method in term of computing time, and the interest of its use to reduce the learning of parameters with genetic algorithms. The proposed method opens new perspectives for the development of secure multibiometrics systems by speeding up their computation time.}
}
@article{YANG2023106838,
title = {Neuromorphic electronics for robotic perception, navigation and control: A survey},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {106838},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106838},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623010229},
author = {Yi Yang and Chiara Bartolozzi and Haiyan H. Zhang and Robert A. Nawrocki},
keywords = {Neuromorphic electronics, Organic and flexible electronic materials, Neuromorphic robot, Perception, Navigation, Control, SLAM, Path planning},
abstract = {Neuromorphic electronics have great potential in the emulation of the sensory, cognitive, self-learning, and actuating functions of robots. While typically implemented in rigid silicon, emerging technologies in organic and flexible electronic materials have also led to tremendous advances in the development of neuromorphic perception systems. However, a comprehensive review of the contribution/role of organic neuromorphic electronics for robotic applications is still missing. This review presents advancements in silicon-based and organic neuromorphic electronics for intelligent robot development, focusing on perception, navigation, and learning-based control. Organic synaptic devices, along with dynamic vision sensors, enable diverse forms of sensory-enabled computational perception, offering tunability, stability, low power consumption, and conformal substrates. Integration of simultaneous localization and mapping techniques and path planning algorithms empowers robots to efficiently navigate, build accurate maps, and make informed decisions. Different learning algorithms and their hardware implementations in neuromorphic robotic control are explored, enabling robots to learn and adapt to dynamic environments. The review highlights the potential of neuromorphic electronics for sensing, thinking, and acting in advanced robotic systems. Organic, inorganic, and hybrid materials are discussed for implementing perception, navigation, and control in robots. Future research directions in the field are outlined. Leveraging various neuromorphic electronics unlocks the full potential of intelligent robotic systems for diverse applications.}
}
@article{GOODSELL2020472,
title = {Art and Science of the Cellular Mesoscale},
journal = {Trends in Biochemical Sciences},
volume = {45},
number = {6},
pages = {472-483},
year = {2020},
issn = {0968-0004},
doi = {https://doi.org/10.1016/j.tibs.2020.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0968000420300566},
author = {David S. Goodsell and Arthur J. Olson and Stefano Forli},
keywords = {mesoscale modeling, integrative structural biology, drug discovery, drug design, cell structure, cell function, molecular structure, molecular function},
abstract = {Experimental information from microscopy, structural biology, and bioinformatics may be integrated to build structural models of entire cells with molecular detail. This integrative modeling is challenging in several ways: the intrinsic complexity of biology results in models with many closely packed and heterogeneous components; the wealth of available experimental data is scattered among multiple resources and must be gathered, reconciled, and curated; and computational infrastructure is only now gaining the capability of modeling and visualizing systems of this complexity. We present recent efforts to address these challenges, both with artistic approaches to depicting the cellular mesoscale, and development and application of methods to build quantitative models.}
}