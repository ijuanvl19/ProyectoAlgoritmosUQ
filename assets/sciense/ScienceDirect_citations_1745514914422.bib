@article{RIBEIRO2011639,
title = {Re-thinking diagnosis for future automation systems: An analysis of current diagnostic practices and their applicability in emerging IT based production paradigms},
journal = {Computers in Industry},
volume = {62},
number = {7},
pages = {639-659},
year = {2011},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2011.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0166361511000303},
author = {Luis Ribeiro and Jose Barata},
keywords = {Diagnosis, Reconfigurable manufacturing systems, Adaptive production systems},
abstract = {With the advent of the Internet and the progressive development and consolidation of a wide range of web standards and technologies as well as the advances in distributed artificial intelligence (DAI), namely the multi agent system concept, new opportunities have emerged for conceiving, modelling and enhancing shop floor's performance and response. Modern IT-supported production paradigms denote a common concept where the shop floor is a lively entity composed by interacting intelligent modules whose individual and collective function adapts and evolves ensuring the fitness and adequacy of the organization, owning the system, in tackling profitable but volatile business opportunities. The self-organizing and peer to peer nature of these systems renders a collective behaviour and dynamics that are fundamentally new. Conventional diagnostic methods and tools have not been designed targeting the envisioned systems therefore lack the required support. In this paper the emerging IT-based production paradigms are surveyed as well as the existing diagnostic methods whose adequacy is analysed. The resulting requirements and characteristics are exposed to stress the need for rethinking current diagnostic practices in future automation systems.}
}
@article{STAVERT2023432,
title = {Unlocking the holy grail of sustainable and scalable mesoporous silica using computational modelling},
journal = {RSC Sustainability},
volume = {1},
number = {3},
pages = {432-438},
year = {2023},
issn = {2753-8125},
doi = {https://doi.org/10.1039/d3su00019b},
url = {https://www.sciencedirect.com/science/article/pii/S2753812523000952},
author = {Tom Stavert and Siddharth V. Patwardhan and Robert Pilling and Miguel Jorge},
abstract = {ABSTRACT
Bio-inspired methods offer a great alternative to design high-value mesoporous silica under more environmentally friendly conditions, allowing for an economical and sustainable scale-up. However, the synthesis of bio-inspired silica (BIS) is currently poorly understood, creating barriers to achieving products with comparable quality to traditional mesoporous silica. This perspective summarizes the key findings in the development of ordered mesoporous silica (OMS) and BIS synthesis, highlighting in particular the challenges faced in the development of scalable processing routes for these materials. Recent successes in improving mechanistic understanding of these syntheses using computational modelling are then presented, followed by suggestions as to how modelling may be used for predictive design of BIS with desired quality attributes. A multi-scale computational model, utilizing a combination of both ‘top-down’ and ‘bottom-up’ approaches, is argued to be critical for achieving a unified description of both BIS and OMS synthesis, allowing the potential of these materials to be fully realised.}
}
@article{YIP2023319,
title = {From Computation to Clinic},
journal = {Biological Psychiatry Global Open Science},
volume = {3},
number = {3},
pages = {319-328},
year = {2023},
issn = {2667-1743},
doi = {https://doi.org/10.1016/j.bpsgos.2022.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S2667174322000507},
author = {Sarah W. Yip and Deanna M. Barch and Henry W. Chase and Shelly Flagel and Quentin J.M. Huys and Anna B. Konova and Read Montague and Martin Paulus},
keywords = {Cognitive neuroscience, Computational psychiatry, Machine learning, Neuroimaging, Reinforcement learning},
abstract = {Theory-driven and data-driven computational approaches to psychiatry have enormous potential for elucidating mechanism of disease and providing translational linkages between basic science findings and the clinic. These approaches have already demonstrated utility in providing clinically relevant understanding, primarily via back translation from clinic to computation, revealing how specific disorders or symptoms map onto specific computational processes. Nonetheless, forward translation, from computation to clinic, remains rare. In addition, consensus regarding specific barriers to forward translation—and on the best strategies to overcome these barriers—is limited. This perspective review brings together expert basic and computationally trained researchers and clinicians to 1) identify challenges specific to preclinical model systems and clinical translation of computational models of cognition and affect, and 2) discuss practical approaches to overcoming these challenges. In doing so, we highlight recent evidence for the ability of computational approaches to predict treatment responses in psychiatric disorders and discuss considerations for maximizing the clinical relevance of such models (e.g., via longitudinal testing) and the likelihood of stakeholder adoption (e.g., via cost-effectiveness analyses).}
}
@article{THOWYICK1998275,
title = {General information theory: Some macroscopic dynamics of the human thinking systems},
journal = {Information Processing & Management},
volume = {34},
number = {2},
pages = {275-290},
year = {1998},
issn = {0306-4573},
doi = {https://doi.org/10.1016/S0306-4573(97)00069-1},
url = {https://www.sciencedirect.com/science/article/pii/S0306457397000691},
author = {Liang Thow-Yick},
abstract = {This study is an attempt to put in place the component of the general information theory that explains the macroscopic dynamics of the human thinking systems. The fundamental structure of such a theory must include the domains of external basic entity interactions, external basic entity and information-coded energy quantum transformations, and energy quantum and information-coded matter interactions. In this respect, a human thinking system is perceived to have at least a natural energy-matter subsystem and a human-created physical symbol subsystem. The artifacts of the human-created subsystem are the external basic physical entities, namely, data, information, knowledge, and wisdom. The intrinsic and interactive properties of these entities depict the characteristics of the physical symbol subsystem. Besides interacting among themselves, the external entities also interact with the natural entities, the information-coded energy quanta, according to certain rules and principles. Subsequently, the energy quanta interact with the information-coded matter structure. Such interactions occurring within the individual subsystems and between the two subsystems constitute the dynamics of the human thinking systems. In intelligent systems of this nature information can exist in physical, energy and matter forms, and the different forms are interconvertible. The interactions among these entities and the conversion of one form to another is made possible by the existence of an intelligence space in the human mind.}
}
@article{DU2023108546,
title = {OSSCAR, an open platform for collaborative development of computational tools for education in science},
journal = {Computer Physics Communications},
volume = {282},
pages = {108546},
year = {2023},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2022.108546},
url = {https://www.sciencedirect.com/science/article/pii/S001046552200265X},
author = {Dou Du and Taylor J. Baird and Sara Bonella and Giovanni Pizzi},
keywords = {Jupyter, Notebooks, Computational physics, Computational chemistry, Computational materials science, Education},
abstract = {In this paper we present the Open Software Services for Classrooms and Research (OSSCAR) platform. OSSCAR provides an open collaborative environment to develop and access educational resources in the form of web applications, for which various deployment methods are discussed and compared. To minimize efforts in the creation and use of new educational material, OSSCAR combines software tools that have emerged as standards with custom domain-specific ones. The technical solutions adopted to create and distribute content are described and motivated on the basis of reliability, sustainability, ease of uptake and use. Examples from courses in the domains of physics, chemistry, and materials science are shown to demonstrate the style and level of interactivity of typical applications. The tools presented are easy to use, and create a uniform and open environment exploitable by a large community of teachers, students, and researchers with the goal of facilitating learning and avoiding, when possible, duplication of efforts in creating teaching material. Contributions to expand the educational content of the OSSCAR project are welcome.
Program summary
Program Title: OSSCAR Interactive Notebooks for Quantum Mechanics and Computational Materials Science CPC Library link to program files: https://doi.org/10.17632/26py5zz9f8.1 Developer's repository link: https://github.com/osscar-org/quantum-mechanics Licensing provisions: MIT Programming language: Python Nature of problem: Among others, computational courses (e.g. on quantum mechanics) can benefit from advanced interactive visualizations of the content. However, on the one hand it might be complicated for teachers to develop such interactive content; on the other hand, students need to be able to access very quickly and efficiently the content, reducing the time needed to install libraries and dependencies that might differ between courses. Solution method: Here, we developed interactive web applications to complement teaching and encourage computational thinking for courses in computational physics, chemistry and materials science, using Jupyter notebooks and their rendering as interactive web applications. The latter is powered by a combination of Voila, to hide code and convert notebooks into live web applications, and (existing or custom) Jupyter widgets to enable interactiveness. The code is ready to be deployed via a number of open approaches.}
}
@incollection{ALLAHVIRANLOO2024407,
title = {Chapter 23 - Computations with words},
editor = {Tofigh Allahviranloo and Witold Pedrycz and Amir Seyyedabbasi},
booktitle = {Decision-Making Models},
publisher = {Academic Press},
pages = {407-415},
year = {2024},
series = {Uncertainty, Computational Techniques, and Decision Intelligence},
isbn = {978-0-443-16147-6},
doi = {https://doi.org/10.1016/B978-0-443-16147-6.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443161476000128},
author = {Tofigh Allahviranloo},
keywords = {Computation, Fuzzy, Application},
abstract = {In fact, computing with words is a method in which the objects are words, and the computations are propositions extracted from ordinary conversation. For example, small, large, far, and heavy, not very likely, the price of gas in Iran is low and increasing a lot. Computing with words is inspired by the remarkable ability of humans to perform various types of physical and mental activities without any measurement or calculation. Familiar examples of these activities are parking a car, driving in heavy traffic, riding a bicycle, understanding speech, etc.}
}
@article{KONG2024105016,
title = {The impact of school support for professional development on teachers' adoption of student-centered pedagogy, students’ cognitive learning and abilities: A three-level analysis},
journal = {Computers & Education},
volume = {215},
pages = {105016},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105016},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524000307},
author = {Siu-Cheung Kong and Yi-Qing Wang},
keywords = {Cognitive learning, Computational thinking, Multilevel analysis, Student-centered pedagogy, Teacher professional development},
abstract = {Student-centered pedagogy (SCP) is highly considered for its potential to facilitate cognitive learning in Computational Thinking (CT) education. However, there is a noticeable gap in understanding its influence on students' cognitive development from a multilevel perspective. This study delves into cognitive learning theories and aims to bridge the existing gap by introducing a three-level conceptual model to illustrate how the influence of SCP on students' cognitive CT abilities is mediated through the cognitive learning processes. This multilevel approach simultaneously explores SCP within the intricate school environment where factors at the school, teacher, and student levels are closely intertwined. Data was collected from 82 programming teachers and their 2433 students across 43 Hong Kong primary schools. Using multilevel modeling, results indicate that the adoption of SCP is significantly anchored by school support on teacher professional development (TPD), which in turn enhances students’ cognitive learning (i.e., active, interactive, constructive, and reflective learning) in class, further contributing to their enhanced cognitive CT abilities. The findings underscore the nuances of SCP adoption in school scenarios, advocating for strategic approaches to maximize student achievements in CT education. Recommendations for future research are discussed.}
}
@incollection{DASGUPTA2020554,
title = {Technology: Computational Creativity},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {554-559},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23765-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245237656},
author = {Subrata Dasgupta},
keywords = {Artifact, Artificer, Artificial intelligence, Computational creativity, Computational thinking, Creativity, Heuristics search, Historicity, Human creativity, Purposive evolution},
abstract = {The focus of this article is computational creativity, which is concerned with the problem of understanding, theorizing, designing and constructing computational artifacts that manifest behavior which would be deemed ‘creative’ if exhibited by human beings. Historically, this problem is a derivative of the agenda of artificial intelligence (AI) and, thus, is a technological problem. However, as will be seen, even in the specifically technological realm of computational creativity issues pertaining to human creativity cannot be evaded since, at the very least, the criteria for judging and evaluating the creativity of computational artifacts will originate in the realm of human creativity.}
}
@article{YANG2025101808,
title = {Cross-domain analogical reasoning ability links functional connectome to creativity},
journal = {Thinking Skills and Creativity},
volume = {57},
pages = {101808},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101808},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000574},
author = {Lin Yang and Rongcan Zeng and Xueyang Wang and Jing Chen and Jing Gu and Jiaxin Fan and Jiang Qiu and Guikang Cao},
keywords = {Cross-domain analogical reasoning, Creativity, CPM, Natural language processing},
abstract = {Cross-domain analogical reasoning (CAR) is a potent cognitive tool that links seemingly unrelated knowledge domains, fostering creative thinking by identifying similarities across different fields. This study aimed to identify functional connectomes encoding individual variations in CAR abilities and assess their role in creativity. Participants included 69 typical university students who underwent resting-state brain MRI scans and behavioral tests. These tests assessed both CAR and within-domain analogical reasoning (WAR) abilities using verbal analogy tasks in the A:B::C:D format and measured individual creativity levels using the Alternative Uses Test (AUT). We employed a connectome-based predictive modeling (CPM) approach, utilizing the Power264 brain atlas to identify functional connectomes supporting CAR abilities. The CPM analysis indicated that the positive network model could reliably predict individual CAR scores. Functional anatomy and lesion analysis revealed that functional connectivity was broadly distributed across the brain. However, the default mode network, along with specific internetwork connections—such as between the salience and sensory/somatomotor mouth networks, and between the fronto-parietal task control and cingulo-opercular task control networks—showed preferential involvement. Moreover, mediation analysis suggested that CAR mediates the influence of brain functional connectomes on creativity. Our research provides evidence for functional neural markers of CAR and reveals a potential neuropsychological pathway for predicting creativity, whereby brain functional connectomes support creativity through CAR.}
}
@article{SUMI199771,
title = {Computer-aided thinking by mapping text-objects into metric spaces},
journal = {Artificial Intelligence},
volume = {91},
number = {1},
pages = {71-84},
year = {1997},
note = {Artificial Intelligence Research in Japan},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(96)00058-6},
url = {https://www.sciencedirect.com/science/article/pii/S0004370296000586},
author = {Yasuyuki Sumi and Koichi Hori and Setsuo Ohsuga},
keywords = {Computer-aided thinking, Concept formation, Visualizing thought space structure, Computer-supported cooperative work},
abstract = {This paper presents a system for computer-aided thinking. We propose the idea of reflecting the mental world indirectly into a metric space to support such human thinking activities as externalizing and forming new ideas. We use a method that maps text-objects into metric spaces for visualizing a user's thought space structure. Text-objects imply fragments of a user's idea, which have several keywords given by him/her. Spaces composed of text-objects are configured in the way “the higher the mutual relevance between a pair of text-objects is, the closer the text-objects are mapped”. The relevance values among text-objects are calculated due to cooccurrence of their keywords. Results of experiments with our implemented system, named CAT1 (computer-aided thinking, version 1), show that users of the system can get effective stimuli for further thinking in creative concept formation. The paper also discusses the potential application of CAT1 to collaborative work by groups of people.}
}
@article{JANECK2003181,
title = {Too much thinking about thinking?: metacognitive differences in obsessive–compulsive disorder},
journal = {Journal of Anxiety Disorders},
volume = {17},
number = {2},
pages = {181-195},
year = {2003},
issn = {0887-6185},
doi = {https://doi.org/10.1016/S0887-6185(02)00198-6},
url = {https://www.sciencedirect.com/science/article/pii/S0887618502001986},
author = {Amy S. Janeck and John E. Calamari and Bradley C. Riemann and Susan K. Heffelfinger},
keywords = {Obsessive–compulsive disorder, Cognition, Metacognition},
abstract = {Negative appraisals of intrusive thoughts and beliefs about the importance of thoughts are considered core mechanisms in cognitive models of obsessive–compulsive disorder (OCD). In refinements of cognitive theory, differences in metacognitive processes have been emphasized. Cartwright-Hatton and Wells [J. Anxiety Disord. 37 (1997) 279–296] found that cognitive self-consciousness (CSC), a tendency to be aware of and monitor thinking, was the only metacognitive dimension that differentiated OCD patients from patients with generalized anxiety disorder. To evaluate the relative importance of different cognitive processes to OCD, we administered an expanded CSC scale and two state-of-the-art measures of thought appraisals and beliefs. Scores on the CSC scale reliably differentiated OCD patients (n=30), from an anxious comparison group (OAD, n=25) after controlling for scores on the two cognition measures. The tendency to excessively reflect upon one’s cognitive processes may increase opportunities for negative appraisals of intrusive thoughts, foster over-importance of thought beliefs, and increase the likelihood of developing OCD.}
}
@article{SIMON1999363,
title = {The foundations of numerical thinking in a brain without numbers},
journal = {Trends in Cognitive Sciences},
volume = {3},
number = {10},
pages = {363-365},
year = {1999},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(99)01383-2},
url = {https://www.sciencedirect.com/science/article/pii/S1364661399013832},
author = {Tony J Simon},
keywords = {Brain, Number, Development, Counting, Attention}
}
@article{MARTINEZ20001657,
title = {Systems thinking and functional modeling of batch process management using projects},
journal = {Computers & Chemical Engineering},
volume = {24},
number = {2},
pages = {1657-1663},
year = {2000},
issn = {0098-1354},
doi = {https://doi.org/10.1016/S0098-1354(00)00446-4},
url = {https://www.sciencedirect.com/science/article/pii/S0098135400004464},
author = {E.C. Martinez},
keywords = {Batch process management, Systems thinking, Functional modeling},
abstract = {Intense competition and rapid environmental changes are revealing severe limitations in the effectiveness of the hierarchical, stable and Tayloristic management system currently used by the vast majority of batch manufacturing industries. A project-oriented enterprise model of batch plants which results of integrating together systems thinking and functional modeling is proposed here. The latter refers to the set of intents and relationships between goals, functions and components (both physical and abstract) that comprise an analytical viewpoint of batch processes involving product recipes, equipment capabilities, constraints and human competencies (skills and knowledge). Complementarily, the systemic perspective accounts for the organizational setting (roles, objectives and actors), and provides an orthogonal view through the duality of whole-parts relationships and the ubiquitous concepts of boundary, emergence and hierarchy upon which the project-oriented enterprise model is built. A case study that comprises a dairy facility involving the production + 100 different fresh products using an order-driven management system will be presented. To support the prototype implementation of a plant information system using a hierarchy of project-based objects, a conceptual design has been developed. The implementation of the resulting enterprise model in Project 98™ will be discussed to highlight its easy and cheap implementation, and a number of advantages including: accumulation of information and knowledge, direct tracing of activities and cost analysis.}
}
@article{MENG2025105053,
title = {Time-variant response computation of flexible multibody systems with imprecise random fields},
journal = {International Journal of Non-Linear Mechanics},
volume = {173},
pages = {105053},
year = {2025},
issn = {0020-7462},
doi = {https://doi.org/10.1016/j.ijnonlinmec.2025.105053},
url = {https://www.sciencedirect.com/science/article/pii/S0020746225000411},
author = {Jingwei Meng and Yanfei Jin},
keywords = {Hybrid uncertain analysis, Flexible multibody systems, Imprecise random fields, Interval parameters, Polynomial chaos-Legendre metamodel},
abstract = {This paper proposes a new uncertain modelling and analysis method for flexible multibody systems with imprecise random field uncertainties. The standard random field is expanded to the imprecise random field model containing the behavior of imprecise randomness with bounded statistical moments more appropriately for real engineering problems. The imprecise random field is further discretized to independent standard Gaussian random variables by using the Karhunen-Loève expansion method. The flexible multibody system is modeled by using a unified mesh of the absolute node coordinate formula. Mathematical expressions and solution procedure based on the Polynomial chaos-Legendre metamodel are developed to solve the dynamic equations of systems involving imprecise random field. Two types of evaluation indexes are effectively established by constructing the second layer polynomial chaos expansion, namely interval mean value, interval variance, mean of the upper bound, variance of the lower bound. Finally, the effectiveness of the presented method is illustrated by two numerical examples of flexible multibody systems. Especially, for complicated multibody systems, it is necessary to calculate two uncertainty evaluation indexes to study the complete dynamic behavior.}
}
@article{WU20112788,
title = {Myth of ecological architecture designs: Comparison between design concept and computational analysis results of natural-ventilation for Tjibaou Cultural Center in New Caledonia},
journal = {Energy and Buildings},
volume = {43},
number = {10},
pages = {2788-2797},
year = {2011},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2011.06.035},
url = {https://www.sciencedirect.com/science/article/pii/S0378778811002842},
author = {Yu-Chou Wu and An-Shik Yang and Li-Yu Tseng and Chin-Lung Liu},
keywords = {Ecological architecture, Wind-driven ventilation design, Tjibaou Cultural Center, Computational Fluid Dynamics},
abstract = {The Jean-Marie Tjibaou Cultural Center, designed by Renzo Piano, a world renown Italian architect and a recipient of the Pritzker Architecture Prize, was described as a piece of “Ecological Architecture” in New Caledonia. This building is recognized by its sustainable ventilation design concept that implements the unique ten shell-like structures for aeration enhancement. This paper presents an approach using the computational fluid dynamics (CFD)-based simulations to compare the numerical predictions with the original architectural insight for a verification of the architect's thinking in his realization of the design purpose. In the analysis, we consider the incompressible isothermal turbulent airflow to examine the interaction of the flow with the building for a better understanding of the wind-driven self-sustaining ventilation mechanism. We also propose a modified model via enlarging the aeration opening with the least blockages along the wind pathway. The simulated results indicate that the improved design substantially enhances the air-intake effectiveness and realizes a satisfactory pressure balance for the Tjibaou Cultural Center.}
}
@article{FRADKIN2023S122,
title = {71. A Transdiagnostic Investigation of the Computational Mechanisms of Formal Thought Disorder},
journal = {Biological Psychiatry},
volume = {93},
number = {9, Supplement },
pages = {S122-S123},
year = {2023},
note = {Abstract Supplement},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2023.02.311},
url = {https://www.sciencedirect.com/science/article/pii/S0006322323003852},
author = {Isaac Fradkin and Rick Adams and Noam Siegelman and Rani Moran and Raymond Dolan}
}
@article{BIANCIARDI201787,
title = {Biomimicry thinking: methodological improvements and practical implementation},
journal = {Bioinspired, Biomimetic and Nanobiomaterials},
volume = {6},
number = {2},
pages = {87-101},
year = {2017},
issn = {2045-9866},
doi = {https://doi.org/10.1680/jbibn.16.00007},
url = {https://www.sciencedirect.com/science/article/pii/S2045986617000111},
author = {Alessandro Bianciardi and Caterina Credi and Marinella Levi and Francesco Rosa and Alessandro Zecca},
keywords = {bioinspired, low-dimensional structures, oleophobic},
abstract = {The importance of oilwater separation processes is rapidly increasing in the modern industry. This family of processes, in fact, is of fundamental importance in solving problems in several industrial sectors, among which, for instance, are the management of oil spills, accidental industrial waste water dispersions, water treatment industry, engine fuel filtration and oil sand tailing technology. This paper, firstly, presents and discusses a biologically inspired design approach, based on biomimicry thinking (BT). Besides integrating linguistic tools and brainstorming within the BT approach, the importance of a stricter integration with the engineering context is also discussed. Secondly, the paper presents a practical application of this approach: design an innovative and sustainable oilwater separation device. In particular, the application of the proposed approach allowed identifying a bioinspired solution capable to improve the process performances in a device based on a known strategy. More in detail, the adopted bioinspired solution consists of a superoleophobic surface that mimics the microstructure of the filefish scale surface and eases the oilwater separation process by hindering oil drops deposition on some surfaces. The cost and resource effectiveness of the practical realisation of this surface greatly benefited by the latest advancements in the additive manufacturing field.}
}
@article{MENG2023103514,
title = {The price paid: Heuristic thinking and biased reference points in the housing market},
journal = {Journal of Urban Economics},
volume = {134},
pages = {103514},
year = {2023},
issn = {0094-1190},
doi = {https://doi.org/10.1016/j.jue.2022.103514},
url = {https://www.sciencedirect.com/science/article/pii/S0094119022000900},
author = {Charlotte C. Meng},
keywords = {Left-digit Bias, Reference dependence, Behavioural economics, Housing markets},
abstract = {Does the power of reference points mean that minute differences in a purchase price then reverberate in future sales prices? In this research, I show that if previous sales prices are round numbers, defined as multiples of £1,000 (e.g. £231,000), subsequent sales prices entail a considerable premium relative to similar properties that were previously priced at charm numbers that are marginally below those round numbers (e.g. £230,999 or £230,950). Using a sample of repeat sales from the Greater London region from 1995 to 2017, I estimate the premium to be approximately 4 percent after controlling for property characteristics and a large set of fixed effects. Increasing public accessibility of information attenuates the effect. Tax considerations, financial constraints, and pricing errors cannot explain the result. I propose a framework of reference dependence and left-digit bias to explain the result, highlighting the presence of behavioural biases in household decisions, even when very high stakes are involved.}
}
@article{MAJZOUB20231011,
title = {Investigating the adaptability and implementation of computational design methods in concept design taking plasterboard opportunities for dimensional coordination and waste reduction as a case study},
journal = {Frontiers of Architectural Research},
volume = {12},
number = {5},
pages = {1011-1029},
year = {2023},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S209526352300047X},
author = {Omar Majzoub and M. Hank Haeusler and Sisi Zlatanova},
keywords = {Computational design, Plasterboard dimensional coordination, Concept design},
abstract = {Construction material offcuts is a data problem that can largely be avoided by dimensional coordination during concept design. Besides the environmental benefits, early phase coordination is beneficial to the overall design process as it integrates information not typically considered until later in the design process. However, taking reality-changing actions is often challenged by uncertainty, time constraints, and lack of integration of available tools. Acknowledging the potential of computational design in enabling architects to manage design and coordination complexities and taking plasterboard opportunities for dimensional coordination, the paper presents a review and assessment of the existing methods to interrogate what, when, and how are these adaptable to the task. The study shows that ML-based methods outperform other methods and concludes that leveraging computational design powers to reduce offcuts is not a question of a tool, but one of a strategy. Eventually, the future steps to achieving such a strategy are discussed.}
}
@article{FLEMING2024896,
title = {Quality space computations for consciousness},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {10},
pages = {896-906},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001657},
author = {Stephen M. Fleming and Nicholas Shea},
keywords = {consciousness, sensory states, quality space, similarity, neural representation},
abstract = {The quality space hypothesis about conscious experience proposes that conscious sensory states are experienced in relation to other possible sensory states. For instance, the colour red is experienced as being more like orange, and less like green or blue. Recent empirical findings suggest that subjective similarity space can be explained in terms of similarities in neural activation patterns. Here, we consider how localist, workspace, and higher-order theories of consciousness can accommodate claims about the qualitative character of experience and functionally support a quality space. We review existing empirical evidence for each of these positions, and highlight novel experimental tools, such as altering local activation spaces via brain stimulation or behavioural training, that can distinguish these accounts.}
}
@article{GOVINDAN2019653,
title = {Computational decision framework for enhancing resilience of the energy, water and food nexus in risky environments},
journal = {Renewable and Sustainable Energy Reviews},
volume = {112},
pages = {653-668},
year = {2019},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2019.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364032119304083},
author = {Rajesh Govindan and Tareq Al-Ansari},
keywords = {Energy, water, and food nexus, Risk management, Artificial intelligence, Regime switching, Reinforcement learning},
abstract = {The energy, water and food (EWF) nexus modelling and analysis frameworks proposed recently have demonstrated their effectiveness in the assessment and quantification of synergies and trade-offs in the interlinkages between the three sectors. They largely rely on static, deterministic or equilibrium-based models that facilitate in making decisions for well-behaved and predictable resource systems over time. These frameworks, however, are partly limited in their functionality due to the fact that they do not consider the exposure of systems to the dynamic nature of extrinsic uncertainties and the associated risks in the nexus. Hence, there is a need for a sequential learning, planning and optimal control modelling framework which could help achieve adaptive systems under volatile conditions with the objective to maximise economic output and enhance their operational resilience. In this paper, the authors discuss the development of a novel computational framework which incorporates “algorithmic resilience thinking” to achieve adaptive and robust inter-networked systems. Here, the question of adaptive systems for EWF nexus resilience is posed as a reinforcement learning problem based on sequential decision-making called the Markov decision process (MDP). The authors further discuss a case study, considering weather volatility, its spatial impact on vegetation, and the consequent risks on the water-food nexus for outdoor agricultural operations in the State of Qatar. The application of the developed framework particularly demonstrates promise in providing the functionality to track and mitigate emerging risks that have the potential to cause unprecedented disruption in the operations of integrated natural resource systems. The outcome of this study has positive implications for the advancement and effectiveness of EWF nexus planning and risk management to avert resource shortages and price risks, socio-economic disruption, and cascading failures of critical infrastructures, particularly when the global supply chains are subjected to stresses and shocks, such as extreme weather conditions.}
}
@article{KAVGA2023102837,
title = {Design and simulation of a greenhouse in a computational environment (ANSYS/FLUENT) and an automatic control system in a LABVIEW environment},
journal = {Simulation Modelling Practice and Theory},
volume = {129},
pages = {102837},
year = {2023},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2023.102837},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X23001144},
author = {Angeliki Kavga and Vasileios Thomopoulos and Evangelos Pischinas and Dimitris Tsipianitis and Pantelis Nikolakopoulos},
keywords = {Greenhouses, Digital twin, Control, Arduino, Fuzzy logic},
abstract = {Greenhouses have been used to increase agricultural production. With the development of technology, they can now be automated. Many studies have been done on the automatic control of their microclimate, from intelligent control systems to Computational Fluid Dynamics (CFD) analyses, with the main purpose of optimal control of the microclimate and at the same time saving energy. This research concerns the process of modeling, design, and simulation of an automatic control system in greenhouses. More specifically, a virtual greenhouse (digital twin) is designed, and in it, the natural phenomena that take place in a real greenhouse are simulated. The program used for the simulations is Ansys FLUENT, suitable for CFD analyses. A branch of artificial intelligence, fuzzy logic, which is a method of replicating human thinking was utilized. To find the optimal control system, four fuzzy controllers were tested, and the optimal control system that the simulations indicated was implemented on an Arduino board using the LabVIEW program. The control was done at the temperature inside the greenhouse, with real weather data from a real greenhouse.}
}
@article{ZILCHAMANO2025100478,
title = {Contrasting Individual-Specific Resilience and Compensation Personalization Frameworks: The Case of Rumination},
journal = {Biological Psychiatry Global Open Science},
volume = {5},
number = {3},
pages = {100478},
year = {2025},
issn = {2667-1743},
doi = {https://doi.org/10.1016/j.bpsgos.2025.100478},
url = {https://www.sciencedirect.com/science/article/pii/S2667174325000321},
author = {Sigal Zilcha-Mano},
keywords = {Capitalization, Compensation, Complementing, Mechanism of change, Personalized treatment, Resilience, Rumination},
abstract = {Background
Rumination has been identified as a potential mechanism of therapeutic change, particularly in directive and focused psychotherapies for depression. Previous research has predominantly focused on either trait-like individual differences or state-like changes in rumination without integrating these aspects. In the current study, we propose a computational approach to investigating whether rumination serves as a compensatory or a resilience mechanism by integrating trait-like and state-like effects.
Methods
Rumination and depressive symptoms were assessed (in N = 100) pretreatment and repeatedly throughout treatment. Mixed-level models were used to examine whether pretreatment trait-like rumination interacted with a time-variant variable of in-treatment state-like changes in rumination to predict subsequent changes in treatment outcomes. These models were used to determine whether individuals with higher or lower pretreatment trait-like levels of rumination benefited more from state-like reductions in rumination, thus contrasting the compensatory and resilience theoretical frameworks.
Results
As hypothesized, the findings supported the compensatory framework; individuals with higher pretreatment trait-like levels of rumination benefited most from greater state-like reductions in rumination during treatment, as evidenced by greater subsequent symptom reduction (p = .04).
Conclusions
The findings refine our understanding of rumination as an individual-specific mechanism of therapeutic change, dependent on an individual’s trait-like levels of rumination. The proposed computational approach enabled an empirical comparison of the 2 main theoretical frameworks of treatment personalization, compensatory and resilience, offering new insights into mechanisms that drive therapeutic change. Future studies could leverage the paradigm proposed here to examine for which patients and in what contexts mechanisms of change function as compensatory versus resilience mechanisms.}
}
@incollection{MAHER2025205,
title = {Reactive transport as a scientific framework},
editor = {Ariel Anbar and Dominique Weis},
booktitle = {Treatise on Geochemistry (Third edition)},
publisher = {Elsevier},
edition = {Third edition},
address = {Oxford},
pages = {205-254},
year = {2025},
isbn = {978-0-323-99763-8},
doi = {https://doi.org/10.1016/B978-0-323-99762-1.00071-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323997621000711},
author = {K. Maher and Z. Perzan},
keywords = {Reactive transport, Advective transport, Advective velocity, Dispersion and diffusion, Hydrodynamic dispersion, Geochemical systems, Mineral dissolution and precipitation, Microbial reaction modeling, Sensitivity analysis, Uncertainty quantification},
abstract = {Reactive transport is a framework that integrates across disciplines and scales, and leverages cutting-edge computational techniques to advance a nuanced understanding of Earth's complex systems. As a way of thinking, it connects science, engineering, and natural systems, and unifies across experiment, field and modeling studies. This chapter links core reactive transport concepts to their mathematical constructs embodied in reactive transport models. Approaches for scaling, such as dimensionless numbers, enable translation from conceptual to numerical models. The increasing complexity of numerical models also requires both targeted measurements and tools for evaluating and learning from multifaceted numerical models, emphasizing the importance of implementing reactive transport frameworks early in the design of any scientific study.}
}
@article{INGRAO2018556,
title = {How can life cycle thinking support sustainability of buildings? Investigating life cycle assessment applications for energy efficiency and environmental performance},
journal = {Journal of Cleaner Production},
volume = {201},
pages = {556-569},
year = {2018},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.08.080},
url = {https://www.sciencedirect.com/science/article/pii/S0959652618324144},
author = {Carlo Ingrao and Antonio Messineo and Riccardo Beltramo and Tan Yigitcanlar and Giuseppe Ioppolo},
keywords = {Built environment, Buildings, Energy efficiency, Environmental sustainability, Life cycle assessment, Sustainable urban development},
abstract = {In the context of built environment, buildings are amongst the principal generators of environmental externalities. Life Cycle Assessment (LCAs) of energy efficiency and environmental performance of buildings are deemed critical to address sustainable development issues. This paper aims to investigate LCA as a tool to support the design of buildings with two objectives in mind. Firstly, it determines the role of LCA in the evaluation of energy efficiency and environmental performance of buildings. Secondly, it elaborates LCA of these constructions through the lens of international standards. The methodological approach of the study leads to development of a whole building life cycle formula that sums up the contributions from a set of LCAs. By doing so, the paper highlights the necessity of LCA applications in buildings, and the need for minimisation of resource and energy consumption, and environmental impact. The study helps in better understanding the way LCA supports the search for and identification of innovation pathways in buildings. This paper contributes to the efforts in providing theoretical expansions in LCA of buildings and stimulates the creation of technical standards for the residential building construction sector.}
}
@article{RAJPUT2023100147,
title = {Computational nanoscience and technology},
journal = {OpenNano},
volume = {12},
pages = {100147},
year = {2023},
issn = {2352-9520},
doi = {https://doi.org/10.1016/j.onano.2023.100147},
url = {https://www.sciencedirect.com/science/article/pii/S2352952023000269},
author = {Amarjitsing Rajput and Ganesh Shevalkar and Krutika Pardeshi and Prashant Pingale},
keywords = {Nanomaterials, Computational models, Mathematical models, Molecular dynamics, Drug development},
abstract = {Nanoscience and nanotechnology are the most widely utilized field of science in human healthcare, tissue engineering, food and agriculture. It has several advantages, such as superior surface area and nano-sized molecular structure. Nanomaterial properties like elasticity, mechanical characteristics like hardness, tensile strength, and magnetic and optical properties. It has capability to store high energy, which makes them applicable in the healthcare system. “Executable biology” is applied to the computational model of physiological processes. These models have the advantage of computer science and simulation of pharmacokinetic study. Because of their high potential and computational power, they are widely accepted in pharmaceutical research. US-FDA has tested and utilized computational models in manufacturing various pharmaceutical equipment's that also can be used in drug discovery and manufacturing. These models can create exact validated in vitro and in vivo pharmacological systems, which helps to obtain faster, accurate and more pertinent human data. These models suffer from simplicity, versatility and lack of cumulative research. Multiscale simulations, like the ones based on coarse-graining, are important areas for future research. More significantly, a collaboration between the pharmaceutical industry and computational scientists involved in this field could assist in work in areas wherein molecular dynamic simulations can influence substantially. In this review, different drug target identification models via chemo genomic methods are explained, and the advantages of computational modeling over mathematical model is studied. It also focuses on a wide range of simulation techniques, biomedical applications and challenges of computational modelling. Finally, it gives a brief account of compounds studied using computational modeling and its future perspectives.}
}
@article{BOURGEADE2023105390,
title = {New PWM inverter control based on optimal pulse pattern computation without phases symmetry constraints},
journal = {Control Engineering Practice},
volume = {132},
pages = {105390},
year = {2023},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2022.105390},
url = {https://www.sciencedirect.com/science/article/pii/S0967066122002210},
author = {Adrien Bourgeade and Malek Ghanes and Barbot Jean-Pierre and Bouarfa Abdelkader and Fadel Maurice and Boisliveau Robert},
keywords = {Power electronics, Simulation and Experimental Model Validation, Optimization, Pulse Width Modulation, Optimized pulse patterns, Phase symmetry relaxation},
abstract = {The control of inverters has degrees of freedom that open the way to improve the output harmonic spectrum. Numerous works dealing with this objective have been proposed in the literature, particularly within the definition of switching angles. Among them, the well-known PWM techniques such as Quarter Wave Symmetry (QWS), Half Wave Symmetry (HWS), and Full Wave Symmetry (FWS) are based on Optimal Pulse Patterns (OPP) computation using symmetries angles constraints. In this paper to improve the harmonic quality, the symmetry angles constraints are not considered leading to a new OPP method: Phases Symmetry Relaxation (PSR). To highlight the interest in the proposed PSR method, an evaluation in terms of Weighted Total Harmonic Distortion (WTHD) is performed. Simulation and experimental tests are conducted in comparison with the well known FWS, highlighting the interest in the proposed PSR strategy.}
}
@article{MANISCALCO2005305,
title = {The Cradle of Thought: Exploring the Origins of Thinking.},
journal = {Journal of the American Academy of Child & Adolescent Psychiatry},
volume = {44},
number = {3},
pages = {305},
year = {2005},
issn = {0890-8567},
doi = {https://doi.org/10.1097/00004583-200503000-00019},
url = {https://www.sciencedirect.com/science/article/pii/S0890856709614805},
author = {Joshua Maniscalco}
}
@article{NEDYALKOVA20249,
title = {Progress and future of the computational design of antimicrobial peptides (AMPs): bio-inspired functional molecules},
journal = {Digital Discovery},
volume = {3},
number = {1},
pages = {9-22},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00186e},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000317},
author = {Miroslava Nedyalkova and Andrew S. Paluch and Diana Potes Vecini and Marco Lattuada},
abstract = {The effectiveness of antibiotics is greatly enhanced by their ability to target invasive organisms involved in the ancient evolutionary battle between hosts and pathogens. Conventional antibiotics no longer offer adequate protection due to the evolution of strategies to evade them. As a result, efforts are needed to design novel replacement antibiotics, making them unique from most other forms of drug development. As drug discovery costs have steadily increased along with the need for novel antibiotics, the interest in antimicrobial peptides (AMPs) as alternative antimicrobial treatments has grown in recent years. As a complement to experimental high-throughput screening, computational methods have become essential in hit and lead discovery in pharmaceutical research. It may be possible to access unexplored chemical space with customized virtual compound libraries. It has been questioned whether screening billions of molecules virtually with the risk of false positives is practical despite their unlimited potential size. In terms of finding novel chemical compounds capable of solving many global problems, machine learning, deep learning, and generative models hold significant promise. It is anticipated that the current challenges and limitations about the applicability of the stated approaches will be overcome in the coming years. However, plenty of advances are still required to achieve their full potential. In this perspective, we review the previous and ongoing work based on the latest scientific breakthroughs and technologies that could offer new opportunities and alternative strategies for developing novel AMPs.}
}
@article{ZHANG2022111493,
title = {mechanoChemML: A software library for machine learning in computational materials physics},
journal = {Computational Materials Science},
volume = {211},
pages = {111493},
year = {2022},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2022.111493},
url = {https://www.sciencedirect.com/science/article/pii/S0927025622002531},
author = {X. Zhang and G.H. Teichert and Z. Wang and M. Duschenes and S. Srivastava and E. Livingston and J. Holber and M. Faghih Shojaei and A. Sundararajan and K. Garikipati},
keywords = {Machine learning software library, Machine learning workflows, Computational materials physics, Partial differential equation solvers, Scientific software},
abstract = {We present mechanoChemML, a machine learning software library for computational materials physics. mechanoChemML is designed to function as an interface between platforms that are widely used for machine learning on one hand, and others for solution of partial differential equations-based models of physics. Of special interest here, and the focus of mechanoChemML, are applications to computational materials physics. These typically feature the coupled solution of material transport, reaction, phase transformation, mechanics, heat transport and electrochemistry. Central to the organization of mechanoChemML are machine learning workflows that arise in the context of data-driven computational materials physics. The mechanoChemML code structure is described, the machine learning workflows are laid out and their application to the solution of several problems in materials physics is outlined.}
}
@article{YOSHIDA2023102799,
title = {Computational role of sleep in memory reorganization},
journal = {Current Opinion in Neurobiology},
volume = {83},
pages = {102799},
year = {2023},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2023.102799},
url = {https://www.sciencedirect.com/science/article/pii/S0959438823001241},
author = {Kensuke Yoshida and Taro Toyoizumi},
abstract = {Sleep is considered to play an essential role in memory reorganization. Despite its importance, classical theoretical models did not focus on some sleep characteristics. Here, we review recent theoretical approaches investigating their roles in learning and discuss the possibility that non-rapid eye movement (NREM) sleep selectively consolidates memory, and rapid eye movement (REM) sleep reorganizes the representations of memories. We first review the possibility that slow waves during NREM sleep contribute to memory selection by using sequential firing patterns and the existence of up and down states. Second, we discuss the role of dreaming during REM sleep in developing neuronal representations. We finally discuss how to develop these points further, emphasizing the connections to experimental neuroscience and machine learning.}
}
@article{MANNILA2023100132,
title = {Student and teacher co-agency when combining CT with arts and design in a cross-curricular project},
journal = {Computers and Education Open},
volume = {4},
pages = {100132},
year = {2023},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2023.100132},
url = {https://www.sciencedirect.com/science/article/pii/S2666557323000101},
author = {Linda Mannila and Teemu Leinonen and Merja Bauters and Marjaana Veermans},
keywords = {K-12 education, Computational thinking, Cross-curricular projects, Arts and design},
abstract = {The technological development has raised awareness for the importance of digital competence and computational thinking (CT) to understand the digital world and has resulted in revised curricula in many countries. In Finland, a new curriculum for grades 1–9 came into force in 2016 introducing digital competence (including programming) to be integrated in other subjects. Most teachers lack prior experience in programming and there is a need for suitable instructional models. This article presents a cross-curricular teaching sequence and the results from a case study conducted in four Finnish schools. Students in grades 4–6 collaboratively worked on a project combining arts, design and CT with other subjects. The results show that students demonstrated several CT abilities while working on their projects, in particular creativity, tinkering and debugging. The findings also indicate that teachers and students learned together (co-agency) and suggest that models like the teaching sequence can help and encourage teachers to integrate programming and CT in a cross-curricular manner. Still, the teachers’ knowledge, ambition level and understanding of the task at hand, as well as the organizational support appear to play a notable role when planning and carrying out projects of this kind. While CT is commonly seen as developed through programming, the teaching sequence seems to have fostered CT abilities through the project as a whole, with programming playing the role of a tool or a glue depending on the time available, and the students’ skill and ambition level.}
}
@article{BONANNI202525,
title = {Simplifying the calculation of residual properties using numerical methods},
journal = {Education for Chemical Engineers},
volume = {50},
pages = {25-31},
year = {2025},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000253},
author = {Sebastián Bonanni and Tomás Melloni and J. Pablo Tomba},
keywords = {, , , },
abstract = {The calculation of thermodynamic properties using Residual properties (Rp) is a key element in Chemical Engineering curricula. Traditionally, the derivation of Rp involves solving analytical expressions through partial differentiation and integration of generalized thermodynamics equations combined with specific equations of state (EoS). This method is mathematically demanding, increasing cognitive load and often limiting classroom discussions to simpler EoS for which analytical solutions are readily available in textbooks. To enhance student engagement and reduce the time spent on complex derivations, we propose a simplified approach that numerically evaluates Rp using standard software tools. This approach not only minimizes the mathematical effort, allowing students to focus on thermodynamic concepts, but also extends the applicability to more complex EoS that are not covered in textbooks. By significantly reducing the instructional time required for Rp calculations, this method fosters critical thinking, promotes autonomy, and can be applied to other fundamental thermodynamics topics that traditionally rely on analytical expressions, such as multicomponent solution models.}
}
@article{KOPPL2008837,
title = {Thinking impossible things: A review essay},
journal = {Journal of Economic Behavior & Organization},
volume = {66},
number = {3},
pages = {837-847},
year = {2008},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2007.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167268107000340},
author = {Roger Koppl}
}
@article{SHOVLIN20253,
title = {When “loss-of-function” means proteostasis burden: Thinking again about coding DNA variants},
journal = {The American Journal of Human Genetics},
volume = {112},
number = {1},
pages = {3-10},
year = {2025},
issn = {0002-9297},
doi = {https://doi.org/10.1016/j.ajhg.2024.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002929724004440},
author = {Claire L. Shovlin and Micheala A. Aldred},
abstract = {Each human genome has approximately 5 million DNA variants. Even for complete loss-of-function variants causing inherited, monogenic diseases, current understanding based on gene-specific molecular function does not adequately predict variability observed between people with identical mutations or fluctuating disease trajectories. We present a parallel paradigm for loss-of-function variants based on broader consequences to the cell when aberrant polypeptide chains of amino acids are translated from mutant RNA to generate mutated proteins. Missense variants that modify primary amino acid sequence, and nonsense/frameshift variants that generate premature termination codons (PTCs), are placed in context alongside emergent themes of chaperone binding, protein quality control capacity, and cellular adaptation to stress. Relatively stable proteostasis burdens are contrasted with rapid changes after induction of gene expression, or stress responses that suppress nonsense mediated decay (NMD) leading to higher PTC transcript levels where mutant proteins can augment cellular stress. For known disease-causal mutations, an adjunctive variant categorization system enhances clinical predictive power and precision therapeutic opportunities. Additionally, with typically more than 100 nonsense and frameshift variants, and ∼10,000 missense variants per human DNA, the paradigm focuses attention on all protein-coding DNA variants, and their potential contributions to multimorbid states beyond classically designated inherited diseases. Experimental testing in clinically relevant systems is encouraged to augment current atlases of protein expression at single-cell resolution, and high-throughput experimental data and deep-learning models that predict which amino acid substitutions generate enhanced degradative burdens. Incorporating additional dimensions such as pan-proteome competition for chaperones, and age-related loss of proteostasis capacity, should further accelerate health impacts.}
}
@article{AYDOGAN2018100,
title = {The effect of oxytocin on group formation and strategic thinking in men},
journal = {Hormones and Behavior},
volume = {100},
pages = {100-106},
year = {2018},
issn = {0018-506X},
doi = {https://doi.org/10.1016/j.yhbeh.2018.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0018506X17302908},
author = {Gökhan Aydogan and Andrea Jobst and Fabian Loy and Sandra Dehning and Peter Zill and Norbert Müller and Martin Kocher},
abstract = {Decision-making in groups is a remarkable and decisive element of human societies. Humans are able to organize themselves in groups, engage in collaborative decision-making processes and arrive at a binding agreement, even in the absence of unanimous consent. However, the transfer of decision-making autonomy requires a willingness to deliberately expose oneself to the decisions of others. A lack of trust in the abilities of others or of the underlying decision-making process, i.e. public trust, can lead to a breakdown of organizations in political or economic domains. Recent studies indicate that the biological basis of trust on an individual level is related to Oxytocin, an endogenous neuropeptide and hormone, which is also associated with pro-social behavior and positive conflict resolution. However, little is known about the effects of Oxytocin on the inclination of individuals to form or join groups and to deliberately engage in collaborative decision-making processes. Here, we show that intranasal administration of Oxytocin (n = 60) compared to placebo (n = 60) in males causes an adverse effect on the choice for forming groups in the presence of a competitive environment. In particular, Oxytocin negatively affects the willingness to work collaboratively in a p-Beauty contest game, whereas the effect is most pronounced for participants with relatively high strategic sophistication. Since our data provide initial evidence that Oxytocin has a positive effect on strategic thinking and performance in the p-Beauty contest game, we argue that the adverse effect on group formation might be rooted in an enhanced strategic sophistication of participants treated with Oxytocin.}
}
@incollection{ESTES2011249,
title = {Chapter eight - Thematic Thinking: The Apprehension and Consequences of Thematic Relations},
editor = {Brian H. Ross},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {54},
pages = {249-294},
year = {2011},
booktitle = {Advances in Research and Theory},
issn = {0079-7421},
doi = {https://doi.org/10.1016/B978-0-12-385527-5.00008-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123855275000085},
author = {Zachary Estes and Sabrina Golonka and Lara L. Jones},
keywords = {Categorization, Language, Similarity, Taxonomic relations, Thematic integration, Thematic relations},
abstract = {A thematic relation is a temporal, spatial, causal, or functional relation between things that perform complementary roles in the same scenario or event. For example, cows and milk are related by a production theme, and sails and anchors are related via a boating theme. Thematic relations are distinct from mere associations, scripts, and ad hoc categories. They also contrast and complement taxonomic (categorical) relations such as “fruits” and “furniture.” Thematic relations and taxonomic relations arise from distinct processes, as evidenced by numerous neuropsychological and behavioral dissociations. Thematic relations may be apprehended uncontrollably and rapidly according to how frequently and recently they have been encountered. They exert profound effects on many core cognitive processes, including similarity, categorization, memory, language, inference, and analogy, and they exhibit robust processing differences across individuals and cultures. In sum, without such thematic thinking, models of cognition will remain categorically limited.}
}
@article{NYBLOM201430,
title = {Making plans or “just thinking about the trip”? Understanding people’s travel planning in practice},
journal = {Journal of Transport Geography},
volume = {35},
pages = {30-39},
year = {2014},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2014.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0966692314000040},
author = {Åsa Nyblom},
keywords = {Travel planning, Travel information, Sustainable social practices, Practice theory},
abstract = {ICT solutions have been proposed as a means for changing environmentally unfavourable traffic behaviour by providing better, real-time and more accessible travel information. However, prevailing models of travel choice and travel behaviour tend to overemphasise the impact and importance of information and the individualistic perspective. The issue of choice and travel planning in everyday life situations, and how information is used and acted on in these processes, was examined in a qualitative study in Stockholm, Sweden. Practice Theory was used as the theoretical framework for the study. Interviews were supplemented with an explorative diary and photo assignment to bring unreflected choices and actions of planning travel to the conscious level. The results showed that travel planning involves the immediate situation where planning and decisions are made, but also aspirations, cognitive/time/material limitations, social norms and social relations that extend widely in time and space. Definitions of travel planning and travel information based on the situated practices of planning are suggested. In the muddle of everyday life, travel planning takes place in the brief moments where circumstances at different levels – time, place, the social realm - interact and are considered or directly acted upon. In the development of new ICT-based travel information services, the role of technology in changing normal practices should be considered.}
}
@article{AWAD2022388,
title = {Computational ethics},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {5},
pages = {388-405},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322000456},
author = {Edmond Awad and Sydney Levine and Michael Anderson and Susan Leigh Anderson and Vincent Conitzer and M.J. Crockett and Jim A.C. Everett and Theodoros Evgeniou and Alison Gopnik and Julian C. Jamison and Tae Wan Kim and S. Matthew Liao and Michelle N. Meyer and John Mikhail and Kweku Opoku-Agyemang and Jana Schaich Borg and Juliana Schroeder and Walter Sinnott-Armstrong and Marija Slavkovik and Josh B. Tenenbaum},
keywords = {ethics, computation, moral psychology, AI ethics, machine ethics, moral cognition},
abstract = {Technological advances are enabling roles for machines that present novel ethical challenges. The study of 'AI ethics' has emerged to confront these challenges, and connects perspectives from philosophy, computer science, law, and economics. Less represented in these interdisciplinary efforts is the perspective of cognitive science. We propose a framework – computational ethics – that specifies how the ethical challenges of AI can be partially addressed by incorporating the study of human moral decision-making. The driver of this framework is a computational version of reflective equilibrium (RE), an approach that seeks coherence between considered judgments and governing principles. The framework has two goals: (i) to inform the engineering of ethical AI systems, and (ii) to characterize human moral judgment and decision-making in computational terms. Working jointly towards these two goals will create the opportunity to integrate diverse research questions, bring together multiple academic communities, uncover new interdisciplinary research topics, and shed light on centuries-old philosophical questions.}
}
@article{DENOBEL2024109011,
title = {Biophysics-inspired spike rate adaptation for computationally efficient phenomenological nerve modeling},
journal = {Hearing Research},
volume = {447},
pages = {109011},
year = {2024},
issn = {0378-5955},
doi = {https://doi.org/10.1016/j.heares.2024.109011},
url = {https://www.sciencedirect.com/science/article/pii/S0378595524000649},
author = {Jacob {de Nobel} and Savine S.M. Martens and Jeroen J. Briaire and Thomas H.W. Bäck and Anna V. Kononova and Johan H.M. Frijns},
keywords = {Neural model, Spike rate adaptation, Auditory nerve, Cochlear implants, Optimization, Evolutionary algorithms},
abstract = {This study introduces and evaluates the PHAST+ model, part of a computational framework designed to simulate the behavior of auditory nerve fibers in response to the electrical stimulation from a cochlear implant. PHAST+ incorporates a highly efficient method for calculating accommodation and adaptation, making it particularly suited for simulations over extended stimulus durations. The proposed method uses a leaky integrator inspired by classic biophysical nerve models. Through evaluation against single-fiber animal data, our findings demonstrate the model’s effectiveness across various stimuli, including short pulse trains with variable amplitudes and rates. Notably, the PHAST+ model performs better than its predecessor, PHAST (a phenomenological model by van Gendt et al.), particularly in simulations of prolonged neural responses. While PHAST+ is optimized primarily on spike rate decay, it shows good behavior on several other neural measures, such as vector strength and degree of adaptation. The future implications of this research are promising. PHAST+ drastically reduces the computational burden to allow the real-time simulation of neural behavior over extended periods, opening the door to future simulations of psychophysical experiments and multi-electrode stimuli for evaluating novel speech-coding strategies for cochlear implants.}
}
@article{SWANSON2005313,
title = {Techniques: Subcellular imaging technologies – microscopic visual thinking},
journal = {Current Opinion in Microbiology},
volume = {8},
number = {3},
pages = {313-315},
year = {2005},
note = {Ecology and industrial microbiology/Edited by Sergio Sánchez and Betty Olson · Techniques/Edited by Peter J Peters and Joel Swanson},
issn = {1369-5274},
doi = {https://doi.org/10.1016/j.mib.2005.04.015},
url = {https://www.sciencedirect.com/science/article/pii/S136952740500055X},
author = {Joel A Swanson and Peter J Peters}
}
@article{BANKER2022104617,
title = {Disrupted computations of social control in individuals with obsessive-compulsive and misophonia symptoms},
journal = {iScience},
volume = {25},
number = {7},
pages = {104617},
year = {2022},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2022.104617},
url = {https://www.sciencedirect.com/science/article/pii/S2589004222008896},
author = {Sarah M. Banker and Soojung Na and Jacqueline Beltrán and Harold W. Koenigsberg and Jennifer H. Foss-Feig and Xiaosi Gu and Daniela Schiller},
keywords = {Biological sciences, Neuroscience, Behavioral neuroscience, Clinical neuroscience, Sensory neuroscience},
abstract = {Summary
Misophonia is a disorder in which certain sounds produced by other people lead to intense negative reactions. It remains unknown how misophonia relates to other psychiatric conditions or impairments. To identify latent constructs underlying symptoms, we conducted a factor analysis consisting of items from questionnaires assessing symptoms of misophonia and other psychiatric conditions. One thousand forty-two participants completed the questionnaires and a social exchange task in which they either could (“controllable”) or could not (“uncontrollable”) influence future monetary offers from other people. Misophonia and obsessive-compulsive (OC) symptoms loaded onto the same factor. Compared with individuals with low Miso-OC factor scores, individuals with high scores reported higher perceived controllability of their social interactions during the uncontrollable condition and stronger aversion to social norm violations in the uncontrollable compared with the controllable condition. Together, these results suggest misophonia, and OC symptoms share a latent psychiatric dimension characterized by aberrant computations of social controllability.}
}
@article{KURTHNELSON2023454,
title = {Replay and compositional computation},
journal = {Neuron},
volume = {111},
number = {4},
pages = {454-469},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.028},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322011254},
author = {Zeb Kurth-Nelson and Timothy Behrens and Greg Wayne and Kevin Miller and Lennart Luettgau and Ray Dolan and Yunzhe Liu and Philipp Schwartenbeck},
abstract = {Summary
Replay in the brain has been viewed as rehearsal or, more recently, as sampling from a transition model. Here, we propose a new hypothesis: that replay is able to implement a form of compositional computation where entities are assembled into relationally bound structures to derive qualitatively new knowledge. This idea builds on recent advances in neuroscience, which indicate that the hippocampus flexibly binds objects to generalizable roles and that replay strings these role-bound objects into compound statements. We suggest experiments to test our hypothesis, and we end by noting the implications for AI systems which lack the human ability to radically generalize past experience to solve new problems.}
}
@article{BANK2014540,
title = {Thinking too positive? Revisiting current methods of population genetic selection inference},
journal = {Trends in Genetics},
volume = {30},
number = {12},
pages = {540-546},
year = {2014},
issn = {0168-9525},
doi = {https://doi.org/10.1016/j.tig.2014.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168952514001589},
author = {Claudia Bank and Gregory B. Ewing and Anna Ferrer-Admettla and Matthieu Foll and Jeffrey D. Jensen},
keywords = {natural selection, background selection, population genetic inference, evolution, computational biology},
abstract = {In the age of next-generation sequencing, the availability of increasing amounts and improved quality of data at decreasing cost ought to allow for a better understanding of how natural selection is shaping the genome than ever before. However, alternative forces, such as demography and background selection (BGS), obscure the footprints of positive selection that we would like to identify. In this review, we illustrate recent developments in this area, and outline a roadmap for improved selection inference. We argue (i) that the development and obligatory use of advanced simulation tools is necessary for improved identification of selected loci, (ii) that genomic information from multiple time points will enhance the power of inference, and (iii) that results from experimental evolution should be utilized to better inform population genomic studies.}
}
@article{KHALIL2022104656,
title = {A neurocomputational model of creative processes},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {137},
pages = {104656},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104656},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422001452},
author = {Radwa Khalil and Ahmed A. Moustafa},
keywords = {Divergent Thinking, Convergent Thinking, Abstraction, Improvisation, Novelty, Computational Model, Prefrontal Cortex, Hippocampus, Basal Ganglia, Cerebellum, Dopamine, Usefulness, Surprise},
abstract = {Creativity is associated with finding novel, surprising, and useful solutions. We argue that creative cognitive processes, divergent thinking, abstraction, and improvisation are constructed on different novelty-based processes. The prefrontal cortex plays a role in creative ideation by providing a control mechanism. Moreover, thinking about novel solutions activates the distant or loosely connected neurons of a semantic network that involves the hippocampus. Novelty can also be interpreted as different combinations of earlier learned processes, such as the motor sequencing mechanism of the basal ganglia. In addition, the cerebellum is responsible for the precise control of movements, which is particularly important in improvisation. Our neurocomputational perspective is based on three creative processes centered on novelty seeking, subserved by the prefrontal cortex, hippocampus, cerebellum, basal ganglia, and dopamine. The algorithmic implementation of our model would enable us to describe commonalities and differences between these creative processes based on the proposed neural circuitry. Given that most previous studies have mainly provided theoretical and conceptual models of creativity, this article presents the first brain-inspired neural network model of creative cognition.}
}
@article{CHEN2024769,
title = {The causal structure and computational value of narratives},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {8},
pages = {769-781},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000822},
author = {Janice Chen and Aaron M. Bornstein},
keywords = {narratives, causality, reasoning, value, credit assignment, plausibility},
abstract = {Many human behavioral and brain imaging studies have used narratively structured stimuli (e.g., written, audio, or audiovisual stories) to better emulate real-world experience in the laboratory. However, narratives are a special class of real-world experience, largely defined by their causal connections across time. Much contemporary neuroscience research does not consider this key property. We review behavioral and neuroscientific work that speaks to how causal structure shapes comprehension of and memory for narratives. We further draw connections between this work and reinforcement learning, highlighting how narratives help link causes to outcomes in complex environments. By incorporating the plausibility of causal connections between classes of actions and outcomes, reinforcement learning models may become more ecologically valid, while simultaneously elucidating the value of narratives.}
}
@article{BAYAGA2024100491,
title = {Enhancing M Enhancing mathematics problem-solving skills in AI-driven environment: Integrated SEM-neural network approach},
journal = {Computers in Human Behavior Reports},
volume = {16},
pages = {100491},
year = {2024},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100491},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824001246},
author = {Anass Bayaga},
keywords = {Gamification, AI, Digitisation, Education, Higher-order thinking, Game-based learning},
abstract = {This study explores the nexus of gamification, artificial intelligence (AI), and mathematics cognition. Sample size of 71 responded in an intervention using game-based learning (GBL) approach. The purpose of designing the GBL was to enhance computational thinking and mathematical skills. The research employed multigroup partial least squares structural equation modelling (MGA-PLS-SEM) and artificial neural networks (ANN) through multilayer perceptron (MLP) as data analysis technique. The findings showed significant positive influence on class engagement, attitudes toward mathematics, as well as student performance. The analysis also revealed gender-related variations, which affirmed the model's consistency across diverse groups. The study validated the hypothesis and consequently advocated for the transformative potential of gamification, in preparation of 21st-century learners for AI-driven digital landscape. The implications are to ensure the integration of gamified elements into educational strategies, benefiting educators, curriculum developers, and policymakers resonating strongly for educators, curriculum developers, and policymakers.}
}
@article{HEMMO202364,
title = {Is the mind in the brain in contemporary computational neuroscience?},
journal = {Studies in History and Philosophy of Science},
volume = {100},
pages = {64-80},
year = {2023},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2023.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0039368123000870},
author = {Meir Hemmo and Orly Shenker},
keywords = {Mind-brain identity, Indeterminacy of computation, Multiple-computations, Multiple-realization, Physicalism},
abstract = {According to contemporary computational neuroscience the mental is associated with computations implemented in the brain. We analyze in physical terms based on recent results in the foundations of statistical mechanics two well-known (independent) problems that arise for this approach: the problem of multiple-computations and the problem of multiple-realization. We show that within the computational theory of the mind the two problems are insoluble by the physics of the brain. We further show that attempts to solve the problems by the interactions of the systems implementing the computations with an environment (in or outside the brain) must introduce non-physical factors, and therefore fail on physical grounds. We also show that the problems are endemic and pertain to other forms of functional theories of the mind, most notably, causal functionalism. Finally, we propose a physicalist reductive identity theory, which is a generalization of statistical mechanics for all the special sciences, and show that only a theory of this kind can provide physical solutions to the above two problems in computational neuroscience. We conclude that functionalism in the theory of mind must be replaced with a reductive identity theory. This result has far-reaching implications with respect to the research programs in brain science.}
}
@article{CSERNOCH2025100676,
title = {Lean digital education to resolve the paradox of the illusion of digital prosperity},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {2},
pages = {100676},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100676},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25000265},
author = {Mária Csernoch},
keywords = {Push and pull production system, Lean education, TPS, Low- and high-mathability problem-solving, Digital prosperity, Waste},
abstract = {Digital education, including digitally supported education, is loaded with biases. Most participants are blinded by the abundance of digital devices and misled by the hardware and software providers who try to convince and force education systems to keep track of untraceable developments. However, recent studies have revealed that the productivity of the participants and the sustainability of their digital artifacts generate a huge but silent waste, both in terms of human and machine resources. This contradiction generates a paradox in which the illusion of digital prosperity does not allow us to clearly see the ineffectiveness of digital processes and artifacts and the losses piling up. Our research revealed that the methodology of Lean Thinking allows us to find the root causes of the problems and the revolutionary changes which must be applied to eliminate the waste generated by the participants in the digital era. It was also found that the adaptation of the lean philosophy, proven effective in production, services, and administration, can be a solution in resolving the paradox of digital education, which leads us to Lean Digital Education (LDE). Within this framework – instead of the widely accepted tool-centered ideas – we offer a human-centered, long-term thinking philosophy focusing on respect for participants, on their development, tasks, and problems, while at the same time eliminating and reducing waste. The present paper details the strength of this innovative approach which is based on (1) a solid theoretical background (2) a reliable measuring system for calculating the waste of digital activities and artifacts, (3) approaches proven to be effective and efficient in end-user data management, and (4) examples of the learning-teaching materials which support the philosophy adapted.}
}
@article{AGBOOLA2025100283,
title = {Computational analysis of Curcuma longa L compounds: Unraveling molecular interactions and drug-like properties for novel therapeutic applications},
journal = {Next Research},
volume = {2},
number = {2},
pages = {100283},
year = {2025},
issn = {3050-4759},
doi = {https://doi.org/10.1016/j.nexres.2025.100283},
url = {https://www.sciencedirect.com/science/article/pii/S305047592500154X},
author = {Oluwaseun E. Agboola and Samuel S. Agboola and Abimbola E. Fadugba and Adekunle T. Adegbuyi and Othuke B. Odeghe},
keywords = { L, Drug discovery, Computational methods, Structure-activity relationships},
abstract = {Cyclooxygenase-2 (COX-2) overexpression is implicated in inflammation and various pathological conditions. Although synthetic COX-2 inhibitors demonstrate therapeutic efficacy, their adverse effects necessitate alternative treatment approaches. Curcuma longa L., traditionally known for its anti-inflammatory properties, presents promising therapeutic potential, yet the molecular mechanisms of its active compounds remain incompletely characterized. This study aimed to elucidate the binding mechanisms, molecular interactions, and drug-like properties of Curcuma longa L. compounds against human COX-2 and compare their efficacy with that of the standard drug rofecoxib. We employed molecular docking using AutoDock Vina, assessed drug-likeness using Lipinski's Rule analysis, and conducted a comprehensive pharmacokinetic property evaluation. Isorhamnetin exhibited superior binding affinity (-9.8 kcal/mol), surpassing rofecoxib (-7.5 kcal/mol) by 30.7%. It formed crucial hydrogen bonds with Thr192, Val349, and Ser530 and hydrophobic interactions with Leu352 and Val523. Dihydrocostunolide (-9.2 kcal/mol) and beta-Vatirenene (-8.8 kcal/mol) exhibited predominantly hydrophobic interactions with Phe518 and Ala527. We discovered an inverse relationship between Lipinski's Rule compliance and binding strength, with rule violations showing enhanced affinities (single: -8.19 kcal/mol; double: -10.4 kcal/mol). Molecular size was negatively correlated with binding affinity (r = -0.66). Notably, 40.3 % of the compounds outperformed rofecoxib. Our findings identified promising natural COX-2 inhibitors of Curcuma longa L., with isorhamnetin showing particular potential through its unique interaction profile. This study challenges traditional drug design paradigms, suggesting that controlled deviation from drug-likeness rules may benefit COX-2 inhibitor development. These results provide a foundation for developing natural anti-inflammatory agents with potentially improved safety profiles.}
}
@article{HALES2023105083,
title = {Computational approaches to modeling gambling behaviour: Opportunities for understanding disordered gambling},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {147},
pages = {105083},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105083},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423000520},
author = {C.A. Hales and L. Clark and C.A. Winstanley},
keywords = {Gambling disorder, Reinforcement learning, Drift diffusion modeling, Bayesian, Computational psychiatry},
abstract = {Computational modeling has become an important tool in neuroscience and psychiatry research to provide insight into the cognitive processes underlying normal and pathological behavior. There are two modeling frameworks, reinforcement learning (RL) and drift diffusion modeling (DDM), that are well-developed in cognitive science, and have begun to be applied to Gambling Disorder. RL models focus on explaining how an agent uses reward to learn about the environment and make decisions based on outcomes. The DDM is a binary choice framework that breaks down decision making into psychologically meaningful components based on choice reaction time analyses. Both approaches have begun to yield insight into aspects of cognition that are important for, but not unique to, gambling, and thus relevant to the development of Gambling Disorder. However, these approaches also oversimplify or neglect various aspects of decision making seen in real-world gambling behavior. Gambling Disorder presents an opportunity for ‘bespoke’ modeling approaches to consider these neglected components. In this review, we discuss studies that have used RL and DDM frameworks to investigate some of the key cognitive components in gambling and Gambling Disorder. We also include an overview of Bayesian models, a methodology that could be useful for more tailored modeling approaches. We highlight areas in which computational modeling could enable progression in the investigation of the cognitive mechanisms relevant to gambling.}
}
@article{BHATT2005424,
title = {Self-referential thinking and equilibrium as states of mind in games: fMRI evidence},
journal = {Games and Economic Behavior},
volume = {52},
number = {2},
pages = {424-459},
year = {2005},
note = {Special Issue on Neuroeconomics},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2005.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0899825605000308},
author = {Meghana Bhatt and Colin F. Camerer},
abstract = {Sixteen subjects' brain activity were scanned using fMRI as they made choices, expressed beliefs, and expressed iterated 2nd-order beliefs (what they think others believe they will do) in eight games. Cingulate cortex and prefrontal areas (active in “theory of mind” and social reasoning) are differentially activated in making choices versus expressing beliefs. Forming self-referential 2nd-order beliefs about what others think you will do seems to be a mixture of processes used to make choices and form beliefs. In equilibrium, there is little difference in neural activity across choice and belief tasks; there is a purely neural definition of equilibrium as a “state of mind.” “Strategic IQ,” actual earnings from choices and accurate beliefs, is negatively correlated with activity in the insula, suggesting poor strategic thinkers are too self-focused, and is positively correlated with ventral striatal activity (suggesting that high IQ subjects are spending more mental energy predicting rewards).}
}
@incollection{FISH2024303,
title = {2.10 - Predictive Multiscale Paradigm for Computational Design Certification},
editor = {Vadim Silberschmidt},
booktitle = {Comprehensive Mechanics of Materials (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {303-351},
year = {2024},
isbn = {978-0-323-90647-0},
doi = {https://doi.org/10.1016/B978-0-323-90646-3.00052-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323906463000526},
author = {Jacob Fish and Karel Matouš and Roger Ghanem and WaiChing Sun},
keywords = {Artificial Intelligence, Certification, Data creation, Design, Icme, Industry 4.0, Machine learning, Manufacturing, Multiscale, Statistical framework, Validation, Verification},
abstract = {The book chapter offers a detailed exploration of the significant influence that a predictive multiscale paradigm has on computational design certification, particularly in the realms of Industry 4.0 and the Industrial Internet of Things (IIoT). It surveys the latest advancements in multiscale methodologies, data creation, and statistical framework for multiscale certification, underscoring the pivotal role of artificial intelligence within this paradigm. The narrative underscores how this predictive multiscale approach propels the creation of novel product designs and eco-friendly manufacturing practices, crucial for meeting the emerging demands of engineering and materials science.Throughout, the book chapter underscores the significance of Integrated Computational Materials Engineering (ICME), which melds computational science, applied mathematics, and statistics into a coherent framework for certifying products. This strategy is paramount for overcoming the intricate challenges associated with the properties of materials at multiple scales, system efficacy, and the mechanisms of failure across various scales and scenarios.In essence, the book chapter envisions a future where the convergence of science, technology, and innovation propels the fields of manufacturing and design forward through the use of comprehensive computational tools, and cutting-edge manufacturing technologies. This fusion is projected to usher in a new epoch of innovation and operational efficiency in the development of products.}
}
@article{KORUKONDA2003240,
title = {Taking stock of Turing test: a review, analysis, and appraisal of issues surrounding thinking machines},
journal = {International Journal of Human-Computer Studies},
volume = {58},
number = {2},
pages = {240-257},
year = {2003},
issn = {1071-5819},
doi = {https://doi.org/10.1016/S1071-5819(02)00139-8},
url = {https://www.sciencedirect.com/science/article/pii/S1071581902001398},
author = {Appa Rao Korukonda},
keywords = {Turing test, artificial intelligence},
abstract = {The Turing test (TT) has provided the inspiration for the inception and rapid development of artificial intelligence (AI) as a discipline. Additionally, it provided a platform for what might be termed a spirited, enduring, and enlightening—albeit occasionally frustrating—rounds of debate on a broad range of questions. Turing, who proved to be much ahead of his time in more ways than one, predicted that it would be possible to develop machines capable of passing the TT in about 50 years time, that is just about now. Perhaps, Turing overestimated the rate of progress of technology, or of transformation of deeply entrenched paradigms of thought; but whatever the reason, his prediction about the feasibility of “thinking machines” is yet to come true in an engineering or in a symbolic-semantic sense. This paper presents a set of reflections on this and other predictions made by Turing and relates them to what has actually transpired in the 50 years since his original paper was published. Contributions of TT to the field of AI are assessed and directions for the future are presented.}
}
@article{FITRIANTO2016249,
title = {Modeling Asia's Child Mortality Rate: A Thinking of Human Development in Asia},
journal = {Procedia Economics and Finance},
volume = {35},
pages = {249-255},
year = {2016},
note = {7th International Economics & Business Management Conference (IEBMC 2015)},
issn = {2212-5671},
doi = {https://doi.org/10.1016/S2212-5671(16)00031-9},
url = {https://www.sciencedirect.com/science/article/pii/S2212567116000319},
author = {Anwar Fitrianto and Imam Hanafi and Tan Li Chui},
keywords = {Regression, Mortality rate, Backward elimination, Asia, Variable selection},
abstract = {Multiple linear regression model was employed to model child under age of five mortality rate and related factors in Asia of year 2010. Data analysis was carried out to find factors which influence the child mortality in Asia. Correlation analysis was done to check on the relationship among all the variables, as well as to identify the problem of multicollinearity in the data. Having fitted multiple linear regression, it was found that mortality rate of children under age of five in Asia countries are significantly influenced by percentage of case detection for all forms of tuberculosis, number of reported deaths on measles, number of population using an improved drinking water source, and number of birth trauma reported. Among those variable, it was identified that number of population using an improved drinking water source is the most important factor.}
}
@article{SCARR201755,
title = {Examining the temporo-mandibular joint from a biotensegrity perspective: A change in thinking},
journal = {Journal of Applied Biomedicine},
volume = {15},
number = {1},
pages = {55-62},
year = {2017},
issn = {1214-021X},
doi = {https://doi.org/10.1016/j.jab.2016.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1214021X15300545},
author = {Graham Scarr and Helen Harrison},
keywords = {Biomechanics, Biotensegrity, Four-bar mechanism, Joint loading, Kinematic chain, Orthodontic, Temporomandibular, Tensegrity},
abstract = {The temporo-mandibular joint is a characteristic feature of mammalian development, and essential to mastication and speech, yet it causes more problems than any other joint in the body and remains the least understood. While it is generally accepted that the normal joint is loaded under compression, the problems and controversies surrounding this view remain unresolved and the disparity in opinion over its treatment continues. Although difficulties in the acquisition of reliable information have undoubtedly contributed to this situation, it is now considered that deficits in neural control and shortcomings in the underlying biomechanical theory and analysis have also played a part, and that a re-assessment from a different perspective could resolve these. Biotensegrity considers the TMJ from this position, where the mandible is suspended within a tensioned network that extends over a much wider anatomical field than is generally recognized and significant motion control is contained within the structure itself. It is an evolutionary-conserved arrangement that enables the system to rapidly respond to changing functional demands and provides a more complete model of joint physiology that can be used to guide further research.}
}
@incollection{SAHIN202431,
title = {Chapter Two - Computational psychiatry and AI - High hopes: heralded heights or hollow hype?},
editor = {Marcello Ienca and Georg Starke},
series = {Developments in Neuroethics and Bioethics},
publisher = {Academic Press},
volume = {7},
pages = {31-47},
year = {2024},
booktitle = {Brains and Machines: Towards a Unified Ethics of AI and Neuroscience},
issn = {2589-2959},
doi = {https://doi.org/10.1016/bs.dnb.2024.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S2589295924000183},
author = {Derya Şahin},
keywords = {computational psychiatry, epistemology, reductionism, psychiatry ethics, medical ethics, AI ethics in health, fairness, bias, explainability},
abstract = {Computational psychiatry is a multidisciplinary field that utilizes mathematical, statistical, and computational methods to better understand mental disorders. The integration of AI in computational psychiatry has opened new possibilities for creating more precise and nuanced models of psychiatric disorders, simultaneously raising important ethical concerns related to privacy, data security, transparency, bias, alignment, and limits of computational psychiatry. This chapter provides an overview of the ethical considerations and challenges of computational psychiatry and the use of AI, specifically related to nosology, reductionism, and data constraints specific to psychiatry. Finally, it questions the epistemological limits of computational psychiatry.}
}
@article{MASEL2007216,
title = {A Bayesian model of quasi-magical thinking can explain observed cooperation in the public good game},
journal = {Journal of Economic Behavior & Organization},
volume = {64},
number = {2},
pages = {216-231},
year = {2007},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2005.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167268106000977},
author = {Joanna Masel},
keywords = {Conditional expected utility, Rationality},
abstract = {Models of learning, reciprocity and altruism cannot explain all aspects of observed contributions in the public good game. Here a new model is described in which players recognize a correlation between their own contribution and the likely contributions of other players. The correlation is calculated by treating a player's own conjectured contribution just like any other data point within a learning model. Although players recognize that this correlation is not causal, they nevertheless choose to maximize expected utility conditional on their own action rather than standard expected utility. Results from the model explain previously puzzling quantitative trends in the data.}
}
@article{LI2024,
title = {Investigating Health and Well-Being Challenges Faced by an Aging Workforce in the Construction and Nursing Industries: Computational Linguistic Analysis of Twitter Data},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/49450},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124003030},
author = {Weicong Li and Liyaning Maggie Tang and Jed Montayre and Celia B Harris and Sancia West and Mark Antoniou},
keywords = {social media, construction, nursing, aging, health and well-being, Twitter},
abstract = {Background
Construction and nursing are critical industries. Although both careers involve physically and mentally demanding work, the risks to workers during the COVID-19 pandemic are not well understood. Nurses (both younger and older) are more likely to experience the ill effects of burnout and stress than construction workers, likely due to accelerated work demands and increased pressure on nurses during the COVID-19 pandemic. In this study, we analyzed a large social media data set using advanced natural language processing techniques to explore indicators of the mental status of workers across both industries before and during the COVID-19 pandemic.
Objective
This social media analysis aims to fill a knowledge gap by comparing the tweets of younger and older construction workers and nurses to obtain insights into any potential risks to their mental health due to work health and safety issues.
Methods
We analyzed 1,505,638 tweets published on Twitter (subsequently rebranded as X) by younger and older (aged <45 vs >45 years) construction workers and nurses. The study period spanned 54 months, from January 2018 to June 2022, which equates to approximately 27 months before and 27 months after the World Health Organization declared COVID-19 a global pandemic on March 11, 2020. The tweets were analyzed using big data analytics and computational linguistic analyses.
Results
Text analyses revealed that nurses made greater use of hashtags and keywords (both monograms and bigrams) associated with burnout, health issues, and mental health compared to construction workers. The COVID-19 pandemic had a pronounced effect on nurses’ tweets, and this was especially noticeable in younger nurses. Tweets about health and well-being contained more first-person singular pronouns and affect words, and health-related tweets contained more affect words. Sentiment analyses revealed that, overall, nurses had a higher proportion of positive sentiment in their tweets than construction workers. However, this changed markedly during the COVID-19 pandemic. Since early 2020, sentiment switched, and negative sentiment dominated the tweets of nurses. No such crossover was observed in the tweets of construction workers.
Conclusions
The social media analysis revealed that younger nurses had language use patterns consistent with someone experiencing the ill effects of burnout and stress. Older construction workers had more negative sentiments than younger workers, who were more focused on communicating about social and recreational activities rather than work matters. More broadly, these findings demonstrate the utility of large data sets enabled by social media to understand the well-being of target populations, especially during times of rapid societal change.}
}
@article{TOYOTA2025109094,
title = {Cerebellum as a neural substrate for impoverishment in early psychosis},
journal = {Neuropsychologia},
volume = {210},
pages = {109094},
year = {2025},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2025.109094},
url = {https://www.sciencedirect.com/science/article/pii/S0028393225000296},
author = {Eric Toyota and Michael Mackinley and Angelica M. Silva and Yuchao Jiang and Tyler C. Dalal and Caroline Nettekoven and Lena Palaniyappan},
abstract = {Background
Formal Thought Disorder and includes both positive (i.e., disorganized speech) and negative (i.e., impoverished speech) symptoms. Emerging evidence suggests that the cerebellum plays a critical role in cognitive functions, including language processing. This study leverages Natural Language Processing to objectively measure language disturbances in patients with first-episode psychosis and investigates the relationship between these disturbances and cerebellar structure.
Methods
Fifty-four patients with schizophrenia, either drug-naïve or minimally medicated, were recruited from an early psychosis program. Impoverished thought was assessed using the Thought Language Index while lexico-semantic features (affect, cognitive, linguistic, perception, time) were identified from speech samples analyzed using the Linguistic Inquiry Word Count-22 software. Structural cerebellar analysis was completed on 7.0 Tesla MRI scans using voxel-based morphometry (VBM) to measure global and regional grey matter volume changes.
Results
Linear regression analysis revealed that reduced perceptual word usage was the strongest predictor of impoverished thinking. Correlational analysis identified reduced cerebellar volumes in patients with lower LIWC-based perception scores. VBM localized this relationship to a cluster in the right posterolateral cerebellar hemisphere, an area related to executive demand and verb generation function.
Conclusion
The cerebellum contributes to impoverished thinking in early psychosis, likely by influencing the lexical expression of perceptual experiences. This underscores the cerebellum's role in higher-order cognitive processes relevant to psychotic disorders and its potential as a therapeutic target for language and cognitive deficits in schizophrenia.}
}
@article{MELO20232833,
title = {Fostering discoveries in the era of exascale computing: How the next generation of supercomputers empowers computational and experimental biophysics alike},
journal = {Biophysical Journal},
volume = {122},
number = {14},
pages = {2833-2840},
year = {2023},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2023.01.042},
url = {https://www.sciencedirect.com/science/article/pii/S0006349523000917},
author = {Marcelo C.R. Melo and Rafael C. Bernardi},
abstract = {Over a century ago, physicists started broadly relying on theoretical models to guide new experiments. Soon thereafter, chemists began doing the same. Now, biological research enters a new era when experiment and theory walk hand in hand. Novel software and specialized hardware became essential to understand experimental data and propose new models. In fact, current petascale computing resources already allow researchers to reach unprecedented levels of simulation throughput to connect in silico and in vitro experiments. The reduction in cost and improved access allowed a large number of research groups to adopt supercomputing resources and techniques. Here, we outline how large-scale computing has evolved to expand decades-old research, spark new research efforts, and continuously connect simulation and observation. For instance, multiple publicly and privately funded groups have dedicated extensive resources to develop artificial intelligence tools for computational biophysics, from accelerating quantum chemistry calculations to proposing protein structure models. Moreover, advances in computer hardware have accelerated data processing from single-molecule experimental observations and simulations of chemical reactions occurring throughout entire cells. The combination of software and hardware has opened the way for exascale computing and the production of the first public exascale supercomputer, Frontier, inaugurated by the Oak Ridge National Laboratory in 2022. Ultimately, the popularization and development of computational techniques and the training of researchers to use them will only accelerate the diversification of tools and learning resources for future generations.}
}
@article{MIAO2024117850,
title = {Progress toward adsorption mechanism exploration method for capacitive deionization: Experimental, mathematical model, computational chemistry and machine learning},
journal = {Desalination},
volume = {586},
pages = {117850},
year = {2024},
issn = {0011-9164},
doi = {https://doi.org/10.1016/j.desal.2024.117850},
url = {https://www.sciencedirect.com/science/article/pii/S0011916424005617},
author = {Luwei Miao and Ming Gao and Weilong Xiao and Yuchen Kang and Ran Li and Hao Kong and Haiyan Mou and Wenqing Chen and Tianqi Ao},
keywords = {Capacitive deionization mechanism, Experimental, Mathematical model, Computational chemistry, Machine learning},
abstract = {Capacitive deionization (CDI) is a novel and prospective technique mainly for desalination, featuring low-cost, easy maintenance, and environmental-friendly. As CDI develops by leaps and bounds, the electrode materials, the cell architectures, and the application fields have gained a lot of progress as reported. In order to optimize electrode materials, innovate cell architectures, broaden application fields, CDI adsorption mechanism exploration, as a necessary and important approach, have aroused enormous interest by researchers. This work provides a review of the strategies for investigating CDI adsorption mechanism form four aspects: experimental, mathematical model, computational chemistry, and machine learning, accompanied by discussing the prospects of these methods. Through a fine-grained summarization of the correlative reports from initial studies to the publications of late, it is expected that the meticulous statement of the characteristics, progress, and challenges of these exploration methods in this review can provide a fundamental support to facilitate prospective development of CDI.}
}
@article{LECORCHICK2020655,
title = {Problem Solving Archetype - Computer Science},
journal = {Procedia Computer Science},
volume = {172},
pages = {655-659},
year = {2020},
note = {9th World Engineering Education Forum (WEEF 2019) Proceedings : Disruptive Engineering Education for Sustainable Development},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.05.085},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920314149},
author = {Douglas Lecorchick and Scott Nichols and Lauren Tabor},
keywords = {problem formulation, computational thinking, problem solving archetype},
abstract = {Problems that are carefully formulated lead students to develop more sufficient and realistic solutions. By front-loading the process of problem solving through problem formulation, students are able to reduce the amount of time spent on solution development, and thus increase their efficiency towards meeting their main objective. By teaching students problem formulation, especially in computer science related activities, foundational skills in computational thinking are introduced, used, and refined. Using a problem solving archetype as a means for this formulation is an effective tool for students to leverage. As computational thinking skills are honed, these concepts can translate across barriers into other content areas.}
}
@article{ROSENBLAU2023105181,
title = {A neuro-computational social learning framework to facilitate transdiagnostic classification and treatment across psychiatric disorders},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {149},
pages = {105181},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105181},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423001501},
author = {Gabriela Rosenblau and Koen Frolichs and Christoph W. Korn},
keywords = {Mental health, Transdiagnostic, Social learning, Reinforcement learning, Neuro-computational modelling, Autism spectrum disorder, Personality disorders, Major depressive disorder},
abstract = {Social deficits are among the core and most striking psychiatric symptoms, present in most psychiatric disorders. Here, we introduce a novel social learning framework, which consists of neuro-computational models that combine reinforcement learning with various types of social knowledge structures. We outline how this social learning framework can help specify and quantify social psychopathology across disorders and provide an overview of the brain regions that may be involved in this type of social learning. We highlight how this framework can specify commonalities and differences in the social psychopathology of individuals with autism spectrum disorder (ASD), personality disorders (PD), and major depressive disorder (MDD) and improve treatments on an individual basis. We conjecture that individuals with psychiatric disorders rely on rigid social knowledge representations when learning about others, albeit the nature of their rigidity and the behavioral consequences can greatly differ. While non-clinical cohorts tend to efficiently adapt social knowledge representations to relevant environmental constraints, psychiatric cohorts may rigidly stick to their preconceived notions or overly coarse knowledge representations during learning.}
}
@article{CHICK2002371,
title = {Collaborative influences on emergent statistical thinking — a case study},
journal = {The Journal of Mathematical Behavior},
volume = {21},
number = {3},
pages = {371-400},
year = {2002},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00135-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302001359},
author = {Helen L Chick and Jane M Watson},
keywords = {Emergent statistical thinking, Collaboration, Elementary students, Data handling, Cognitive change},
abstract = {The purpose of this case study is to examine how collaboration affects the emergent statistical thinking of a group of three Grade 6 boys. Results of previous studies of students in Grades 3, 6, and 9 suggested that (a) when finding and justifying associations in data sets students working in groups may produce higher level outcomes than those working individually, and (b) there are numerous factors that influence the success or otherwise of collaborative activity. The current study, based on detailed analysis of video tape and transcripts of a group working collaboratively on a data handling task, documents various factors that affect collaboration and how these contribute to the attainment of desirable cognitive outcomes in terms of the task set. These outcomes are classified by emergent statistical themes and insight is gained into how naı̈ve statistical thinking begins to develop during the collaborative process. Implications for educators and researchers are considered.}
}
@article{PERKINS2015492,
title = {Thinking too much: self-generated thought as the engine of neuroticism},
journal = {Trends in Cognitive Sciences},
volume = {19},
number = {9},
pages = {492-498},
year = {2015},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2015.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661315001540},
author = {Adam M. Perkins and Danilo Arnone and Jonathan Smallwood and Dean Mobbs},
keywords = {personality, neuroticism, creativity, self-generated thought, medial prefrontal cortex},
abstract = {Neuroticism is a dimension of personality that captures trait individual differences in the tendency to experience negative thoughts and feelings. Established theories explain neuroticism in terms of threat sensitivity, but have limited heuristic value since they cannot account for features of neuroticism that are unrelated to threat, such as creativity and negative psychological states experienced in benign, threat-free environments. We address this issue by proposing that neuroticism stems from trait individual differences in activity in brain circuits that govern the nature of self-generated thought (SGT). We argue our theory explains not only the association of neuroticism with threat sensitivity but also the prominence within the neurotic mind of representations of information that are unrelated to the way the world is right now, such as creativity and nonsituational ‘angst’.}
}
@article{DECARVALHO202196,
title = {The enactive computational basis of cognition and the explanatory cognitive basis for computing},
journal = {Cognitive Systems Research},
volume = {67},
pages = {96-103},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720301108},
author = {Leonardo Lana {de Carvalho} and João Eduardo Kogler},
keywords = {Cognitive systems, Enaction, Computing, Socio-natural practices},
abstract = {The computational theory of cognition, or computationalism, holds that cognition is a form of computation. Two issues related to this view are comprised by the goal of this paper: A) Computing systems are traditionally seen as representational systems, but functional and enactive approaches support non-representational theories; B) Recently, a sociocultural theory against computationalism was proposed with the aim of ontologically reducing computing to cognition. We defend, however, that cognition and computation are in action, thus cognition is just a form of computing and that cognition is the explanatory basis for computation. We state that: 1. Representational theories of computing recurring to intentional content run into metaphysical problems. 2. Functional non-representational theories do not incur this metaphysical problem when describing computing in terms of the abstract machine. 3. Functional theories are consistent with enactive in describing computing machines not in a strictly functional way, but especially in terms of their organization. 4. Enactive cognition is consistent with the computationalism in describing Turing machines as functionally and organizationally closed systems. 5. The cognitive explanatory basis for computing improves the computational theory of cognition. When developed in the human linguistic domain, computer science is seen as a product of human socionatural normative practices, however, cognition is just an explanatory, not ontological, basis for computing. The paper concludes by supporting that computation is in action, that cognition is just one form of computing in the world and the explanatory basis for computation.}
}
@article{YAN2024107454,
title = {A computational social science approach to understanding predictors of Chafee service receipt},
journal = {Children and Youth Services Review},
volume = {158},
pages = {107454},
year = {2024},
issn = {0190-7409},
doi = {https://doi.org/10.1016/j.childyouth.2024.107454},
url = {https://www.sciencedirect.com/science/article/pii/S0190740924000264},
author = {Jason Yan and Seventy F. Hall and Melanie Sage and Yuhao Du and Kenneth Joseph},
keywords = {Chafee services, Computational social science, Predictive modeling, National Youth in Transition Database},
abstract = {The John H. Chafee Foster Care Program for Successful Transition to Adulthood (CFCIP) allocates funding to provide services to youth who are likely to age out of foster care. These services, covering everything from mentoring to financial aid, are expected to be distributed in ways that prepare youth for life after care. One natural question to ask is, which youth receive Chafee services? The present work makes use of the National Youth in Transition Database (NYTD), a large-scale administrative dataset that tracks services allocated to youth that use CFCIP funds to answer this question. Specifically, we conduct a forensic social science analysis of the NYTD data. To do so, we first use computational methods to help us uncover the factors that best predict which youth will receive services associated with service receipt. We find that the majority of variables in the Adoption and Foster Care Analysis and Reporting System (AFCARS) and NYTD have limited or no utility in predicting Chafee service receipt, and that a subset of three variables—youth age, youth time in care, and the state in which a youth is in care—explain almost all variability in service receipt. We conclude with a discussion of the implications of these and other findings on future research on Chafee service allocation, and the utility of predictive modeling in child welfare, with a particular focus on the utility of the NYTD in this context.}
}
@incollection{DEWOSKIN2024779,
title = {Virtual models (aka: in silico or computational models)},
editor = {Philip Wexler},
booktitle = {Encyclopedia of Toxicology (Fourth Edition)},
publisher = {Academic Press},
edition = {Fourth Edition},
address = {Oxford},
pages = {779-793},
year = {2024},
isbn = {978-0-323-85434-4},
doi = {https://doi.org/10.1016/B978-0-12-824315-2.00094-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128243152000944},
author = {Robert S. DeWoskin and Thomas B. Knudsen and Imran Shah},
keywords = {Adverse outcome pathways, Computational model, Emergent properties, In silico models, Microphysiological systems (MPS), PBPK models, Physiome project, Systems biology, Virtual embryo, Virtual liver, Virtual model (vM), Virtual physiological human},
abstract = {Virtual models (vM) are mathematical representations of biological processes that are numerically solved computationally, and are used to investigate and predict system behaviors that cannot be predicted solely from studying the nature of the individual parts, or from the domain of the available data. Computational power is now available to develop advanced vMs capable of supporting predictive toxicology and drug efficacy, and of reducing the dependence on in vivo animal studies for basic research and risk assessment purposes. The ultimate goal is to simulate in vivo responses of biological organisms to environmental change, drugs, toxins, or human activities, and to predict the effects of defined perturbations on system behaviors. Examples of virtual models are presented from research in the fields of physiology, pharmacology, toxicology and risk assessment.}
}
@article{OHARA2022102540,
title = {Automated Epistemology: Bots, Computational Propaganda & Information Literacy Instruction},
journal = {The Journal of Academic Librarianship},
volume = {48},
number = {4},
pages = {102540},
year = {2022},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2022.102540},
url = {https://www.sciencedirect.com/science/article/pii/S0099133322000568},
author = {Ian O'Hara},
keywords = {Computational propaganda, Information literacy, Bots, Social media, Epistemology, Misinformation, Epistemic crisis, Algorithms, Algorithmic systems},
abstract = {Computational technologies have vastly replaced our prior modalities of information seeking. Social media platforms have become the first choice of many information seekers. Increasingly, these platforms are also becoming vehicles for coordinated, manipulative disinformation campaigns. These campaigns of computational propaganda have resulted in an information environment in which the assignment of authority and trust in information sources has become increasingly opaque. This epistemic process of information evaluation has increasingly become the purview of automated algorithmic systems that we as human beings tend to falsely implicitly trust to provide us with the most accurate information available. Propagandists have begun to exploit the algorithmic components of these systems as well as human cognitive deficits in order to manipulate public opinion, control the narrative of public discourse, and flood our information ecosystems in order to work towards the manufacture of false consensus on a wide range of political and cultural issues. This work aims to review and synthesize the literature on computational propaganda, how it manipulates our human cognitive deficits, and how information literacy can be utilized in order to correct for the resultant epistemic failure.}
}
@article{ISMAILOVA2022463,
title = {Applicative approach to construe a computational model of concepts and individuals},
journal = {Procedia Computer Science},
volume = {213},
pages = {463-470},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.092},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922017835},
author = {Larisa Ismailova and Viacheslav Wolfengagen and Sergey Kosikov},
keywords = {concept-as-a-process, application, abstraction, conceptual minimalism, computational model},
abstract = {This paper considers the application of conceptual mathematics to construct a computational model of concepts and individuals. An applicative approach is systematically applied to build a concept-as-process design. Since modern computing considers information processes as the main objects of modeling, the developed design is indeed representative of the semantic processing of information. The nature of concepts – what concepts are – and the constraints that govern the theory of concepts have been, and continue to be, the subject of debate. It is especially interesting to discuss the nature of concepts in connection with the recently established fundamental nature of information processes that are attributable to all phenomena and events occurring in the world around us. The current trend elevates information processes to forms of computing, which can also be implemented through practices, for example, in the form of programming. The deep component is computational models, one way or another expressed by means of mathematics and metamathematics. The main meta-operations used are abstraction and application. Of greatest interest is functional abstraction and application in the form of applying a function to an argument. Despite this “conceptual minimalism”, a rich theory of concepts can be developed. Using this theory, it is possible to focus further discussion not only on the nature of concepts, but also to characterize the position on each of the five important issues that are central to many theories of concepts: (1) ontology of concepts, (2) structure of concepts, (3) empiricism, and nativism about concepts, (4) concepts and natural language, and (5) concepts and conceptual analysis.}
}
@article{MANLY200899,
title = {Strategies and tactics for optimizing the Hit-to-Lead process and beyond—A computational chemistry perspective},
journal = {Drug Discovery Today},
volume = {13},
number = {3},
pages = {99-109},
year = {2008},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2007.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S135964460700459X},
author = {Charles J. Manly and Jayaraman Chandrasekhar and Joseph W. Ochterski and Jack D. Hammer and Benjamin B. Warfield},
abstract = {The Hit-to-Lead-to-Candidate process continues to evolve rapidly, and while technological advances offer much potential, the reality often pales to the promise. Conversely, strategies and tactics implementing existing technologies may result in more benefit in the end. This article focuses on some of the thinking and approaches that may improve the efficiency and effectiveness of the beginnings of the drug discovery path. From the perspective of computational chemists, different types of strategy and philosophy of approach will be treated including: considerations of early lead choices, strategies for improving poor leads, multivariate optimization, opportunities for informatics, and engineering good decisions.}
}
@article{CHEN2022307,
title = {Computational markers of experience- but not description-based decision-making are associated with future depressive symptoms in young adults},
journal = {Journal of Psychiatric Research},
volume = {154},
pages = {307-314},
year = {2022},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0022395622004484},
author = {Chong Chen and Yasuhiro Mochizuki and Kosuke Hagiwara and Masako Hirotsu and Toshio Matsubara and Shin Nakagawa},
keywords = {Decision-making, Description-experience gap, Risk preference, Probability weighting, Reinforcement learning, Computational psychiatry},
abstract = {Background
Early prediction of high depressive symptoms is crucial for selective intervention and the minimization of functional impairment. Recent cross-sectional studies indicated decision-making deficits in depression, which may be an important contributor to the disorder. Our goal was to test whether description- and experience-based decision making, two major neuroeconomic paradigms of decision-making under uncertainty, predict future depressive symptoms in young adults.
Methods
One hundred young adults performed two decision-making tasks, one description-based, in which subjects chose between two gambling options given explicitly stated rewards and their probabilities, and the other experience-based, in which subjects were shown rewards but had to learn the probability of those rewards (or cue-outcome contingencies) via trial-and-error experience. We evaluated subjects' depressive symptoms with BDI-II at baseline (T1) and half a year later (T2).
Results
Comparing subjects with low versus high levels of depressive symptoms at T2 showed that the latter performed worse on the experience- but not description-based task at T1. Computational modeling of the decision-making process suggested that subjects with high levels of depressive symptoms had a more concave utility function, indicating enhanced risk aversion. Furthermore, a more concave utility function at T1 increased the odds of high depressive symptoms at T2, even after controlling depressive symptoms at T1, perceived stress at T2, and several covariates (OR = 0.251, 95% CI [0.085, 0.741]).
Conclusions
This is the first study to demonstrate a prospective link between experience-based decision-making and depressive symptoms. Our results suggest that enhanced risk aversion in experience-based decision-making may be an important contributor to the development of depressive symptoms.}
}
@article{MALGAROLI202213,
title = {Machine yearning: How advances in computational methods lead to new insights about reactions to loss},
journal = {Current Opinion in Psychology},
volume = {43},
pages = {13-17},
year = {2022},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2021.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X21000683},
author = {Matteo Malgaroli and Fiona Maccallum and George A. Bonanno},
keywords = {Grief, Machine learning, Computation, Trajectories, Networks},
abstract = {The loss of a loved one is a potentially traumatic event that can result in disparate outcomes and symptom patterns. Machine learning methods offer computational tools to probe this heterogeneity and understand grief psychopathology in its complexity. In this article, we examine the latest contributions to the scientific study of bereavement reactions garnered through the use of computational methods. We focus on findings originating from trajectory modeling studies, as well as the recent insights originating from the network analysis of prolonged grief symptoms. We also discuss applications of artificial intelligence for the accurate identification of major depression and post-traumatic stress, as examples for their potential applications to the study of loss reactions.}
}
@incollection{DAVID20241,
title = {Chapter One - Why is implementing computational intelligence for social good so challenging? Principles and its application},
editor = {Preetha Evangeline David and P. Anandhakumar},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {132},
pages = {1-17},
year = {2024},
booktitle = {Applying Computational Intelligence for Social Good},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065245823000530},
author = {Preetha Evangeline David and P. Anandhakumar},
keywords = {Decision-making, Business models, Risk mitigation, health care, criminal justice, Smart cities},
abstract = {Computational intelligence (CI) has the potential to help tackle some of the world's most challenging social problems. Real-life examples of AI are already being applied in about one-third of these use cases They range from diagnosing cancer to helping blind people navigate their surroundings, identifying victims of online sexual exploitation, and aiding disaster-relief efforts etc. AI is only part of a much broader tool kit of measures that can be used to tackle societal issues, however. For now, issues such as data accessibility and shortages of AI talent constrain its application for social good. This chapter has grouped use cases into 10 social-impact domains based on taxonomies in use among social-sector organizations. Each use case highlights a type of meaningful problem that can be solved by one or more AI capability. The cost of human suffering, and the value of alleviating it, are impossible to gauge and compare. Nonetheless, employing usage frequency as a proxy, we measure the potential impact of different AI capabilities.}
}
@article{BANERJEE2017227,
title = {A computational model for the endogenous arousal of thoughts through Z*-numbers},
journal = {Information Sciences},
volume = {405},
pages = {227-258},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.03.035},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517306321},
author = {Romi Banerjee and Sankar K. Pal},
keywords = {Artificial general intelligence, Attention dynamics, Man-machine interaction, Multimodal integration, Perception of meaning, Self-aware systems},
abstract = {Natural language provides a rich combinatorial mechanism for encoding meanings - a finite set of words can express an unbounded number of thoughts. Framed in 2015 to extend the purpose of Zadeh's Z-numbers, a Z*-number is a perceptual symbol of the meaning of a natural language expression and consequently mentalese – or internal speech. This article, through decomposition of the Z*-macro-parameters into its atomic constituents, presents a model for the endogenous arousal of thoughts during empathetic, bespoke comprehension of the real-world. Based on Minsky's Society of Mind, the framework is founded on the assimilation of multimodal experiences, a sense of ‘unified self’ and its derivatives (choice, interest, curiosity, etc.), objective and subjective components of knowledge, commonsense, and attention dynamics over a real-world scenario. The model attempts emulation of slow and fast thinking, instinctive reactions, learning, deliberation, reflection and self-conscious decisions. The design has been validated against human responses, and aims to contribute to the development of autonomous artificial systems for man-machine symbiosis.}
}
@article{KACZANOWSKA2022111287,
title = {Molecular archaeology of human cognitive traits},
journal = {Cell Reports},
volume = {40},
number = {9},
pages = {111287},
year = {2022},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2022.111287},
url = {https://www.sciencedirect.com/science/article/pii/S221112472201107X},
author = {Joanna Kaczanowska and Florian Ganglberger and Olga Chernomor and Dominic Kargl and Bence Galik and Andreas Hess and Yoshan Moodley and Arndt {von Haeseler} and Katja Bühler and Wulf Haubensak},
keywords = {evolutionary genetics, neurogenetic evolution, computational neuroanatomy, human cognition, archaic brains, Neanderthal, Denisovan, language, attention, strategic thinking},
abstract = {Summary
The brains and minds of our human ancestors remain inaccessible for experimental exploration. Therefore, we reconstructed human cognitive evolution by projecting nonsynonymous/synonymous rate ratios (ω values) in mammalian phylogeny onto the anatomically modern human (AMH) brain. This atlas retraces human neurogenetic selection and allows imputation of ancestral evolution in task-related functional networks (FNs). Adaptive evolution (high ω values) is associated with excitatory neurons and synaptic function. It shifted from FNs for motor control in anthropoid ancestry (60–41 mya) to attention in ancient hominoids (26–19 mya) and hominids (19–7.4 mya). Selection in FNs for language emerged with an early hominin ancestor (7.4–1.7 mya) and was later accompanied by adaptive evolution in FNs for strategic thinking during recent (0.8 mya–present) speciation of AMHs. This pattern mirrors increasingly complex cognitive demands and suggests that co-selection for language alongside strategic thinking may have separated AMHs from their archaic Denisovan and Neanderthal relatives.}
}
@article{LENG2025528,
title = {Review of manufacturing system design in the interplay of Industry 4.0 and Industry 5.0 (Part II): Design processes and enablers},
journal = {Journal of Manufacturing Systems},
volume = {79},
pages = {528-562},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525000366},
author = {Jiewu Leng and Jiwei Guo and Junxing Xie and Xueliang Zhou and Ang Liu and Xi Gu and Dimitris Mourtzis and Qinglin Qi and Qiang Liu and Weiming Shen and Lihui Wang},
keywords = {Manufacturing system design, Production system design, Smart manufacturing, Industry 5.0, Design methods},
abstract = {Following up on our previous review paper ‘Review of manufacturing system design in the interplay of Industry 4.0 and Industry 5.0 (Part I): Design thinking and modeling methods’ [1], based on the proposed Thinking-Modelling-Process-Enabler (TMPE) framework of Manufacturing System Design (MSD), this paper (Part II of the two-part review) further reviews the Process and Enabler dimensions of MSD in the interplay of Industry 4.0 and Industry 5.0. MSD methods are reviewed from the single-dimensional design process and cross-dimensional design process perspectives, respectively. MSD methods are reorganized and categorized from the key enabler's perspective. Finally, challenges are discussed along with directions for future research in the domain of MSD. This review is anticipated to offer novel insights for advancing MSD research and engineering in the interplay of Industry 4.0 and Industry 5.0.}
}
@incollection{KENNEDY2001261,
title = {chapter six - Thinking Is Social},
editor = {James Kennedy and Russell C. Eberhart and Yuhui Shi},
booktitle = {Swarm Intelligence},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {261-284},
year = {2001},
series = {The Morgan Kaufmann Series in Artificial Intelligence},
isbn = {978-1-55860-595-4},
doi = {https://doi.org/10.1016/B978-155860595-4/50006-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558605954500061},
author = {James Kennedy and Russell C. Eberhart and Yuhui Shi},
abstract = {Publisher Summary
Neural networks, simulated annealing, cultural algorithms, ant colony optimization, and evolutionary algorithms are several instances where psychological, physical, and biological theories have influenced the development of computational methods for problem solving. This chapter takes simulation from the social sciences and shows how it can be modified slightly to perform combinatorial optimization. It explains that thinking is a social activity; human culture and cognition are aspects of a single process. A recent simulation of the spread of culture provides insights into the effects of social interaction and gives a starting point for demonstrating that a small number of simple principles can cause an artificial system to behave remarkably like a complex human society. Though all interactions are local, insights and innovations are transported by culture from the originator to distant individuals; moreover, a combination of various innovations results in more improved methods.}
}
@article{ROBSON2022102517,
title = {A dynamical systems view of neuroethology: Uncovering stateful computation in natural behaviors},
journal = {Current Opinion in Neurobiology},
volume = {73},
pages = {102517},
year = {2022},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2022.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959438822000022},
author = {Drew N. Robson and Jennifer M. Li},
keywords = {Neural dynamics, Neuroethology, Internal state, Innate behavior, Neuromodulation, Dynamical systems},
abstract = {State-dependent computation is key to cognition in both biological and artificial systems. Alan Turing recognized the power of stateful computation when he created the Turing machine with theoretically infinite computational capacity in 1936. Independently, by 1950, ethologists such as Tinbergen and Lorenz also began to implicitly embed rudimentary forms of state-dependent computation to create qualitative models of internal drives and naturally occurring animal behaviors. Here, we reformulate core ethological concepts in explicitly dynamical systems terms for stateful computation. We examine, based on a wealth of recent neural data collected during complex innate behaviors across species, the neural dynamics that determine the temporal structure of internal states. We will also discuss the degree to which the brain can be hierarchically partitioned into nested dynamical systems and the need for a multi-dimensional state-space model of the neuromodulatory system that underlies motivational and affective states.}
}
@article{FELDMANHALL20211045,
title = {The computational challenge of social learning},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {12},
pages = {1045-1057},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321002291},
author = {Oriel FeldmanHall and Matthew R. Nassar},
keywords = {social learning, computational modeling, inference, reward, emotion, coordination, uncertainty},
abstract = {The complex reward structure of the social world and the uncertainty endemic to social contexts poses a challenge for modeling. For example, during social interactions, the actions of one person influence the internal states of another. These social dependencies make it difficult to formalize social learning problems in a mathematically tractable way. While it is tempting to dispense with these complexities, they are a defining feature of social life. Because the structure of social interactions challenges the simplifying assumptions often made in models, they make an ideal testbed for computational models of cognition. By adopting a framework that embeds existing social knowledge into the model, we can go beyond explaining behaviors in laboratory tasks to explaining those observed in the wild.}
}
@article{FAVERO2024111903,
title = {Ten questions concerning statistical data analysis in human-centric buildings research: A focus on thermal comfort investigations},
journal = {Building and Environment},
volume = {264},
pages = {111903},
year = {2024},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.111903},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324007455},
author = {Matteo Favero and Salvatore Carlucci and Giorgia Chinazzo and Jan Kloppenborg Møller and Marcel Schweiker and Marika Vellei and Andrew Sonta},
keywords = {Thermal comfort, Human-centric research, Statistical data analysis, Simulations, Causal thinking, Statistical thinking},
abstract = {Given the large amount of time we spend indoors, designing and operating buildings that are safe, comfortable, and conducive to productivity and well-being is essential. To achieve this goal, in the past decades, research has been conducted to investigate the influence of the indoor environment on occupants. Thermal comfort has been the subject of most investigations in this field. However, despite being a consolidated research topic since the 1920s, statistical practices for analysing thermal comfort data often rely on simplified premises, which may be due to several possible factors (e.g., limited computational capabilities and lack of training). Consequently, important aspects of data analysis are often absent or overlooked. Recent statistics and statistical software advances have provided more options for effectively modelling complex issues. However, properly using these tools requires a solid understanding of statistical analysis, increasing the risk of misuse in practice. This paper presents ten questions highlighting the most critical issues regarding statistical analysis for thermal comfort research and practice. The first four questions provide general perspectives concerning statistical data analysis, while the remaining ones address specific problems related to thermal comfort research, but that can extend to all human-centric research in the built environment. Additionally, the last five questions demonstrate the practical significance of analysis pitfalls (i.e., sampling variability, selection bias, variable selection, clustered/nested observations, and measurement error) through examples with synthetic data. This study provides insights into the current statistical ‘habits’ in thermal comfort research and, more importantly, help researchers better define and conduct their statistical analyses.}
}
@article{ASMUSSEN2025103328,
title = {Distrusting cores by separating computation from isolation},
journal = {Journal of Systems Architecture},
volume = {159},
pages = {103328},
year = {2025},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2024.103328},
url = {https://www.sciencedirect.com/science/article/pii/S1383762124002650},
author = {Nils Asmussen and Till Miemietz and Sebastian Haas and Michael Roitzsch},
keywords = {Multicore architectures, Hardware security, Reliability, Operating systems},
abstract = {Security mechanisms such as address spaces rely on the assumption that processor cores can be fully trusted. But the steady influx of side-channel vulnerabilities in processors is challenging this assumption. To minimize the impact of security vulnerabilities in processors, we need a system architecture that can tolerate potentially exploitable cores. In this paper, we propose the untrusted core isolation model to protect critical computation on trusted cores from untrusted and potentially buggy cores. We survey how current architectural building blocks such as MMUs fall short of this goal and derive requirements for untrusted core isolation. To demonstrate its feasibility, we discuss both changes to commodity platforms and show how research works such as fulfill the requirements. We evaluate the security benefits via a qualitative comparison of current architectures in both industry and academia and study its costs by a quantitative comparison of the most promising approaches on off-the-shelf and FPGA-based platforms.}
}
@article{OTANI2024104086,
title = {Computational study on the effects of central retinal blood vessels with asymmetric geometries on optic nerve head biomechanics},
journal = {Medical Engineering & Physics},
volume = {123},
pages = {104086},
year = {2024},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2023.104086},
url = {https://www.sciencedirect.com/science/article/pii/S1350453323001418},
author = {Tomohiro Otani and Kota Miyata and Atsuya Miki and Shigeo Wada},
keywords = {Central retinal vessel, Optic nerves head, Optical coherence tomography, Glaucoma, Smoothed finite element method},
abstract = {Optic nerve head (ONH) biomechanics are associated with glaucoma progression and have received considerable attention. Central retinal vessels (CRVs) oriented asymmetrically in the ONH are the single blood supply source to the retina and are believed to act as mechanically stable elements in the ONH in response to intraocular pressure (IOP). However, these mechanical effects are considered negligible in ONH biomechanical studies and received less attention. This study investigated the effects of CRVs on ONH biomechanics taking into consideration three-dimensional asymmetric CRV geometries. A CRV geometry was constructed based on CRV centerlines extracted from optical coherence tomography ONH images in eight healthy subjects and superimposed in the idealized ONH geometry established in previous studies. Mechanical analyses of the ONH in response to the IOP were conducted in the cases with and without CRVs for comparison. Obtained results demonstrated that the CRVs induced anisotropic ONH deformation, particularly in the lamina cribrosa and the associated upper neural tissues (prelamina) with wide ranges of spatial strain distributions. These results indicated that the CRVs result in anisotropic deformation with local strain concentration, rather than function to mechanically support in response to the IOP as in the conventional thinking in ophthalmology.}
}
@article{JAYBONK1998261,
title = {Alternative instructional strategies for creative and critical thinking in the accounting curriculum},
journal = {Journal of Accounting Education},
volume = {16},
number = {2},
pages = {261-293},
year = {1998},
issn = {0748-5751},
doi = {https://doi.org/10.1016/S0748-5751(98)00012-8},
url = {https://www.sciencedirect.com/science/article/pii/S0748575198000128},
author = {Curtis {Jay Bonk} and G {Stevenson Smith}},
abstract = {In the midst of numerous accounting reform reports declaring that the memorization of accounting facts will no longer suffice, global economies have increased the pressure on universities to develop higher-order thinking skill curricula. This paper suggests that a consultative model of teaching can meet these challenges. From this framework, learning environments can be reshaped to support both the creative and critical thinking skills demanded by workplaces of the 21st century. In contrast to the passive reception of knowledge of teacher-centered classrooms, this style of teaching promotes active, student-centered learning. Importantly, a myriad of critical and creative thinking techniques, activities, and examples are detailed for developing accounting curricula in accordance with these views. Peripheral issues related to assessing higher-order thinking as well as cooperative grouping also are considered.}
}
@article{GONI2024103324,
title = {Analytical categories to describe imaginations about the collective futures: From theory to linguistics to computational analysis},
journal = {Futures},
volume = {156},
pages = {103324},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103324},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724000077},
author = {Julian “Iñaki” Goñi and Maria Paz Raveau and Claudio {Fuentes Bravo}},
keywords = {Imaginations about the collective futures, Images of the future, Linguistic markers, Natural language processing},
abstract = {Anticipation of collective futures has been described as one of the most critical challenges of contemporary societies. Imaginations or images of the collective future are a form of narrative and social activity that involves many complex political, psychological and cultural nuances that pose significant challenges in terms of assessment. In this article, we propose six analytical categories to describe qualitative information regarding imaginations about the collective futures. These categories reflect a conceptual integration of normative stances in Science, Technology and Society and capacity approaches to Futures Studies. We translated those analytical categories into grammatical markers that allow for their operationalisation. Using a large-scale participatory process in Chile aimed at systematising images of the future, we utilised Natural Language Process to transform the grammatical markers into computational codes that allowed us to automatically assess large amounts of qualitative data. Ultimately, our main argument is that analytical categories to describe imaginations about collective futures can be generated with reasonable foundations in the humanities and social sciences.}
}
@article{ROYCHOWDHURY20231,
title = {Brain inspired face recognition: A computational framework},
journal = {Cognitive Systems Research},
volume = {78},
pages = {1-13},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000687},
author = {Pinaki {Roy Chowdhury} and Angad {Singh Wadhwa} and Nikhil Tyagi},
keywords = {ANN, CNN, Deep learning, Classification algorithms, Brain inspired face recognition, Feature extraction, Scaled conjugate gradient, Adam},
abstract = {This paper presents a new proposal of an efficient computational model of face recognition which uses cues from the distributed face recognition mechanism of the brain, and by gathering engineering equivalent of these cues from existing literature. Three distinct and widely used features – Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), and Principal components (PCs) extracted from target images are used in a manner which is simple, and yet effective. The HOG and LBP features further undergo Principal Component Analysis (PCA) for dimensionality reduction. Our model uses multi-layer perceptrons (MLP) to classify these three features and fuse them to form a sparsely connected model. A computational theory is first developed by using concepts from the information processing mechanism of the brain. Extensive experiments are carried out using eight publicly available face datasets to validate our proposed model’s performance in recognizing faces with extreme variation of illumination, pose angle, expression, and background. We also investigate the same mechanism because of reasons discussed later, on object recognition tasks as well. Results obtained are extremely promising when compared with other face and object recognition algorithms including CNN and deep learning-based methods. This highlights that simple computational processes, if clubbed properly, can produce competing performance with best algorithms.}
}
@article{BERTOLDI2025108397,
title = {Linking systems to agencies in urban metabolism studies: A conceptual framework and computational analysis of research literature},
journal = {Ecological Economics},
volume = {227},
pages = {108397},
year = {2025},
issn = {0921-8009},
doi = {https://doi.org/10.1016/j.ecolecon.2024.108397},
url = {https://www.sciencedirect.com/science/article/pii/S0921800924002945},
author = {Nicola Bertoldi and Daniela Perrotti},
keywords = {Urban metabolism, Agency, Social ecology, Stock-flow-practice nexus, Semantic network analysis, Computational linguistics, Text mining},
abstract = {This study outlines a conceptual framework linking a conceptualization of agency in urban metabolism studies with a systems-based perspective. To this aim, we engage with contributions to socio-metabolic studies, notably from social ecology, that are not directly concerned with the urban dimension but explicitly question how systems and actors shape each other and how social practices can influence the distribution of resource flows and stocks and their interdependencies. Based on those contributions, we identify three critical axes of investigation that help track implicit uses of the concept of “agency” in urban metabolism studies and constitute the pillars of our proposed framework: (1) characterizing structures comprising urban social-ecological systems – understood as patterns of connections among elements and subsystems – as actors, (2) identifying the chains of events that such actors influence by exerting their agentic capacities, and (3) associating those same actors with definite agentic dimensions, i.e., specific modalities of agency. By drawing on methods from computational linguistics, text mining, and semantic network analysis, we extract concepts cognate to “urban metabolism” from a relevant body of research literature. Through our framework, we show how such concepts define forms of agency that can be ascribed to structural components of urban social-ecological systems.}
}
@article{SCHWABE201360,
title = {Stress and multiple memory systems: from ‘thinking’ to ‘doing’},
journal = {Trends in Cognitive Sciences},
volume = {17},
number = {2},
pages = {60-68},
year = {2013},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2012.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661312002811},
author = {Lars Schwabe and Oliver T. Wolf},
abstract = {Although it has been known for decades that stress influences memory performance, it was only recently shown that stress may alter the contribution of multiple, anatomically and functionally distinct memory systems to behavior. Here, we review recent animal and human studies demonstrating that stress promotes a shift from flexible ‘cognitive’ to rather rigid ‘habit’ memory systems and discuss, based on recent neuroimaging data in humans, the underlying brain mechanisms. We argue that, despite being generally adaptive, this stress-induced shift towards ‘habit’ memory may, in vulnerable individuals, be a risk factor for psychopathology.}
}
@article{NARAYANAMURTHY201884,
title = {Is the hospital lean? A mathematical model for assessing the implementation of lean thinking in healthcare institutions},
journal = {Operations Research for Health Care},
volume = {18},
pages = {84-98},
year = {2018},
note = {EURO 2016—New Advances in Health Care Applications},
issn = {2211-6923},
doi = {https://doi.org/10.1016/j.orhc.2017.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2211692316301060},
author = {Gopalakrishnan Narayanamurthy and Anand Gurumurthy},
keywords = {Process improvement, Healthcare institution, Lean thinking, Implementation, Assessment, Fuzzy-logic, Lean implementation index},
abstract = {Many academic and practice articles have been published in healthcare operations management literature documenting the experience of implementing lean thinking (LT) in healthcare institutions. But, none of them have developed a procedure for assessing the implementation of LT in healthcare institutions. Lack of assessment procedures make it difficult to evaluate the progress made during the implementation of LT. The current study attempts to address this gap by developing and demonstrating an assessment procedure to evaluate the extent of lean implementation in a healthcare institution To begin with, different lean tenets and elements applied in healthcare institutions were identified through a literature review. Following it, a Fuzzy-Logic Input Based Healthcare Institution Lean Implementation Assessment (FLB-HLIA) was developed and deployed in an Indian case hospital to compute “Healthcare Institution’s Lean Implementation Index” (HLII). FLB-HLIA revealed that the case hospital has to focus on two lean tenets, namely establishing pull system, and seeking perfection, to improve its HLII. Assessment also revealed the lean elements that the case hospital can focus to upgrade its HLII. HLII can be used by practitioners to perform intra-benchmarking and inter-benchmarking of healthcare institutions. Results of FLB-HLIA provide a future action plan for the lean implementation journey of the healthcare institution by identifying the possible areas of improvement for future.}
}
@article{OPRISAN2022101642,
title = {Interdisciplinary curriculum for computational neuroscience at primarily undergraduate institutions},
journal = {Journal of Computational Science},
volume = {61},
pages = {101642},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2022.101642},
url = {https://www.sciencedirect.com/science/article/pii/S187775032200062X},
author = {Sorinel A. Oprisan},
keywords = {Computational neuroscience, Undergraduate education, Interdisciplinary curricula},
abstract = {Developing interdisciplinary undergraduate courses is challenging at all levels; it requires involving trained faculty who can successfully cover more than one discipline and creating a new curriculum that crosses discipline boundaries. While such integrative curricula are expected in a graduate school setting, they are challenging at the undergraduate level since they require proficiency in multiple disciplines. However, making this transition to interdisciplinary, project-based teaching at the undergraduate level gives a competitive edge to undergraduates. As part of a broader effort of developing a comprehensive neuroscience curriculum, we implemented an interdisciplinary, one-semester, upper-level course called Biophysical Modeling of Excitable Cells (BMEC). The course exposes undergraduate students to broad areas of computational biology. It focuses on computational neuroscience, develops scientific literacy, and promotes teamwork between biology, psychology, physics, and mathematics-oriented undergraduates. This course also provides pedagogical experience for senior Ph.D. students in Neuroscience. BMEC is a three contact hours per week lecture-based course that includes a set of computer-based activities designed to gradually increase the undergraduates’ ability to apply mathematics and computational concepts to solving biologically-relevant problems. The class brings together two different groups of students with very dissimilar and complementary backgrounds, i.e., biology/psychology and physics/mathematics oriented. The teamwork allows students with more substantial biology/psychology backgrounds to explain to physics/mathematics students the biological implications and instill realism into the computer modeling project they completed for this class. Simultaneously, students with substantial physics/mathematics backgrounds can apply techniques learned in specialized mathematics, physics, or computer science classes to generate mathematical hypotheses and implement them in computer codes. This study expands on Oprisan (2021) by including examples of hands-on activities, student projects, and a brief overview of course assessment tools and results. This study also includes more recent approaches to teaching computational neuroscience using cloud computing.}
}
@article{LOVE2022100543,
title = {A screen-based or physical computing unit? Examining secondary students’ attitudes toward coding},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100543},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100543},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000617},
author = {Tyler S. Love and Reuben S. Asempapa},
keywords = {Computational thinking, Physical computing, Integrated STEM education, Design and technology, Technology and engineering education, Tangible interaction},
abstract = {In recent years there has been a growing emphasis placed on access to computational thinking (CT) instruction for every K-12 student in the United States (U.S.). Concurrently, calls for integrating CT concepts within authentic science, technology, engineering, and mathematics (STEM) contexts have also increased. This is reflected by the inclusion of CT in the Next Generation Science Standards and the Standards for Technological and Engineering Literacy. However, methods for teaching CT concepts within secondary level STEM courses vary drastically. Physical computing, the design and programming of physical systems or devices using computational thinking skills, has become increasingly popular in the U.S. in attempts to integrate CT within authentic STEM problem-solving contexts. Despite this rise in popularity, there remains a limited but growing body of research investigating physical computing pedagogy and student learning. A mixed methods design was used in this study to examine 170 middle school students’ attitudes toward coding and after participating in either a screen-based or physical computing unit. The results indicated that students who completed the screen-based unit reported statistically greater attitudes toward the classroom applications and career/future use of computing concepts. Students in the treatment group believed that physical computing made learning computing concepts more difficult, but they preferred the hands-on learning opportunities provided by physical computing. Furthermore, male students reported higher attitudinal ratings than females regarding the influence computing would have on their future academic and career choices. This study provides implications for improving physical computing instruction and integration within STEM education contexts.}
}
@article{OXMAN2002135,
title = {The thinking eye: visual re-cognition in design emergence},
journal = {Design Studies},
volume = {23},
number = {2},
pages = {135-164},
year = {2002},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(01)00026-6},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X01000266},
author = {Rivka Oxman},
keywords = {perception, design cognition, visual reasoning, emergence, creativity},
abstract = {Emergence has been widely recognized as a significant phenomenon of visual reasoning in design. Despite its centrality as a cognitive phenomenon, research in emergence currently lacks a comprehensive theoretical foundation. A broadened view of design emergence that adds to the perceptual phenomenon of shape emergence in reflecting the way the design domains are conceptualized is proposed. An expanded theory of emergence in which visual cognition plays an important role is presented. Beginning with an attempt to broaden the perceptual perspectives of shape emergence, the process of cognitive emergence is defined. The duality of related perceptual and cognitive components provides a working basis for conceptualizing visual emergence in design. Antithetical to the idea of accidental emergence, it is proposed that emergence is guided and anticipated. We claim that it is the re-cognition of visual shapes and images in design that enables emergence. This kind of guidance function in emergence is termed ‘anticipated emergence’. We demonstrate how high-level domain knowledge of visual forms can be accommodated as cognitive content, and how this can contribute to establishing a cognitive basis for emergence. An empirical experiment from the domain of architecture is presented.}
}
@article{MAMMINO2023101151,
title = {Green chemistry and computational chemistry: A wealth of promising synergies},
journal = {Sustainable Chemistry and Pharmacy},
volume = {34},
pages = {101151},
year = {2023},
issn = {2352-5541},
doi = {https://doi.org/10.1016/j.scp.2023.101151},
url = {https://www.sciencedirect.com/science/article/pii/S2352554123001857},
author = {Liliana Mammino},
keywords = {Design of new molecules, Education to cross-disciplinary attitudes, Prediction of, Molecular properties, Prediction of reaction mechanisms},
abstract = {The green chemistry principles envisage the design of substances and production processes that are benign for human health and the environment, where ‘benign’ refers to the entire life of a substance, from production through usage and to final disposal. The design of new substances entails the design of new molecules, and the design of more benign processes may entail the design of other substances (besides reactants and products) facilitating the process' ‘greenness’, from catalysts to green solvents. Designing molecules with specific properties requires the possibility of predicting their properties before the actual synthesis. Computational chemistry has made molecular design rational by being able to predict the properties of not-yet-synthesized molecules. The results of molecular calculations enable a preliminary selection singling out the promising molecules among a high number of possibilities; only the promising ones are then synthesized and experimentally tested. Synergies between computational chemistry and green chemistry would thus appear a natural outcome. The present work outlines them with reference to the main components of an industrial process and of their potential ‘greening’. The presentation follows a pattern that can be used within educational contexts. The conclusions stress the importance to familiarise students with the variety of possible synergies and the benefits of each of them, within a perspective viewing a ‘knowing each other’ criterion as the main key to nurture true cross-areas attitudes, that will be valuable for the students' future professional activities.}
}
@article{LOCKWOOD2021100857,
title = {Reinforcing key combinatorial ideas in a computational setting: A case of encoding outcomes in computer programming},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100857},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100857},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000183},
author = {Elise Lockwood and Adaline {De Chenne}},
keywords = {Combinatorics, Encoding outcomes, Computation, Programming, Discrete mathematics},
abstract = {Counting problems are difficult for students to solve, and there is a perennial need to investigate ways to help students solve counting problems successfully. One promising avenue for students’ successful counting is for them to think judiciously about how they encode outcomes – that is, how they symbolize and represent the outcomes they are trying to count. We provide a detailed case study of two students as they encoded outcomes in their work on several related counting problems within a computational setting. We highlight the role that a computational environment may have played in this encoding activity. We illustrate ways in which by-hand work and computer programming worked together to facilitate the students’ successful encoding activity. This case demonstrates ways in which the activity of computation seemed to interact with by-hand work to facilitate sophisticated encoding of outcomes.}
}
@article{ANANE2023104782,
title = {BIM-driven computational design for robotic manufacturing in off-site construction: an integrated Design-to-Manufacturing (DtM) approach},
journal = {Automation in Construction},
volume = {150},
pages = {104782},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104782},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523000420},
author = {Walid Anane and Ivanka Iordanova and Claudiane Ouellet-Plamondon},
keywords = {Design-to-manufacturing, BIM, Computational design, Robotic manufacturing, Off-site construction, Interoperability},
abstract = {Technological interoperability is a driver for seamless data and information exchange between project team members in the Architecture, Engineering, and Construction (AEC) industry. It is defined as the ability of different systems to exchange information with minimum loss. Therefore, interoperability lack is often a barrier in modern construction applications, such as robotics. Construction and robotics, seen from their respective areas, are highly divergent in context, organization, procedures, and technologies. However, both paradigms use computation, which gives computational systems the potential to enable construction robotics. This research is based on the Design Science Research (DSR) methodology and aims to develop a framework for operationalizing industrial robots in construction. To this end, it uses Computational Design (CD) driven by Building Information Modeling (BIM) for Robotic Manufacturing (RM) within Off-Site Construction (OSC) systems. This technological alignment allowed the development of an integrated Design-to-Manufacturing (DtM) framework, validated by 16 evaluators.}
}
@article{MCKOWN2004597,
title = {Age and ethnic variation in children's thinking about the nature of racism},
journal = {Journal of Applied Developmental Psychology},
volume = {25},
number = {5},
pages = {597-617},
year = {2004},
issn = {0193-3973},
doi = {https://doi.org/10.1016/j.appdev.2004.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0193397304000668},
author = {Clark McKown},
keywords = {Racism, Stereotypes, Ethnic conflict, Elaboration, Differentiation},
abstract = {A content analysis of interviews with an ethnically diverse group of 202 children aged 6 to 10 describes what children think racism is, and examines associations between age, ethnicity, and children's thinking about racism. Children's narratives capture many dimensions of racism, including stereotypes, prejudice, discrimination, and ethnic conflict. With age, children's ideas about racism become more elaborated and differentiated. At every age, compared to their peers, African American children have more elaborated and differentiated ideas about racism and mention those dimensions of racism that overtly reflect power relations more frequently. Qualitative analyses suggest that children's ideas about racism are abstract, increasingly coherent with age, and sometimes incorporate causal language. Findings are discussed in terms of origins of individual differences, the extent to which children's ideas about racism might be considered a lay theory, and the likely consequences of such a theory in daily life.}
}
@article{DUBLJEVIC2023113168,
title = {Computational BIM tool for automated LEED certification process},
journal = {Energy and Buildings},
volume = {292},
pages = {113168},
year = {2023},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2023.113168},
url = {https://www.sciencedirect.com/science/article/pii/S0378778823003985},
author = {Sanja Dubljević and Bojan Tepavčević and Branko Markoski and Aleksandar S. Anđelković},
keywords = {Building information modeling, LEED, Visual programming language, Computational BIM},
abstract = {Building information modeling (BIM) and sustainable building certification integration have been the focus of several studies in recent years, aiming to create a simpler and more effective building certification process. This paper describes a novel computational tool for architects and engineers, considering that the certification process takes place in a work environment that is familiar to them. The goal is to present a method for developing a computational tool that will automate the process of verifying the achievement of certain Leadership in Energy and Environmental Design (LEED) credits using visual programming in a BIM environment. In this way, designers can have an insight into the achievement of certain LEED credits at any phase during the design process. Considering the complexity of the digital parameterization of LEED credits, this method includes the achievement of three credits listed in the Material and Resources chapter of the LEED for Building Design and Construction protocol. Apart from similar research, the presented tool enables visibility of real-time LEED credits achievement at every moment of the design, from the building concept development to the final stage. The presented method creates space for the elaboration on the other LEED credits, as well as research in the area of applicability to other green rating certification programs and evaluation of existing building stock.}
}
@article{CABRERA2008311,
title = {Distinctions, systems, relationships, and perspectives (DSRP): A theory of thinking and of things},
journal = {Evaluation and Program Planning},
volume = {31},
number = {3},
pages = {311-317},
year = {2008},
issn = {0149-7189},
doi = {https://doi.org/10.1016/j.evalprogplan.2008.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0149718908000359},
author = {Derek Cabrera and Laura Colosi}
}
@article{PAPIN2004641,
title = {Hierarchical thinking in network biology: the unbiased modularization of biochemical networks},
journal = {Trends in Biochemical Sciences},
volume = {29},
number = {12},
pages = {641-647},
year = {2004},
issn = {0968-0004},
doi = {https://doi.org/10.1016/j.tibs.2004.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0968000404002610},
author = {Jason A. Papin and Jennifer L. Reed and Bernhard O. Palsson},
abstract = {As reconstructed biochemical reaction networks continue to grow in size and scope, there is a growing need to describe the functional modules within them. Such modules facilitate the study of biological processes by deconstructing complex biological networks into conceptually simple entities. The definition of network modules is often based on intuitive reasoning. As an alternative, methods are being developed for defining biochemical network modules in an unbiased fashion. These unbiased network modules are mathematically derived from the structure of the whole network under consideration.}
}