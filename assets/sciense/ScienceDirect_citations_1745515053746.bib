@article{CHANG201323,
title = {Discovering Taiwanese design college students’ learning performance and imaginative capacity},
journal = {Thinking Skills and Creativity},
volume = {10},
pages = {23-39},
year = {2013},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2013.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S1871187113000266},
author = {Hsiang-Tang Chang and Tung-I. Lin},
keywords = {Imaginative capacity, Imagination, Learning performance, Design college, RASCH measurement},
abstract = {Imagination affects not only the structure of design ideas at the initial stage but also influences the manifestation of final products. The purpose of this study was to investigate the association between Taiwanese design college students’ imaginative capacity and their learning performance in class. On the basis of recent scholarship, the authors proposed several reasonably related factors, which were classified into three aspects: personality traits, learning atmosphere, and imaginative thinking. They then verified and discussed four research questions through a teaching experiment with 63 junior college students in YunTech, Taiwan. To proceed smoothly without significantly changing the current teaching process, the authors developed a set of supplementary teaching material and two sets of questionnaires which they then used in the teaching experiment. The results of the teaching experiment proved and suggested the following points corresponding to the research questions: (1) students’ senior high school backgrounds have an effect on their imaginative capacities; (2) judges from other schools should be invited to join the judgement to ensure fairness and with a broader scope; (3) students’ imaginative capacity indeed has an effect on the grade of their final products in the judgement; (4) teachers can identify students with higher imaginative capacity through the responses to the proposed supplementary teaching materials and questionnaires used in the study's curricula. Furthermore, the supplementary teaching material is conjectured to be able to inspire students’ imaginative capacity.}
}
@article{YIN2024133163,
title = {Mobileception-ResNet for transient stability prediction of novel power systems},
journal = {Energy},
volume = {309},
pages = {133163},
year = {2024},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2024.133163},
url = {https://www.sciencedirect.com/science/article/pii/S0360544224029384},
author = {Linfei Yin and Wei Ge},
keywords = {Transient stability, Deep learning, MobileNet-v2, Convolutional neural network, Inception-ResNet-v2},
abstract = {Power system transient stability prediction (TSP) is particularly important as power systems change and evolve, including the rapid growth of renewable energy, the proliferation of electric vehicles, and the construction of smart grids. Traditional time-domain simulation methods are time-consuming and cannot achieve online prediction. Direct methods are poorly adapted and cannot be applied to complex power systems. Existing machine learning algorithms only classify the transient stability without providing the degree of transient stability of the system. Therefore, a fast and accurate power system TSP method is needed to assist operators in implementing timely measures to improve the stability of the power system running. This study proposes a Mobileception-ResNet network, Mobileception-ResNet is formed by Inception-ResNet-v2, MobileNet-v2, and a fully connected layer. In this study, Mobileception-ResNet and nine comparison models are experimented on two node systems, i.e., the IEEE 10–39 and 69–300 systems. In the IEEE 10–39 system, the root mean square error, mean absolute error, and mean absolute percentage error of Mobileception-ResNet are 44.13 %, 36.74 %, and 39.96 % lower, and the coefficient of determination is 0.04 % higher, respectively, when compared to the comparative model with the best evaluation indicator; in the IEEE 69–300 system, the corresponding values are 2.6 %, 12.83 %, 12.55 %, and 0.01 %, respectively.}
}
@article{KUO2013510,
title = {Cultural Evolution Algorithm for Global Optimizations and its Applications},
journal = {Journal of Applied Research and Technology},
volume = {11},
number = {4},
pages = {510-522},
year = {2013},
issn = {1665-6423},
doi = {https://doi.org/10.1016/S1665-6423(13)71558-X},
url = {https://www.sciencedirect.com/science/article/pii/S166564231371558X},
author = {H.C. Kuo and C.H. Lin},
keywords = {Cultural Algorithm, Genetic Algorithm, Nelder-Mead’s simplex method, Global optimization},
abstract = {The course of socio-cultural transition can neither be aimless nor arbitrary, instead it requires a clear direction. A common goal of social species’ evolution is to move towards an advanced spiritual and conscious state. This study aims to develop a population-based algorithm on the basis of cultural transition goal. In this paper, the socio-cultural model based on a system thought framework could be used to develop a cultural evolution algorithm (CEA). CEA leverage four strategies, each consists of several search methods with similar thinking. Seven benchmark functions are utilized to validate the search performance of the proposed algorithm. The results show that all of the four strategies of cultural evolution algorithm have better performance when compared with relevant literatures. Finally, the CEA was then applied to optimize two different reliability engineering problems, a Serial-Parallel System design and a Bridge System design. For the Serial-Parallel System design, the CEA achieved the exact solution with ease, and for the Bridge System design, the solution obtained by the CEA is superior to those from other literatures.}
}
@incollection{FREUND20151,
title = {Chapter 1 - Introduction},
editor = {Jack Freund and Jack Jones},
booktitle = {Measuring and Managing Information Risk},
publisher = {Butterworth-Heinemann},
address = {Boston},
pages = {1-11},
year = {2015},
isbn = {978-0-12-420231-3},
doi = {https://doi.org/10.1016/B978-0-12-420231-3.00001-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780124202313000014},
author = {Jack Freund and Jack Jones},
keywords = {Analysis, Assessment, Assumptions, Bald tire, Risk, Threat, Vulnerability},
abstract = {This chapter makes the case for the need for quantitative risk management. It begins with the Bald Tire thought experiment to help make the case for a need to articulate assumptions, discuss terminology, and makes plain the factors of risk that we care about modeling and how to communicate them effectively to management. This section also discusses the difference between risk assessment and risk analysis, and details the deficiencies in current approaches that treat the two the same. Lastly, the chapter spells out the progression of topics for the remainder of the book and offers some words of advice on how thinking about risk will impact your ability to make better decisions in all aspects of your life.}
}
@article{SATO2019293,
title = {Statistical analysis of word usage in biological publications since 1965: Historical delineation highlighting an emergence of function-oriented discourses in contemporary molecular and cellular biology},
journal = {Journal of Theoretical Biology},
volume = {462},
pages = {293-303},
year = {2019},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2018.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S0022519318305708},
author = {Naoki Sato and Kaoru Sato},
keywords = {Contemporary biology, Function, History of biology, Statistical text analysis, Role, Social responsibility of research},
abstract = {Typical studies on the history of science, or particularly of biology, have been focused on a particular scientist or book, but this selection has a risk of being arbitrary. To find a more objective way of studying history of biology, we applied a statistical method. First, we downloaded from the PubMed database all available titles and abstracts of 934,807 articles in 32 selected journals from 1965 to 2014, and extracted most frequently used 322 terms by text mining. Clustering of these terms according to the annual frequency of usage resulted in three main clusters: Cluster 1 represented terms that were no longer used frequently, Cluster 3 included terms that became abundantly used recently, and Cluster 2 contained terms constantly used. Three phases were delineated in the history of biology over the past 50 years, with transitions in 1987 and 1997. In contrast with our tacit understanding that “function” is a key notion in biological thinking, the results suggest that function-oriented discourses are a new habit of biologists in the genomic era after 1997, in which biological researches focus on identifying a link between a molecule or a structure with its function. We hypothesize that, in spite of repeated warnings, function-related discourses have a teleological connotation, which is easily misunderstood by general audience and, with emphatic expressions such as “important” and “essential”, fit to the need for justification of researches as part of researcher's responsibility for public funding.}
}
@article{LEACH2024,
title = {The engineering legacy of the FIFA World Cup Qatar 2022: Al Janoub stadium},
journal = {Proceedings of the Institution of Civil Engineers - Structures and Buildings},
year = {2024},
issn = {0965-0911},
doi = {https://doi.org/10.1680/jstbu.22.00127},
url = {https://www.sciencedirect.com/science/article/pii/S0965091124000155},
author = {Jon Leach and Craig Sparrow and Federico Iori and Hamad N. Al-Nuaimi and Mohammed Z. E. B. Elshafie and Nasser A. Al-Nuaimi},
keywords = {buildings, structures & design, thermal effects, wind loading & aerodynamics},
abstract = {Al Janoub was the first new-build stadium designed for the FIFA World Cup Qatar 2022. This paper describes the journey of the engineering design of the 40 000 seat stadium, from the concept and detailed design development stages led by AECOM and Zaha Hadid Architects, through to the design and build contract on site. An architectural jewel located in Al Wakrah, just south of the city of Doha, the stadium was a world-first, using state-of-the-art computational analysis and physical modelling to create a safe, cooled environment that satisfies FIFA's requirements for both player and spectator comfort in the extreme temperatures of the region. A sustainable post-tournament legacy was also a key factor of the design, allowing it to be reduced to a 20 000-capacity stadium for the local football club and community. The task of integrating the stadium's stringent performance requirements on this path-finder project, including extensive scientific research and development, was a challenge that was overcome through close collaboration between the design team and the Supreme Committee's subject matter experts. The project's success as a test-bed helped it to set the standard for other stadia as part of the overall FIFA World Cup Qatar 2022 programme.}
}
@article{NGUYEN2022108381,
title = {Knowledge mapping of digital twin and physical internet in Supply Chain Management: A systematic literature review},
journal = {International Journal of Production Economics},
volume = {244},
pages = {108381},
year = {2022},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2021.108381},
url = {https://www.sciencedirect.com/science/article/pii/S0925527321003571},
author = {Tiep Nguyen and Quang Huy Duong and Truong Van Nguyen and You Zhu and Li Zhou},
keywords = {, , , },
abstract = {Physical Internet (PI) is an open global logistics system of which components are hyperconnected for increased efficiency and sustainability. Digital twin (DT), referring to the virtual representation of a physical object, is well-perceived as a key driver in the development of PI-based Supply Chain Management (SCM). Due to the capabilities of real-time monitoring and evaluation of large-scale complex systems, significant research efforts have been made to exploit values of PI/DT in SCM. Despite this, the current literature remained largely unstructured and scattered due to a lack of systematic literature reviews to synergise research findings, analyse the evolution of research fronts and extract emerging trends in the field. To address this issue, the paper deploys a bibliometric knowledge mapping approach to provide a bird's eye view of the current research status in the PI/DT-SCM area. Using CiteSpace's keyword co-occurrence network, 518 journal articles are clustered into 10 key research streams on PI/DT applications in: job shop scheduling, smart manufacturing design, PI-based SCM, manufacturing virtualisation, information management, sustainability development, data analytics, manufacturing operations management, simulation and optimisation, and assembly process planning. Based on citation burst rate, keywords representing research frontiers of the PI/DT are detected and their temporal evolutions are discussed. Likewise, some identified emerging research trends are production process and system, robotics, computer architecture, and cost. Finally, seven future research directions are suggested, which emphasise on several PI/DT-related issues, including business ecosystem, sustainability development, SC downstream management, cognitive thinking in Industry 5.0, citizen twin in digital society, and SC resilience.}
}
@article{ERDMANN202242,
title = {A generative framework for the study of delusions},
journal = {Schizophrenia Research},
volume = {245},
pages = {42-49},
year = {2022},
note = {Computational Approaches to Understanding Psychosis},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2020.11.048},
url = {https://www.sciencedirect.com/science/article/pii/S0920996420306277},
author = {Tore Erdmann and Christoph Mathys},
keywords = {Delusion, Dirichlet process, Hierarchical predictive coding, Auxiliary hypothesis, Epistemic trust},
abstract = {Despite the ubiquity of delusional information processing in psychopathology and everyday life, formal characterizations of such inferences are lacking. In this article, we propose a generative framework that entails a computational mechanism which, when implemented in a virtual agent and given new information, generates belief updates (i.e., inferences about the hidden causes of the information) that resemble those seen in individuals with delusions. We introduce a particular form of Dirichlet process mixture model with a sampling-based Bayesian inference algorithm. This procedure, depending on the setting of a single parameter, preferentially generates highly precise (i.e. over-fitting) explanations, which are compartmentalized and thus can co-exist despite being inconsistent with each other. Especially in ambiguous situations, this can provide the seed for delusional ideation. Further, we show by simulation how the excessive generation of such over-precise explanations leads to new information being integrated in a way that does not lead to a revision of established beliefs. In all configurations, whether delusional or not, the inference generated by our algorithm corresponds to Bayesian inference. Furthermore, the algorithm is fully compatible with hierarchical predictive coding. By virtue of these properties, the proposed model provides a basis for the empirical study and a step toward the characterization of the aberrant inferential processes underlying delusions.}
}
@article{VAKILI2021112687,
title = {The development of a transdisciplinary policy framework for shipping companies to mitigate underwater noise pollution from commercial vessels},
journal = {Marine Pollution Bulletin},
volume = {171},
pages = {112687},
year = {2021},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2021.112687},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X21007219},
author = {Seyedvahid Vakili and Aykut I. Ölçer and Fabio Ballini},
keywords = {Energy Efficiency Design Index, Energy Efficiency Existing Ship Index, Enhanced Ship Energy Efficiency Management Plan, Policy, Transdisciplinary, Underwater noise pollution},
abstract = {One of the newly emerging environmental issues is underwater noise pollution. It has both negative environmental and socio-economic impacts and threatens sustainable shipping. While other types of shipping pollutants have been regulated and societal awareness has been raised, due to the intangible characteristics of underwater noise pollution, there is neither societal awareness nor an international legally binding instrument to mitigate underwater noise pollution. This paper aims to raise awareness of ship owners regarding UWN pollution by introducing the sources of UWN pollution, as well as proposing a transdisciplinary policy for shipping companies to mitigate UWN pollution from their ships. The proposed policy is aligned with IMO's initial GHG strategy, especially the Energy Efficiency Design Index, Energy Efficiency Existing Ship Index, and Enhanced Ship Energy Efficiency Management Plan. This multi-dimensional approach will make stakeholders more enthusiastic to tackle underwater noise pollution while enhancing the efficient use of capacities and resources.}
}
@article{LI2022101701,
title = {A framework and method for Human-Robot cooperative safe control based on digital twin},
journal = {Advanced Engineering Informatics},
volume = {53},
pages = {101701},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101701},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622001604},
author = {Hao Li and Wenfeng Ma and Haoqi Wang and Gen Liu and Xiaoyu Wen and Yuyan Zhang and Miying Yang and Guofu Luo and Guizhong Xie and Chunya Sun},
keywords = {Human-robot collaboration, Digital twin, Safety control, Machine vision, Convolutional neural network},
abstract = {Human-robot collaboration (HRC) combines the robot’s mechanical properties and predictability with human experience, logical thinking, and strain capabilities to alleviate production efficiency. However, ensuring the safety of the HRC process in-real time has become an urgent issue. Digital twin extends functions of virtual models in the design phase of the physical counterpart in the production phase through virtual-real interactive feedback, data fusion analysis, advanced computational features, etc. This paper proposes an HRC safety control framework and corresponding method based on the digital twin. In the design phase, virtual simulation and virtual reality technology are integrated to construct virtual twins of various HRC scenarios for testing and analyzing potential safety hazards. In the production phase, the safety distance between humans and robots of the HRC scene is monitored and calculated by an iterative algorithm according to machine vision and a convolutional neural network. Finally, the virtual twin is driven based on real-scene data, real-time online visual monitoring, and optimization of the HRC’s overall process. A case study using ABB-IRB1600 is presented to verify the feasibility of the proposed approach.}
}
@article{KOCHEN1958267,
title = {The acquisition and utilization of information in problem solving and thinking},
journal = {Information and Control},
volume = {1},
number = {3},
pages = {267-288},
year = {1958},
issn = {0019-9958},
doi = {https://doi.org/10.1016/S0019-9958(58)80005-4},
url = {https://www.sciencedirect.com/science/article/pii/S0019995858800054},
author = {Manfred Kochen and Eugene H. Galanter},
abstract = {Some of the logical consequences of drawing a distinction between the following two aspects of problem-solving behavior are explored: (a) actions directed toward the acquisition of information to guide future actions toward valuable goals; (b) actions directed toward the utilization of accumulated information to attain a valuable goal. An experimental paradigm accomplishing this separation is described for the case of an environment of periodic sequences of binary events. A general way of describing behavioral strategies is developed in terms of: (a) a plan for when to acquire information, to guess an outcome, or to guess at the solution; and (b) a program for how to compute guesses from the information accumulated. The structure of the binary environmental sequences, the structure of these behavioral strategies, and the relations between them are analyzed, and certain strategies which maximize value are suggested. Computing machine interpretations of certain specific strategies for a restricted kind of experiment are displayed, and predictions from these are compared with experimental data from pilot studies performed with human subjects.}
}
@article{MONTEIRO2023100076,
title = {Environmental assessment in concrete pole industries},
journal = {CEMENT},
volume = {13},
pages = {100076},
year = {2023},
issn = {2666-5492},
doi = {https://doi.org/10.1016/j.cement.2023.100076},
url = {https://www.sciencedirect.com/science/article/pii/S2666549223000221},
author = {Nathalie Barbosa Reis Monteiro and José Machado {Moita Neto} and Elaine Aparecida {da Silva}},
keywords = {Concrete poles, Life cycle, Environmental impact},
abstract = {Purpose
Companies that manufacture poles generate several negative environmental impacts, whose extent needs to be assessed to find ways to mitigate them.
Methods
In this research, Life Cycle Assessment (LCA) was used as a methodology to measure the potential environmental impacts throughout the poles' life cycle. Primary data (amount of cement, gravel, sand, steel rebars, energy, water) were collected from industries located in Teresina, Piauí, Brazil, and information from the Ecoinvent 3.7.1 database (transport, solid waste, liquid effluents, particulate matter) was used.
Results and discussion
The literature addresses pole production from a different perspective, making this study relevant to disseminate the life cycle thinking in concrete pole production. However, the literature points to a correlation trend for ecotoxicity and human toxicity indicators, as well as the results found in this research. Waste disposal stands out as an important source of impact for these industries, confirming the necessity of efficient management of these materials at the end of their lifespan and during the production process. The scenario analysis showed that is possible to reduce the potential impacts of these industries.
Conclusion
The reuse of waste within the industry itself is feasible (using a shredder for this purpose) and can contribute to decreasing the extraction of natural deposits in various production processes related to the poles' life cycle and reducing their accumulation in the environment. The use of inputs from closer suppliers is a strategy that contributes to mitigating the potential impact of gaseous emissions, reducing the impact that generates global warming and climate change. In addition, other papers show viable alternatives in different scenarios, based on complex laboratory studies. Nevertheless, his approach shows how impacts can be mitigated with the adoption of simple actions such as the reuse of effluents and residues from these industries. It is possible to redefine the production process through a scenario close to the ideal, bringing environmental sustainability to the sector.}
}
@incollection{SHAH2017251,
title = {Chapter Seven - What Makes Everyday Scientific Reasoning So Challenging?},
editor = {Brian H. Ross},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {66},
pages = {251-299},
year = {2017},
issn = {0079-7421},
doi = {https://doi.org/10.1016/bs.plm.2016.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079742116300214},
author = {Priti Shah and Audrey Michal and Amira Ibrahim and Rebecca Rhodes and Fernando Rodriguez},
keywords = {ANCOVA, Anecdotes, Causality bias, Decision making, Heuristic vs. analytic thinking, Science education, Scientific reasoning, Selection bias, Statistical validity},
abstract = {Informed citizens are expected to use science-based evidence to make decisions about health, behavior and public policy. To do so, they must judge whether the evidence is consistent with the claims presented (theory-evidence coordination). Unfortunately, most individuals make numerous errors in theory-evidence coordination. In this chapter, we provide an overview of research on science evidence evaluation, drawing from research in cognitive and developmental psychology, science and statistics education, decision sciences, political science and science communication. Given the breadth of this research area, we highlight some influential studies and reviews across these different topics. This body of research provides several clues about: (1) why science evidence evaluation is challenging, (2) the influence of the content and context of the evidence and (3) how the characteristics of the individual examining the evidence impact the quality of the evaluations. Finally, we suggest some possible directions for empirical research on improving evidence evaluation and point to the responsibility of scientists, especially social and behavioral scientists, in communicating their findings to the public. Overall, our goal is to give readers an interdisciplinary view of science evidence evaluation research and to integrate research from different scientific communities that address similar questions.}
}
@article{POURFOULADI2025107722,
title = {PoliBrick plugin as a parametric tool for digital stereotomy modelling},
journal = {Computers & Structures},
volume = {311},
pages = {107722},
year = {2025},
issn = {0045-7949},
doi = {https://doi.org/10.1016/j.compstruc.2025.107722},
url = {https://www.sciencedirect.com/science/article/pii/S004579492500080X},
author = {Mohammad Pourfouladi and Natalia Pingaro and Marco Valente},
keywords = {PoliBrick Plugin, Software Development, Masonry Construction, Brick Pattern, Stereotomy, Single and Double Curvature Vaults},
abstract = {This paper presents the development of a new plugin that is both simple and user-friendly for the digital modelling of multiple brick patterns in 3D on any surface, from simple flat walls to complex single and double curvature geometries. The plugin, named PoliBrick, is specifically conceived to assist in modelling different types of brickwork shells with intricate patterns, such as masonry arches and vaults. It excels in streamlining parametric modelling across a broad spectrum of free-form curved surfaces, standing out from existing tools. Developed for Rhino software within the Grasshopper environment, PoliBrick features an intuitive interface and comprises only six essential components. Its parametric method makes it competitive with any procedure documented in the literature, as it can accurately replicate brick assemblies on all types of free-form shells. PoliBrick can reproduce, with immediate feedback, any brick arrangement, including patterns like basket weave, stretcher bond, herringbone bond, and many others. Such a functionality addresses a significant gap in current software tools, which cannot often handle curved geometries with complex brick layouts. Moreover, the new plugin can be integrated into a variety of software tools to enable pre-analysis capabilities for the structural evaluation of single and double curvature vaulted structures, using preferred methods like finite element or distinct element approaches. It also supports robotic fabrication processes by considering paths and construction order, enhancing its practical utility in modern construction techniques. PoliBrick is benchmarked on some case studies to demonstrate the validity of the developed procedure and the robustness of the proposed algorithm, which is expected to be effective in markedly reducing the computational effort in pre-structural analysis modelling phases and allows designers to take into account the non-negligible role of stereotomy in curved structures.}
}
@article{PESSOA2019158,
title = {Neural dynamics of emotion and cognition: From trajectories to underlying neural geometry},
journal = {Neural Networks},
volume = {120},
pages = {158-166},
year = {2019},
note = {special Issue in Honor of the 80th Birthday of Stephen Grossberg},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2019.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608019302242},
author = {Luiz Pessoa},
keywords = {Emotion, Cognition, Dynamics, Trajectories, Manifold},
abstract = {How can we study, characterize, and understand the neural underpinnings of cognitive-emotional behaviors as inherently dynamic processes? In the past 50 years, Stephen Grossberg has developed a research program that embraces the themes of dynamics, decentralized computation, emergence, selection and competition, and autonomy. The present paper discusses how these principles can be heeded by experimental scientists to advance the understanding of the brain basis of behavior. It is suggested that a profitable way forward is to focus on investigating the dynamic multivariate structure of brain data. Accordingly, central research problems involve characterizing “neural trajectories” and the associated geometry of the underlying “neural space.” Finally, it is argued that, at a time when the development of neurotechniques has reached a fever pitch, neuroscience needs to redirect its focus and invest comparable energy in the conceptual and theoretical dimensions of its research endeavor. Otherwise we run the risk of being able to measure “every atom” in the brain in a theoretical vacuum.}
}
@article{NAGHDY2025102445,
title = {Collaboration with GenAI in Engineering Research Design},
journal = {Data & Knowledge Engineering},
pages = {102445},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102445},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000400},
author = {Fazel Naghdy},
keywords = {literature review, hypothesis, research design, GenAI, research gaps},
abstract = {Over the past five years, the fast development and use of generative artificial intelligence (GenAI) and large language models (LLMs) has ushered in a new era of study, teaching, and learning in many domains. The role that GenAIs can play in engineering research is addressed. The related previous works report on the potential of GenAIs in the literature review process. However, such potential is not demonstrated by case studies and practical examples. The previous works also do not address how GenAIs can assist with all the steps traditionally taken to design research. This study examines the effectiveness of collaboration with GenAIs at various stages of research design. It explores whether collaboration with GenAIs can result in more focused and comprehensive outcomes. A generalised approach for collaboration with AI tools in research design is proposed. A case study to develop a research design on the concept of “shared machine-human driving” is deployed to show the validity of the articulated concepts. The case study demonstrates both the pros and cons of collaboration with GenAIs. The results generated at each stage are rigorously validated and thoroughly examined to ensure they remain free from inaccuracies or hallucinations and align with the original research objectives. When necessary, the results are manually adjusted and refined to uphold their integrity and accuracy. The findings produced by the various GenAI models utilized in this study highlight the key attributes of generative artificial intelligence, namely speed, efficiency, and scope. However, they also underscore the critical importance of researcher oversight, as unexamined inferences and interpretations can render the results irrelevant or meaningless.}
}
@article{DASILVA2024105785,
title = {Optimization of open web steel beams using the finite element method and genetic algorithms},
journal = {Structures},
volume = {60},
pages = {105785},
year = {2024},
issn = {2352-0124},
doi = {https://doi.org/10.1016/j.istruc.2023.105785},
url = {https://www.sciencedirect.com/science/article/pii/S2352012423018738},
author = {Amilton Rodrigues {da Silva} and Gabriela Pereira Lubke},
keywords = {Open-web beams, Optimization, Genetic algorithm, Finite element method},
abstract = {Studies on structural optimization have gained prominence recently, and the search to consume resources in a more conscious and effective way encourages the use of such techniques in all fields. In this respect, this study aims to use computational optimization techniques to determine the maximum load-bearing capacity of hollow-core steel beams for two groups of different shear lines, one generating beams with opening in the shape of hexagons and the other having the shape of ellipses. The second group includes beams with circular openings as a particular case. A three-node triangular finite element for the analysis of structures in plane stress is used for the structural analysis of the beams. The design variables define the shape and number of opening in the beam, and a computational formulation using a genetic algorithm is presented to find the cut line that maximizes the load capacity of the beam considering different ultimate and service limit states. Numerical and experimental models in the literature are used to validate the implementations presented in this article, and the results of optimized hollow core beams are presented, demonstrating the efficiency of the formulations used.}
}
@article{PRADNYANA2025100307,
title = {An explainable ensemble model for revealing the level of depression in social media by considering personality traits and sentiment polarity pattern},
journal = {Online Social Networks and Media},
volume = {46},
pages = {100307},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2025.100307},
url = {https://www.sciencedirect.com/science/article/pii/S2468696425000084},
author = {Gede Aditra Pradnyana and Wiwik Anggraeni and Eko Mulyanto Yuniarno and Mauridhi Hery Purnomo},
keywords = {Explainable ensemble model, Personality trait, Sentiment polarity pattern, RoBERTa, Hybrid RF-BiLSTM},
abstract = {Early detection of depression in mental health is crucial for better intervention. Social media has been extensively used to examine users’ behavior, motivating researchers to develop an automatic depression detection model. However, the accuracy and clarity of the reasons behind the detection results still need to be improved. Current research focuses primarily on syntactic and semantic information in user-posted texts, while other aspects of users’ psychological characteristics are often overlooked. Therefore, this study addresses the gap by proposing a novel model integrating personality traits and sentiment polarity patterns into an explainable ensemble model. Specifically, we developed two base learners for the averaged and meta-ensemble learning strategy. The first learner employed the Robustly Optimized BERT Pre-training Approach (RoBERTa). For the second learner, we combined the Random Forest and Bidirectional Long Short-Term Memory (RF-BiLSTM) methods to effectively handle the combination of personality traits and sequential information in sentiment polarity patterns. These additional features are obtained by performing domain adaptation for personality prediction and sentiment analysis using a lexicon-based model. Based on the experimental results, our ensemble model improved depression detection results by leveraging the strengths of each base learner. Our model advanced the state-of-the-art, outperforming existing models with an increase in accuracy and F1-score of 4.14% and 2.99%, respectively. The model successfully enhanced the interpretability of detection results, providing a more comprehensive understanding of the factors underlying depressive symptoms. This research highlights the potential of considering alternative additional features as a promising avenue for enhancing depression detection in social media.}
}
@article{PRINSLOO2021101515,
title = {Sustainability assessment framework and methodology with trans-disciplinary numerical simulation model for analytical floatovoltaic energy system planning assessments},
journal = {Sustainable Energy Technologies and Assessments},
volume = {47},
pages = {101515},
year = {2021},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101515},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821005269},
author = {F.C. Prinsloo and Peter Schmitz and Andrea Lombard},
keywords = {Floatovoltaic system synthesis, WELF-nexus environmental profiling, Sustainability profiling, Floating solar simulation model, FPV sustainability assessment},
abstract = {Floatovoltaics is rapidly emerging as a novel type of sustainable energy technology, in which solar photovoltaic installations are sited directly on open-water spaces. As an agro-renewable energy-generation technology, it makes dual use of water to generate revenue from under-utilised irrigation water surfaces while also offering mutually beneficial layers of land-saving, environmental conservation and water-preservation benefits. Standardised metrics for ground-mounted photovoltaic projects, however, do not properly account for the technology’s extended range of resource-use-efficiencies and impact-effect-positives. Such knowledge gaps hinder evidence-based scientific assessments in regulatory project permissions mandated by law. Technology planning and impact assessment practices can benefit from a computer-aided technique to characterise floatovoltaic performance profiles. This paper introduces a conceptual empirical modelling framework, a holistic system dynamics-thinking methodology and a computer synthesis model to empirically predict the performance and sustainability profiles of prospective floatovoltaic installations. By inherently exploring the techno-economic and techno-environmental externalities of floatovoltaic enterprises, it translates performance profiles into sustainability indicators, articulated as WELF-nexus parameters. The paper details the integrated analytical framework, mathematical modelling formulation and digital computer synthesis model towards quantitative floatovoltaic energy system planning and sustainability assessments. The study’s main finding is that an integrated techno-enviro-economic floatovoltaic assessment methodology can be successfully modelled as a context-sensitive synthesis technique in a system dynamics modelling environment. The proposed technique can find utility in solving real-world problems with assessments in efficiency, feasibility and sustainability for agricultural floatovoltaics.}
}
@article{DING2024120338,
title = {Next generation of computer vision for plant disease monitoring in precision agriculture: A contemporary survey, taxonomy, experiments, and future direction},
journal = {Information Sciences},
volume = {665},
pages = {120338},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120338},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524002512},
author = {Weiping Ding and Mohamed Abdel-Basset and Ibrahim Alrashdi and Hossam Hawash},
keywords = {Computer vision, Deep learning, Convolutional neural networks (CNNs), Vision transformers, Vision MLPs, Plant recognition, Precision agriculture},
abstract = {Efficient and rational monitoring of plant health is an essential prerequisite for ensuring optimal crop production and resource management in the field of agriculture. Computer vision techniques have revolutionized visual disease monitoring with their exceptional visual recognition performance. However, despite the outstanding results, the widespread acceptance of these methods in agriculture practice is still in its early stages. This study presents a comprehensive survey of the next generation of computer vision models applied to plant disease monitoring in precision agriculture. Our study begins by tracing the evolution of agricultural computer vision research over the past decade, encompassing legacy methods such as convolutional neural networks (CNNs), progressing to newer techniques like vision transformers (ViTs), and culminating in cutting-edge vision multi-layer perceptrons (MLPs). Next, our study embraces both qualitative and quantitative approaches, supporting a profound review of literature and classifying methodologies and experimental approaches. A significant contribution lies in our comprehensive taxonomy, offering a fine-grained categorization of current computer vision models. This taxonomy meticulously highlights the potentials and limitations of these models while explaining their roles in improving plant disease management. Moreover, extensive experimental comparisons are conducted on PlantVillage dataset to evaluate the performance of state-of-the-art computer-vision models for plant recognition data. The obtained results are then utilized to draw insightful conclusions about the behavior of these models and provide guidance for selecting the most suitable one for specific tasks at hand. Additionally, we discuss open research avenues and future directions of computer-vision models in plant disease management including challenges related to the data scarcity, the computational efficiency, need for explainability, and multi-modal analysis.}
}
@article{KUMAR202415,
title = {Hybrid approach of type-2 fuzzy inference system and PSO in asthma disease},
journal = {Clinical eHealth},
volume = {7},
pages = {15-26},
year = {2024},
issn = {2588-9141},
doi = {https://doi.org/10.1016/j.ceh.2024.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2588914124000017},
author = {Tarun Kumar and Anirudh {Kumar Bhargava} and M.K. Sharma and Nitesh Dhiman and Neha Nain},
keywords = {Asthma, Type-2 fuzzy set, Type-2 fuzzy optimized system, Particle swarm optimization, Medical diagnostic},
abstract = {This research work presents a hybrid approach combining a type-2 fuzzy inference system with particle swarm optimization (PSO) to develop a type-2 fuzzy optimized inference system, specifically tailored for asthma patient data. Addressing the inherent uncertainty in medical diagnostics, this model enhances traditional type-1 fuzzy logic by incorporating ambiguity into linguistic variables and utilizing type-2 fuzzy if-then rules. The system is trained to minimize diagnostic error in asthma disease identification. Applied to a dataset comprising eight medical entities from asthma patients, the model demonstrates substantial accuracy improvements. Numerical computations validate the system, showing a decrease in error rate from 1.445 to 0.03, indicating a significant enhancement in diagnostic precision. These results underscore the potential of our model in medical diagnostic problems, providing a novel and effective tool for tackling the complexities of asthma diagnosis.}
}
@incollection{BENTHEM1989331,
title = {Semantic Parallels in Natural Language and Computation},
editor = {H.-D. Ebbinghaus and J. Fernandez-Prida and M. Garrido and D. Lascar and M. Rodriquez Artalejo},
series = {Studies in Logic and the Foundations of Mathematics},
publisher = {Elsevier},
volume = {129},
pages = {331-375},
year = {1989},
booktitle = {Logic Colloquium'87},
issn = {0049-237X},
doi = {https://doi.org/10.1016/S0049-237X(08)70133-2},
url = {https://www.sciencedirect.com/science/article/pii/S0049237X08701332},
author = {Johan van Benthem},
abstract = {Publisher Summary
This chapter describes two major themes: (1) techniques for local strengthening of logical inference via minimization of models and (2) the more general dynamics of progressive handling of information in interpretation and argument. The chapter provides a coherent pattern behind some recent developments in these areas and discusses their value as affecting logic in general. The chapter also provides a mathematical analysis of the minimization operator on classes of models while also investigating several special systems in which minimal models play a central role. The chapter develops an analogy with earlier work in the philosophy of science on so-called “Ramsey eliminability” of theoretical terms in scientific theories. A technical connection is found between the general inferential properties of circumscription and more traditional conditional logic. It considers possible reductions of circumscriptive inference to standard first-order logic, establishing a high complexity for the question just when this is possible. The chapter reviews a number of results on dynamical semantics and several reductions of proposed dynamic systems to standard first-order logic. The latter system provides a promising tool for investigating dynamic modes of handling propositions.}
}
@article{WELLMAN1991205,
title = {The ecology of computation: B.A. Huberman, ed.},
journal = {Artificial Intelligence},
volume = {52},
number = {2},
pages = {205-218},
year = {1991},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(91)90044-K},
url = {https://www.sciencedirect.com/science/article/pii/000437029190044K},
author = {Michael P. Wellman}
}
@article{FEIZABADI2024103461,
title = {When and under what conditions ambidextrous supply chains prove effective? Insights from simulation and empirical studies},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {183},
pages = {103461},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103461},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524000516},
author = {Javad {Feiz Abadi} and David M. Gligor and Somayeh {Alibakhshi Motlagh} and Raj Srivastava},
keywords = {Supply Chain Archetype, Ambidexterity, NK modeling, Paradoxes},
abstract = {Our research delves into the impact of ambidextrous supply chain activity configurations on performance, particularly in the dynamic and complex contexts of today's business landscape. Drawing from the rich literature on paradox theory, we aim to unravel the efficacy of ambidextrous supply chain setup in mitigating the tensions inherent in managing dynamism, complexities, munificence, and, as well as understanding the contextual factors that modulate this efficacy. To accomplish this, we construct a computational model that captures the resource allocation and search behavior of the ambidextrous supply chain archetype within the ever-shifting terrain of performance. Our findings reveal that ambidextrous supply chain configurations excel at reconciling paradoxical tensions stemming from high complexity, limited resource abundance, and turbulent market conditions. Empirical data substantiate these findings.}
}
@article{CHAIARWUT2025101338,
title = {Enhancing executive mathematics problem-solving through a constructivist digital learning platform: Design, development and evaluation},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101338},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101338},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000658},
author = {Supaluk Chaiarwut and Sanit Srikoon and Apirat Siritaratiwat and Parama Kwangmuang},
keywords = {Learning innovation, Digital platform, Mathematics problem solving},
abstract = {Recent international assessments have highlighted a global decline in mathematics performance, particularly among students in Thailand. This study aims to (1) design and evaluate a constructivist learning innovation model on a digital platform that promotes executive mathematics problem-solving and (2) develop and assess a prototype based on the designed model. A mixed-method research design was employed across two phases. Phase 1 involved designing and evaluating the learning model through document analysis and expert validation (n = 9). Phase 2 focused on developing and testing a prototype with experts (n = 15) and students (n = 30). Data collection utilized the Index of Item-Objective Congruence (IOC), System Usability Scale (SUS), and User Engagement Scale (UES). The model showed strong alignment with theoretical principles (IOC = 0.84). The prototype showed excellent usability (SUS = 91.0/100) and high engagement (UES = 4.26/5.00). Expert evaluations indicated high quality in content (M = 4.47, SD = 0.48), media (M = 4.40, SD = 0.50), and innovation design (M = 4.59, SD = 0.64). The findings validate the model's efficacy in promoting executive mathematics problem-solving skills through a constructivist digital platform approach.}
}
@article{RIZZOLATTI1997562,
title = {Parietal cortex: from sight to action},
journal = {Current Opinion in Neurobiology},
volume = {7},
number = {4},
pages = {562-567},
year = {1997},
issn = {0959-4388},
doi = {https://doi.org/10.1016/S0959-4388(97)80037-2},
url = {https://www.sciencedirect.com/science/article/pii/S0959438897800372},
author = {Giacomo Rizzolatti and Leonardo Fogassi and Vittorio Gallese},
abstract = {Recent findings have altered radically our thinking about the functional role of the parietal cortex. According to this view, the parietal lobe consists of a multiplicity of areas with specific connections to the frontal lobe. These areas, together with the frontal areas to which they are connected, mediate distinct sensorimotor transformations related to the control of hand, arm, eye or head movements. Space perception is not unitary, but derives from the joint activity of the fronto-parietal circuits that control actions requiring space computation.}
}
@article{COIERA2022100860,
title = {Evidence synthesis, digital scribes, and translational challenges for artificial intelligence in healthcare},
journal = {Cell Reports Medicine},
volume = {3},
number = {12},
pages = {100860},
year = {2022},
issn = {2666-3791},
doi = {https://doi.org/10.1016/j.xcrm.2022.100860},
url = {https://www.sciencedirect.com/science/article/pii/S2666379122004244},
author = {Enrico Coiera and Sidong Liu},
keywords = {evidence-based medicine, evidence synthesis, patient safety, research replication, machine learning, algorithmic transportability, deep learning, clinical trial registries},
abstract = {Summary
Healthcare has well-known challenges with safety, quality, and effectiveness, and many see artificial intelligence (AI) as essential to any solution. Emerging applications include the automated synthesis of best-practice research evidence including systematic reviews, which would ultimately see all clinical trial data published in a computational form for immediate synthesis. Digital scribes embed themselves in the process of care to detect, record, and summarize events and conversations for the electronic record. However, three persistent translational challenges must be addressed before AI is widely deployed. First, little effort is spent replicating AI trials, exposing patients to risks of methodological error and biases. Next, there is little reporting of patient harms from trials. Finally, AI built using machine learning may perform less effectively in different clinical settings.}
}
@article{ROBSON2022101018,
title = {Searching for the principles of a less artificial A.I.},
journal = {Informatics in Medicine Unlocked},
volume = {32},
pages = {101018},
year = {2022},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2022.101018},
url = {https://www.sciencedirect.com/science/article/pii/S2352914822001617},
author = {B. Robson and G. Ochoa-Vargas},
keywords = {AI, Algorithms, X factor, Emergent properties, Consciousness, Quantum effects},
abstract = {What would it take to build a computer physician that can take its place amongst human peers? Currently, Neural Nets, especially as so-called “Deep Learning” nets, dominate what is popularly called “Artificial Intelligence”, but to many critics they seem to be little more than powerful data-analytic tools inspired by some of the more basic functions and regions of the human brain such as those involved in early processes in biological vision, classification, and categorization. The deeper nature of human intelligence as the term is normally meant, including relating to consciousness, has been the domain of philosophers, psychologists, and some neuroscientists. Now, attention is turning to neuronal mechanisms in humans and simpler organisms as a basis of a truer AI with far greater potential. Arguably, the approach required should be rooted in information theory and algorithmic science. But as discussed in this paper, caution is required: “just any old information” might not do. The information might need to be of a particular dynamical and actioning nature, and that might significantly impact the kind of computation and computer hardware required. Overall, however, the authors do not favor emergent properties such as those based on complexity and quantum effects. Despite the possible difficulties, such studies could, in return, have substantial benefits for biology and medicine beyond the computational tools that they produce to serve those disciplines.}
}
@incollection{MENAMADATHIL202463,
title = {Chapter 4 - Machine learning approach for vaccine development-fundamentals},
editor = {Jayashankar Das and Sushma Dave and Siomar de Castro Soares and Sandeep Tiwari},
booktitle = {Reverse Vaccinology},
publisher = {Academic Press},
pages = {63-85},
year = {2024},
isbn = {978-0-443-13395-4},
doi = {https://doi.org/10.1016/B978-0-443-13395-4.00025-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443133954000253},
author = {Dhanalakshmi Menamadathil and Kajari Das and Sushma Dave and Jayashankar Das},
keywords = {Artificial intelligence, machine learning, support vector machine, logistic regression, extreme gradient boosting, convolutional neural network, recurrent neural networks, reverse vaccinology},
abstract = {Artificial intelligence (AI)–assisted vaccine creation has emerged as a significant development among the cutting-edge technologies that will help society in the 21st century. AI and machine learning technologies have brought answers to issues that have arisen as a result of the advent of recurring and emerging infectious diseases and the rise in antibiotic resistance. The rapid discovery of effective vaccines has been crucial in preparation for outbreaks, including epidemics and pandemics. The urgent requirement for precise vaccine creation in a short duration has led the way for researchers to investigate diverse vaccine-development technologies such as computational biology, structure-based antigen design, protein engineering, gene synthesis, and novel manufacturing platforms, With the advent of whole-genome sequencing and big data analytic platforms aided by AI, omics-based vaccine design has emerged, which is also known as reverse vaccinology (RV). RV accomplishes comprehensive immunogenicity profiling employing proteome and structural data. With the advancement of AI and deep learning algorithms, a range of modeling tools for accurate and precise prediction of immune-recognition patterns have been created, which may be utilized to generate novel vaccine candidates. Given that vaccinations are available for a few infectious illnesses, there is an urgent need for the quick development of vaccines for numerous lethal and developing infections, which can give prominence to RV. Within the course of this chapter, a thorough view of AI -employed algorithms and their role in RV is offered, with a particular emphasis on immunoinformatic and AI methods utilized in it.}
}
@article{WANG2022799,
title = {BMW-TOPSIS: A generalized TOPSIS model based on three-way decision},
journal = {Information Sciences},
volume = {607},
pages = {799-818},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522006004},
author = {Yumei Wang and Peide Liu and Yiyu Yao},
keywords = {Three-way decision, TOPSIS, Reference point, Multiple attribute decision making},
abstract = {TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) uses a pair of a positive ideal solution and a negative ideal solution as two reference points to rank a set of decision alternatives. In some situations, a trade-off of the distances to the two extreme reference points may not necessarily be meaningful. Inspired by the theory of three-way decision as thinking in threes (e.g., two opposite poles and a third middle), in this paper we generalize the classical TOPSIS by adding a third middle reference point. We use a common setting for investigating systematically reference-point-based TOPSIS-style multi-criteria decision-making methods. In particular, we examine three classes of approaches: a) a best reference point based model (i.e., B-TOPSIS) and a worst reference point based model (i.e., W-TOPSIS), b) the classical best and worst reference points based model (i.e., BW-TOPSIS), and c) a new best, mean, and worst reference points based model (i.e., BMW-TOPSIS). The three classes are one-way TOPSIS, two-way TOPSIS, and three-way TOPSIS, respectively. Based on one-way and two-way TOPSISs, we give two specific methods of three-way TOPSIS. The experimental results, compared with the existing TOPSIS methods, show that the BMW-TOPSIS model is feasible and effective.}
}
@article{AICHA2022107933,
title = {A mathematical formulation for processing time computing in disassembly lines and its optimization},
journal = {Computers & Industrial Engineering},
volume = {165},
pages = {107933},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.107933},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222000031},
author = {Mahdi Aicha and Imen Belhadj and Moncef Hammadi and Nizar Aifaoui},
keywords = {DP Evaluation, Index of Quality, Operating time, Optimization, Lean thinking},
abstract = {Disassembly is the first practice in maintenance and recycling of industrial products. For productivity and efficiency, it is necessary to optimize its operative manners by reducing: change of tools and directions, process variation, wastes, etc. The simulation of Disassembly Plan (DP) allows the detection and identification of difficulties from the design stage in order to avoid them. This paper proposes a mathematical formulation which combines two principal indicators: the index of Quality (Qi) and the index of processing Time (Ti) in order to choose the best and feasible disassembly plan. The Failure Mode, Effects and Criticality Analysis method is implemented to compute Qi. Ti is obtained according to real manufacturing constraints (workspace, layout, tools, machines, etc.). Based on 5S method, the workspace can be optimized which directly impacts the timing index and contribute to the selection of the best DP. A gear box is used to show up the efficiency of the proposed approach.}
}
@article{SHARMA2024100944,
title = {Towards intelligent industrial systems: A comprehensive survey of sensor fusion techniques in IIoT},
journal = {Measurement: Sensors},
volume = {32},
pages = {100944},
year = {2024},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100944},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423002805},
author = {Deepak sharma and Anuj kumar and Nitin Tyagi and Sunil S. Chavan and Syam Machinathu Parambil Gangadharan},
keywords = {Sensor fusion, Machine learning, Fault tolerance, Fault prediction, Neural network},
abstract = {Industrial Internet of Things (IIoT) is systems aim to facilitate human monitoring and the direction of efficient production of goods in industrial settings by linking a wide variety of intelligent devices such as sensors, actuators, and controllers. This is achieved by utilizing Internet of Things (IoT) to diagnose a problem with a specific IIoT part is to employ a basic diagnostic technique that's based on models and data. Physical models, signal patterns, and machine-learning strategies must be adequately built to account for system challenges. Another factor that could lead to an exponential rise in complexity is the ever-increasing interconnections between different electronic hardware. The knowledge-based defect diagnosis methods boost interoperability in the operation. Users don't need to be experts in the field to benefit from the system's high-level thinking and response to their queries. So, in advanced IIoT systems, a knowledge-based fault diagnostic approach is favored over traditional model-based and data-driven diagnosis methods. The goal of this study is to evaluate recent improvements in the design of knowledge-based defect detection in the context of IIoT systems, deductive and inductive reasoning, and many other forms of logical reasoning. IIoT-based systems have revolutionized industrial settings by connecting intelligent devices such as sensors, actuators, and controllers to enable efficient production and human monitoring. In this survey paper, we explore machine learning-based sensor fusion techniques within the realm of Industrial Internet of Things (IIoT), addressing critical challenges in fault detection and diagnosis.}
}
@article{LI2025108,
title = {Enhancing energy materials with data-driven methods: A roadmap to long-term hydrogen energy sustainability using machine learning},
journal = {International Journal of Hydrogen Energy},
volume = {119},
pages = {108-125},
year = {2025},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2025.03.201},
url = {https://www.sciencedirect.com/science/article/pii/S0360319925013151},
author = {Cheng Li and Jianjun Ma and Des Gibson and Yijun Yan and Muhammad Haroon and Mehak {Bi Bi}},
keywords = {Hydrogen energy, Machine learning, Data driven, Artificial intelligence, Energy materials},
abstract = {In the past few years, there has been a lot of interest in studying new substances and figuring out how their structure affects their activity. This is seen as an alternative to the problems that come with traditional methods of making energy materials, like the high cost of computation, the time consumption, and the low success rate. Improving the study and production of energy materials requires new research, ideas, and methodologies. Some believe that data-driven materials science, enabled by recent advances in artificial intelligence (AI) and machine learning (ML), might modify current scientific knowledge and radically alter the production of energy materials. This includes essential advancements in hydrogen energy, like creating catalysts for producing hydrogen, finding materials for storing hydrogen, and improving fuel cell components. New findings in data-driven materials science suggest that ML technologies enable the development, identification and deployment of improved energy materials while simultaneously making their creation and improvement less of a hassle. This paper argues that funding research into alternative energy materials is an important first step towards achieving global carbon neutrality. Also included is a comprehensive ML concept overview covering topics like open-source databases, feature development, ML algorithms, and ML model assessment, among others. We discuss the modern developments in data-driven material sciences (DDMS) and technology, which cover topics such as materials for alkaline ion batteries, solar energy catalysis, and carbon dioxide recovery. This section concludes with some important ideas for making effective use of ML and some additional difficulties in creating new energy materials.}
}
@article{GINEITYTE1999205,
title = {On the future of the Hückel model},
journal = {Journal of Molecular Structure: THEOCHEM},
volume = {491},
number = {1},
pages = {205-209},
year = {1999},
issn = {0166-1280},
doi = {https://doi.org/10.1016/S0166-1280(99)00116-5},
url = {https://www.sciencedirect.com/science/article/pii/S0166128099001165},
author = {V. Gineityte},
keywords = {Basis orbitals, Hückel model, Hamiltonian matrix},
abstract = {In an attempt to foresee the prospects of the qualitative trend in quantum chemistry, the place of the Hückel model is analyzed in the broad context of quantum mechanical and chemical perspectives on the molecular world. Quantum mechanics and chemistry are considered as complementary approaches to molecular structure and properties that are irreducible one to another. Arguments are given for the hypothesis that the Hückel model makes a separate level of investigation of molecules situated in between quantum mechanics and chemistry. In this context, the need is emphasized for development of new concepts immanent in the very Hückel model. These concepts are anticipated to play the role of terms for qualitative orbital thinking, the persistent need for which was emphasized recently (R. Hoffmann, J. Mol. Struct. (Theochem), 424 (1998) 1).}
}
@article{RICAURTE2020102,
title = {Project-based learning as a strategy for multi-level training applied to undergraduate engineering students},
journal = {Education for Chemical Engineers},
volume = {33},
pages = {102-111},
year = {2020},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2020.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772820300464},
author = {Marvin Ricaurte and Alfredo Viloria},
keywords = {Project-based learning, Multi-level, Undergraduate students, Process engineering},
abstract = {This study presents a project-based learning methodology whose particularity is the inclusion of training at different levels of undergraduate engineering programs, which allows for the interaction among students from different semesters who work together on a common project. To show the applicability of the proposed methodology, a project for the industrial production of ethanol from sugar cane was considered. Students enrolled in Process Design (9th semester) and Computer-Assisted Technical Design (5th semester), courses included in the engineering programs offered by the Department of Chemical Engineering at Yachay Tech University (Ecuador), jointly developed it. The details of the project were presented to the students of the Introduction to Engineering course (3rd semester) to boost their interest in the engineering as applied science. The activities carried out in each of the courses are described in detail together with a description of how the learning outcomes were achieved thanks to the implementation of a multi-level training strategy. Teamwork and collaborative-integrated learning are the elements highlighted by the students who participated in the project. Some of the innovative aspects of the proposed methodology include professional training and multi-level learning, the development of logical thinking typical of engineers, the knowledge handover associated with the professional activities of process engineers engaged with real-world projects. Additionally, this methodology prizes the industrial experience that professors at the undergraduate level may have by allowing them to contribute with an engineering vision to the training of young people in engineering projects. This study was inspired by the principle of Constructive Alignment and by goal # 4 (quality education) of the 2030 Agenda for Sustainable Development.}
}
@article{FROWNFELTERLOHRKE201768,
title = {Teaching good Excel design and skills: A three spreadsheet assignment project},
journal = {Journal of Accounting Education},
volume = {39},
pages = {68-83},
year = {2017},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2016.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575115300403},
author = {Cynthia {Frownfelter- Lohrke}},
keywords = {Excel, Spreadsheets, Spreadsheet design, Active learning, Project-based learning},
abstract = {Over sixty percent of AIS courses cover Excel because it is an important tool for accounting students to learn and master. Although spreadsheet programs like Excel provide powerful analytical tools for business, in practice, they are often created and used by people with minimal programming experience. Consequently, users can often develop spreadsheets containing critical errors, which, in turn, can cause significant losses for their businesses. Errors can be reduced, however, by learning and employing good spreadsheet design techniques. Good spreadsheet design also makes it easier to update and continue to use a spreadsheet over time. This paper describes a method for teaching spreadsheet design where students complete three spreadsheet assignments in an iterative and repetitive process. By the time students have completed these assignments, they will have acquired good spreadsheet design skills and improved their basic Excel skills.}
}
@article{ZHAO2013278,
title = {An intelligent chiller fault detection and diagnosis methodology using Bayesian belief network},
journal = {Energy and Buildings},
volume = {57},
pages = {278-288},
year = {2013},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2012.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0378778812005968},
author = {Yang Zhao and Fu Xiao and Shengwei Wang},
keywords = {Fault detection, Fault diagnosis, Centrifugal chiller, Bayesian network},
abstract = {A generic intelligent fault detection and diagnosis (FDD) strategy is proposed in this study to simulate the actual diagnostic thinking of chiller experts. A three-layer Diagnostic Bayesian Network (DBN) is developed to diagnose chiller faults based on the Bayesian Belief Network (BBN) theory. The structure of the DBN is a graphical and qualitative illustration of the intrinsic causal relationships among causal factors in Layer 1, faults in Layer 2 and fault symptoms in Layer 3. The parameters of the DBN represent the quantitative probabilistic relationships among the three layers. To diagnose chiller faults, posterior probabilities of the faults under observed evidences are calculated based on the probability analysis and the graph theory. Compared with other FDD strategies, the proposed strategy can make use of more useful information of the chiller concerned and expert knowledge. It is effective and efficient in diagnosing faults based on uncertain, incomplete and conflicting information. Evaluation of the strategy was made on a 90-ton water-cooled centrifugal chiller reported in ASHRAE RP-1043.}
}
@article{NAKAMURA20091639,
title = {A shift of mind – Introducing a concept creation model},
journal = {Information Sciences},
volume = {179},
number = {11},
pages = {1639-1646},
year = {2009},
note = {Including Special Issue on Chance Discovery},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2008.11.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025508004933},
author = {Jun Nakamura and Yukio Ohsawa},
keywords = {Creativity, Concept, Ambiguity and constraint},
abstract = {The ability to construct concepts is indispensable to both individual and evolutionary development. Our model involves the use of ambiguous stimuli to facilitate decision-making by promoting analogical reasoning. Toward this end, we have developed Web-based exercises in word categorization for the purpose of engaging participants in analogical reasoning that contributes to the integration of words and leads to the construction of new concepts. 12 graduate students and 20 junior high school students were presented with ambiguous information for the purpose of comparison between the senior and the junior students. We hypothesized that the senior students tend to behave with more insight rather than junior students with less activation of thought process. Our results suggested that the presentation of the ambiguous stimuli were associated with unique thought processes, which are consistent with approaches to word categorization that reflect either the experience of insight or the operation of a trial and error strategy, depending on the junior or the senior students. We showed that the senior students tend to be more like insight into categorization design, while the junior as rather try and error behavior, in consideration of needed time and actions in analogical thinking.}
}
@article{LEVESQUE201427,
title = {On our best behaviour},
journal = {Artificial Intelligence},
volume = {212},
pages = {27-35},
year = {2014},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2014.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0004370214000356},
author = {Hector J. Levesque},
keywords = {IJCAI Research Excellence},
abstract = {The science of AI is concerned with the study of intelligent forms of behaviour in computational terms. But what does it tell us when a good semblance of a behaviour can be achieved using cheap tricks that seem to have little to do with what we intuitively imagine intelligence to be? Are these intuitions wrong, and is intelligence really just a bag of tricks? Or are the philosophers right, and is a behavioural understanding of intelligence simply too weak? I think both of these are wrong. I suggest in the context of question-answering that what matters when it comes to the science of AI is not a good semblance of intelligent behaviour at all, but the behaviour itself, what it depends on, and how it can be achieved. I go on to discuss two major hurdles that I believe will need to be cleared.}
}
@article{CLEMENTZ2020808,
title = {Testing Psychosis Phenotypes From Bipolar–Schizophrenia Network for Intermediate Phenotypes for Clinical Application: Biotype Characteristics and Targets},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {5},
number = {8},
pages = {808-818},
year = {2020},
note = {Understanding the Nature and Treatment of Psychopathology: Letting the Data Guide the Way},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2020.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S2451902220301002},
author = {Brett A. Clementz and Rebekah L. Trotti and Godfrey D. Pearlson and Matcheri S. Keshavan and Elliot S. Gershon and Sarah K. Keedy and Elena I. Ivleva and Jennifer E. McDowell and Carol A. Tamminga},
keywords = {Biomarkers, Computational neuroscience, Neurobiological, Precision medicine, Psychopathology, Transdiagnostic},
abstract = {Background
Psychiatry aspires to the molecular understanding of its disorders and, with that knowledge, to precision medicine. Research supporting such goals in the dimension of psychosis has been compromised, in part, by using phenomenology alone to estimate disease entities. To this end, we are proponents of a deep phenotyping approach in psychosis, using computational strategies to discover the most informative phenotypic fingerprint as a promising strategy to uncover mechanisms in psychosis.
Methods
Doing this, the Bipolar–Schizophrenia Network for Intermediate Phenotypes (B-SNIP) has used biomarkers to identify distinct subtypes of psychosis with replicable biomarker characteristics. While we have presented these entities as relevant, their potential utility in clinical practice has not yet been demonstrated.
Results
Here we carried out an analysis of clinical features that characterize biotypes. We found that biotypes have unique and defining clinical characteristics that could be used as initial screens in the clinical and research settings. Differences in these clinical features appear to be consistent with biotype biomarker profiles, indicating a link between biological features and clinical presentation. Clinical features associated with biotypes differ from those associated with DSM diagnoses, indicating that biotypes and DSM syndromes are not redundant and are likely to yield different treatment predictions. We highlight 3 predictions based on biotype that are derived from individual biomarker features and cannot be obtained from DSM psychosis syndromes.
Conclusions
In the future, biotypes may prove to be useful for targeting distinct molecular, circuit, cognitive, and psychosocial therapies for improved functional outcomes.}
}
@article{SALEMDEEB2022200069,
title = {Beyond recycling: An LCA-based decision-support tool to accelerate Scotland's transition to a circular economy},
journal = {Resources, Conservation & Recycling Advances},
volume = {13},
pages = {200069},
year = {2022},
issn = {2667-3789},
doi = {https://doi.org/10.1016/j.rcradv.2022.200069},
url = {https://www.sciencedirect.com/science/article/pii/S2667378922000074},
author = {Ramy Salemdeeb and Ruth Saint and Francesco Pomponi and Kimberley Pratt and Michael Lenaghan},
keywords = {Life cycle assessment, Policy development, Resource and waste management, Circular economy, Zero waste},
abstract = {Resources and waste strategies have recently seen a shift in focus from weight-based recycling targets to impact-driven policies. To support this transition, numerous decision-support tools were developed to help identify waste streams with the highest impacts. However, the majority of these tools focus solely on greenhouse gas emissions and show a narrow picture of the overall environmental impacts. Furthermore, they cover burdens associated with direct waste management activities and hence fall short when it comes to highlighting the substantial benefits that can be achieved by preventing waste in the first place. This paper quantitatively demonstrates the necessity to adopt impact-based targets that go beyond estimating the greenhouse gas emissions of waste and highlights the substantial benefits of waste reduction and prevention. Using a state-of-the-art waste environmental footprint tool, the paper quantifies the overall environmental impacts of Scotland's household waste and shows how targeting ‘heavy’ materials does not necessarily have the highest overall environmental benefit. Results show that embodied environmental impacts of household waste dominate the total environmental burdens, contributing more than 90% to the whole life cycle impacts, and hence policymakers should prioritise interventions that aim at waste reduction and prevention. Moreover, our analysis shows that food and textile wastes are high-priority materials in Scotland, with the largest contribution to overall environmental burdens; up to 42% and 30%, respectively. Considering the overall environmental impacts of specific waste materials will enable policymakers to develop more granular and targeted interventions to accelerate our transition to a sustainable circular economy.}
}
@article{BOEING2021102013,
title = {Spatial information and the legibility of urban form: Big data in urban morphology},
journal = {International Journal of Information Management},
volume = {56},
pages = {102013},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0268401219302154},
author = {Geoff Boeing},
keywords = {OpenStreetMap, Urban design, Urban form, Urban morphology, Urban planning, Visualization},
abstract = {Urban planning and morphology have relied on analytical cartography and visual communication tools for centuries to illustrate spatial patterns, conceptualize proposed designs, compare alternatives, and engage the public. Classic urban form visualizations – from Giambattista Nolli’s ichnographic maps of Rome to Allan Jacobs’s figure-ground diagrams of city streets – have compressed physical urban complexity into easily comprehensible information artifacts. Today we can enhance these traditional workflows through the Smart Cities paradigm of understanding cities via user-generated content and harvested data in an information management context. New spatial technology platforms and big data offer new lenses to understand, evaluate, monitor, and manage urban form and evolution. This paper builds on the theoretical framework of visual cultures in urban planning and morphology to introduce and situate computational data science processes for exploring urban fabric patterns and spatial order. It demonstrates these workflows with OSMnx and data from OpenStreetMap, a collaborative spatial information system and mapping platform, to examine street network patterns, orientations, and configurations in different study sites around the world, considering what these reveal about the urban fabric. The age of ubiquitous urban data and computational toolkits opens up a new era of worldwide urban form analysis from integrated quantitative and qualitative perspectives.}
}
@article{LI2025125605,
title = {Traffic scenario frozen callback and adaptive neuro-fuzzy inference system based energy management strategy for connected fuel cell buses},
journal = {Applied Energy},
volume = {387},
pages = {125605},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.125605},
url = {https://www.sciencedirect.com/science/article/pii/S0306261925003356},
author = {Menglin Li and Haoran Liu and Mei Yan and Boyu Guo and Jingda Wu and Guokai Jiang and Xupeng Fu},
keywords = {Connected fuel cell bus, Energy management strategy, Traffic scenario frozen callback, Adaptive neuro-fuzzy inference system},
abstract = {Exploring the full potential of energy savings for new energy vehicles in a future connected transportation system is a challenging task. To address how connected buses can leverage surrounding traffic information to improve their energy efficiency, an intelligent fuel cell bus energy management method based on traffic scenario frozen callback is proposed， which enables high real-time performance in online energy management. To tackle the issue of inconsistent data dimensions caused by random fluctuations in the number of vehicles in a fixed traffic flow, a traffic flow representation based on grid grayscale images is designed. Building upon this representation, a speed trajectory prediction model based on traffic scenario frozen callback is developed. Subsequently, offline historical global optimal data are used to construct a training dataset that links speed trajectories to optimal control sequences. An end-to-end energy management framework based on the adaptive neuro-fuzzy inference system (ANFIS) is presented and validated in scenarios that before entering bus station and after exiting bus station. Simulation results demonstrate that, the proposed energy management strategy (EMS) approaches the overall energy consumption of dynamic programming (DP), reaching 97.76 % and 98.82 % in the two kinds of scenarios of its performance, outperforms the other two comparative EMSs. In terms of timeliness, the computational time spent by the proposed EMS is only 0.2076 times and 0.1952 times that of traditional model predictive control (MPC)-based EMS in the separate scenario.}
}
@article{CAUDEK2021317,
title = {Susceptibility to eating disorders is associated with cognitive inflexibility in female university students},
journal = {Journal of Behavioral and Cognitive Therapy},
volume = {31},
number = {4},
pages = {317-328},
year = {2021},
issn = {2589-9791},
doi = {https://doi.org/10.1016/j.jbct.2021.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2589979121000159},
author = {Corrado Caudek and Claudio Sica and Silvia Cerea and Ilaria Colpizzi and Debora Stendardi},
keywords = {Eating disorders, Cognitive inflexibility, Individual differences, Computational modeling, Reversal learning},
abstract = {Summary
The inability to learn from and adapt to changing feedback in our environment may be etiologically linked to eating disorders (EDs). However, previous investigations on this issue have shown conflicting results. In the current study with a non-clinical sample of female students, we investigated the relation between cognitive inflexibility (CI) and vulnerability to EDs by using a modified version of the probabilistic reversal learning (PRL) task, which requires participants to adapt their response strategy according to changes in stimulus-reward contingencies. We found that females vulnerable to EDs in the general population showed an impaired PRL performance, also after controlling for comorbidity. However, our results also show that the ED construct comprises separate dimensions, which affect contingency learning in opposite manners: some individuals vulnerable to EDs showed impaired contingency learning; others used unimpaired contingency learning skills to pursue self-harming goals. Such results point to the necessity of an appropriate assessment of CI in order to better apply individualized treatment.}
}
@article{ANDROUTSOPOULOS2023141,
title = {Punctuating the other: Graphic cues, voice, and positioning in digital discourse},
journal = {Language & Communication},
volume = {88},
pages = {141-152},
year = {2023},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2022.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0271530922000957},
author = {Jannis Androutsopoulos},
keywords = {Voice, Positioning, Graphic cues, <!!1!>, Reddit, Punctuation},
abstract = {This article investigates the nested relationship between graphic cues, voice, and positioning in digital discourse. The focus is on the ‘indignation mark’, or <!!1!>, an allographic sign used in German-language discussion boards on Reddit. The study's theoretical backdrop brings research on graphic practices in digitally-mediated communication into dialogue with sociolinguistic approaches to the enactment of group relations in discourse, in particular double-voicing, stylization, and positioning, thereby aiming to foster theory-building on both sides. Data is extracted from a large German-language forum (‘subreddit’) on Reddit and subjected to computational, sequential, and microlinguistic analysis. The findings show how participants in public online discussions use punctuation signs and other graphic cues to animate voices, i.e. ways of speaking that index recognizable social positions and ideologies; how these stylized voices provide a resource for positioning; and how participants display recognition of and alignment to this feature's indexical meaning. The findings also suggest that the ‘indignation mark’ is part of a wider ecology of graphic cues, which evolve constantly to enable multi-voicedness in public digital discourse. Overall, this paper aims to advance our understanding about how graphic elements of digital discourse are indexically and ideologically connected with positioning activities in online communities of practice.}
}
@article{XIE2023119,
title = {2D magnetotelluric inversion based on ResNet},
journal = {Artificial Intelligence in Geosciences},
volume = {4},
pages = {119-127},
year = {2023},
issn = {2666-5441},
doi = {https://doi.org/10.1016/j.aiig.2023.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S2666544123000266},
author = {LiAn Xie and Bo Han and Xiangyun Hu and Ningbo Bai},
keywords = {Magnetotellurics, 2D inversion, Residual network, Deep learning},
abstract = {In this study, a deep learning algorithm was applied to two-dimensional magnetotelluric (MT) data inversion. Compared with the traditional linear iterative inversion methods, the MT inversion method based on convolutional neural networks (CNN) does not rely on the selection of the initial model parameters and does not fall into the local optima. Although the CNN inversion models can provide a clear electrical interface division, their inversion results may remain prone to abrupt electrical interfaces as opposed to the actual underground electrical situation. To solve this issue, a neural network with a residual network architecture (ResNet-50) was constructed in this study. With the apparent resistivity and phase pseudo-section data as the inputs and with the resistivity parameters of the geoelectric model as the training labels, the modified ResNet-50 model was trained end-to-end for producing samples according to the corresponding production strategy of the study area. Through experiments, the training of the ResNet-50 with the dice loss function effectively solved the issue of over-segmentation of the electrical interface by the cross-entropy function, avoided its abrupt inversion, and overcame the computational inefficiency of the traditional iterative methods. The proposed algorithm was validated against MT data measured from a geothermal field prospect in Huanggang, Hubei Province, which showed that the deep learning method has opened up broad prospects in the field of MT data inversion.}
}
@article{JARLEBLAD2024108930,
title = {A framework for synthetic diagnostics using energetic-particle orbits in tokamaks},
journal = {Computer Physics Communications},
volume = {294},
pages = {108930},
year = {2024},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2023.108930},
url = {https://www.sciencedirect.com/science/article/pii/S0010465523002758},
author = {H. Järleblad and L. Stagner and M. Salewski and J. Eriksson and M. Nocente and B.S. Schmidt and M. {Rud Larsen}},
keywords = {Nuclear fusion, Fast ions, Orbits, Weight functions},
abstract = {In fusion plasma physics, the large-scale trajectories of energetic particles in magnetic confinement devices are known as orbits. To effectively and efficiently be able to work with orbits, the Orbit Weight Computational Framework (OWCF) was developed. The OWCF constitutes a set of scripts, functions and applications capable of computing, visualizing and working with quantities related to fast-ion (FI) orbits in toroidally symmetric fusion devices. The current version is highly integrated with the DRESS code, which enables the OWCF to compute and analyze the orbit sensitivity for arbitrary neutron- and gamma-diagnostics. However, the framework is modular in the sense that any future codes (e.g. FIDASIM) can be easily integrated. The OWCF can also compute projected velocity spectra for FI orbits, which play a key role in many FI diagnostics. Via interactive applications, the OWCF can function both as a tool for investigative research but also for teaching. The OWCF will be used to analyze and simulate the diagnostic results of current and future fusion experiments such as ITER. The orbit weight functions computed with the OWCF can be used to reconstruct the FI distribution in terms of FI orbits from experimental measurements using tomographic inversion.}
}
@article{TAYLOR1999943,
title = {Towards the networks of the brain: from brain imaging to consciousness},
journal = {Neural Networks},
volume = {12},
number = {7},
pages = {943-959},
year = {1999},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(99)00044-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608099000441},
author = {J.G. Taylor},
keywords = {Brain imaging, Consciousness, Structural modelling, Motion after-effect, Planning, Thinking, Self},
abstract = {The manner in which the brain computes in various tasks is being probed at a deep level by modern brain imaging techniques, with an increasing appreciation of the different networks being used to solve these tasks. There is simultaneously developing a neural modelling technology, which attempts to explain the underlying computations being performed by this set of networks. This paper describes results from brain imaging and how they may be related to the underlying neural networks by means of structural modelling. It thereby attempts to give an initial glimpse of the emerging picture of the functionality of brain networks. It concludes with a discussion of the role of consciousness in global processing, and how particular styles of neural processing can attain this.}
}
@article{RAM2022100232,
title = {The role of ‘big data’ and ‘in silico’ New Approach Methodologies (NAMs) in ending animal use – A commentary on progress},
journal = {Computational Toxicology},
volume = {23},
pages = {100232},
year = {2022},
issn = {2468-1113},
doi = {https://doi.org/10.1016/j.comtox.2022.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2468111322000202},
author = {Rebecca N. Ram and Domenico Gadaleta and Timothy E.H. Allen},
keywords = {Computational toxicology, In-silico, NAMs, New approach methodologies, Human relevant, QSAR, Read across, Chemical safety, High throughput, Adverse outcome pathways},
abstract = {In silico (computational) methods continue to evolve as part of a robust 21st century public health strategy in risk assessment, relevant to all sectors of chemical safety including preclinical drug discovery, industrial chemicals testing, food and cosmetics. Alongside in vitro methods as components of intelligent testing and pathway driven strategies, in silico models provide the potential for more human relevant solutions to the use of animals in safety testing and biomedical research. These are often termed ‘New Approach Methodologies’ (NAMs). Some NAMs incorporate the use of ‘big data’, for example the information provided from high throughput or high content in vitro screening assays or ‘omics’ technologies. Big data has increasing relevance to predictive toxicology but must be appropriately defined, particularly with regard to ‘quality vs quantity’. The purpose of this article is to provide a commentary on the progress of in silico human-based research methods within the context of NAMs, as well as discussion of the emerging use of big data with relevance to safety assessment. The current status of in silico methods is discussed, with input from researchers in the field. Scientific and legislative drivers for change are also considered, along with next steps to address challenges in funding and recognition, to achieve regulatory acceptance and uptake within the research community. To provide some wider context, the use of in silico methods alongside other relevant approaches (e.g., human-based in vitro) is also discussed.}
}
@article{LOU2023541,
title = {Human Creativity in the AIGC Era},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {9},
number = {4},
pages = {541-552},
year = {2023},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000054},
author = {Yongqi Lou},
keywords = {AIGC, Artificial intelligence, Meaning-making, Paradigmatic innovation, Human values},
abstract = {Recent advances in artificial intelligence raise profound questions for humanity. Is the artificial intelligence-generated content (AIGC) technology merely a tool? Or is AIGC developing a level of creativity comparable to that of human beings? This essay explores the challenges and opportunities that AIGC technology brings to creativity, industry, and the ways of living of people around the world. These questions involve scale, authenticity, choice, and wisdom. Further, this essay addresses the core capabilities of future creative workers in the era of AIGC. The author believes that the ability to create meaning—meaning making—is and will remain a distinctive strength of human creativity in the AIGC era. To build on this strength, human beings must focus on six key areas: human-centered values, paradigmatic innovation, holistic experiences, cultural awareness, situational connections, and narrative reasoning. The best outcome for the AIGC is to make machines more machine-like and humans more human. Achieving this goal requires a cultural renaissance. We must break through the limits of computational rationality with the brilliance of humanity.}
}
@incollection{MOUSTAFA202149,
title = {3 - Deductive reasoning abilities in schizophrenia and related disorders: A systematic review},
editor = {Ahmed A. Moustafa},
booktitle = {Cognitive and Behavioral Dysfunction in Schizophrenia},
publisher = {Academic Press},
pages = {49-65},
year = {2021},
isbn = {978-0-12-820005-6},
doi = {https://doi.org/10.1016/B978-0-12-820005-6.00004-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128200056000049},
author = {Ahmed A. Moustafa and Anchal Garg and Ahmed A. Helal and Eid {Abo Hamza}},
keywords = {Schizophrenia, Delusions, Hallucinations, Negative symptoms, Reasoning, Transitive inference, Wason Selection Task, Syllogism, Inductive vs. deductive reasoning},
abstract = {Background: Schizophrenia is a psychiatric disorder characterized by delusions, hallucinations, negative symptoms, and disorganized thinking. There has been a multitude of studies assessing reasoning performance in schizophrenia patients by using various reasoning tasks. Methods: We reviewed the existing literature using the following reasoning tasks in schizophrenia and related disorders: Transitive Inferences, Wason Card Selection, conditional reasoning, syllogisms, and other related tasks. Results: Some deductive reasoning studies have reported conflicting results where schizophrenia patients sometimes, outperform or underperform healthy controls. These findings are related to the plausibility, emotional content of logical sentences used in these studies. Importantly, data show that performance in deductive reasoning tasks is impacted by emotional and cognitive processes, such as theory of mind and working memory. However, neural studies report different brain mechanisms underlying different deductive reasoning task performance. Conclusions: Overall, there are differences in the findings of reasoning tasks which should be investigated in future studies as it will contribute towards an accurate understanding of reasoning processes in schizophrenia spectrum and related disorders.}
}
@article{ISMAILOVA2021341,
title = {Cognitive System to Clarify the Semantic Vulnerability and Destructive Substitutions},
journal = {Procedia Computer Science},
volume = {190},
pages = {341-360},
year = {2021},
note = {2020 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: Eleventh Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.06.044},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921012898},
author = {Larisa Ismailova and Viacheslav Wolfengagen and Sergey Kosikov},
keywords = {cognitive system, information process, knowledge stage, cognitive interference, semantic web, functor-as-object, dynamics, semantic virus, variable sets, category theory},
abstract = {The development of special mathematics capable of directly taking into account the dynamics of the problem domain, as it turns out, is a non-trivial task. Its very formulation in a refined form and the fixation of the most important features cause noticeable complications in the target formalism, significantly complicating the development of software. A constructive solution to this problem is given, obtained using the original functor-as-object construction. The concept of semantic viralization is introduced. It is expected that the obtained computational model has a high innovative potential for the development of information systems designed for intensive data exchange.}
}
@article{JIANG2021116441,
title = {Impacts of COVID-19 on energy demand and consumption: Challenges, lessons and emerging opportunities},
journal = {Applied Energy},
volume = {285},
pages = {116441},
year = {2021},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.116441},
url = {https://www.sciencedirect.com/science/article/pii/S030626192100009X},
author = {Peng Jiang and Yee Van Fan and Jiří Jaromír Klemeš},
keywords = {COVID-19, Energy impacts, Environmental impacts, Energy recovery, Lessons, Emerging opportunities},
abstract = {COVID-19 has caused great challenges to the energy industry. Potential new practices and social forms being facilitated by the pandemics are having impacts on energy demand and consumption. Spatial and temporal heterogeneities of impacts appear gradually due to the dynamics of pandemics and mitigation measures. This paper overviews the impacts and challenges of COVID-19 pandemics on energy demand and consumption and highlights energy-related lessons and emerging opportunities. The discussion on energy-related issues is divided into four main sections: emergency situation and its impacts, environmental impacts and stabilising energy demand, recovering energy demand, and lessons and emerging opportunities. The changes in energy requirements are compared and analysed from multiple perspectives according to available data and information. In general, although the overall energy demand declines, the spatial and temporal variations are complicated. The energy intensity has presented apparent changes, the extra energy for COVID-19 fighting is non-negligible for stabilising energy demand, and the energy recovery in different regions presents significant differences. A crucial issue has been to allocate and find energy-related emerging opportunities for the post pandemics. This study could offer a direction in opening new avenues for increasing energy efficiency and promoting energy saving.}
}
@article{HAUSER201778,
title = {The Universal Generative Faculty: The source of our expressive power in language, mathematics, morality, and music},
journal = {Journal of Neurolinguistics},
volume = {43},
pages = {78-94},
year = {2017},
note = {Language Evolution: On the Origin of Lexical and Syntactic Structures},
issn = {0911-6044},
doi = {https://doi.org/10.1016/j.jneuroling.2016.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0911604416300811},
author = {Marc D. Hauser and Jeffrey Watumull},
keywords = {Domain-specificity, Evolution, Generative functions, Language faculty, Recursion, Turing machine, Universal generative faculty},
abstract = {Many have argued that the expressive power of human thought comes from language. Language plays this role, so the argument goes, because its generative computations construct hierarchically structured, abstract representations, covering virtually any content and communicated in linguistic expressions. However, language is not the only domain to implement generative computations and abstract representations, and linguistic communication is not the only medium of expression. Mathematics, morality, and music are three others. These similarities are not, we argue, accidental. Rather, we suggest they derive from a common computational system that we call the Universal Generative Faculty or UGF. UGF is, at its core, a suite of contentless generative procedures that interface with different domains of knowledge to create contentful expressions in thought and action. The representational signatures of different domains are organized and synthesized by UGF into a global system of thought. What was once considered the language of thought is, on our view, the more specific operation of UGF and its interfaces to different conceptual domains. This view of the mind changes the conversation about domain-specificity, evolution, and development. On domain-specificity, we suggest that if UGF provides the generative engine for different domains of human knowledge, then the specificity of a given domain (e.g., language, mathematics, music, morality) is restricted to its repository of primitive representations and to its interfaces with UGF. Evolutionarily, some generative computations are shared with other animals (e.g., combinatorics), both for recognition-learning and generation-production, whereas others are uniquely human (e.g., recursion); in some cases, the cross-species parallels may be restricted to recognition-learning, with no observable evidence of generation-production. Further, many of the differences observed between humans and other animals, as well as among nonhuman animals, are the result of differences in the interfaces: whereas humans promiscuously traverse (consciously and unconsciously) interface conditions so as to combine and analogize concepts across many domains, nonhuman animals are far more limited, often restricted to a specific domain as well as a specific sensory modality within the domain. Developmentally, the UGF perspective may help explain why the generative powers of different domains appear at different stages of development. In particular, because UGF must interface with domain-specific representations, which develop on different time scales, the generative power of some domains may mature more slowly (e.g., mathematics) than others (e.g., language). This explanation may also contribute to a deeper understanding of cross-cultural differences among human populations, especially cases where the generative power of a domain appears absent (e.g., cultures with only a few count words). This essay provides an introduction to these ideas, including a discussion of implications and applications for evolutionary biology, human cognitive development, cross-cultural variation, and artificial intelligence.}
}
@incollection{ILLES2015735,
title = {Chapter 45 - Advances in Ethics for the Neuroscience Agenda},
editor = {Michael J. Zigmond and Lewis P. Rowland and Joseph T. Coyle},
booktitle = {Neurobiology of Brain Disorders},
publisher = {Academic Press},
address = {San Diego},
pages = {735-747},
year = {2015},
isbn = {978-0-12-398270-4},
doi = {https://doi.org/10.1016/B978-0-12-398270-4.00045-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123982704000458},
author = {Judy Illes and Peter B. Reiner},
keywords = {animal model, biomedical science, data sharing, ethics, health, incidental finding, neuroscience, public policy, science communication},
abstract = {Critical thinking about ethics in neuroscience can be a powerful force in enabling research and translating results meaningfully for society. This chapter provides four examples of such an empowered approach to neuroscience. The authors discuss how upfront consideration of the societal implications of advances in neuroscience can shape the use of animal models. They situate ethical thinking in this era of big science and big data, reflecting on strategies for sharing databases while protecting contributors and users. They highlight how collaboration among neuroscientists, ethicists, and others can produce positive measures to resolve the problem of incidental discoveries in brain imaging research, as one example of debates on incidental findings more broadly. The mandate of neuroscience research as public service and ethical imperative is addressed by describing opportunities for neuroscientists to engage with societal issues emerging from their research, and how this deepens the discourse and adds value to the research enterprise.}
}
@article{OH2015e6,
title = {The effects of simulation-based learning using standardized patients in nursing students: A meta-analysis},
journal = {Nurse Education Today},
volume = {35},
number = {5},
pages = {e6-e15},
year = {2015},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2015.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0260691715000507},
author = {Pok-Ja Oh and Kyeong Deok Jeon and Myung Suk Koh},
keywords = {Students, Nursing, Patient simulation, Meta-analysis},
abstract = {Summary
Purpose
The aim of this study was to evaluate the effect of simulation-based learning using standardized patients (SPs) on cognitive, affective, and psychomotor domain outcomes of learning in nursing students.
Methods
MEDLINE via PubMed, Cochrane Library CENTRAL, EMBASE, CINAHL, and several Korean electronic databases (to June 2014) were searched. The RevMan 5.3 program of the Cochrane library was used for data analysis.
Results
A meta-analysis was conducted of 18 controlled trials (4 randomized and 14 non-randomized designs), with a total of 1326 nursing students. Overall, simulation-based learning using SPs appeared to have beneficial effects on the cognitive, affective, and psychomotor domains of learning. In subgroup analysis, use of SPs showed significant effects on knowledge acquisition (d=0.38, p=.05, I2=42%), communication skill (d=1.86, p<.001, I2=15%), self-efficacy (d=0.61, p<.001, I2=6%), learning motivation (d=0.77, p<.001, I2=0%) and clinical competence (d=0.72, p<.001, I2=0%). Treatment effects on critical thinking (p=.75) and learning satisfaction (p=.43) were not significant.
Conclusion
The findings of the current study suggest that simulation-based learning using SPs might have a positive impact on self efficacy and learning motivation that affects knowledge and clinical skill acquisition. Therefore, these findings demonstrate that, if integrated appropriately, an SP educational approach can be used in academic settings as an active learning methodology.}
}
@article{PIERCE2024,
title = {Identifying Factors Associated With Heightened Anxiety During Breast Cancer Diagnosis Through the Analysis of Social Media Data on Reddit: Mixed Methods Study},
journal = {JMIR Cancer},
volume = {10},
year = {2024},
issn = {2369-1999},
doi = {https://doi.org/10.2196/52551},
url = {https://www.sciencedirect.com/science/article/pii/S2369199924000569},
author = {Joni Pierce and Mike Conway and Kathryn Grace and Jude Mikal},
keywords = {breast cancer, anxiety, NLP, natural language processing, mixed methods study, cancer diagnosis, social media apps, descriptive analysis, diagnostic progression, patient-centered care},
abstract = {Background
More than 85% of patients report heightened levels of anxiety following breast cancer diagnosis. Anxiety may become amplified during the early stages of breast cancer diagnosis when ambiguity is high. High levels of anxiety can negatively impact patients by reducing their ability to function physically, make decisions, and adhere to treatment plans, with all these elements combined serving to diminish the quality of life.
Objective
This study aimed to use individual social media posts about breast cancer experiences from Reddit (r/breastcancer) to understand the factors associated with breast cancer–related anxiety as individuals move from suspecting to confirming cancer diagnosis.
Methods
We used a mixed method approach by combining natural language processing–based computational methods with descriptive analysis. Our team coded the entire corpus of 2170 unique posts from the r/breastcancer subreddit with respect to key variables, including whether the post was related to prediagnosis, diagnosis, or postdiagnosis concerns. We then used Linguistic Inquiry and Word Count (LIWC) to rank-order the codified posts as low, neutral, or high anxiety. High-anxiety posts were then retained for deep descriptive analysis to identify key themes relative to diagnostic progression.
Results
After several iterations of data analysis and classification through both descriptive and computational methods, we identified a total of 448 high-anxiety posts across the 3 diagnostic categories. Our analyses revealed that individuals experience higher anxiety before a confirmed cancer diagnosis. Analysis of the high-anxiety posts revealed that the factors associated with anxiety differed depending on an individual’s stage in the diagnostic process. Prediagnosis anxiety was associated with physical symptoms, cancer-related risk factors, communication, and interpreting medical information. During the diagnosis period, high anxiety was associated with physical symptoms, cancer-related risk factors, communication, and difficulty navigating the health care system. Following diagnosis, high-anxiety posts generally discussed topics related to treatment options, physical symptoms, emotional distress, family, and financial issues.
Conclusions
This study has practical, theoretical, and methodological implications for cancer research. Content analysis reveals several possible drivers of anxiety at each stage (prediagnosis, during diagnosis, and postdiagnosis) and provides key insights into how clinicians can help to alleviate anxiety at all stages of diagnosis. Findings provide insights into cancer-related anxiety as a process beginning before engagement with the health care system: when an individual first notices possible cancer symptoms. Uncertainty around physical symptoms and risk factors suggests the need for increased education and improved access to trained medical staff who can assist patients with questions and concerns during the diagnostic process. Assistance in understanding technical reports, scheduling, and patient-centric clinician behavior may pinpoint opportunities for improved communication between patients and providers.}
}
@article{CHEN201910,
title = {An artificial intelligence based data-driven approach for design ideation},
journal = {Journal of Visual Communication and Image Representation},
volume = {61},
pages = {10-22},
year = {2019},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2019.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1047320319300604},
author = {Liuqing Chen and Pan Wang and Hao Dong and Feng Shi and Ji Han and Yike Guo and Peter R.N. Childs and Jun Xiao and Chao Wu},
keywords = {Idea generation, Artificial intelligence in design, Data-driven design, Generative adversarial networks, Semantic network analysis, Network visualisation, Computational creativity},
abstract = {Ideation is a source of innovation and creativity, and is commonly used in early stages of engineering design processes. This paper proposes an integrated approach for enhancing design ideation by applying artificial intelligence and data mining techniques. This approach consists of two models, a semantic ideation network and a visual concepts combination model, which provide inspiration semantically and visually based on computational creativity theory. The semantic ideation network aims to provoke new ideas by mining potential knowledge connections across multiple knowledge domains, and this was achieved by applying “step-forward” and “path-track” algorithms which assist in exploring forward given a concept and in tracking back the paths going from a departure concept through a destination concept. In the visual concepts combination model, a generative adversarial networks model is proposed for generating images which synthesize two distinct concepts. An implementation of these two models was developed and tested in a design case study, which indicated that the proposed approach is able to not only generate a variety of cross-domain concept associations but also advance the ideation process quickly and easily in terms of quantity and novelty.}
}
@article{ANDRADE2022102986,
title = {Writing styles and modes of engagement with the future},
journal = {Futures},
volume = {141},
pages = {102986},
year = {2022},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2022.102986},
url = {https://www.sciencedirect.com/science/article/pii/S0016328722000866},
author = {Stefan B. Andrade and Anneke Sools and Yashar Saghai},
keywords = {Anticipation, Writing style, Modes of engagement with the future, Anticipatory functions, narrative, Digital story grammar},
abstract = {This paper present a new approach to analyze how people anticipate the future in times of uncertainty. Our approach combines insights from narrative theory and the sociology of anticipatory modes of engagement with the future. We applied a mixed method approach to analyze 166 letters from a creative writing exercise where residents from five countries was asked to write retrospectively from the viewpoint of a desired post-corona future. Using the methodology of Digital Story Grammar, we first categorized the letters given their grammatical structure in terms of who are in stories (characters), what the stories are about (type of action), and to what or whom were the actions directed to (objects for the character’s actions). This resulted in four writing styles: (1) analytical-observational, (2) collective-moral, (3) dialogical-personal, and (4) sensory-emotional. Consequently, we interpreted the four writing styles qualitatively in relation to the theory of modes of engagement with the future (i.e., familiarity, plans, exploration, and justification). We conclude by reflecting on the relationships between writing styles and modes in a multi-paradigmatic approach to the study of anticipation and the relevance to scenario-building practices.}
}
@article{DO2000483,
title = {Intentions in and relations among design drawings},
journal = {Design Studies},
volume = {21},
number = {5},
pages = {483-503},
year = {2000},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(00)00020-X},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X0000020X},
author = {Ellen Yi-Luen Do and Mark D Gross and Bennett Neiman and Craig Zimring},
keywords = {drawing(s), architectural design, case study/studies, design activity, design research},
abstract = {Designers use drawings to explore alternatives and to test ideas. We report here on two studies on design and drawing. The first study of design drawing symbols aims to determine whether and to what extent it is possible to infer, interpret, or even guess what a designer was thinking about by looking at the drawings she has made. In the second study we examined a collection of drawings for the design of a house to investigate the systems of design transformations. Drawings are characterized by drawing style, projection type, and key elements. We analyzed the relationships among the drawings and developed a notation system for documenting these relationships.}
}
@article{PARIKH2024138,
title = {A comprehensive study on epigenetic biomarkers in early detection and prognosis of Alzheimer's disease},
journal = {Biomedical Analysis},
volume = {1},
number = {2},
pages = {138-153},
year = {2024},
issn = {2950-435X},
doi = {https://doi.org/10.1016/j.bioana.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2950435X24000167},
author = {Dhruv Parikh and Manan Shah},
keywords = {Alzheimer’s Disease, Biomarkers, Detection, Epigenetics},
abstract = {Alzheimer's Disease (AD) is a neurodegenerative disorder characterized by beta-amyloid plaques and tau tangles, disrupting brain cell communication, causing atrophy, and leading to cognitive decline. It poses a substantial global health challenge, necessitating urgent research. Molecular biomarkers, reflecting AD progression, have been identified in diverse bodily tissues. Notably, emerging epigenetic biomarkers introduce a novel dimension to AD pathophysiology. However, their precise role in early AD detection and prognosis remains unclear. This review classifies various epigenetic biomarkers, emphasizing their potential in early detection and prognosis. Various epigenetic biomarkers like DNA methylation, non-coding RNAs, histone modification, OMICS, and many more get significantly altered during AD; these biomarkers being distinctly expressed in normal conditions to AD offer a huge therapeutic benefit to stop the progression or worsening it. We explore the therapeutic implications and propose integration with existing diagnostic methods to intervene in AD progression, mitigating exacerbation. Addressing challenges, we envision the future scope of these biomarkers, emphasizing their synergy with computational approaches for enhanced AD detection. This review contributes to the field by proposing a multifaceted approach that combines epigenetic markers with computational analysis to improve early detection and facilitate timely therapeutic interventions. Furthermore, we discuss the economic implications of these biomarkers, proposing that their early application could significantly reduce the financial burden of AD by delaying the progression and severity of the disease.}
}
@article{OSTLUND1985109,
title = {WATERLOPP V2/64: A highly parallel machine for numerical computation},
journal = {Computer Physics Communications},
volume = {37},
number = {1},
pages = {109-117},
year = {1985},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(85)90142-0},
url = {https://www.sciencedirect.com/science/article/pii/0010465585901420},
author = {Neil S. Ostlund},
abstract = {Current technological trends suggest that the high performance scientific machines of the future are very likely to consist of a large number (greater than 1024) of processors connected and communicating with each other in some as yet undetermined manner. Such an assembly of processors should behave as a single machine in obtaining numerical solutions to scientific problems. However, the appropriate way of organizing both the hardware and software of such an assembly of processors is an unsolved and active area of research. It is particularly important to minimize the organizational overhead of interprocessor comunication, global synchronization, and contention for shared resources if the performance of a large number (n) of processors is to be anything like the desirable n times the performance of a single processor. In many situations, adding a processor actually decreases the performance of the overall system since the extra organizational overhead is larger than the extra processing power added. The systolic loop architecture is a new multiple processor architecture which attemps at a solution to the problem of how to organize a large number of asynchronous processors into an effective computational system while minimizing the organizational overhead. This paper gives a brief overview of the basic systolic loop architecture, systolic loop algorithms for numerical computation, and a 64-processor implementation of the architecture, WATERLOOP V2/64, that is being used as a testbed for exploring the hardware, software, and algorithmic aspects of the architecture.}
}
@article{RUTHVEN2004259,
title = {Teacher representations of the successful use of computer-based tools and resources in secondary-school English, mathematics and science},
journal = {Teaching and Teacher Education},
volume = {20},
number = {3},
pages = {259-275},
year = {2004},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2004.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X04000113},
author = {Kenneth Ruthven and Sara Hennessy and Sue Brindley},
keywords = {Computer uses in education, Educational technology, Teacher attitude and cognition, Subject teaching and learning, Secondary education, England},
abstract = {This study investigated professional thinking about pedagogical aspects of technology use in mainstream classroom practice. It focuses on the systems of ideas which frame teacher accounts of the successful use of computer-based tools and resources in the core subjects of English, Mathematics and Science at secondary-school level. These accounts were elicited through group interviews with the relevant subject departments in six secondary schools in England. The analysis identifies seven broad themes in which teachers point to the contribution of technology use in: effecting working processes and improving production; supporting processes of checking, trialling and refinement; enhancing the variety and appeal of classroom activity; fostering pupil independence and peer support; overcoming pupil difficulties and building assurance; broadening reference and increasing currency of activity; and focusing on overarching issues and accentuating important features. Further examination of these themes shows how professional thinking about technology use is anchored in well-established representations of pupil motivation and classroom learning, and how contrasting subject profiles reflect corresponding differences in wider subject cultures.}
}
@article{XI2025106930,
title = {Depression detection based on the temporal-spatial-frequency feature fusion of EEG},
journal = {Biomedical Signal Processing and Control},
volume = {100},
pages = {106930},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.106930},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424009881},
author = {Yang Xi and Ying Chen and Tianyu Meng and Zhu Lan and Lu Zhang},
keywords = {Depression detection, EEG, Temporal-spatial-frequency feature, Channel selection, Attention mechanism},
abstract = {Depression is a prevalent affective psychiatric disorder projected to be the leading contributor to the world’s disease burden by 2030. Due to its high prevalence and low recognition rate, an objective and effective detection method is urgently needed. Deep learning methods based on electroencephalography (EEG) have shown significant potential in depression detection. However, excessive channels can increase redundancy and computational complexity in EEG, while irrelevant channels may reduce accuracy. Additionally, existing models often overlook the complementarity between the temporal-, spatial-, and frequency-domain features of EEG, limiting their detection capabilities. To address these issues, we propose a method that fuses the temporal, spatial, and frequency domain features of EEG to enhance the detection accuracy while eliminating redundant channels. We introduce an EEG channel selection method based on frequency domain weighting that automatically adjusts the channel weights to select the EEG channels that best capture spatial information across the delta, theta, alpha, beta, and gamma bands, thereby optimizing the extraction of spatial-frequency features. In addition, we designed a multiscale spatiotemporal convolutional attention network to extract the spatiotemporal features of EEG. In this network, the multiscale convolutional attention module enhanced the model’s ability to capture spatial features, whereas the temporal trend-aware self-attention module extracted long-term temporal features by analyzing global correlations across different time points. Experimental results on the MODMA dataset show that our method achieved a 97.24% detection accuracy, surpassing current state-of-the-art models. This study offers a novel approach for constructing depression detection models, providing a foundation for future research and application.}
}
@article{KANSELAAR2001123,
title = {Computer supported collaborative learning Computer supported collaborative learning: cognitive and computational approaches: P. Dillenbourg (Ed.); Pergamon, Elsevier Science Ltd., Oxford, 1999, 246pp., ISBN 0-08-043073-2},
journal = {Teaching and Teacher Education},
volume = {17},
number = {1},
pages = {123-129},
year = {2001},
issn = {0742-051X},
doi = {https://doi.org/10.1016/S0742-051X(00)00042-1},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X00000421},
author = {Gellof Kanselaar and Gijsbert Erkens and Jos Jaspers and Hermi (Tabachneck-) Schijf}
}
@article{TSAI2017997,
title = {An empirical study on the incorporation of APP and progressive reasoning teaching materials for improving technical creativity amongst students in the subject of automatic control},
journal = {Computers in Human Behavior},
volume = {75},
pages = {997-1007},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216307117},
author = {Hsieh–Chih Tsai and Min Jou and JingYing Wang and Chun-Chiang Huang},
keywords = {APP, Progressive reasoning, Technical creativity, Scientific reasoning},
abstract = {This study reformed teaching materials for automatic control, a mandatory course for engineering students, and designed a set of digital teaching materials based upon progressive reasoning with hand-mind combinations. The teaching materials were mainly delivered via a hands-on APP. The authors conducted an empirical study as well as pre-tests and post-tests for a total of 118 sophomore students majoring in engineering at two Universities. Outcomes found that the progressive reasoning teaching materials designed for this course were helpful in improving student creativity and scientific reasoning. Significant improvements were also achieved in product design, technical methods, and technological ideas aspects of technological creativity and every scientific reasoning skill, with the exception of proportional reasoning. Results also identified strong correlation between technical creativity and scientific reasoning. This relationship may be further investigated in follow-up studies. This study also proposed recommendations for coordinating designs of digital teaching materials in other engineering courses with the development of student thinking.}
}
@article{SELIG2025105923,
title = {Using the kinematics of the RC linkage to find the degree of the adjoint representation of SE(3)},
journal = {Mechanism and Machine Theory},
volume = {206},
pages = {105923},
year = {2025},
issn = {0094-114X},
doi = {https://doi.org/10.1016/j.mechmachtheory.2025.105923},
url = {https://www.sciencedirect.com/science/article/pii/S0094114X25000126},
author = {J.M. Selig},
keywords = {Adjoint representation, Birational mappings, Study quadric, Assembly configurations},
abstract = {This work studies the projective algebraic variety formed from the closure of the adjoint representation of the group of rigid-body displacements, SE(3). This is motivated by asking how many assembly configurations a mechanism would have in general, if it was designed to keep six given lines in six linear line complexes. The main result is to find the degree of the variety defined by the adjoint representation and hence answer the motivating question. A simple special case is discussed, a mechanism that maintains a single given line reciprocal to three fixed lines from the regulus of a cylindrical hyperboloid of one sheet. The three dimensional variety defined in this way can be realised by an RC linkage. More specifically, the variety splits into two components each of which can be realised by an RC linkage. The homology of these 3-dimensional varieties, as subvarieties of the Study quadric, is found and used to determine the degree of the adjoint representation as an algebraic variety. The possible equations defining the variety determined by the adjoint representation of SE(3), are also discussed but no definitive result is found.}
}
@article{ACAR2016861,
title = {Soundscapes of Digital Morphogenesis in Architecture which Created from Musical Algorithm},
journal = {Procedia - Social and Behavioral Sciences},
volume = {216},
pages = {861-873},
year = {2016},
note = {Urban Planning and Architectural Design for Sustainable Development (UPADSD)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.12.083},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815062631},
author = {Didem Acar},
keywords = {Transcoding, Acoustic, Computational Design, Transdisciplinary framework, Architectural design},
abstract = {Music and architecture have made use of mathematical proportions throughout the history for the purpose of creating acoustic and visual forms. The reason for this is the aesthetic pursuit of both disciplines since centuries. Mathematics is one of the most important factors that influence aesthetic results. While forming their abstract aesthetic compositions the musicians use the musical notes that have definite frequency values. Each of these frequency values are defined by one integer. Every classical music artist uses the fractal sequencing of these frequencies. On the other hand we encounter hundreds of silent formats which are produced using mathematical ideas. In this context if we think of the interdisciplinary interaction between music and architecture no form is ever silent. In this study, the intersection of two disciplines will be examined in the perspective of architecture; a stumper and interrogative start for pursuit of architectural forms of the present day with the transformation of auditory forms to visual forms will be made; and a basis will be provided to be able to discuss the innovations that the spaces, structures and auditory experiences which can be formed by obtaining musical codes bring.}
}
@article{AYERS201861,
title = {A first step toward a practice-based theory of pedagogical content knowledge in secondary economics},
journal = {The Journal of Social Studies Research},
volume = {42},
number = {1},
pages = {61-79},
year = {2018},
issn = {0885-985X},
doi = {https://doi.org/10.1016/j.jssr.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885985X17300177},
author = {Cheryl A. Ayers},
keywords = {Secondary economic education, Pedagogical content knowledge, Horizon content knowledge, Specialized content knowledge, Knowledge of content and teaching, Knowledge of content and students},
abstract = {The purpose of this qualitative case study was to gain an in-depth understanding of how three award-winning secondary economics teachers demonstrated their pedagogical content knowledge (PCK), specifically horizon content knowledge, specialized content knowledge, knowledge of content and teaching, and knowledge of content and students. The teachers consistently connected economic content to other grades, subjects, and economic concepts and skills. Economic content was also regularly used to prepare students for citizenship, including casting more informed votes and understanding current events. However, authentic discussions, including ones about controversial issues, were mostly lacking. An emphasis was placed on developing students’ economic reasoning skills, including real-world applications of the economic way of thinking and decision-making models. Additionally, active learning instructional practices were frequently incorporated, and economic content was almost always related to students’ interests and experiences. A detailed description of a first step toward a practice-based theory of PCK in secondary economics concludes the article.}
}
@article{WANG2023120829,
title = {DBCT-Net:A dual branch hybrid CNN-transformer network for remote sensing image fusion},
journal = {Expert Systems with Applications},
volume = {233},
pages = {120829},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120829},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423013313},
author = {Quanli Wang and Xin Jin and Qian Jiang and Liwen Wu and Yunchun Zhang and Wei Zhou},
keywords = {Image fusion, Convolutional neural network, Pansharpening, Transformer},
abstract = {Remote sensing image fusion aims at fusing high spatial resolution single-band panchromatic (PAN) image with spectrally informative multispectral (MS) image to generate panchromatic sharpened image with high resolution and color information, it is also called pansharpening. Most of the proposed single convolutional neural network (CNN) or transformer-based pansharpening methods own several problems, such as inability to acquire long-range features or difficult to train, resulting the loss of spatial details and colors. In addition, the computational complexity of transformer cannot be ignored. In this work, we propose a dual-branch hybrid CNN-Transformer network (DBCT-Net) that utilizes the local specificity of CNN and models the global dependencies by transformer. First, a multi-branch dense connected block (MDCB-4) network is designed to obtain spectral and textural information in MS and PAN images, respectively. Next, an encoder–decoder transformer based on the self-attention and co-attention modules is able to inject the missing local and global information, which can further enhance the results. It is worth noting that an inverted multi-head transposed attention (IMTA) is applied here to build attention maps from feature dimensions, which greatly reduces the computation time. Finally, an image reconstruction module is employed to effectively fuse the acquired texture and spectral features. Furthermore, to generate visually better pansharpened images, we propose a combined loss function that includes a focal frequency loss. Extensive experiments on WorldView II (WV2), GF-2,and QuickBird (QB) datasets show that DBCT-Net can perform better in spatial preservation and spectral feature recovery.}
}
@article{MALINVERNI2025100727,
title = {Scaffolding Children's critical reflection on intelligent technologies: Opportunities from speculative fiction},
journal = {International Journal of Child-Computer Interaction},
volume = {43},
pages = {100727},
year = {2025},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2025.100727},
url = {https://www.sciencedirect.com/science/article/pii/S2212868925000078},
author = {Laura Malinverni and Marie-Monique Schaper and Elisa Rubegni and Mariana Aki Tamashiro},
keywords = {AI literacy, Critical reflection, Speculative fiction, Children, Reflective AI literacy},
abstract = {Current technological development of Artificial Intelligence (AI) requires educational practices that address the social and ethical implications derived from these emerging technologies. To this end, an increasing number of educational practices are pursuing the goal of supporting children's critical reflection on these topics. Our research aims at understanding how speculative fiction-based resources can meet and respond to the goals of supporting children's critical reflection on AI technologies and their impact on society. Through revisiting relevant literature on these topics and critically analyzing our own practices in three different settings, we identify a set of opportunities and challenges oriented at guiding the design of resources capable of taking advantage of speculative fiction as a way to support critical reflection.}
}
@article{AYERS201883,
title = {The axiomatic approach to chemical concepts},
journal = {Computational and Theoretical Chemistry},
volume = {1142},
pages = {83-87},
year = {2018},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2018.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X18304237},
author = {Paul W. Ayers and Stijn Fias and Farnaz Heidar-Zadeh},
abstract = {Many concepts that are central to chemical language and thought emerge from the wealth of chemists’ historical experience and cannot be precisely defined mathematically from the underlying physics. In such cases, it is useful to take an axiomatic approach: list the chemical, mathematical and computational properties that one desires for a concept to possess, and then find the rigorous (and, if possible, elegant) mathematical formulation of the concept that satisfies those desiderata. This mathematical formulation is most useful if it relies on fundamental quantities—quantum-mechanical observables, reduced density matrices, or the N-electron wavefunction—rather than method-dependent quantities (e.g., orbitals) that are not defined for some computational approaches to the molecular electronic structure problem. This ensures that the pursuit of chemical intuition does not lead one too far from the underlying physics. It also ensures that one can interpret the results of any computational method, even methods (e.g., quantum Monte Carlo) that make no reference to any molecular-orbital or valence-bond model.}
}
@article{BALAKRISHNAN2025109810,
title = {Alzheimer's Disease detection and classification using optimized neural network},
journal = {Computers in Biology and Medicine},
volume = {187},
pages = {109810},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.109810},
url = {https://www.sciencedirect.com/science/article/pii/S001048252500160X},
author = {Nair Bini Balakrishnan and Anitha S. Pillai and Jisha {Jose Panackal} and P.S. Sreeja},
keywords = {Recurrent neural network, Moth flame optimization, Deep reinforcement learning, Alzheimer's detection},
abstract = {Alzheimer's disease (AD) is a degenerative neurological condition characterized by a progressive decline in cognitive abilities, resulting in memory impairment and limitations in performing daily tasks. Timely and precise identification of AD holds paramount importance for prompt intervention and enhanced patient prognosis. In this research, a novel approach to AD mechanism was developed by combining Deep Reinforcement Learning (DRL) with a Moth Flame Optimized Recurrent Neural Network (MFORNN). Initially, the brain MRI samples are gathered and preprocessed to discard the noise features and to improve their quality. Consequently, the MFO algorithm captures and selects the most informative and highly correlative features from the preprocessed images, making it easier for Recurrent Neural Networks (RNNs) to learn the temporal dependencies and patterns differentiating normal and AD-affected images. The DRL component fine-tunes the parameters of RNN through its reward-based mechanism, ensuring that the classifier produces accurate outcomes and reduces computational complexity. The Python tool was utilized to implement the outlined framework, with the outcomes showcased that the designed algorithm attained an accuracy of 99.31 %, precision of 99.24 %, recall of 99.43 %, and f-measure of 99.35 %. Ultimately, a comparative analysis was performed against established classifier models, affirming the superior performance of the proposed technique over conventional algorithms.}
}
@article{1989N1,
title = {Newsletter on computational and applied mathematics},
journal = {Journal of Computational and Applied Mathematics},
volume = {25},
number = {2},
pages = {N1-N18},
year = {1989},
issn = {0377-0427},
doi = {https://doi.org/10.1016/0377-0427(89)90050-2},
url = {https://www.sciencedirect.com/science/article/pii/0377042789900502}
}
@article{VIJAYALAKSHMI2022103179,
title = {Predicting Hepatitis B to be acute or chronic in an infected person using machine learning algorithm},
journal = {Advances in Engineering Software},
volume = {172},
pages = {103179},
year = {2022},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2022.103179},
url = {https://www.sciencedirect.com/science/article/pii/S0965997822000898},
author = {C. Vijayalakshmi and S. Pakkir Mohideen},
keywords = {Hepatitis B, Machine learning, SVM, Stochastic gradient algorithm, Dataset},
abstract = {Hepatitis B is a viral infection which causes liver damage. It can lead to death. This hepatitis B along with Hepatitis C can cause hepatocellular carcinoma and liver cirrhosis. In this paper it is discussed about Hepatitis B found positive in a person's blood test is acute or chronic. This research work plans to code an endurance forecast model for the dataset which contains the boundaries or data of Hepatitis-B patients. At first the information will be pre-prepared, to improve fit for additional handling and for being in satisfactory configuration for the calculations. At that point, several calculations to indicate the forecast and draw out the precision of the model. What's more, further contrast those calculations with indicate the calculation with most adequacy. The precision is determined by contrasting the anticipated result and ongoing result of the patient. In light of thinking about different boundaries, the model will anticipate the danger of a patient of his endurance rate of acute or chronic infected person accuracy. In this paper we use Stochastic Gradient algorithm to find the Co-connection between boundaries of the date set, kernel approximation to finalise the resulting accuracy of the acute or choric prediction of patients and SVM method we use to clustering the kernel approximation calculation and connection analysis.}
}
@article{HO2024124656,
title = {Unraveling the complexity of amorphous solid as direct ingredient for conventional oral solid dosage form: The story of Elagolix Sodium},
journal = {International Journal of Pharmaceutics},
volume = {665},
pages = {124656},
year = {2024},
issn = {0378-5173},
doi = {https://doi.org/10.1016/j.ijpharm.2024.124656},
url = {https://www.sciencedirect.com/science/article/pii/S0378517324008901},
author = {Raimundo Ho and Richard S. Hong and Joseph Kalkowski and Kevin C. Spence and Albert W. Kruger and Jayanthy Jayanth and Nandkishor K. Nere and Samrat Mukherjee and Ahmad Y. Sheikh and Shailendra V. Bordawekar},
keywords = {Amorphous drug substance, Impinging jet precipitation, Scale-up, Glass transition, Microstructure, Physical property control, Multi-scale modeling},
abstract = {Conventional solid oral dosage form development is not typically challenged by reliance on an amorphous drug substance as a direct ingredient in the drug product, as this may result in product development hurdles arising from process design and scale-up, control of physical quality attributes, drug product processability and stability. Here, we present the Chemistry, Manufacturing and Controls development journey behind the successful commercialization of an amorphous drug substance, Elagolix Sodium, a first-in-class, orally active gonadotropin-releasing hormone antagonist. The reason behind the lack of crystalline state was assessed via Molecular Dynamics (MD) at the molecular and inter-molecular level, revealing barriers for nucleation due to prevalence of intra-molecular hydrogen bond, repulsive interactions between active pharmaceutical ingredient (API) molecules and strong solvation effects. To provide a foundational basis for the design of the API manufacturing process, we modeled the solvent-induced plasticization behavior experimentally and computationally via MD for insights into molecular mobility. In addition, we applied material science tetrahedron concepts to link API porosity to drug product tablet compressibility. Finally, we designed the API isolation process, incorporating computational fluid dynamics modeling in the design of an impinging jet mixer for precipitation and solvent-dependent glass transition relationships in the cake wash, blow-down and drying process, to enable the consistent manufacture of a porous, non-sintered amorphous API powder that is suitable for robust drug product manufacturing.}
}
@article{GONZALEZFELIU201289,
title = {Modeling Urban Goods Movement: How to be Oriented with so Many Approaches?},
journal = {Procedia - Social and Behavioral Sciences},
volume = {39},
pages = {89-100},
year = {2012},
note = {Seventh International Conference on City Logistics which was held on June 7- 9,2011, Mallorca, Spain},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.03.093},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812005605},
author = {Jesus Gonzalez-Feliu and Jean-Louis Routhier},
keywords = {Urban goods movement, modeling approaches, systematic review, multidisciplinarity},
abstract = {This paper proposes an analysis of the different model construction and development approaches in the context of urban goods movement (UGM). We focus on the model development issues more than on the mathematical tools applied in these models. First, we explore the main UGM models in the field, identifying their main construction schemas and their features limits. From this analysis, we propose a classification of UGM modeling frameworks, synthesizing them on a table that illustrates their construction schemas. Second, we analyze their limits and find a first set of synergies between the different thinking schools. This analysis allows us to highlight the strong points and override their weaknesses, and to propose a set of recommendations for planners and modeling schools in order to find co-operative schemas that improve the models’ efficiency.}
}
@article{POLHILL2023103121,
title = {Cognition and hypocognition: Discursive and simulation-supported decision-making within complex systems},
journal = {Futures},
volume = {148},
pages = {103121},
year = {2023},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2023.103121},
url = {https://www.sciencedirect.com/science/article/pii/S0016328723000253},
author = {J. Gareth Polhill and Bruce Edmonds},
keywords = {Simulation, Cognition, Hypocognition, Divination, Ecocyborgs, Blasphemy},
abstract = {Homo sapiens is currently believed to have evolved in the African savannah several hundreds of thousands of years ago. Since then, human societies have become, through technological innovation and application, powerful influencers of the planet’s ecological, hydrological and meteorological systems – for good and ill. They have experimented with many different systems of governance, in order to manage their societies and the environments they inhabit – using computer simulations as a tool to help make decisions concerning highly complex systems, is only the most recent of these. In questioning whether, when and how computer simulations should play a role in determining decision-making in these systems of governance, it is also worth reflecting on whether, when and how humans, or groups of humans, have the capability to make such decisions without the aid of such technology. This paper looks at and compares the characteristics of natural language-based and simulation-based decision-making. We argue that computational tools for decision-making can and should be complementary to natural language discourse approaches, but that this requires that both systems are used with their limitations in mind. All tools and approaches – physical, social and mental – have dangers when used inappropriately, but it seems unlikely humankind can survive without them. The challenge is how to do so.}
}
@article{SHEKHAR2024820,
title = {Topological data analysis enhanced prediction of hydrogen storage in metal–organic frameworks (MOFs)††Electronic supplementary information (ESI) available: Figure showing the effect of training set size. See DOI: https://doi.org/10.1039/d3ma00591g},
journal = {Materials Advances},
volume = {5},
number = {2},
pages = {820-830},
year = {2024},
issn = {2633-5409},
doi = {https://doi.org/10.1039/d3ma00591g},
url = {https://www.sciencedirect.com/science/article/pii/S2633540924000550},
author = {Shivanshu Shekhar and Chandra Chowdhury},
abstract = {Metal–organic frameworks (MOFs) have the capacity to serve as gas capturing, sensing, and storing systems. It is usual practice to select the MOF from a vast database with the best adsorption property in order to do an adsorption calculation. The costs of computing thermodynamic values are sometimes a limiting factor in high-throughput computational research, inhibiting the development of MOFs for separations and storage applications. In recent years, machine learning has emerged as a promising substitute for traditional methods like experiments and simulations when trying to foretell material properties. The most difficult part of this process is choosing characteristics that produce interpretable representations of materials that may be used for a variety of prediction tasks. We investigate a feature-based representation of materials using tools from topological data analysis. In order to describe the geometry of MOFs with greater accuracy, we use persistent homology. We show our method by forecasting the hydrogen storage capacity of MOFs during a temperature and pressure swing from 100 bar/77 K to 5 bar/160 K, using the synthetically compiled CoRE MOF-2019 database of 4029 MOFs. Our topological descriptor is used in conjunction with more conventional structural features, and their usefulness to prediction tasks is explored. In addition to demonstrating significant progress over the baseline, our findings draw attention to the fact that topological features capture information that is supplementary to the structural features.}
}
@incollection{BERNINGER2004197,
title = {Chapter 6 - The Reading Brain in Children and Youth: A Systems Approach},
editor = {Bernice Wong},
booktitle = {Learning About Learning Disabilities (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {San Diego},
pages = {197-248},
year = {2004},
isbn = {978-0-12-762533-1},
doi = {https://doi.org/10.1016/B978-012762533-1/50009-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780127625331500093},
author = {Virginia W. Berninger},
abstract = {Publisher Summary
This chapter presents a systems approach to the reading brain in children and youth. A supervisory attentional system in the frontal lobes protects the working brain from external and internal distraction through an inhibitory mechanism that suppresses distraction. Brains are electrochemical computers whose computations create inner mental worlds and overt interactions with the external world. Complete understanding of the functional reading system will require knowledge of regionally specific localized brain activation and interconnectivity of specific regions during the computational processes that create the inner mental worlds as well as the overt reading behavior of reading brains. Visual inspection of the brains of normal and disabled readers reveals no secrets about the structural anomalies that differentiate the neural architecture of those who learn to read easily and those who struggle to learn to read. Domain-general systems that the functional reading system may draw upon include specific sensory systems, fine motor systems for the mouth and hand, attentional systems, networks of supervisory executive functions, the limbic system, and the higher-level thinking and problem solving system.}
}
@incollection{HANEES202523,
title = {Chapter 2 - The evolution of healthcare: bridging conventional and quantum computing},
editor = {Gayathri Nagasubramanian and S. Rakesh Kumar and Valentina {Emilia Balas}},
booktitle = {Quantum Computing for Healthcare Data},
publisher = {Academic Press},
pages = {23-42},
year = {2025},
series = {Advances in Biomedical Informatics},
isbn = {978-0-443-29297-2},
doi = {https://doi.org/10.1016/B978-0-443-29297-2.00011-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443292972000113},
author = {Ahamed Lebbe Hanees and Elakkiya Elango and Gnanasankaran Natarajan and Gayathri Nagasubramanian},
keywords = {Traditional computing, quantum computing healthcare, AI (artificial intelligence), medical diagnostics, real-time data analysis, personalized medicine, treatment optimization},
abstract = {Quantum computing is going to completely transform the medical field, replacing traditional computing. Pattern identification and predictive analysis are two types of jobs that quantum computing may expedite significantly. In contrast, classical computing, which is fueled by artificial intelligence techniques including machines learning and deep learning, primarily uses enormous datasets to feed these types of operations. This development is anticipated to enable real-time visualization of complex medical records, leading to faster and more accurate diagnoses via genetics and imaging information. Through leveraging the mathematical capabilities of quantum computing, healthcare providers may anticipate significant advancements in individualized medicine, therapy optimizing, and entire patient care, that will improve the standards for the delivery of medical services. Innovative and inventive collaborations exist involving Quantum Computing and the healthcare sector. Thus it was merely an extension of decades when the field of healthcare was drastically changed by quantum computing. The development of quantum technology means that an entirely new phase of computation is about to begin. Despite being a purely scientific subject, the laws of quantum mechanics and technologies have the power to completely transform a variety of industries, including healthcare. Quantum convergence presents enormous opportunities throughout the medical sector. Furthermore, technologies in general and AI in particular have made major improvements to the healthcare sector. These advances in technology are being used and transforming the healthcare industry to provide better care, assistance, and diagnosis. In the same way, quantum computing hopes to revolutionize how it is used in the field of healthcare. These days, personalized medicine that utilizes pharmaceutical kinetics human physiology and genomics is the standard. Therefore quantum computing is an ideal way to achieve this.}
}
@article{TEMPL20249,
title = {Advancing forensic research: An examination of compositional data analysis with an application on petrol fraud detection},
journal = {Science & Justice},
volume = {64},
number = {1},
pages = {9-18},
year = {2024},
issn = {1355-0306},
doi = {https://doi.org/10.1016/j.scijus.2023.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1355030623001223},
author = {M. Templ and J. Gonzalez-Rodriguez},
keywords = {Forensic science, Petrol data, Chemical compounds, Compositional data analysis, Classification},
abstract = {In recent years, numerous studies have examined the chemical compounds of petrol and petrol data for forensic research. Standard quantitative methods often assume that the variables or compounds do not have compositional constraints or are not part of a constrained whole, operating within an Euclidean vector space. However, chemical compounds are typically part of a whole, and the appropriate vector space for their analysis is the simplex. Biased and arbitrary results result when statistical analysis are applied on such data without proper pre-processing of such data. Compositional analysis of data has not yet been considered in forensic science. Therefore, we compare classical statistical analysis as applied in forensic research and the new proposed paradigm of compositional data analysis (CoDa). It is demonstrated how such analysis improves the analysis in petrol and forensic science. Our study shows how principal component analysis (PCA) and classification results are affected by the preprocessing steps performed on the raw data. Our results indicate that results from a log ratio analysis provides a better separation between subgroups of the data and leads to an easier interpretation of the results. In addition, with a compositional analysis a higher classification accuracy is obtained. Even a non-linear classification method - in our case a random forest - was shown to perform poorly when applied without using compositional methods. Moreover, normalization of samples due to laboratory/unit-of-measurement effects is no longer necessary, since the composition of an observation is in compositional thinking equivalent to a multiple of it, because the used (log) ratios on raw and log ratio transformed data are equal. Petrol data from different petrol stations in Brazil are used for the demonstration. This data is highly susceptible to counterfeit petrol. Forensic analysis of its chemical elements requires non-biased statistical analysis designed for compositional data to detect fraud. Based on these results, we recommend the use of compositional data methods for gasoline and petrol chemical element analysis and gasoline product characterization, authentication and fraud detection in forensic sciences.}
}
@article{BYRNE2002426,
title = {Mental models and counterfactual thoughts about what might have been},
journal = {Trends in Cognitive Sciences},
volume = {6},
number = {10},
pages = {426-431},
year = {2002},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(02)01974-5},
url = {https://www.sciencedirect.com/science/article/pii/S1364661302019745},
author = {Ruth M.J. Byrne},
keywords = {counterfactual thinking, reasoning, imagination, emotions, if only},
abstract = {Counterfactual thoughts about what might have been (‘if only…’) are pervasive in everyday life. They are related to causal thoughts, they help people learn from experience and they influence diverse cognitive activities, from creativity to probability judgements. They give rise to emotions and social ascriptions such as guilt, regret and blame. People show remarkable regularities in the aspects of the past they mentally ‘undo’ in their counterfactual thoughts. These regularities provide clues about their mental representations and cognitive processes, such as keeping in mind true possibilities, and situations that are false but temporarily supposed to be true.}
}
@article{OBIEKE2020373,
title = {Supporting Design Problem-exploring with Emergent Technologies},
journal = {Procedia CIRP},
volume = {91},
pages = {373-381},
year = {2020},
note = {Enhancing design through the 4th Industrial Revolution Thinking},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.02.189},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120308362},
author = {Chijioke Obieke and Jelena Milisavljevic-Syed and Ji Han},
keywords = {Creativity, Design Process, Industry 4.0, Problem-exploring},
abstract = {The goal in this study is to highlight the value of using emergent technologies to support human effort in identifying creative design problems. First, we explore the relationship between design and creativity - a popular concept and an important requirement in engineering design process. A search is conducted across repositories. This includes search in Google, Google Scholar and Google Books databases in addition to others. Findings show that the extent to which the design process requires creativity is somewhat obscure and not generally perceptible. We observe that creativity consists of two aspects: problem-solving and problem-exploring. We also observe that creativity drives the design process, not by the way of problem-solving but by the way of problem-exploring. However, currently, focus is on problem-solving than the equally important problem-exploring. For every 135 studies on problem-solving, there is only one on problem-exploring. Study on problem-exploring is limited. We research further and identify some determinants of the neglect in problem-exploring in design. These determinants are lack of motivation, significant level of difficulty and the presence of many problems yet unsolved. Using the X-Design Process model and Problem-dependent Solution model we show the importance and benefits of problem-exploring in design and why it deserves attention. Consequently, we illustrate the use of emergent technologies to support problem-exploring in design and give reasons why this is possible in Industry 4.0. These technologies include data mining, natural language processing, machine learning, duplication recognition, and so on. We indicate that these technologies will only play subordinate role to humans towards inspiring problem-exploring in design. Also, we state that a precondition to applying these technologies is a study of the human problem-exploring cognition process for subsequent simulation. Success in computational problem-exploring would lead to breakthroughs in global problem-exploring and trigger more creative solutions in coming years.}
}
@article{TUCKER199223,
title = {Deterministic and nondeterministic computation, and horn programs, on abstract data types},
journal = {The Journal of Logic Programming},
volume = {13},
number = {1},
pages = {23-55},
year = {1992},
issn = {0743-1066},
doi = {https://doi.org/10.1016/0743-1066(92)90020-4},
url = {https://www.sciencedirect.com/science/article/pii/0743106692900204},
author = {J.V. Tucker and J.I. Zucker},
abstract = {We investigate the notion of “semicomputability,” intended to generalize the notion of recursive enumerability of relations to abstract structures. Two characterizations are considered and shown to be equivalent: one in terms of “partial computable functions” (for a suitable notion of computability over abstract structures) and one in terms of definability by means of Horn programs over such structures. This leads to the formulation of a “Generalized Church-Turing Thesis” for definability of relations on abstract structures.}
}
@article{ALI2023e14993,
title = {Small hydropower generation using pump as turbine; a smart solution for the development of Pakistan's energy},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e14993},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e14993},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023022004},
author = {Asad Ali and Jianping Yuan and Hamza Javed and Qiaorui Si and Ibra Fall and Israel Enema Ohiemi and Fareed Konadu Osman and Rice ul Islam},
keywords = {Pump-as-turbine, Small hydropower, Renewable energy, Environment friendly, Energy resources, Energy in developing countries},
abstract = {Energy supply that is sustainable, effective, and economical has a strong association with socio-economic growth, particularly in developing countries such as Pakistan. Due to the ever-increasing gap between supply and demand, Pakistan has become an energy-deficient nation, with most people having no-to-limited access to power. Pakistan has been suffering from power shortages and an energy crisis because of its strong reliance on fossil-fuels to provide expensive electricity. Therefore, this paper offers a novel concept for developing Pakistan's energy by producing small-hydropower using Pump-As-Turbine (PAT), which is a form of Renewable-energy with lower environmental-impact and has not been used in Pakistan previously. PATs have shown several advantages over traditional hydro-turbines, such as minimum expenses, low-complexity, short delivery time, ease of spare parts, easy installation, availability in a large number of standard sizes, and massive production for broad-range of heads and flow rates. According to technical standards, any sort of pump could be used as PAT, including radial, mixed, single-stage, multi-stage etc. for power generation, which are capable of producing 5kW–1000kW of power, depending on their usage. However, Pakistan has shown little to no interest in exploring small/micro hydropower generation (PATs technology). Thus, this study offers public awareness and forward thinking regarding the use of advanced SHPs and draws the interests of legislators and different investors via solid recommendations about the cost-effective and environmental-friendly technology (PAT).}
}
@article{ERA2021105070,
title = {Dissociating cognitive, behavioral and physiological stress-related responses through dorsolateral prefrontal cortex inhibition},
journal = {Psychoneuroendocrinology},
volume = {124},
pages = {105070},
year = {2021},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2020.105070},
url = {https://www.sciencedirect.com/science/article/pii/S0306453020304935},
author = {Vanessa Era and Luca Carnevali and Julian F. Thayer and Matteo Candidi and Cristina Ottaviani},
keywords = {Dorsolateral prefrontal cortex, Perseverative cognition, Cortisol, Heart rate variability, High-frequency repetitive transcranial magnetic stimulation},
abstract = {The left dorsolateral prefrontal cortex (dlPFC) has been implicated in the regulation of stress-related cognitive processes and physiological responses and is the principal target of noninvasive brain stimulation techniques applied to psychiatric conditions. However, existing studies are mostly correlational and causal evidence on the role of this region in mediating specific psychophysiological mechanisms underpinning stress-related responses are needed to make the application of such techniques more efficient. To fill this gap, this study used inhibitory continuous theta burst stimulation (cTBS) in healthy individuals to examine the extent to which activity of the left dlPFC is associated with cognitive (subjective focus on a tracking task), behavioral (reaction times and variability), and physiological responses (heart rate and its variability and cortisol level) following induction of perseverative cognition. Compared to sham and left ventral PreMotor area stimulation (as active control area), inhibition of left dlPFC determined sustained autonomic and neuroendocrine activation and increased the subjective perception of being task-focused, while not changing the behavioral and self-reported stress-related responses. Adopting a causative approach, we describe a role of left dlPFC in inhibitory control of the physiological stress-response associated to perseverative thinking.}
}
@article{YAN2025129868,
title = {SPRInT: Scaling Programmatic Reasoning for INstruction Tuning in mathematics},
journal = {Neurocomputing},
volume = {634},
pages = {129868},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129868},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225005405},
author = {Yan Yan and Lin Li and Bo-Wen Zhang},
keywords = {Programmatic mathematical reasoning, Data augmentation, Data synthesis, Decoupled numeric dependencies, Logical inconsistencies},
abstract = {We present SPRInT, a novel approach for large-scale, cost-effective synthesis of instruction-tuning datasets, leveraging Program-of-Thoughts (PoT) to enhance mathematical reasoning capabilities. Through the SPRInT framework, we synthesized data from seven high-quality open-source math datasets (including GSM8K, MATH, AQuA), and developed InfinityMATH-a dataset containing over 100,000 samples generated from QA pairs, offering extensive coverage across various mathematical domains. The SPRInT model series, fine-tuned on InfinityMATH using open-source language and code models such as Llama2-7B, Mistral-7B, and CodeLlama-7B, achieved remarkable improvements in mathematical reasoning, with performance gains between 184.7% and 514.3%. In zero-shot settings, our SPRInT-CodeLlama-7B model surpassed MAmmoTH-Coder on widely-used benchmarks, including GSM8K (65.80% vs. 56.86%) and MATH (34.06% vs. 29.88%). To assess logical consistency in numerical transformations, we created the GSM8K+ and MATH＋ test sets by modifying the numerical values in the original datasets. While traditional models struggled with these alterations, the SPRInT models exhibited superior robustness. The InfinityMATH dataset is publicly available at https://huggingface.co/datasets/BAAI/InfinityMATH.}
}
@incollection{BLAGOJEVIC20171,
title = {Chapter One - A Systematic Approach to Generation of New Ideas for PhD Research in Computing},
editor = {Ali R. Hurson and Veljko Milutinović},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {104},
pages = {1-31},
year = {2017},
booktitle = {Creativity in Computing and DataFlow SuperComputing},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2016.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065245816300572},
author = {V. Blagojević and D. Bojić and M. Bojović and M. Cvetanović and J. Đorđević and Đ. Đurđević and B. Furlan and S. Gajin and Z. Jovanović and D. Milićev and V. Milutinović and B. Nikolić and J. Protić and M. Punt and Z. Radivojević and Ž. Stanisavljević and S. Stojanović and I. Tartalja and M. Tomašević and P. Vuletić},
keywords = {PhD research, Idea generation, Research methodology, Research idea classification, Creative thinking},
abstract = {This article represents an effort to help PhD students in computer science and engineering to generate good original ideas for their PhD research. Our effort is motivated by the fact that most PhD programs nowadays include several courses, as well as the research component, that should result in journal publications and the PhD thesis, all in a timeframe of 3–6 years. In order to help PhD students in computing disciplines to get focused on generating ideas and finding appropriate subject for their PhD research, we have analyzed some state-of-the-art inventions in the area of computing, as well as the PhD thesis research of faculty members of our department, and came up with a proposal of 10 methods that could be implemented to derive new ideas, based on the existing body of knowledge in the research field. This systematic approach provides guidance for PhD students, in order to improve their efficiency and reduce the dropout rate, especially in the area of computing.}
}
@incollection{EDELMAN2015596,
title = {Marr, David (1945–80)},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {596-598},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.61085-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868610851},
author = {Shimon Edelman and Lucia M Vaina},
keywords = {Biological information processing, Brain function, Cognitive psychology, Computational theory and modeling, Neuroscience, Scientific methodology, Vision},
abstract = {David Courtnay Marr was born in 1945 in Essex, England. Marr's dissertation, written at Trinity College, Cambridge and published between 1969 and 1971, presented a theory of mammalian brain function, parts of which remain relevant to the present day, despite vast advances in neurobiology in the past decades. In 1973, Marr joined the Artificial Intelligence Laboratory at the Massachusetts Institute of Technology, where he was made a tenured full professor in 1980. Marr died in November 1980, of leukemia. His highly influential book, Vision: A Computational Investigation into the Human Representation and Processing of Visual Information, which has redefined and revitalized the study of human and machine vision, was published posthumously, in 1982, with a new edition appearing in 2010.}
}
@article{WANG2024109848,
title = {An effective DOA estimation method for low SIR in small-size hydrophone array},
journal = {Applied Acoustics},
volume = {217},
pages = {109848},
year = {2024},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2023.109848},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X23006461},
author = {Wenbo Wang and Ye Li and TongSheng Shen and Feng Liu and DeXin Zhao},
abstract = {The estimation ability of traditional direction of arrival (DOA) estimation methods is relatively fragile in small-size hydrophone arrays with limited space. Especially in low signal to interference ratio (SIR), the strong interference signals may submerge some weak signals of interest (SOI) and make DOA estimation difficult in response to this issue. This paper introduces an improved sparse DOA estimation method for practical multi-objective DOA estimation in complex scenarios. The main work is to introduce a noise weight constraint in the sparse iterative covariance process. It leads the algorithm to output sparse peaks and smooth spatial energy spectra and achieve faster fitting while reducing the probability of false peaks. The algorithm can complete DOA estimation of the multi-target reliably without prior information of sources. Then, we propose a fast region grid refinement method based on allocation reconstruction to increase angle resolution. The method increases the accuracy of multi-objective DOA estimation while reducing computational costs. Finally, simulation and experiment have verified the method's effectiveness.}
}
@article{SAHU2023105206,
title = {SCZ-SCAN: An automated Schizophrenia detection system from electroencephalogram signals},
journal = {Biomedical Signal Processing and Control},
volume = {86},
pages = {105206},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.105206},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423006390},
author = {Geet Sahu and Mohan Karnati and Abhishek Gupta and Ayan Seal},
keywords = {Schizophrenia, Electroencephalography, Continuous wavelet transform, Scalogram, Convolutional neural network},
abstract = {Schizophrenia (SCZ) is a severe neurological and physiological syndrome that perverts a patient’s perception of reality. SCZ exhibits several symptoms, including hallucinations, delusions, aberrant behavior, and thinking. It affects their professional, academic, personal, and social lives. Neurologists use a variety of verbal and visual tests to determine SCZ. However, these methods are laborious, time-consuming, superficial, and vulnerable to mistakes. Therefore, it is necessary to create an automated model for SCZ detection. Convolutional neural networks have swiftly established themselves in the field of mental health care due to the growth of deep learning in recent decades. Electroencephalogram (EEG) data records the variations in the neural dynamics of human memory. Using EEG data, this study proposes an automatic SCZ detection method using separable convolution attention network (SCZ-SCAN). The proposed network employs depth-wise separable convolution and attention networks on high-level and low-level to aggregate characteristics of 2-D scalogram images acquired from the continuous wavelet transform. The depth-wise separable convolutions help to create a lightweight framework, while attention techniques concentrate on significant features and reduce futile computations by removing the transmission of irrelevant features. The proposed approach has an average classification accuracy of 99% and 95% on the IBIB-PAN and EEG data from the basic sensory task in SZ dataset. Moreover, statistical hypothesis testing is performed using Wilcoxon’s Rank-Sum test to signify the model performance and it proves that SCZ-SCAN is statistically efficient to nine cutting-edge methods. Experimental results show that the PSFAN statistically defeats 11 contemporary methods, proving its effectiveness for medical industrial applications.}
}
@article{GENNARI2023103006,
title = {Design for social digital well-being with young generations: Engage them and make them reflect},
journal = {International Journal of Human-Computer Studies},
volume = {173},
pages = {103006},
year = {2023},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2023.103006},
url = {https://www.sciencedirect.com/science/article/pii/S1071581923000125},
author = {Rosella Gennari and Maristella Matera and Diego Morra and Alessandra Melonio and Mehdi Rizvi},
keywords = {Digital well-being, Social digital well-being, Responsible design, Smart-thing design, Toolkit},
abstract = {Digital well-being traditionally means limiting the effects on individuals of technology abuses. However, in a broader perspective, it can be crucial to consider the pervasiveness of technology, and the effect it can have not only on individuals but also on their peers in the context of diverse everyday-life situations. Within this view, which emphasises the social side of digital well-being, the paper argues the need of educating young generations to participate in the making of technology for a social goal and have a reflective attitude towards technology and its impact on society. It, therefore, presents a design toolkit as a means to (i) engage young generations to become active in design for social digital well-being and, thanks to the exposure to how technology works, (ii) reflect deeply on the pros and cons of technology in use in their everyday life. By presenting the results of a study with 24 high-school pupils and their teachers, the paper discusses how a phygital toolkit, which structures the design process, engages them in the rapid prototyping of their own smart things, and how it acts as a proxy for soliciting their own reflections around technology and social digital well-being.}
}
@article{THEOFILIDIS2024219,
title = {Mental Imagery: Investigating the Limits of Mental Partitioning},
journal = {Revista Colombiana de Psiquiatría (English ed.)},
volume = {53},
number = {3},
pages = {219-228},
year = {2024},
issn = {2530-3120},
doi = {https://doi.org/10.1016/j.rcpeng.2024.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S2530312024000602},
author = {Antonios Theofilidis and Maria-Valeria Karakasi and Filippos Kargopoulos},
keywords = {Mental imagery, Mental partitioning, Memory, Cognition, Neuroscience, Imaginería mental, Partición mental, Memoria, Cognición, Neurociencia},
abstract = {Introduction
Do we form mental models which bear an analogical relation to the real world like those of a photograph? Has the language of thought an analogue nature (it makes use of mental imagery) or whether it is exclusively of digital nature like language?
Objectives
The basic aim of the present study is to contribute to the ongoing work on mental imagery by extending the research to an unexplored area that of mental partitioning.
Methods
The present research sample consisted of 498 participants (234 males and 264 females). We used the SPSS software package in order to analyze our data.
Results
According to our results, we detected significant peculiarities in the cognitive performance of the participants in the tasks of mental partitioning of the Moebius strip, indicating certain limitations inherent in human thinking.
Conclusions
The position we are led to adopt is closer to that of Pylyshyn (2003), who maintained that visual mental imagery depends on abstract form of thought and on previous knowledge. Specifically, it rests on previous abstract propositional thought and knowledge rather than on concrete perceptual processes like the ones proposed by Kosslyn and Sheppard. The present work investigates a potentially valuable theoretical basis in imagery research for understanding maladaptive imagery across various related clinical disorders, while encouraging multidisciplinary approaches among cognitive psychological/neuroscientific and clinical domains.
Resumen
Introducción
¿Formamos modelos mentales que guardan una relación analógica con el mundo real como los de una fotografía? ¿Tiene el lenguaje del pensamiento una naturaleza analógica (hace uso de imágenes mentales) o es exclusivamente de naturaleza digital como el lenguaje?
Objetivos
El objetivo básico del presente estudio es contribuir al trabajo en curso sobre la imaginería mental extendiendo la investigación a un área inexplorada que es la partición mental.
Métodos
La muestra de la presente investigación estuvo compuesta por 498 participantes (234 varones y 264 mujeres). Usamos el paquete de software SPSS® para analizar nuestros datos.
Resultados
De acuerdo con nuestros resultados, detectamos peculiaridades significativas en el desempeño cognitivo de los participantes en las tareas de partición mental de la tira de Moebius, indicando ciertas limitaciones inherentes al pensamiento humano.
Conclusiones
La posición a la que nos vemos llevados a adoptar se acerca más a la de Pylyshyn (2003), quien sostenía que la imaginería mental visual depende de formas abstractas de pensamiento y de conocimientos previos. Específicamente, se basa en el pensamiento y el conocimiento proposicionales abstractos previos más que en procesos de percepción concretos como los propuestos por Kosslyn y Sheppard. El presente trabajo investiga una base teórica potencialmente valiosa en la investigación de imágenes para comprender las imágenes desadaptativas en varios trastornos clínicos relacionados, al tiempo que fomenta enfoques multidisciplinarios entre los dominios cognitivos psicológicos/neurocientíficos y clínicos.}
}
@article{CHIU2024100282,
title = {Developing and validating measures for AI literacy tests: From self-reported to objective measures},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100282},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100282},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000857},
author = {Thomas K.F. Chiu and Yifan Chen and King Woon Yau and Ching-sing Chai and Helen Meng and Irwin King and Savio Wong and Yeung Yam},
keywords = {AI literacy, Instrument, K-12 education, AI education, Co-design process, Measures},
abstract = {The majority of AI literacy studies have designed and developed self-reported questionnaires to assess AI learning and understanding. These studies assessed students' perceived AI capability rather than AI literacy because self-perceptions are seldom an accurate account of true measures. International assessment programs that use objective measures to assess science, mathematical, digital, and computational literacy back up this argument. Furthermore, because AI education research is still in its infancy, the current definition of AI literacy in the literature may not meet the needs of young students. Therefore, this study aims to develop and validate an AI literacy test for school students within the interdisciplinary project known as AI4future. Engineering and education researchers created and selected 25 multiple-choice questions to accomplish this goal, and school teachers validated them while developing an AI curriculum for middle schools. 2390 students in grades 7 to 9 took the test. We used a Rasch model to investigate the discrimination, reliability, and validity of the items. The results showed that the model met the unidimensionality assumption and demonstrated a set of reliable and valid items. They indicate the quality of the test items. The test enables AI education researchers and practitioners to appropriately evaluate their AI-related education interventions.}
}
@article{BENEDEK2014125,
title = {To create or to recall? Neural mechanisms underlying the generation of creative new ideas},
journal = {NeuroImage},
volume = {88},
pages = {125-133},
year = {2014},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2013.11.021},
url = {https://www.sciencedirect.com/science/article/pii/S1053811913011130},
author = {Mathias Benedek and Emanuel Jauk and Andreas Fink and Karl Koschutnig and Gernot Reishofer and Franz Ebner and Aljoscha C. Neubauer},
keywords = {Creativity, fMRI, Human cognition, Memory retrieval, Inferior parietal cortex},
abstract = {This fMRI study investigated brain activation during creative idea generation using a novel approach allowing spontaneous self-paced generation and expression of ideas. Specifically, we addressed the fundamental question of what brain processes are relevant for the generation of genuinely new creative ideas, in contrast to the mere recollection of old ideas from memory. In general, creative idea generation (i.e., divergent thinking) was associated with extended activations in the left prefrontal cortex and the right medial temporal lobe, and with deactivation of the right temporoparietal junction. The generation of new ideas, as opposed to the retrieval of old ideas, was associated with stronger activation in the left inferior parietal cortex which is known to be involved in mental simulation, imagining, and future thought. Moreover, brain activation in the orbital part of the inferior frontal gyrus was found to increase as a function of the creativity (i.e., originality and appropriateness) of ideas pointing to the role of executive processes for overcoming dominant but uncreative responses. We conclude that the process of idea generation can be generally understood as a state of focused internally-directed attention involving controlled semantic retrieval. Moreover, left inferior parietal cortex and left prefrontal regions may subserve the flexible integration of previous knowledge for the construction of new and creative ideas.}
}
@article{CROMWELL20112026,
title = {Rethinking the cognitive revolution from a neural perspective: How overuse/misuse of the term ‘cognition’ and the neglect of affective controls in behavioral neuroscience could be delaying progress in understanding the BrainMind},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {35},
number = {9},
pages = {2026-2035},
year = {2011},
note = {Pioneering Research in Affective Neuroscience: Celebrating the Work of Dr. Jaak Panksepp},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2011.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0149763411000273},
author = {Howard Casey Cromwell and Jaak Panksepp},
keywords = {Cognition, Emotion, Motivation, Perception, Concepts, Neural activity, Behavior},
abstract = {Words such as cognition, motivation and emotion powerfully guide theory development and the overall aims and goals of behavioral neuroscience research. Once such concepts are accepted generally as natural aspects of the brain, their influence can be pervasive and long lasting. Importantly, the choice of conceptual terms used to describe and study mental/neural functions can also constrain research by forcing the results into seemingly useful ‘conceptual’ categories that have no discrete reality in the brain. Since the popularly named ‘cognitive revolution’ in psychological science came to fruition in the early 1970s, the term cognitive or cognition has been perhaps the most widely used conceptual term in behavioral neuroscience. These terms, similar to other conceptual terms, have potential value if utilized appropriately. We argue that recently the term cognition has been both overused and misused. This has led to problems in developing a usable shared definition for the term and to promotion of possible misdirections in research within behavioral neuroscience. In addition, we argue that cognitive-guided research influenced primarily by top-down (cortical toward subcortical) perspectives without concurrent non-cognitive modes of bottom-up developmental thinking, could hinder progress in the search for new treatments and medications for psychiatric illnesses and neurobehavioral disorders. Overall, linkages of animal research insights to human psychology may be better served by bottom-up (subcortical to cortical) affective and motivational ‘state-control’ perspectives, simply because the lower networks of the brain are foundational for the construction of higher ‘information-processing’ aspects of mind. Moving forward, rapidly expanding new techniques and creative methods in neuroscience along with more accurate brain concepts, may help guide the development of new therapeutics and hopefully more accurate ways to describe and explain brain-behavior relationships.}
}
@article{WU2020242,
title = {Mentalizing during social InterAction: A four component model},
journal = {Cortex},
volume = {126},
pages = {242-252},
year = {2020},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2019.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0010945220300277},
author = {Haiyan Wu and Xun Liu and Cindy C. Hagan and Dean Mobbs},
keywords = {Metacognition, Mentalizing, Vicarious mentalizing, Co-mentalizing, Social inference},
abstract = {Mentalizing, conventionally defined as the process in which we infer the inner thoughts and intentions of others, is a fundamental component of human social cognition. Yet its role, and the nuanced layers involved, in real world social interaction are rarely discussed. To account for this lack of theory, we propose the interactive mentalizing theory (IMT) -to emphasize the role of metacognition in different mentalizing components. We discuss the connection between mentalizing, metacognition, and social interaction in the context of four elements of mentalizing: (i) Metacognition–inference of our own thought processes and social cognitions and which is central to all other components of mentalizing including: (ii) first-order mentalizing–inferring the thoughts and intentions of an agent's mind; (iii) personal second-order mentalizing–inference of other's mentalizing of one's own mind; (iv) Collective mentalizing: which takes at least two forms (a) vicarious mentalizing: adopting another's mentalizing of an agent (i.e., what we think others think of an agent) and (b) co-mentalizing: mentalizing about an agent in conjunction with others' mentalizing of that agent (i.e., conforming to others beliefs about another agent's internal states). The weights of these four elements is determined by metacognitive insight and confidence in one's own or another's mentalizing ability, yielding a dynamic interaction between these circuits. To advance our knowledge on mentalizing during live social interaction, we identify how these subprocesses can be organized by different target agents and facilitated by combining computational modeling and interactive brain approaches.}
}
@article{TANTILLO2021n/a,
title = {Dynamic effects on organic reactivity—Pathways to (and from) discomfort},
journal = {Journal of Physical Organic Chemistry},
volume = {34},
number = {6},
pages = {n/a},
year = {2021},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.4202},
url = {https://www.sciencedirect.com/science/article/pii/S0894323022006889},
author = {Dean J. Tantillo},
keywords = {bifurcation, dynamics, entropy},
abstract = {Recent computational studies highlighting the importance of accounting for dynamic effects on organic reactivity are discussed, accompanied by descriptions of the factors that led the author to pursue these projects.}
}
@article{ATANASIU2023e20698,
title = {On the utility of Colour in shape analysis: An introduction to Colour science via palaeographical case studies},
journal = {Heliyon},
volume = {9},
number = {10},
pages = {e20698},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e20698},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023079069},
author = {Vlad Atanasiu and Peter Fornaro},
keywords = {Colour science, Colour processing, Colour perception, Image processing, Image enhancement, Palaeography},
abstract = {In this article, we explore the use of colour for the analysis of shapes in digital images. We argue that colour can provide unique information that is not available from shape alone, and that familiarity with the interdisciplinary field of colour science is essential for unlocking the potential of colour. Within this perspective, we offer an illustrated overview of the colour-related aspects of image management and processing, perceptual psychology, and cultural studies, using for exemplary purposes case studies focused on computational palaeography. We also discuss the changing roles of colour in society and the sciences, and provide technical solutions for using digital colour effectively, highlighting the impact of human factors. The article concludes with an annotated bibliography. This work is a primer, and its intended readership are scholars and computer scientists unfamiliar with colour science.}
}