@ARTICLE{8753748,
  author={Xu, Lei},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={An overview and perspectives on bidirectional intelligence: Lmser duality, double IA harmony, and causal computation}, 
  year={2019},
  volume={6},
  number={4},
  pages={865-893},
  abstract={Advances on bidirectional intelligence are overviewed along three threads, with extensions and new perspectives. The first thread is about bidirectional learning architecture, exploring five dualities that enable Lmser six cognitive functions and provide new perspectives on which a lot of extensions and particularlly flexible Lmser are proposed. Interestingly, either or two of these dualities actually takes an important role in recent models such as U-net, ResNet, and DenseNet. The second thread is about bidirectional learning principles unified by best yIng-yAng ( IA ) harmony in BYY system. After getting insights on deep bidirectional learning from a bird-viewing on existing typical learning principles from one or both of the inward and outward directions, maximum likelihood, variational principle, and several other learning principles are summarised as exemplars of the BYY learning, with new perspectives on advanced topics. The third thread further proceeds to deep bidirectional intelligence, driven by long term dynamics ( LTD ) for parameter learning and short term dynamics ( STD ) for image thinking and rational thinking in harmony. Image thinking deals with information flow of continuously valued arrays and especially image sequence, as if thinking was displayed in the real world, exemplified by the flow from inward encoding / cognition to outward reconstruction / transformation performed in Lmser learning and BYY learning. In contrast, rational thinking handles symbolic strings or discretely valued vectors, performing uncertainty reasoning and problem solving. In particular, a general thesis is proposed for bidirectional intelligence, featured by BYY intelligence potential theory ( BYY-IPT ) and nine essential dualities in architecture, fundamentals, and implementation, respectively. Then, problems of combinatorial solving and uncertainty reasoning are investigated from this BYY IPT perspective. First, variants and extensions are suggested for AlphaGoZero like searching tasks, such as traveling salesman problem ( TSP ) and attributed graph matching ( AGM ) that are turned into Go like problems with help of a feature enrichment technique. Second, reasoning activities are summarized under guidance of BYY IPT from the aspects of constraint satisfaction, uncertainty propagation, and path or tree searching. Particularly, causal potential theory is proposed for discovering causal direction, with two roads developed for its implementation.},
  keywords={Deep learning;Bayes methods;Probabilistic logic;Computer architecture;Image reconstruction;Uncertainty;Cognition},
  doi={10.1109/JAS.2019.1911603},
  ISSN={2329-9274},
  month={July},}@ARTICLE{10689568,
  author={Chen, Mark Yu-Shan},
  journal={IEEE Annals of the History of Computing}, 
  title={Mechanical Numeracy: Thinking With the Soroban Abacus in Modern Japan}, 
  year={2025},
  volume={47},
  number={1},
  pages={36-49},
  abstract={The soroban is a traditional arithmetic tool whose life in modern Japan reflected an inherently material dimension of computational numeracy. Using a system of commands to carry out operations, the soroban was both doubted and enthusiastically embraced by educators as a way of teaching basic mathematics, sparking conversations of what it really meant to understand arithmetic. Despite the introduction of Western-style pen and paper arithmetic, it persisted as the standard tool of computing in households, businesses, and bureaucracy, driving the Taylorist training of human calculators who could apply its commands with corporal discipline and the design of mechanical calculators that simplified its procedures. Even when educators held an “intuitive” ideal of mental calculation that moved students away from calculating with physical tools, the soroban persevered as a virtual interface that calculators accessed in their minds.},
  keywords={Arithmetic;Mathematics;Education;Calculators;History;Standards;Business},
  doi={10.1109/MAHC.2024.3465461},
  ISSN={1934-1547},
  month={Jan},}@ARTICLE{9389764,
  author={Riekki, Jukka and Mämmelä, Aarne},
  journal={IEEE Access}, 
  title={Research and Education Towards Smart and Sustainable World}, 
  year={2021},
  volume={9},
  number={},
  pages={53156-53177},
  abstract={We propose a vision for directing research and education in the field of information and communications technology (ICT). Our Smart and Sustainable World vision targets prosperity for the people and the planet through better awareness and control of both human-made and natural environments. The needs of society, individuals, and industries are fulfilled with intelligent systems that sense their environment, make proactive decisions on actions advancing their goals, and perform the actions on the environment. We emphasize artificial intelligence, feedback loops, human acceptance and control, intelligent use of basic resources, performance parameters, mission-oriented interdisciplinary research, and a holistic systems view complementing the conventional analytical reductive view as a research paradigm, especially for complex problems. To serve a broad audience, we explain these concepts and list the essential literature. We suggest planning research and education by specifying, in a step-wise manner, scenarios, performance criteria, system models, research problems, and education content, resulting in common goals and a coherent project portfolio as well as education curricula. Research and education produce feedback to support evolutionary development and encourage creativity in research. Finally, we propose concrete actions for realizing this approach.},
  keywords={Education;Sustainable development;Systems thinking;Pattern recognition;Intelligent systems;Europe;Complex systems;Smart world vision;sustainable development goals;Internet of Things (IoT);artificial intelligence (AI);computational intelligence (CI);reductive view;systems view;emergence;experimental-inductive method;hypothetico-deductive method;functionality;basic resources;performance;energy efficiency;dependability;availability;reliability;safety;security;constraints;optimization;decision making;hierarchy;open-loop control;closed-loop feedback control;degree of centralization;distributed systems;education;integrative learning;research;innovation;history},
  doi={10.1109/ACCESS.2021.3069902},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8491714,
  author={Sabin, Mihaela and Smith, Adrienne and DuBow, Wendy and Deloge, Rosabel},
  booktitle={2018 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Creative computing challenge: teacher professional learning to enhance non-computing career and technical education curricula with engaging computational practices for all students}, 
  year={2018},
  volume={},
  number={},
  pages={i-i},
  abstract={The Creative Computing Challenge (CCC) project (2014-2018) is funded by the National Science Foundation and is designed to broaden participation in computing by providing professional development (PD) for high school teachers at Career & Technical Education (CTE) programs throughout the state of New Hampshire. Teachers receive a stipend and tablets for their classrooms; they attend several in-person PD sessions through the year, where master teachers and PD facilitators introduce modeling of inquiry and equity-based practices, as well as teach the App Inventor tool and how to inculcate computational thinking in students. Project evaluation has included teacher interviews, classroom and PD observations, as well as student and teacher surveys. External evaluation of this project has been an integral part of the project from the beginning and, along with the project team’s observations and input, has significantly reshaped the project activities. It became clear after the first year that a central challenge of this project would be working with a mix of teachers across multiple domains – from teachers who had little experience even using computers to teachers who had computer science degrees; from teachers who came to teaching from professional backgrounds to those who had education degrees; and from beginning teachers to those who had been teaching the same courses for twenty years. Through evaluation data and really listening to teacher feedback, we not only tailored the PD content and structure, but also refined the data collection instruments and evaluation design to bridge the gap between different teacher experiences and levels of preparation. As a result, we have been able to bring computing into non-technical content areas such as Hospitality and non-programming classes such as Photography, as well as support computing educations in New Hampshire CTE programs. In Year 4, we now better understand the range of benefits and challenges involved in working with CTE programs and inserting CCC-inspired curricular modules in non-computing courses.},
  keywords={Education;Handheld computers;Engineering profession;Programming profession;Photography;Interviews;Instruments;teacher professional learning;career and technocal edcuation;inquiry and equity-based teaching professional development evaluation},
  doi={10.1109/RESPECT.2018.8491714},
  ISSN={},
  month={Feb},}@ARTICLE{6519937,
  author={Wang, Song and Li, Ling and Jones, James D.},
  journal={IEEE Systems Journal}, 
  title={Systemic Thinking on Services Science, Management and Engineering: Applications and Challenges in Services Systems Research}, 
  year={2014},
  volume={8},
  number={3},
  pages={803-820},
  abstract={As the world increasingly becomes characterized by the provision of services to customers, service research faces many challenges and needs a new vision. Many of these challenges stem from the fact that technologies are continually experiencing dramatic change, and savvy customers are increasingly demanding more qualified services. Although research and experiential findings on services in many disciplines have achieved impressive results, systematic research on modern services systems is rarely considered. Aiming at services systems (not only services themselves), this paper discusses the contributions and the potentials for the field of systems theory for Services Science, Management and Engineering (SSME). Thus, SSME can provide suitable referential clues for discussing impacts of systems theory on services research, and systemic thinking can be applied to discuss key issues in SSME. Providing basic definitions of services and services systems, this paper elaborates on the research objects and methodologies of SSME from systems perspective, and proposes that systems theory can be applied as the foundations of services engineering. This paper further sheds light on systemic issues in services science and engineering, services operations, and services systems management. It also provides a summary of relevant theories and tools applied to services systems at the systems level. Finally, some potential prospects in SSME research are presented to meet research demands and practical challenges.},
  keywords={Production;Manufacturing;Industries;Economics;Standards organizations;Organizations;Services engineering;services management;services science;services system;SSME;systems theory;Services engineering;services management;services science;services system;SSME;systems theory},
  doi={10.1109/JSYST.2013.2260622},
  ISSN={1937-9234},
  month={Sep.},}@INPROCEEDINGS{974419,
  author={Brandt, M.E.},
  booktitle={Proceedings 2nd Annual IEEE International Symposium on Bioinformatics and Bioengineering (BIBE 2001)}, 
  title={Thinking nonlinearly about brain dynamics: a neurocommentary}, 
  year={2001},
  volume={},
  number={},
  pages={112-118},
  abstract={Despite significant progress over the past several decades in neural research there still remains an ingrained tendency to approach the field using overly reductionistic as well as linear theories and methods. We are just beginning to appreciate the complexity of the brain. A further shift in our "consciousness" about neural dynamics is needed to take the next steps in brain research. We need to use more reflexively what we have learned about the nonlinear dynamical and complex nature of the brain to attempt to "bootstrap" our own thinking processes about neural science itself.},
  keywords={Brain},
  doi={10.1109/BIBE.2001.974419},
  ISSN={},
  month={Nov},}@ARTICLE{10816123,
  author={Liu, Qinrui and Luo, Biao and Zhang, Dongbo and Chen, Renjie},
  journal={IEEE Robotics and Automation Letters}, 
  title={Thinking Before Decision: Efficient Interactive Visual Navigation Based on Local Accessibility Prediction}, 
  year={2025},
  volume={10},
  number={2},
  pages={1688-1695},
  abstract={Embodied AI has made prominent advances in interactive visual navigation tasks based on deep reinforcement learning. In the pursuit of higher success rates in navigation, previous work has typically focused on training embodied agents to push away interactable objects on the ground. However, such interactive visual navigation largely ignores the cost of interacting with the environment and interactions are sometimes counterproductive (e.g., push the obstacle but block the existing path). Considering these scenarios, we develop a efficient interactive visual navigation method. We propose Local Accessibility Prediction (LAP) Module to enable the agent to learn thinking about how the upcoming action will affect the environment and the navigation task before making a decision. Besides, we introduce the interaction penalty term to represent the cost of interacting with the environment. And different interaction penalties are imposed depending on the size of the obstacle pushed away. We introduce the average number of interactions as a new evaluation metric. Also, a two-stage training pipeline is employed to reach better learning performance. Our experiments in AI2-THOR environment show that our method outperforms the baseline in all evaluation metrics, achieving significant improvements in navigation performance.},
  keywords={Navigation;Visualization;Costs;Training;Pipelines;Floors;Engines;Deep reinforcement learning;Predictive models;Portable computers;Interactive visual navigation;local accessibility prediction;interaction cost},
  doi={10.1109/LRA.2024.3522769},
  ISSN={2377-3766},
  month={Feb},}@ARTICLE{10355908,
  author={Mittal, Shweta and Saharia, Ankur and Ismail, Yaseera and Petruccione, Francesco and Bourdine, Anton V. and Morozov, Oleg G. and Demidov, Vladimir V. and Yin, Juan and Singh, Ghanshyam and Tiwari, Manish and Kumar, Santosh},
  journal={IEEE Sensors Journal}, 
  title={Design and Performance Analysis of a Novel Hoop-Cut SPR-PCF Sensor for High Sensitivity and Broad Range Sensing Applications}, 
  year={2024},
  volume={24},
  number={3},
  pages={2697-2704},
  abstract={This article presents a systematic numerical investigation of a surface plasmon resonance (SPR) sensor based on photonic crystal fiber (PCF). The proposed design is modeled and simulated using the full-vectorial finite-element (FV-FEM) technique and sensing characteristics, such as confinement loss (CL) behaviors, phase matching, and sensitivity, which are investigated and presented. The plasmonic layer is made up of TiO2 and gold for improved sensitivity. The reported sensor exhibits an amplitude sensitivity of −374.062 RIU−1 and a wavelength sensitivity of 2000 nm/RIU for the refractive index (RI) sensing range of (1.39–1.44), according to the loss spectrum shift. The reported hoop-cut PCF-based SPR (HPCF-SPR) sensor is suitable for biosensing and chemical sensing applications because of its broad range (1.39–1.44) of analyte detection.},
  keywords={Biosensors;Sensitivity;Refractive index;Optical fiber sensors;Photonics;Surface plasmon resonance;Biosensors;fiber-optic sensor;photonic crystal fiber (PCF);sensitivity;surface plasmon resonance (SPR)},
  doi={10.1109/JSEN.2023.3339813},
  ISSN={1558-1748},
  month={Feb},}@ARTICLE{10138574,
  author={Dyavangoudar, Amogh A. and Chhipa, Mayur Kumar and Saharia, Ankur and Ismail, Yaseera and Petruccione, Francesco and Bourdine, Anton V. and Morozov, Oleg G. and Demidov, Vladimir V. and Yin, Juan and Singh, Ghanshyam and Tiwari, Manish},
  journal={IEEE Access}, 
  title={Orbital Angular Momentum Mode Propagation and Supercontinuum Generation in a Soft Glass Bragg Fiber}, 
  year={2023},
  volume={11},
  number={},
  pages={56891-56899},
  abstract={This manuscript presents a ring-core Bragg Fiber (RC-BF) for orbital angular momentum (OAM) modes propagation and supercontinuum generation. The proposed RC-BF is composed of alternating layers of soft glasses SF57 and LLF1 to render high nonlinearity to the fiber. Mode analysis using full-vectorial finite element method resulted in obtaining HE/EH modes to support vector modes as well as orbital angular momentum modes. The optimized fiber supports 22 OAM modes and exhibits a zero-dispersion wavelength (ZDW). The small effective area of Fiber 3 aided in achieving the highest nonlinearity,  $\gamma $  = 91.51  $\text{W}^{-1}$ km $^{-1}$ . A near-infrared supercontinuum is generated with a 35 dB flatness over a bandwidth of  $\sim $ 1087 - 2024 nm in a 20 cm long RC-BF using a chirp-free hyperbolic secant pulse of width 200 fs and peak power of 5 kW.},
  keywords={Optical fiber dispersion;Finite element methods;Optical fibers;Supercontinuum generation;Refractive index;Dispersion;Optical fiber networks;Bragg gratings;Bragg fiber;finite element method;OAM modes;zero-dispersion wavelength;supercontinuum generation},
  doi={10.1109/ACCESS.2023.3281370},
  ISSN={2169-3536},
  month={},}@ARTICLE{6418003,
  author={Leeb, Robert and Lancelle, Marcel and Kaiser, Vera and Fellner, Dieter W. and Pfurtscheller, Gert},
  journal={IEEE Transactions on Computational Intelligence and AI in Games}, 
  title={Thinking Penguin: Multimodal Brain–Computer Interface Control of a VR Game}, 
  year={2013},
  volume={5},
  number={2},
  pages={117-128},
  abstract={In this paper, we describe a multimodal brain-computer interface (BCI) experiment, situated in a highly immersive CAVE. A subject sitting in the virtual environment controls the main character of a virtual reality game: a penguin that slides down a snowy mountain slope. While the subject can trigger a jump action via the BCI, additional steering with a game controller as a secondary task was tested. Our experiment profits from the game as an attractive task where the subject is motivated to get a higher score with a better BCI performance. A BCI based on the so-called brain switch was applied, which allows discrete asynchronous actions. Fourteen subjects participated, of which 50% achieved the required performance to test the penguin game. Comparing the BCI performance during the training and the game showed that a transfer of skills is possible, in spite of the changes in visual complexity and task demand. Finally and most importantly, our results showed that the use of a secondary motor task, in our case the joystick control, did not deteriorate the BCI performance during the game. Through these findings, we conclude that our chosen approach is a suitable multimodal or hybrid BCI implementation, in which the user can even perform other tasks in parallel.},
  keywords={Games;Electroencephalography;Electrodes;Training;Brain computer interfaces;Educational institutions;Feature extraction;Brain–computer interfaces (BCI);brain switch;game;hybrid BCI;multimodal;multitasking;virtual reality (VR)},
  doi={10.1109/TCIAIG.2013.2242072},
  ISSN={1943-0698},
  month={June},}@ARTICLE{9677010,
  author={Kartal, Yavuz Selim and Kutlu, Mucahid},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Re-Think Before You Share: A Comprehensive Study on Prioritizing Check-Worthy Claims}, 
  year={2023},
  volume={10},
  number={1},
  pages={362-375},
  abstract={The massive amount of misinformation spreading on the internet on a daily basis has enormous negative impacts on societies. Therefore, we need systems to help fact-checkers to combat misinformation and to raise public awareness of this important problem. In this article, we propose a hybrid model which combines bidirectional encoder representations from transformer (BERT) model with various features to prioritize claims based on their check-worthiness. Features we use include domain-specific controversial topics (CT), word embeddings (WE), part-of-speech (POS) tags, and others. In addition, we explore various ways of increasing labeled data size to effectively train the models, such as increasing positive (IncPos) samples, active learning (AL), and utilizing labeled data in other languages. In our extensive experiments, we show that our model outperforms all state-of-the-art models in test collections of Conference and Labs of Evaluation Forum (CLEF) CheckThat! Lab (CTL) 2018 and 2019. In addition, when positive samples are increased in the training set, our model achieves the best mean average precision (MAP) score reported so far for the test collection of CTL 2020. Furthermore, we show that cross-lingual training is effective for prioritizing Arabic and Turkish claims, but not for English.},
  keywords={Task analysis;Fake news;Data models;Training;Bit error rate;Training data;Predictive models;Check-worthy claims;fact-checking;misinformation},
  doi={10.1109/TCSS.2021.3138642},
  ISSN={2329-924X},
  month={Feb},}@ARTICLE{8945390,
  author={Qiu, Liqing and Tian, Xiangbo and Sai, Shiqi and Gu, Chunmei},
  journal={IEEE Access}, 
  title={LGIM: A Global Selection Algorithm Based on Local Influence for Influence Maximization in Social Networks}, 
  year={2020},
  volume={8},
  number={},
  pages={4318-4328},
  abstract={Influence maximization is to select k nodes from social networks to maximize the expected number of nodes activated by these selected nodes. Influence maximization problem plays a vital role in commercial marketing, news propagation, rumor control and public services. However, the existing algorithms for influence maximization usually tend to select one aspect from efficiency and accuracy as its main improving objective. This method of excessively pursuing one metric often leads to performing poorly in other metrics. Hence, we think that algorithms for influence maximization should make a suitable compromise between computation efficiency and result accuracy instead of excessively pursuing for one metric. Based on the above understanding, this paper proposes a new algorithm, called Global Selection Based on Local Influence (LGIM). The basic idea of the proposed algorithm is following: if a node can influence another node with large influence, the node also has large influence. Therefore, a two-stage filtering strategy of candidate nodes is proposed, which can reduce a large number of running time. Moreover, this paper also proposes a new objective function to estimate the influence spread of a node set. In summarize, the proposed algorithm utilizes the two-stage filtering strategy of candidate nodes to avoid unnecessary computation, and adopts a new objective function to replace time-consuming Monte-Carle simulations. Experimental results on six real-world social networks demonstrate that the proposed algorithm outperforms other four comparison algorithms when comprehensively considering computation efficiency and result accuracy.},
  keywords={Social networking (online);Integrated circuit modeling;Heuristic algorithms;Greedy algorithms;Computational modeling;Technological innovation;Linear programming;Social networks;influence maximization;local influence;global selection},
  doi={10.1109/ACCESS.2019.2963100},
  ISSN={2169-3536},
  month={},}@ARTICLE{8132134,
  author={Verdée, Peter},
  journal={Logic Journal of the IGPL}, 
  title={Modelling defeasible reasoning by means of adaptive logic games}, 
  year={2012},
  volume={20},
  number={2},
  pages={417-437},
  abstract={In this article, I present a dynamic logic game for defeasible reasoning. I argue that, as far as defeasible reasoning is concerned, one should distinguish between practical and ideal rationality. Starting from the adaptive logic framework, I formalize both rationality notions by means of logic games. The presented adaptive logic games are based on (i) standard logic games on the one hand and (ii) dynamic proof procedures for adaptive logic on the other hand. The games are similar to standard logic games, but have the extra property that some moves are revisable. This is handled by means of a main control game, which starts different standard logic games. I argue that the adaptive logic games form intuitive reasoning models for rationality in defeasible reasoning contexts. Moreover, I will also demonstrate that the games give a good insight in the computational complexity of defeasible reasoning forms.},
  keywords={Logic games;rationality;defeasible reasoning;adaptive logic},
  doi={10.1093/jigpal/jzq060},
  ISSN={1368-9894},
  month={Apr},}@INPROCEEDINGS{1342537,
  author={Bastoul, C.},
  booktitle={Proceedings. 13th International Conference on Parallel Architecture and Compilation Techniques, 2004. PACT 2004.}, 
  title={Code generation in the polyhedral model is easier than you think}, 
  year={2004},
  volume={},
  number={},
  pages={7-16},
  abstract={Many advances in automatic parallelization and optimization have been achieved through the polyhedral model. It has been extensively shown that this computational model provides convenient abstractions to reason about and apply program transformations. Nevertheless, the complexity of code generation has long been a deterrent for using polyhedral representation in optimizing compilers. First, code generators have a hard time coping with generated code size and control overhead that may spoil theoretical benefits achieved by the transformations. Second, this step is usually time consuming, hampering the integration of the polyhedral framework in production compilers or feedback-directed, iterative optimization schemes. Moreover, current code generation algorithms only cover a restrictive set of possible transformation functions. This paper discusses a general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions. It presents several improvements to a state-of-the-art code generation algorithm. Two directions are explored: generated code size and code generator efficiency. Experimental evidence proves the ability of the improved method to handle real-life problems.},
  keywords={Iterative algorithms;Optimizing compilers;Production;Computational modeling;Size control;Program processors;Data structures;Solid modeling;Mathematical model;Scheduling},
  doi={10.1109/PACT.2004.1342537},
  ISSN={1089-795X},
  month={Oct},}@ARTICLE{7997798,
  author={Papyan, Vardan and Sulam, Jeremias and Elad, Michael},
  journal={IEEE Transactions on Signal Processing}, 
  title={Working Locally Thinking Globally: Theoretical Guarantees for Convolutional Sparse Coding}, 
  year={2017},
  volume={65},
  number={21},
  pages={5687-5701},
  abstract={The celebrated sparse representation model has led to remarkable results in various signal processing tasks in the last decade. However, despite its initial purpose of serving as a global prior for entire signals, it has been commonly used for modeling low dimensional patches due to the computational constraints it entails when deployed with learned dictionaries. A way around this problem has been recently proposed, adopting a convolutional sparse representation model. This approach assumes that the global dictionary is a concatenation of banded circulant matrices. While several works have presented algorithmic solutions to the global pursuit problem under this new model, very few truly effective guarantees are known for the success of such methods. In this paper, we address the theoretical aspects of the convolutional sparse model providing the first meaningful answers to questions of uniqueness of solutions and success of pursuit algorithms, both greedy and convex relaxations, in ideal and noisy regimes. To this end, we generalize mathematical quantities, such as the l0 norm, mutual coherence, Spark and restricted isometry property to their counterparts in the convolutional setting, intrinsically capturing local measures of the global model. On the algorithmic side, we demonstrate how to solve the global pursuit problem by using simple local processing, thus offering a first of its kind bridge between global modeling of signals and their patch-based local treatment.},
  keywords={Dictionaries;Convolution;Convolutional codes;Computational modeling;Sparse matrices;Mathematical model;Matching pursuit algorithms;Sparse representations;convolutional sparse coding;uniqueness guarantees;stability guarantees;orthogonal matching pursuit;basis pursuit;global modeling;local processing},
  doi={10.1109/TSP.2017.2733447},
  ISSN={1941-0476},
  month={Nov},}@INPROCEEDINGS{8443741,
  author={Gupta, Gaurav and Pequito, Sergio and Bogdan, Paul},
  booktitle={2018 ACM/IEEE 9th International Conference on Cyber-Physical Systems (ICCPS)}, 
  title={Re-Thinking EEG-Based Non-Invasive Brain Interfaces: Modeling and Analysis}, 
  year={2018},
  volume={},
  number={},
  pages={275-286},
  abstract={Brain interfaces are cyber-physical systems that aim to harvest information from the (physical) brain through sensing mechanisms, extract information about the underlying processes, and decide/actuate accordingly. Nonetheless, the brain interfaces are still in their infancy, but reaching to their maturity quickly as several initiatives are released to push forward their development (e.g., NeuraLink by Elon Musk and `typing-by-brain' by Facebook). This has motivated us to revisit the design of EEG-based non-invasive brain interfaces. Specifically, current methodologies entail a highly skilled neuro-functional approach and evidence-based a priori knowledge about specific signal features and their interpretation from a neuro-physiological point of view. Hereafter, we propose to demystify such approaches, as we propose to leverage new time-varying complex network models that equip us with a fractal dynamical characterization of the underlying processes. Subsequently, the parameters of the proposed complex network models can be explained from a system's perspective, and, consecutively, used for classification using machine learning algorithms and/or actuation laws determined using control system's theory. Besides, the proposed system identification methods and techniques have computational complexities comparable with those currently used in EEG-based brain interfaces, which enable comparable online performances. Furthermore, we foresee that the proposed models and approaches are also valid using other invasive and non-invasive technologies. Finally, we illustrate and experimentally evaluate this approach on real EEG-datasets to assess and validate the proposed methodology. The classification accuracies are high even on having less number of training samples.},
  keywords={Brain modeling;Brain-computer interfaces;Electroencephalography;Complex networks;Computational modeling;Feature extraction;Spatiotemporal phenomena;brain interfaces;spatiotemporal;fractional dynamics;unknown inputs;classification;motor prediction},
  doi={10.1109/ICCPS.2018.00034},
  ISSN={},
  month={April},}@INPROCEEDINGS{6142319,
  author={Carvalho, Jonata Tyska and Santos, Rafael A. Penna dos and Botelho, Silvia Silva da Costa and Filho, Nelson Duarte and Oliveira, Rodrigo Ruas and Santos, Edevaldo},
  booktitle={2011 International Conference on Internet of Things and 4th International Conference on Cyber, Physical and Social Computing}, 
  title={Hyper-Environments: A Different Way to Think about IoT}, 
  year={2011},
  volume={},
  number={},
  pages={25-32},
  abstract={The current technological scenario presents different mobile devices, which support wireless communication at an increasingly low cost. This all makes it possible to build systems thought to be impossible. The utilization of computational and natural elements, and the mixing of virtual and real elements, set up a complex relationship between elements. A good organization of these relations would enable the construction of complex systems that would bring countless benefits to users. This work presents an architecture to build hyper-environments, term proposed in this paper to define the interconnection between smart environments (which involve different elements, technological or not, real and/or virtual).The proposed architecture presents a taxonomy and a set of concepts for the organization of the hyper-environmental elements. It also offers directions to implement a middleware for building such systems. To validate the work, a hyper environment will be built using a middleware implemented based on the proposed architecture.},
  keywords={Computer architecture;Media;Organizations;Context;Middleware;Computational modeling;Architecture;smart environments;architecture;middleware;internet of things},
  doi={10.1109/iThings/CPSCom.2011.110},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9723201,
  author={Shahsavari, Sina and Sarangi, Pulak and Pal, Piya},
  booktitle={2021 55th Asilomar Conference on Signals, Systems, and Computers}, 
  title={KR-LISTA: Re-Thinking Unrolling for Covariance-Driven Sparse Inverse Problems}, 
  year={2021},
  volume={},
  number={},
  pages={1403-1408},
  abstract={This paper considers the problem of joint support recovery in Multiple Measurement Vector (MMV) models. We show that by exploiting correlation priors, one can boost the performance and computational cost of unrolled data-driven techniques for joint support recovery. We propose a novel unrolling of the Iterative Shrinkage Thresholding Algorithm (ISTA) for correlation-aware support recovery, which preserves the special "Khatri-Rao" structure that underlies the model. The proposed network, termed as "KR-LISTA", provides a parameter-efficient unrolling which enables training with limited data. Our numerical simulations demonstrate the effectiveness of KR-LISTA at test time for different values of SNR, and support sizes which were not provided to the network during training. In addition, KR-LISTA is also seen to be effective even in presence of model uncertainties. 1},
  keywords={Training;Uncertainty;Computational modeling;Training data;Network architecture;Numerical simulation;Time measurement;Joint Support Recovery;Multiple Measurement Vector;Correlation-awareness;Iterative Shrinkage Thresholding Algorithm (ISTA);Learned ISTA (LISTA);Khatri-Rao Product},
  doi={10.1109/IEEECONF53345.2021.9723201},
  ISSN={2576-2303},
  month={Oct},}@INPROCEEDINGS{10943344,
  author={Garcia, Gonzalo Martin and Zeid, Karim Abou and Schmidt, Christian and De Geus, Daan and Hermans, Alexander and Leibe, Bastian},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Fine-Tuning Image-Conditional Diffusion Models is Easier than you Think}, 
  year={2025},
  volume={},
  number={},
  pages={753-762},
  abstract={Recent work showed that large diffusion models can be reused as highly precise monocular depth estimators by casting depth estimation as an image-conditional image generation task. While the proposed model achieved state-of-the-art results, high computational demands due to multi-step inference limited its use in many scenarios. In this paper, we show that the perceived inefficiency was caused by a flaw in the inference pipeline that has so far gone unnoticed. The fixed model performs comparably to the best previously reported configuration while being more than 200x faster. To optimize for downstream task performance, we perform end-to-end fine-tuning on top of the single-step model with task-specific losses and get a deterministic model that outperforms all other diffusion-based depth and normal estimation models on common zero-shot benchmarks. We surprisingly find that this fine-tuning protocol also works directly on Stable Diffusion and achieves comparable performance to current state-of-the-art diffusion-based depth and normal estimation models, calling into question some of the conclusions drawn from prior works.},
  keywords={Training;Geometry;Protocols;Image synthesis;Computational modeling;Depth measurement;Pipelines;Estimation;Diffusion models;Reliability},
  doi={10.1109/WACV61041.2025.00083},
  ISSN={2642-9381},
  month={Feb},}@INPROCEEDINGS{10220748,
  author={Saranya, R. and Kalaivani, D.},
  booktitle={2023 5th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Manhattan Distance SMOTE Combined with Stacked Optimal Deep Learning Algorithms for the Efficient Heart Disease Prediction-Design Thinking Approach}, 
  year={2023},
  volume={},
  number={},
  pages={706-712},
  abstract={Advancements in technology and computational power have significantly diversified the field of medical sciences, especially in diagnosing human cardiac disorders, which is currently one of the most severe cardiac illnesses that drastically shortens human lives. Early detection of heart failure is critical to prevent it and improve patients' survival rates. However, traditional manual methods are subject to inter examiner variability and bias, making them unreliable in diagnosing cardiac diseases. The study conducted aimed to evaluate the performance of machine learning algorithms in accurately identifying and classifying individuals with heart disease and those who are healthy. For this purpose, a heart disease dataset was utilized to assess the predictive capabilities of the machine learning models. The study employs nine classifiers, including Probabilistic Neural Network (PNN), Artificial Neural Networks (ANN), Linear Regression (Li-R), Logistic Regression (Lo-R), and Naive Bayes (NB), before and after hyper parameter tuning. This research work also assessed various metrics, such as classification accuracy, F-measure, sensitivity, and specificity. By conducting specific preprocessing, dataset standardization, and hyper parameter tuning, it is observed that data normalization and hyper parameter adjustment of the machine learning classifiers significantly improved their performance in predicting heart disease.},
  keywords={Heart;Machine learning algorithms;Computational modeling;Artificial neural networks;Standardization;Predictive models;Sensitivity and specificity;Machine learning algorithms;Heart disease diagnosis;Data normalization;Hyperparameter tuning},
  doi={10.1109/ICIRCA57980.2023.10220748},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8405151,
  author={Cornejo, Maria Eda and Sommer, Sonia and Rodríguez, Jorge},
  booktitle={2017 36th International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={An approach based on Embodied Programming to teach computer science at a Secondary School}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  abstract={In this article a didactic approach is introduced which seeks to integrate the progress made in the context of Block-Based Programming and other didactic approaches developed in the area of computer teaching. The prospects developed in the area of Project Based Learning Approach, Collaborative Learning and Embodied Programming are taken into account. Surrogate Embodiment, in the Embodied Programming context, is a kind of interaction where the movements performed by a person on a stage are directed by students. Furthermore, it is used as a structuring resource in the teaching process, the development of computational devices, paying special attention to skills development in the area of Computational Thinking. This paper presents a Video Game Development Workshop based on this approach with first year students from a state technical school. The experience has shown satisfactory results in connection to the acquisition of concepts and fundamental practices in the area of Algorithms and Programming.},
  keywords={Programming;Education;Software;Cognition;Collaborative work;Performance evaluation;Secondary School;Computing Science;Computational Thinking;Teaching Programming;Embodied Programming;Blocks-based Programming},
  doi={10.1109/SCCC.2017.8405151},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9962388,
  author={Aulicino, Alexa and Bakrania, Smitesh},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={A Python-based lab module to conduct thermodynamic cycle analysis}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={A Python-based lab activity was developed for a remote Thermodynamics course to add computational thinking to traditional analytical problem solving. Python was selected to conduct the analysis because of its popularity and utility in the broader engineering field. Early exposure to this highly desired engineering skill can provide added benefits to students. Combining Python with an engaging lab experience can have a compounding effect on student learning outcomes. A five-week Python-based lab module was developed for an introductory thermal-fluid science class. The module reinforced fundamental concepts learned in lecture, while expanding on design-related analysis which is often left for advanced courses. The lab module began with an introduction to Python programming and quickly transitioned to the parametric analysis of standard Rankine, Gas Turbine, and Vapor Compression cycles. The lab module was designed to be self-guided with step-by-step instructions presented using Google Colab. This paper details the implementation and the student outcomes. Both direct and indirect assessments were conducted over two semesters of the course. Results indicate a strong positive impact on Python programming learning outcomes. Students acquired a working knowledge of Python programming and experienced how computational tools can be used to solve advanced engineering problems. At the same time, the student feedback indicated students' resistance to open-ended projects and independent learning; even if they are aware of their relevance and benefits to their future careers. Nevertheless, the positive learning outcomes were encouraging. Whether students pursue a career in thermodynamics or in a broader engineering field, this lab experience equipped them with tools that can augment their engineering skills.},
  keywords={Resistance;Knowledge engineering;Thermodynamics;Engineering profession;Internet;Problem-solving;Programming profession;Thermodynamics;Python;Computational Thinking;Open-ended;Online Learning},
  doi={10.1109/FIE56618.2022.9962388},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{234877,
  author={Palmer, J. and Steele, G.L.},
  booktitle={[Proceedings 1992] The Fourth Symposium on the Frontiers of Massively Parallel Computation}, 
  title={Connection Machine model CM-5 system overview}, 
  year={1992},
  volume={},
  number={},
  pages={474-483},
  abstract={The Connection Machine model CM-5 provides high performance and ease of use for large data-intensive applications. The CM-5 architecture is designed to scale to teraflops performance on terabyte-sized problems. SPARC-based processing nodes, each with four vector pipes, are connected by two communications networks, the Data Network and the Control Network. The system combines the best features of SIMD (single-instruction multiple-data) and MIMD (multiple-instruction multiple-data) designs, integrating them into a single 'universal' parallel architecture. The processor nodes may be divided into independent computational partitions; each partition may be independently timeshared or devoted to batch processing. Programming languages include Fortran (with Fortran 90 array constructs) and C*, a parallel dialect of C. The PRISM programming environment supports source-level debugging, tracing, and profiling through a graphical interface based on X Windows.<>},
  keywords={Process control;Control systems;Bandwidth;Communication system control;Computer architecture;Weight control;Concurrent computing;Communication networks;Computer languages;Programming environments},
  doi={10.1109/FMPC.1992.234877},
  ISSN={},
  month={Oct},}@ARTICLE{8138984,
  author={},
  journal={ITNOW}, 
  title={Turing Test}, 
  year={2012},
  volume={54},
  number={2},
  pages={51-51},
  abstract={2012 marks the 100th anniversary of the birth of Alan Turing. To commemorate this event we asked leading figures in IT what they think of Turing's legacy to computing.},
  keywords={},
  doi={10.1093/itnow/bws051},
  ISSN={1746-5710},
  month={June},}@INPROCEEDINGS{9668455,
  author={Mason, A. and Esper, I. and Korostynska, O. and Haiddegger, T. and Popov, A. and Christensen, L. B. and Alvseike, O.},
  booktitle={2021 IEEE 21st International Symposium on Computational Intelligence and Informatics (CINTI)}, 
  title={The Meat Factory Cell: A new way of thinking for meat producers}, 
  year={2021},
  volume={},
  number={},
  pages={000091-000096},
  abstract={This paper presents the novel Meat Factory Cell (MFC) concept which is being developed in both semi- and fully-automated forms. The MFC provides several important opportunities for the red meat sector, including enhanced robustness, scalability and flexibility. Moreover, it is mindful of the need for small-medium meat processors requiring access to automation, which has proven uneconomical until now. The industry has renewed interest in such automation initiatives, particularly considering its need to improve resilience in the face of future global pandemics. The paper describes the progress of the MFC, as well as a rudimentary framework for realising the implementation. Finally, the paper discusses some of the major hurdles faced in the future.},
  keywords={Technological innovation;Automation;Program processors;Scalability;Robustness;Production facilities;Safety;automation;meat;pork;robotics;butchering},
  doi={10.1109/CINTI53070.2021.9668455},
  ISSN={2471-9269},
  month={Nov},}
