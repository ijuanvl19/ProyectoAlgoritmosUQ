@INPROCEEDINGS{9018582,
  author={Pancieri, Jussara and Siqueira, Fábio Ventorim and Oliveira, Márcia Gonçalves de and Santos, Marcelo Cardoso Lima dos},
  booktitle={2019 Latin American Robotics Symposium (LARS), 2019 Brazilian Symposium on Robotics (SBR) and 2019 Workshop on Robotics in Education (WRE)}, 
  title={Robotics in the Resocialization of Youngsters and Teenagers in Socio-Educational Measures}, 
  year={2019},
  volume={},
  number={},
  pages={429-434},
  abstract={This paper presents a proposal and an experience report of an educational robotics course integrated to the process of resocialization of youngsters and teenagers in socio-educational measures. This proposal adopts a teaching approach oriented to the development of comprehension, analysis, logical reasoning, creativity and collaboration skills in order to develop in these young people real world problemsolving skills. The main challenge of this proposal is to favor the assimilation of the contents and the development of robotics practice outside the classroom, since, in accommodation, no course material is accessible from paper and pencil to robotics practice instruments. Thus, the main differential of this work is literally working the computational thinking in spaces of deprivation of liberty in order to develop ideas for problem solving tasks. The results of this developed experience point to excellent opportunities for resocialization and professional orientation of young people in socio-educational measures through the teaching of robotics.},
  keywords={Robots;Education;Electronic components;Proposals;Programming profession;Problem-solving;resocialization, educational robotics, youngsters and teenagers in socio-educational measures},
  doi={10.1109/LARS-SBR-WRE48964.2019.00082},
  ISSN={2643-685X},
  month={Oct},}@INPROCEEDINGS{10366359,
  author={Boya-Lara, Carlos and Diaz-Solano, Daniela and Fehrenbach, Aaron},
  booktitle={2023 VI Congreso Internacional en Inteligencia Ambiental, Ingeniería de Software y Salud Electrónica y Móvil (AmITIC)}, 
  title={Educational robotics to enhance knowledge and skills in higher education: A systematic review}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Because of its ability to prepare students for the 21st century world of work, educational robotics (RE) has assumed a prominent role in education. Following the methodology provided by Kitchenham, we conducted a systematic literature review (SLR) to provide a comprehensive overview of studies, research, and practices related to robotics education in higher education. The study focuses on identifying the most commonly used RE hardware-based platforms in academic research publications, the type of knowledge intended to be imparted, and the skills or competencies reinforced by the platforms. Within the findings we can underline that there is no exclusive platform, but rather commercial ones are used, made by the researchers themselves, and even adapted from robots that were not designed for instructional purposes. Moreover, the subjects intended to be taught were all related to Science, Technology, Engineering and Mathematics (STEM) and oriented to electrical engineering, electronics, robotics, and computer science professions. On the other hand, the skills that improved the most were computational thinking, cooperation and sophisticated problem solving, which are essential for 21st century job descriptions.},
  keywords={Knowledge engineering;Electrical engineering;Computer science;Systematics;Bibliographies;Education;Software;educational robotics;higher education;educational platforms;systematic literature reviews (SLR);STEM},
  doi={10.1109/AmITIC60194.2023.10366359},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6328105,
  author={Mashayekhi, Kaveh and Labusca, Luminita},
  booktitle={2012 Third International Conference on Emerging Security Technologies}, 
  title={Systems Biology Meets Systemic Medicine: The Old, the New and the Blue}, 
  year={2012},
  volume={},
  number={},
  pages={169-175},
  abstract={Breakthroughs in technology that deliver fast and accurate molecular biology data, together with the use of advanced software, and analytical methods made possible quantitative accumulation of biological information leading to a qualitative evolution. Sequencing of human genome was of the first door to the era of systemic understanding in life sciences. The paper reviews the emerging concepts of systems biology, systems medicine and their potential benefits in science and practice.},
  keywords={Bioinformatics;Biomedical imaging;Systems biology;Genomics;Diseases;Humans;systems biology;systemic thinking;systems medicine},
  doi={10.1109/EST.2012.14},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8122725,
  author={Dimirovski, Georgi M. and Wang, Rui and Yang, Bin},
  booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Delay and recurrent neural networks: Computational cybernetics of systems biology?}, 
  year={2017},
  volume={},
  number={},
  pages={906-911},
  abstract={Science of Neural Networks, and even much more so computing applications, have undergone developments beyond any predictions since McCullock-Pitts artificial neuron (1943) up via Hopfield's neurons (1982, 1984) to Kasabov spiking-neurons neucube (2014) and evolving connectionist systems (2003). Still computational functionality of all kinds of neural network implies guaranteed operating steady-state equilibrium is fast-reached first. On the other side of this spectrum Science of Neurophysiology yielded insights converging to Systems Biology approach Gayton-Hall (2006). It appeared, on the crossroad of these findings with Kolmogorov's representation superposition and Hilbert's Thirteen problem certain rater delicate subtle issues emerged Sprecher (2017). This paper gives one perception of these issues and suggested a revised view on the foundations of past developments, possibly by re-thinking own stability results for recurrent neural networks which possess time-varying delays.},
  keywords={Neurons;Delays;Stability criteria;Cybernetics;Recurrent neural networks;Mathematical model;approximation computational models;artificial neurons;artificial recurrent neural networks;complex netwroks;cybernetics;human neural networks;living neurons},
  doi={10.1109/SMC.2017.8122725},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9910069,
  author={Chen, Shiyang and Huang, Shaoyi and Pandey, Santosh and Li, Bingbing and Gao, Guang R. and Zheng, Long and Ding, Caiwen and Liu, Hang},
  booktitle={SC21: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={E.T.: Re-Thinking Self-Attention for Transformer Models on GPUs}, 
  year={2021},
  volume={},
  number={},
  pages={1-14},
  abstract={Transformer-based deep learning models have become a ubiquitous vehicle to drive a variety of Natural Language Processing (NLP) related tasks beyond their accuracy ceiling. However, these models also suffer from two pronounced challenges, that is, gigantic model size and prolonged turnaround time. To this end, we introduce E.T. that rE-thinks self-attention computation for Transformer models on GPUs with the following contributions: First, we introduce a novel self-attention architecture, which encompasses two tailored self-attention operators with corresponding sequence length-aware optimizations, and operation reordering optimizations. Second, we present an attention-aware pruning design which judiciously uses various pruning algorithms to reduce more computations hence achieves significantly shorter turnaround time. For the pruning algorithms, we not only revamp the existing pruning algorithms, but also tailor new ones for transformer models. Taken together, we evaluate E.T. across a variety of benchmarks for Transformer, BERTBASE and DistilBERT, where E.T. presents superior performance over the mainstream projects, including the popular Nvidia Enterprise solutions, i.e., TensorRT and FasterTransformer.},
  keywords={Deep learning;Tensors;Computational modeling;High performance computing;Computer architecture;Benchmark testing;Transformers},
  doi={10.1145/3458817.3476138},
  ISSN={2167-4337},
  month={Nov},}@ARTICLE{10366259,
  author={Aliyu, Ibrahim and Oh, Seungmin and Ko, Namseok and Um, Tai-Won and Kim, Jinsul},
  journal={IEEE Access}, 
  title={Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing}, 
  year={2024},
  volume={12},
  number={},
  pages={11615-11630},
  abstract={The computing in the network (COIN) paradigm is a promising solution that leverages unused network resources to perform tasks to meet computation-demanding applications, such as the metaverse. In this vein, we consider the partial computation offloading problem in the metaverse for multiple subtasks in a COIN environment to minimize energy consumption and delay while dynamically adjusting the offloading policy based on the changing computational resource status. The problem is NP-hard, and we transform it into two subproblems: the task-splitting problem (TSP) on the user side and the task-offloading problem (TOP) on the COIN side. We model the TSP as an ordinal potential game and propose a decentralized algorithm to obtain its Nash equilibrium (NE). Then, we model the TOP as a Markov decision process and propose the double deep Q-network (DDQN) to solve for the optimal offloading policy. Unlike the conventional DDQN algorithm, where intelligent agents sample offloading decisions randomly within a certain probability, the COIN agent explores the NE of the TSP and the deep neural network. Finally, the simulation results reveal that the proposed model approach allows the COIN agent to update its policies and make more informed decisions, leading to improved performance over time compared to the traditional baseline.},
  keywords={Task analysis;Metaverse;Resource management;X reality;Dynamic scheduling;Delays;Optimization;Computational offloading;deep reinforcement learning;game theory;in-network computing;metaverse},
  doi={10.1109/ACCESS.2023.3344817},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6046249,
  author={Erra, Ugo and Scanniello, Giuseppe},
  booktitle={Workshop on Empirical Requirements Engineering (EmpiRE 2011)}, 
  title={Assessing think-pair-square in distributed modeling of use case diagrams}, 
  year={2011},
  volume={},
  number={},
  pages={77-84},
  abstract={In this paper, we propose a new method for the modeling of use case diagrams in the context of global software development. It is based on think-pair-square, a widely used cooperative method for active problem solving. The validity of the developed technology (i.e., the method and its supporting environment) has been assessed through two controlled experiments. In particular, the experiments have been conducted to compare the developed technology with a brainstorming session based on face-to-face interaction. The comparison has been performed with respect to the time needed to model use case diagrams and the quality of the produced models. The data analysis indicates a significant difference in favor of the brainstorming session for the time, with no significant impact on the requirements specification.},
  keywords={Computational modeling;Brain modeling;Unified modeling language;Programming;Software systems;Context;Controlled experiments;Global software engineering;Functional modeling;Requirements engineering},
  doi={10.1109/EmpiRE.2011.6046249},
  ISSN={2329-6356},
  month={Aug},}@ARTICLE{10535493,
  author={Uzam, Murat and El-Sherbeeny, Ahmed M. and Guo, Weiwen and Li, Zhiwu},
  journal={IEEE Access}, 
  title={Design of an Improved Think Globally Act Locally Approach for the Computation of Petri Nets Based Liveness Enforcing Supervisors of FMSs}, 
  year={2024},
  volume={12},
  number={},
  pages={74367-74388},
  abstract={An improved think-globally-act-locally (ITGAL) method is proposed in this paper for the computation of a liveness enforcing/deadlock prevention supervisor containing of a set control places (CPs) for a Petri net (PN) model of a flexible manufacturing system (FMS) suffering from deadlocks. The proposed method is especially suitable for generalized PN classes containing weighted arcs such as S4R and S4PR. It leads to optimal or near-optimal liveness-enforcing supervisors without solving intractable integer linear programming problems. By using a recently proposed optimality test for CPs, the proposed ITGAL method provides improved behavioral permissiveness and/or reduced structural complexity of the CPs. The applicability of the proposed method is shown by means of a number of typical FMS examples.},
  keywords={System recovery;Computational modeling;Law;Frequency modulation;Petri nets;Vectors;Flexible manufacturing systems;Flexible manufacturing system (FMS);deadlock;deadlock prevention;Petri net (PN);liveness enforcing supervisor (LES);optimality test},
  doi={10.1109/ACCESS.2024.3403804},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8912419,
  author={Sowah, Robert and Friedman, Ryan and Ofoli, Abdul R. and Sarkodie-Mensah, Baffour},
  booktitle={2019 IEEE Industry Applications Society Annual Meeting}, 
  title={Think to Speak - A Piezoelectric-EEG system for Augmentative and Alternative Communication (AAC) using Recurrent Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={The collection of individuals with severe speech and physical impairments (SSPI), is the target audience for the Think to Speak Augmentative and Alternative Communication (AAC) system. The slow communication rate of AACs accessible to the target audience renders them undesirable, exhausting to operate, and a barrier to social and economic inclusion. This research synergizes the use of Electroencephalography (EEG) and high-sensitivity piezoelectric sensor readings with a Long Short-Term Memory Recurrent Neural Network (LSTM RNN) to create a physically accessible AAC with performance comparable to 7.8 characters per minute communication rate. Since self-expression is inextricably linked with physical, mental, and emotional health, this research is of great significance to the estimated one percent of the global population with complex communication needs.},
  keywords={Electroencephalography;Brain modeling;Recurrent neural networks;Computer architecture;Headphones;Liquid crystal displays;Computational modeling;Piezoelectric sensor;Electroencephalography (EEG);Long Short-Term Memory;Recurrent Neural Network;Complex Communication Needs},
  doi={10.1109/IAS.2019.8912419},
  ISSN={2576-702X},
  month={Sep.},}@INPROCEEDINGS{10678083,
  author={Kim, Byoungjip and Hwang, Dasol and Cho, Sungjun and Jang, Youngsoo and Lee, Honglak and Lee, Moontae},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Show, Think, and Tell: Thought-Augmented Fine-Tuning of Large Language Models for Video Captioning}, 
  year={2024},
  volume={},
  number={},
  pages={1808-1817},
  abstract={Large language models (LLMs) have achieved a great success in natural language processing, and have a significant potential for multi-modal applications. Despite the surprising zero-shot or few-shot ability, it is also required to effectively fine-tune pre-trained language models for specific downstream tasks. In this paper, we introduce CaptionT5, a video captioning model that fine-tunes T5 towards understanding videos and generating descriptive captions. To generate a more corespondent caption, CaptionT5 introduces thought-augmented fine-tuning for video captioning, in which a pre-trained language model is fine-tuned on thought-augmented video inputs. This resembles the process that human see a video, think of visual concepts such as objects and actions, and then tell a correct and natural sentence based on the thoughts. To automatically generate thoughts, we propose (1) CLIP-guided thought sampling that samples thoughts based on the similarity in an image-text multimodal embedding space by leveraging CLIP. We also propose (2) CLIP-guided caption ranking during decoding for further performance gains. Through experimentation on VATEX, MSRVTT, and YC2 datasets, we empirically demonstrate that CaptionT5 performs competitively against prior-art video captioning approaches without using encoders specialized for video data. Further experiments show that CaptionT5 is especially effective under small number of sampled video frames.},
  keywords={Visualization;Computer vision;Large language models;Computational modeling;Conferences;Performance gain;Data models;Large Language Models;Thought-Augmented Fine-Tuning;Video Captioning},
  doi={10.1109/CVPRW63382.2024.00187},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{10654818,
  author={Cheng, Sijie and Guo, Zhicheng and Wu, Jinawen and Fang, Kechen and Li, Peng and Liu, Huaping and Liu, Yang},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={EgoThink: Evaluating First-Person Perspective Thinking Capability of Vision-Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={14291-14302},
  abstract={Vision-language models (VLMs) have recently shown promising results in traditional downstream tasks. Evaluation studies have emerged to assess their abilities, with the majority focusing on the third-person perspective, and only a few addressing specific tasks from the first-person per-spective. However, the capability of VLMs to “think” from a first-person perspective, a crucial attribute for advancing autonomous agents and robotics, remains largely unexplored. To bridge this research gap, we introduce EgoThink, a novel visual question-answering benchmark that encompasses six core capabilities with twelve detailed dimensions. The benchmark is constructed using selected clips from ego-centric videos, with manually annotated question-answer pairs containing first-person information. To comprehensively assess VLMs, we evaluate twenty-one popular VLMs on EgoThink. Moreover, given the open-ended format of the answers, we use GPT-4 as the automatic judge to compute single-answer grading. Experimental results indicate that although GPT-4V leads in numerous dimensions, all evaluated VLMs still possess considerable potential for improvement in first-person perspective tasks. Meanwhile, enlarging the number of trainable parameters has the most significant impact on model performance on EgoThink. In conclusion, EgoThink serves as a valuable addition to existing evaluation benchmarks for VLMs, providing an indispensable resource for future research in the realm of embodied artificial intelligence and robotics.},
  keywords={Bridges;Visualization;Computer vision;Computational modeling;Focusing;Benchmark testing;Planning;Egocentric;Vision-Language Models;Benchmark},
  doi={10.1109/CVPR52733.2024.01355},
  ISSN={2575-7075},
  month={June},}@INBOOK{9893006,
  author={Rubin, Olis Harold},
  booktitle={Computer Models of Process Dynamics: From Newton to Energy Fields}, 
  title={Creative thinking and scientific theories}, 
  year={2023},
  volume={},
  number={},
  pages={43-56},
  abstract={This chapter describes how the science of dynamics was created. It considers the study of electromagnetism, and focuses on the fluid dynamics. The chapter then focuses on many creative thinkers who formulated scientific models that described the behavior of the real world. Astronomy has been one of the most persistent activities in science. Galileo Galilei's greatest contribution was to combine experimental methods with creative thinking and mathematical analysis. Isaac Newton extended the work of Galileo to replace Kepler's empirical model of the solar system by mathematical equations. In 1864 Clerk Maxwell used an equation to show that an electromagnetic wave would be propagated through space at the speed of light. The chapter considers the efforts to create a mathematical model of aerodynamics.},
  keywords={Moon;Sun;Earth;Planetary orbits;Computational modeling;Extraterrestrial measurements;Analytical models},
  doi={10.1002/9781119885689.ch3},
  ISSN={},
  publisher={IEEE},
  isbn={9781119885665},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9893006},}@INPROCEEDINGS{8725190,
  author={Jaeger, Martin and Adair, Desmond},
  booktitle={2019 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Process Teaching Simulator: Trial and Error, Thinking, Learning Effectiveness}, 
  year={2019},
  volume={},
  number={},
  pages={160-165},
  abstract={The importance of feedback on students' learning activities, so as to facilitate high learning effectiveness, has been shown before. However, the effectiveness of feedback on students' learning activities, when students learn engineering processes based on computer based simulations, is much less well known. The purpose of this study is to analyze the impact of “correcting feedback” (i.e. the feedback indicates only students' mistakes) and “reflective feedback” (i.e. the feedback includes a hint to encourage the student to re-think a specific answer) on learning effectiveness of engineering students, when using computer based simulation in order to enhance the learning of engineering processes. The impact of “reflective feedback” is analyzed by carrying out semi-quasi experiments using experimental and control groups of students. It is found that “reflective feedback” does not result in higher learning effectiveness and that the students of this study prefer to correct their mistakes by focusing on “correcting feedback” and previously learned content, while using a “trial and error mentality”. The results provide evidence, first, about the impact of students' learning background when using teaching simulators, and, secondly, that simulators showing both, “correcting feedback” and “reflective feedback”, may reduce the stimulating effect of “reflective feedback” because of the presence of “correcting feedback”. Consideration of these findings will contribute to further improvement of process teaching simulators. This study is part of an ongoing research effort related to computer simulation based learning in engineering education.},
  keywords={Computational modeling;Engineering students;Games;Companies;Conferences;process simulation;learning effectiveness;computer-based learning;feedback methods},
  doi={10.1109/EDUCON.2019.8725190},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10033178,
  author={Nitsche, Anna-Maria and Franczyk, Bogdan and Schumann, Christian-Andreas},
  booktitle={2022 IEEE 28th International Conference on Engineering, Technology and Innovation (ICE/ITMC) & 31st International Association For Management of Technology (IAMOT) Joint Conference}, 
  title={System Dynamics Modeling for Smart and Collaborative Last Mile Networks}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper presents a comprehensive model of smart and collaborative last mile supply networks. Facing a multitude of challenges such as economic pressure, demographic change, and environmental demands, urban last mile supply networks are increasingly strained. Various solutions and strategies such as the integration of novel technologies and collaborative approaches are discussed in the literature and tested in case studies. The application of artificial intelligence for supply networks holds potential for future urban logistics optimization and is thus considered a relevant research avenue. A design science approach comprising system dynamics-based modeling is chosen due to last mile networks' inherent complexity. Systems thinking has proven to be useful in urban logistics and smart city research contexts as it enables researchers and practitioners to achieve a more holistic perspective. The proposed model contributes to a better understanding of last mile network complexity as well as the underlying interdependencies.},
  keywords={Economics;Smart cities;Biological system modeling;Computational modeling;Collaboration;Complexity theory;Systems thinking;last mile;urban logistics;supply chain collaboration;supply chain management;artificial intelligence;system dynamics},
  doi={10.1109/ICE/ITMC-IAMOT55089.2022.10033178},
  ISSN={},
  month={June},}@INPROCEEDINGS{10631247,
  author={Clemm, Christian and Stobbe, Lutz and Wimalawarne, Kishan and Druschke, Jan},
  booktitle={2024 Electronics Goes Green 2024+ (EGG)}, 
  title={Towards Green AI: Current Status and Future Research}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={The immense technological progress in artificial intelligence research and applications is increasingly drawing attention to the environmental sustainability of such systems, a field that has been termed ‘Green AI’. With this contribution we aim to broaden the discourse on Green AI by investigating the current status of approaches to both environmental assessment and ecodesign of AI systems. We propose a life-cycle-based system thinking approach that accounts for the four key elements of these software-hardware-systems: model, data, server, and cloud. We conduct an exemplary estimation of the carbon footprint of relevant compute hardware and highlight the need to further investigate methods for Green AI and ways to facilitate wide-spread adoption of its principles. We envision that AI could be leveraged to mitigate its own environmental challenges, which we denote as ‘AI4greenAI’.},
  keywords={Computational modeling;Green products;Estimation;Hardware;Data models;Systems thinking;Servers;artificial intelligence;machine learning;energy consumption;environmental impact;sustainable design},
  doi={10.23919/EGG62010.2024.10631247},
  ISSN={},
  month={June},}@INPROCEEDINGS{7352681,
  author={Mavroeidis, Vasileios and Koubias, Stavros},
  booktitle={2013 International Conference on Engineering, Technology and Innovation (ICE) & IEEE International Technology Management Conference}, 
  title={A collaborative business model in hi-tech environments which incorporate the knowledge triangle initiative}, 
  year={2013},
  volume={},
  number={},
  pages={1-11},
  abstract={The purpose of this paper is to propose a collaborative business model of measuring business excellence (MBE) by applying principles of Network Management and Systems Thinking. The proposed model is defined by the interaction of system variables giving the opportunity of a reliable and fair score as well as objective decision-making with regard to the areas that are susceptible of continuous improvement. Such a model is referred to be applicable in ecosystems which run the Knowledge Triangle initiative driven by EIT (E.U. initiative to re-address innovation boost which is mainly hosted by the European Institute of Innovation and Technology, in Europe).},
  keywords={Business;Technological innovation;Collaboration;Europe;Computational modeling;Systems thinking;Context;Business Excellence Models;Total Quality Management;Collaboration Networks;Knowledge Triangle;Performance Management},
  doi={10.1109/ITMC.2013.7352681},
  ISSN={},
  month={June},}@INPROCEEDINGS{1592597,
  author={Nucciarone, J.J. and Ozyoruk, Y. and Long, L.N.},
  booktitle={SC '97: Proceedings of the 1997 ACM/IEEE Conference on Supercomputing}, 
  title={New Life in Dusty Decks: Results of Porting a CM Fortran Based Aeroacoustic Model to High Performance Fortran}, 
  year={1997},
  volume={},
  number={},
  pages={16-16},
  abstract={The High Performance Fortran language is a 'standard by consensus', developed by individuals and vendors in the high performance computing industry, to provide a low barrier entry to parallel computing. It promises to be an easier to use development environment for distributed memory computing platforms compared to the programming complexity required by message passing libraries such as PVM and MPI. HPF promises much and is still in its infancy. Since HPF was developed in part based on experiences gained with early parallel Fortran compilers such as Thinking Machines CM Fortran, we decided to test the effectiveness of HPF with today's generation of HPF compilers by porting a complex existing model code originally developed using CM Fortran. The model code that we selected is a hybrid computational aeroacoustics code that solves the 3D, time-dependent Euler equations in the near flow field and uses a moving surface Kirchhoff's formula to predict the far field sound radiating from turbofan engine inlets. The original CM Fortran model code was developed on a Thinking Machines CM5. The extensive production research use of this model, using varying grid sizes, provides excellent benchmarks with which to compare the HPF port. Two HPF compilers were selected in the porting effort -- The Portland Group's (PGI) pghpf and the xlhpf compiler from IBM. IBM's xlhpf does not implement some elements of the HPF subset while PGI's offering provides several full-HPF extensions. porting efforts using each compiler exposed the strengths and weaknesses of each. Porting this complex code exposed many of the growing pains associated with the current generation of compilers. Critical sections of the code will be explained and these critical areas of the conversion effort will be discussed. Where necessary we will demonstrate how different porting strategies affected the performance of the code. Finally we will present how the ported code ran, using a varying number of processors, on an IBM SP2 and an SGI Origin 2000. While the current simple port does not match the speed of a CM-5, we hope further porting efforts and improved compiler technology will enable us to eventually match and then surpass CM-5 performance levels. With the shutdown of the NCSA CM-5 and the eventual removal and failure of the remaining Thinking Machines hardware currently installed, this effort will demonstrate that investments in CM Fortran code need not be abandoned and that new life can be breathed into those dusty decks.},
  keywords={Standards development;High performance computing;Computer industry;Parallel processing;Distributed computing;Message passing;Libraries;Testing;Predictive models;Equations;High Performance Fortran;Thinking Machines CM Fortran;Aeroacoustics;Dusty Decks},
  doi={10.1145/509593.509609},
  ISSN={},
  month={Nov},}@ARTICLE{9354557,
  author={Abernathey, Ryan P. and Augspurger, Tom and Banihirwe, Anderson and Blackmon-Luca, Charles C. and Crone, Timothy J. and Gentemann, Chelle L. and Hamman, Joseph J. and Henderson, Naomi and Lepore, Chiara and McCaie, Theo A. and Robinson, Niall H. and Signell, Richard P.},
  journal={Computing in Science & Engineering}, 
  title={Cloud-Native Repositories for Big Scientific Data}, 
  year={2021},
  volume={23},
  number={2},
  pages={26-35},
  abstract={Scientific data have traditionally been distributed via downloads from data server to local computer. This way of working suffers from limitations as scientific datasets grow toward the petabyte scale. A “cloud-native data repository,” as defined in this article, offers several advantages over traditional data repositories—performance, reliability, cost-effectiveness, collaboration, reproducibility, creativity, downstream impacts, and access and inclusion. These objectives motivate a set of best practices for cloud-native data repositories: analysis-ready data, cloud-optimized (ARCO) formats, and loose coupling with data-proximate computing. The Pangeo Project has developed a prototype implementation of these principles by using open-source scientific Python tools. By providing an ARCO data catalog together with on-demand, scalable distributed computing, Pangeo enables users to process big data at rates exceeding 10 GB/s. Several challenges must be resolved in order to realize cloud computing’s full potential for scientific research, such as organizing funding, training users, and enforcing data privacy requirements.},
  keywords={Cloud computing;Training data;Computational modeling;Reproducibility of results;Collaboration;Reliability;Distributed databases},
  doi={10.1109/MCSE.2021.3059437},
  ISSN={1558-366X},
  month={March},}@INPROCEEDINGS{1174227,
  author={Richardson, K.A.},
  booktitle={36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the}, 
  title={On the limits of bottom-up computer simulation: towards a nonlinear modeling culture}, 
  year={2003},
  volume={},
  number={},
  pages={9 pp.-},
  abstract={In the complexity and simulation communities there is growing support for the use of bottom-up computer-based simulation in the analysis of complex systems. The presumption is that because these models are more complex than their linear predecessors they must be more suited to the modeling of systems that appear, superficially at least, to be (compositionally and dynamically) complex. Indeed the apparent ability of such models to allow the emergence of collective phenomena from quite simple underlying rules is very compelling. But does this 'evidence' alone 'prove' that nonlinear bottom-up models are superior to simpler linear models when considering complex systems behavior? Philosophical explorations concerning the efficacy of models, whether they be formal scientific models or our personal worldviews, has been a popular pastime for many philosophers, particularly philosophers of science. This paper offers yet another critique of modeling that uses the results and observations of nonlinear mathematics and bottom-up simulation themselves to develop a modeling paradigm that is significantly broader than the traditional model-focused paradigm. In this broader view of modeling we are encouraged to concern ourselves more with the modeling process rather than the (computer) model itself and embrace a nonlinear modeling culture. This emerging view of modeling also counteracts the growing preoccupation with nonlinear models over linear models.},
  keywords={Computer simulation;Computational modeling;Mathematical model;Predictive models;Analytical models;Educational institutions;Coherence;Mathematics;Iron;Physics},
  doi={10.1109/HICSS.2003.1174227},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8622046,
  author={Chandrashekara, Arjun Ankathatti and Talluri, Radha Krishna Murthy and Sivarathri, Sai Swathi and Mitra, Reshmi and Calyam, Prasad and Kee, Kerk and Nair, Satish},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Fuzzy-Based Conversational Recommender for Data-intensive Science Gateway Applications}, 
  year={2018},
  volume={},
  number={},
  pages={4870-4875},
  abstract={Neuro-scientists are increasingly relying on parallel and distributed computing resources for analysis and visualization of their neuron simulations. Although science gateways have democratized relevant high performance/throughput resources, users require expert knowledge about programming and infrastructure configuration that is beyond the repertoire of most neuroscience programs. These factors become deterrents for the successful adoption and the ultimate diffusion (i.e., systemic spread) of science gateways in the neuroscience community. In this paper, we present a novel intuitionistic fuzzy logic based conversational recommender that can provide guidance to users when using science gateways for research and education workflows. The users interact with a context-aware chatbot that is embedded within custom web-portals to obtain simulation tools/resources to accomplish their goals. In order to ensure user goals are met, the chatbot profiles a user's cyberinfrastructure and neuroscience domain proficiency level using a `usability quadrant' approach. Simulation of user queries for an exemplary neuroscience use case demonstrates that our chatbot can provide step-by-step navigational support and generate distinct responses based on user proficiency.},
  keywords={Neuroscience;Fuzzy logic;Logic gates;Neurons;Tools;Computational modeling;Usability;Conversational Recommenders;Intutionistic Fuzzy Logic;Mamdani Inference;Neuroscience Workflows;Science Gateways;Virtual Agents;Guided User Interfaces},
  doi={10.1109/BigData.2018.8622046},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{41811,
  author={Wang, J.},
  booktitle={[1989] Proceedings. Structure in Complexity Theory Fourth Annual Conference}, 
  title={p-creative sets vs. p-completely creative sets}, 
  year={1989},
  volume={},
  number={},
  pages={24-33},
  abstract={It is shown that for recursively enumerable sets, p-creativeness and p-complete creativeness are equivalent, and Myhill's theorem still holds in the polynomial setting. For P (NP), p-creativeness is shown to be equivalent to p-complete creativeness. The existence of p-creative sets for P (NP) in EXP (NEXP) is given. Moreover, it is shown that every p-m-complete set for EXP (NEXP) is p-completely creative for P (NP), and every p-creative set for NP is NP-hard via many-one reductions. Other results for k-completely creative sets are obtained.<>},
  keywords={Polynomials;Turing machines;Computer science;Sufficient conditions;Complexity theory;Computational modeling},
  doi={10.1109/SCT.1989.41811},
  ISSN={},
  month={June},}@INPROCEEDINGS{5937784,
  author={Jensen, Jeff C. and Lee, Edward A. and Seshia, Sanjit A.},
  booktitle={2011 IEEE International Symposium of Circuits and Systems (ISCAS)}, 
  title={An introductory capstone design course on embedded systems}, 
  year={2011},
  volume={},
  number={},
  pages={1199-1202},
  abstract={We review an introductory course in embedded systems that characterizes embedded systems not by resource constraints, but rather by interactions with the physical world. This course teaches students the basics of models, analysis tools, and design for embedded systems. Traditional undergraduate courses in embedded systems focus on ad-hoc engineering practices and the use of existing modeling techniques, often omitting critical analysis and meta-modeling; we emphasize model-based design of embedded and cyber-physical systems. Students learn how to model the physical world with continuous time differential equations, and how to model computation using logic and discrete models such as state machines. Students evaluate these modeling techniques through the use of meta-modeling, illuminating the interplay of practical design with formal models of systems that incorporate both physical dynamics and computation. Students learn formal techniques to specify and verify desired behavior. A combination of structured labs and design projects solidifies these concepts when applied to the design of embedded and cyber-physical systems with real-time and concurrent behaviors.},
  keywords={Computational modeling;Embedded systems;Robot sensing systems;Mathematical model;Laboratories;Accelerometers},
  doi={10.1109/ISCAS.2011.5937784},
  ISSN={2158-1525},
  month={May},}@INPROCEEDINGS{6928187,
  author={Bosse, Tibor and Mogles, Nataliya},
  booktitle={2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)}, 
  title={Spread of Situation Awareness in a Group: Population-Based vs. Agent-Based Modelling}, 
  year={2014},
  volume={3},
  number={},
  pages={206-213},
  abstract={This paper compares population-based and agent-based simulation of the dynamics of group Situation Awareness. The question how Situation Awareness spreads among a team of agents is important for numerous applications. In this paper, a population-based and an agent-based model of this process are proposed, and applied to a case study in aviation. A number of relevant simulations of the models are performed, to investigate whether the behaviour of the population-based model can approximate the pattern produced by the agent-based model. It was demonstrated that, especially for larger populations, the dynamics of the agent-based simulations can be approximated by population-based simulations, since both models demonstrate a similar pattern.},
  keywords={Computational modeling;Atmospheric modeling;Mathematical model;Air traffic control;Aircraft;Sociology;Statistics;group situation awareness;aviation;agent-based vs. Population-based simulation},
  doi={10.1109/WI-IAT.2014.169},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9892833,
  author={Del Fabbro, Olivier and Christen, Patrik},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Philosophy-Guided Modelling and Implementation of Adaptation and Control in Complex Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Control was from its very beginning an important concept in cybernetics. Later on, with the works of W. Ross Ashby, for example, biological concepts such as adaptation were interpreted in the light of cybernetic systems theory. Adaptation is the process by which a system is capable of regulating or controlling itself in order to adapt to changes of its inner and outer environment maintaining a homeostatic state. In earlier works we have developed a system metamodel that on the one hand refers to cybernetic concepts such as structure, operation, and system, and on the other to the philosophy of individuation of Gilbert Simondon. The result is the so-called allagmatic method that is capable of creating concrete models of systems such as artificial neural networks and cellular automata starting from abstract building blocks. In this paper, we add to our already existing method the cybernetic concepts of control and especially adaptation. In regard to the system metamodel, we rely again on philosophical theories, this time the philosophy of organism of Alfred N. Whitehead. We show how these new meta-theoretical concepts are described formally and how they are implemented in program code. We also show what role they play in simple experiments. We conclude that philosophical abstract concepts help to better understand the process of creating computer models and their control and adaptation. In the outlook we discuss how the allagmatic method needs to be extended in order to cover the field of complex systems and Norbert Wiener's ideas on control.},
  keywords={Adaptation models;Philosophical considerations;Codes;Computational modeling;Process control;Control systems;Organisms;adaptation;control;complex systems modelling and simulation;cybernetics;meta-modelling;meta-programming;philosophy of individuation;philosophy of organism},
  doi={10.1109/IJCNN55064.2022.9892833},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{8644945,
  author={Zhang, Weiwen and Liu, Yong and Wang, Long and Li, Zengxiang and Mong Goh, Rick Siow},
  booktitle={2018 IEEE 24th International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={Cost-Efficient and Latency-Aware Workflow Scheduling Policy for Container-Based Systems}, 
  year={2018},
  volume={},
  number={},
  pages={763-770},
  abstract={Container technology is being adopted to simplify workflow execution. In this paper, we investigate a workflow scheduling policy for container-based systems. A workflow, representing an application, consists of a set of tasks. Each task can be executed in a container within a virtual machine (VM), where the container packaging the function for the task should be loaded into the VM before task execution. To reduce the workflow execution time and the network bandwidth consumption, we propose a cost-efficient and latency-aware workflow scheduling algorithm that strategically loads the containers into VMs and executes the tasks on the VMs. The algorithm is based on “Stretch Out and Compact”, which can stretch out the tasks along the resources by critical path analysis and then find the inefficient slots within the computing resources and eventually compact the tasks into those slots. We introduce a concept of “virtual task” into the algorithm, where container loading is regarded as a virtual task that should be executed before the real task. The introduction of the virtual task can be more effective in finding the inefficient slots for the compaction, thus resulting in a more efficient workflow scheduling policy. Simulation results show that compared to the algorithms that fully or selectively load the dockers, the proposed algorithm can achieve less execution time while saving network bandwidth consumption for loading dockers.},
  keywords={Task analysis;Containers;Loading;Scheduling algorithms;Scheduling;Computational modeling;Workflow scheduling;resource efficiency;container-based systems},
  doi={10.1109/PADSW.2018.8644945},
  ISSN={1521-9097},
  month={Dec},}
