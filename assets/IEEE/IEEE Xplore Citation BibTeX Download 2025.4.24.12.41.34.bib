@INPROCEEDINGS{9832076,
  author={Zhu, Ping and Lv, Pohua and Shi, Jin and Jiang, Xuetao and Zou, Weiming and Ma, Yirong},
  booktitle={2022 IEEE 2nd International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Semantic Inheritance and Overloading}, 
  year={2022},
  volume={},
  number={},
  pages={01-09},
  abstract={Humanoid reasoning and computing are the crucial research objectives of computing thinking, so semantic understanding and explicit representation are the basis steps for computing thinking. However, at present, there is no mature and systematic theory and engineering technology to fully describe massive multi-dimensional semantic expressions of natural language. Then the semantic inheritance and overloading theory was proposed to describe the semantic superposition and synthesis processing of the input vocabularies in this paper. Taking the clause as the basic semantic unit, the semantics were integrated by the local semantics of the clause itself and the global semantics of the cross clauses. The semantic frameworks were represented by the core vocabulary sequence of the clause, and the unified semantic representation grammar of the semantic frameworks to explicitly describe the local semantics and global semantics was studied; From the perspective of big data engineering, according to the unified grammar, the semantic annotation was chose as the initial step, the semantic scene based on the pattern matching of semantic frameworks was divided, the implementation technologies of semantic inheritance and overloading theory between scenes on the base of the observed language representation phenomenon were put forward, and the core algorithms of machine humanoid resolving primary mathematics application problems were realized, the effectiveness of semantic inheritance and overloading theory was preliminarily verified. The advantage was that the implementation could make full use of the power of the cloud computing to do semantic annotation and semantic framework pattern matching in parallel, and explore the engineering way to achieve natural language semantic understanding and computing thinking.},
  keywords={Vocabulary;Systematics;Annotations;Semantics;Natural languages;Humanoid robots;Grammar;computing thinking;semantic understanding;semantic inheritance;semantic overloading;humanoid resolving},
  doi={10.1109/SEAI55746.2022.9832076},
  ISSN={},
  month={June},}@INPROCEEDINGS{9071173,
  author={Inoue, Hiroaki and Hori, Masaya and Yu, Kikuti and Maeda, Mayu and Kobayashi, Yusuke and Kiryu, Takuya and Tsubota, Toshiya and Shimizu, Shunji},
  booktitle={2019 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Basic Study on Measuring Brain Activity during Exercise for Evaluation of Welfare Device}, 
  year={2019},
  volume={},
  number={},
  pages={1007-1011},
  abstract={Recently, Japan (also world-wide countries) has become aged society, and a wide variety welfare device and system have been developed. But evaluation of welfare system and device are limited only stability, intensity and partial operability. Thus, evaluation of usefulness is insufficient. Evaluation of usefulness is necessity to consider about interaction of human and welfare device. In this paper, we measure load of sitting and standing movement to use EMG (Electromyogram) and 3D Motion Capture and set a goal to establish objective evaluation method. We think that establishing objective evaluation method is necessity to develop useful welfare device. We examined possibility of assessing load and fatigue from measuring brain activity to use NIRS (Near Infra-Red Spectroscopy). We think that measuring load and fatigue is very important for developing user-friendly welfare device. Idea of universal design is widespread in welfare device and system. Measuring require verification of all generations. However, we performed to measure younger subjects as a first step. We think that younger subjects were observed the significant difference, because they had enough physical function. Considering younger subjects as a benchmark is appropriate for creating evaluation method.},
  keywords={Brain;Electromyography;Fatigue;Motion measurement;Psychology;Physiology;Brain activity;Near Infra-Red Spectroscopy},
  doi={10.1109/CSCI49370.2019.00192},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{7916570,
  author={Abbasi, Abdul Rehman},
  booktitle={2017 International Conference on Innovations in Electrical Engineering and Computational Technologies (ICIEECT)}, 
  title={Open your mind to interdisciplinary research (IDR)}, 
  year={2017},
  volume={},
  number={},
  pages={1-1},
  abstract={Identification and formulation of a research problem, often becomes a dilemma for a research scholar, especially in his/her early days while pursuing a research degree program. In fact, research is all about thinking of problems and their solutions. This thinking is a process of connecting things and ideas present all around you. If you cannot connect ideas then probably you are not connecting yourself to the relevant research. In this talk, the focus will be to guide the audience towards doing research from surroundings and especially look for interdisciplinary research themes that would connect the scientists and society and probably be more beneficial for all.},
  keywords={Joining processes},
  doi={10.1109/ICIEECT.2017.7916570},
  ISSN={},
  month={April},}@INPROCEEDINGS{8247835,
  author={Balci, Osman and Fujimoto, Richard M. and Goldsman, David and Nance, Richard E. and Zeigler, Bernard P.},
  booktitle={2017 Winter Simulation Conference (WSC)}, 
  title={The state of innovation in modeling and simulation: The last 50 years}, 
  year={2017},
  volume={},
  number={},
  pages={821-836},
  abstract={Innovation in Modeling and Simulation (M&S) refers to exploiting new ideas, exploiting new technology, and employing out-of-the-box thinking, which lead to the creation of new methodologies, techniques, concepts, frameworks, and software. This paper addresses the following questions: (a) what was the state of the art in M&S 50 years ago, what is it today, how much progress has been made? (b) how much innovation in M&S has been accomplished over the last half a century? (c) what were the obstacles to innovation in M&S? (d) what are some recommendations to promote innovation in M&S? (e) what message should be sent to the funding agencies to encourage innovation in M&S?},
  keywords={Handheld computers;Data models;Computational modeling;Computer simulation;Cloud computing;Conferences;Technological innovation},
  doi={10.1109/WSC.2017.8247835},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{10341425,
  author={Ivolga, Dmitriy V. and Borisov, Ivan I. and Nasonov, Kirill V. and Kolyubin, Sergey A.},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Computational Design of Closed-Chain Linkages: Respawn Algorithm for Generative Design}, 
  year={2023},
  volume={},
  number={},
  pages={481-486},
  abstract={Designing robots is a multiphase process aimed at solving a multi-criteria optimization problem to find the best possible detailed design. Generative design (GD) aims to accelerate the design process compared to manual design, since GD allows exploring and exploiting the vast design space more efficiently. In the field of robotics, however, relevant research focuses mostly on the generation of fully-actuated open chain kinematics, which is trivial in mechanical engineering perspective. Within this paper, we address the problem of generative design of closed-chain linkage mechanisms. A GD algorithm has to be able to generate meaningful mechanisms which satisfy conditions of existence. We propose an optimization-driven algorithm for generation of planar closed-chain linkages to follow a predefined trajectory. The algorithm creates an unlimited range of physically reproducible design alternatives that can be further tested in simulation. These tests could be done in order to find solutions that satisfy extra criteria, e.g., desired dynamic behavior or low energy consumption. The proposed algorithm is called “respawn” since it builds a new linkage after the ancestor has been tested in a virtual environment in pursuit for the optimal solution. To show that the algorithm is general enough, we show a set of generated linkages that can be used for a wide class of robots.},
  keywords={Couplings;Heuristic algorithms;Software algorithms;Virtual environments;Transforms;Software;Trajectory},
  doi={10.1109/IROS55552.2023.10341425},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{5522827,
  author={Chakradhar, Srimat T. and Raghunathan, Anand},
  booktitle={Design Automation Conference}, 
  title={Best-effort computing: Re-thinking parallel software and hardware}, 
  year={2010},
  volume={},
  number={},
  pages={865-870},
  abstract={With the advent of mainstream parallel computing, applications can obtain better performance only by scaling to platforms with larger numbers of cores. This is widely considered to be a very challenging problem due to the difficulty of parallel programming and the bottlenecks to efficient parallel execution. Inspired by how networking and storage systems have scaled to handle very large volumes of packet traffic and persistent data, we propose a new approach to the design of scalable, parallel computing platforms. For decades, computing platforms have gone to great lengths to ensure that every computation specified by applications is faithfully executed. While this design philosophy has remained largely unchanged, applications and the basic characteristics of their workloads have changed considerably. A wide range of existing and emerging computing workloads have an inherent forgiving nature. We therefore argue that adopting a best-effort service model for various software and hardware components of the computing platform stack can lead to drastic improvements in scalability. Applications are cognizant of the best-effort model, and separate their computations into those that may be executed on a best-effort basis and those that require the traditional execution guarantees. Best-effort computations may be exploited to simply reduce the computing workload, shape it to be more suitable for parallel execution, or execute it on unreliable hardware components. Guaranteed computations are realized either through an overlay software layer on top of the best-effort substrate, or through the use of application-specific strategies. We describe a system architecture for a best-effort computing platform, provide examples of parallel software and hardware that embody the best-effort model, and show that large improvements in performance and energy efficiency are possible through the adoption of this approach.},
  keywords={Concurrent computing;Hardware;Application software;Parallel processing;Parallel programming;Telecommunication traffic;Computer applications;Scalability;Shape;Computer architecture;Best effort systems;parallel computing;multi core;performance;scalability},
  doi={10.1145/1837274.1837492},
  ISSN={0738-100X},
  month={June},}@INPROCEEDINGS{4736743,
  author={Demchenko, Yuri and de Laat, Cees and Koeroo, Oscar and Groep, David},
  booktitle={2008 IEEE Fourth International Conference on eScience}, 
  title={Re-thinking Grid Security Architecture}, 
  year={2008},
  volume={},
  number={},
  pages={79-86},
  abstract={The security models used in Grid systems today strongly bear the marks of their diverse origin. Historically retrofitted to the distributed systems they are designed to protect and control, the security model is usually limited in scope and applicability, and its implementation tailored towards a few specific deployment scenarios. A common approach towards even the "basic" elements such as authentication to resources is only now emerging, whereas for more complex issues such as community organization, integration of site access control with operating systems, cross-domain resource provisioning, or overlay community Grids ("late authentication" for pilot job frameworks or community-based virtual machines) there is no single coherent and consistent "security" view. Via this paper we aim to share some observations on current security models and solutions found in Grid architectures and deployments today and identify architectural limitations in solving complex access control and policy enforcement scenarios in distributed resource management. The paper provides a short overview of the OGSA security services and other security solutions used in Grid middleware and operations practice. However, it is becoming clear that further development in Grid requires a fresh look at the concepts, both operationally and security-wise. This paper analyses the security aspects of different types of Grids and a set of use cases that may require extended security functionality, such as dynamic security context management, and management of stateful services. Recent developments in open systems security, and revisiting basic security concepts in networking and computing including the OSI security architecture and the concepts used in the trusted computing base provide interesting examples on how some of the conceptual security problems in Grid can be addressed, and on how the shortcomings of current systems and the frequently proposed "ad-hoc" stop-gaps for what are in fact complex security manageability problems may be avoided. This paper is thus intended to initiate and stimulate the wider discussion on the concepts of Grid security, thereby setting the scene for and providing input to a Grid security taxonomy leading to a more consistent Grid security architecture.},
  keywords={Security;Authentication;Access control;Open systems;Computer networks;Grid computing;Protection;Operating systems;Virtual machining;Resource management;Grids;Open Grid Security Architecture;Trusted Computing Base;Reference Monitor;Security models;Security Context;Authentication;Authorisation session},
  doi={10.1109/eScience.2008.53},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{5981083,
  author={Yang, Chaowei},
  booktitle={2011 19th International Conference on Geoinformatics}, 
  title={Thinking and computing spatiotemporally to enable cloud computing and science discoveries}, 
  year={2011},
  volume={},
  number={},
  pages={1-6},
  abstract={We live in space time dimensions and all physical and social sciences are based on the dimensions. The representation and digitization of scientific phenomena into data and computation of the digitized data greatly depends on the spatiotemporal principles that govern the relationships of phenomena. The latest advancement of cloud computing is not an exception. Conducting cloud computing in a spatiotemporal fashion will help use spatiotemporal principles, which exist in all physical and social sciences, to optimize cloud computing and science discoveries. This paper 1) introduces the latest advancement of distributed computing; 2) analyzes the impact cloud computing has on GIS science, application, and education; 3) illustrates how spatiotemporal principles exist and can be utilized to enable cloud computing and science discoveries; and 4) discusses research directions and agenda for GIScience professionals in the 21st centuries.},
  keywords={Cloud computing;Spatiotemporal phenomena;Earth;Education;Humans;GIS;Geodynamics;CyberGIS Spatial Computing;Geospatial Cyberinfrastructure},
  doi={10.1109/GeoInformatics.2011.5981083},
  ISSN={2161-0258},
  month={June},}@ARTICLE{10758899,
  author={Chen, Qixin and Wang, Xuanyuan and Feng, Cheng and Li, Chuyi and Zheng, Kedi},
  journal={IEEE Power and Energy Magazine}, 
  title={Empowering the Grid Edge to Think: Applications of Artificial Intelligence for Virtual Power Plants in China}, 
  year={2024},
  volume={22},
  number={6},
  pages={66-77},
  abstract={From massive wind farms in Inner Mongolia to solar farms in Qinghai, from the rapidly growing electric vehicles to home-installed batteries and rooftop solar panels, we see an exciting and diversified transformation of the energy system blooming across China. This low-carbon transformation not only drives a paradigm shift toward greener and more sustainable energy systems, however; this transformation brings with it great challenges, such as improving the efficiency, resilience, and flexibility of China’s energy systems.},
  keywords={Uncertainty;Fluctuations;Green products;Wind farms;Virtual power plants;Power systems;Resource management;Solar panels;Artificial intelligence;Resilience;Electric vehicles;Low carbon economy},
  doi={10.1109/MPE.2024.3398570},
  ISSN={1558-4216},
  month={Nov},}@ARTICLE{7482967,
  author={Sebold, Miriam and Schad, Daniel J. and Nebe, Stephan and Garbusow, Maria and Jünger, Elisabeth and Kroemer, Nils B. and Kathmann, Norbert and Zimmermann, Ulrich S. and Smolka, Michael N. and Rapp, Michael A. and Heinz, Andreas and Huys, Quentin J. M.},
  journal={Journal of Cognitive Neuroscience}, 
  title={Don't Think, Just Feel the Music: Individuals with Strong Pavlovian-to-Instrumental Transfer Effects Rely Less on Model-based Reinforcement Learning}, 
  year={2016},
  volume={28},
  number={7},
  pages={985-995},
  abstract={Behavioral choice can be characterized along two axes. One axis distinguishes reflexive, model-free systems that slowly accumulate values through experience and a model-based system that uses knowledge to reason prospectively. The second axis distinguishes Pavlovian valuation of stimuli from instrumental valuation of actions or stimulus–action pairs. This results in four values and many possible interactions between them, with important consequences for accounts of individual variation. We here explored whether individual variation along one axis was related to individual variation along the other. Specifically, we asked whether individuals' balance between model-based and model-free learning was related to their tendency to show Pavlovian interferences with instrumental decisions. In two independent samples with a total of 243 participants, Pavlovian–instrumental transfer effects were negatively correlated with the strength of model-based reasoning in a two-step task. This suggests a potential common underlying substrate predisposing individuals to both have strong Pavlovian interference and be less model-based and provides a framework within which to interpret the observation of both effects in addiction.},
  keywords={},
  doi={10.1162/jocn_a_00945},
  ISSN={0898-929X},
  month={July},}@INPROCEEDINGS{9039963,
  author={Geselowitz, Michael},
  booktitle={2019 6th IEEE History of Electrotechnology Conference (HISTELCON)}, 
  title={Tinkerers Ever to Chance: Engineers, Computers, and the Rise of Probablistic Thinking}, 
  year={2019},
  volume={},
  number={},
  pages={52-60},
  abstract={Historians of scientific thought and philosophy have emphasized during the Enlightenment a shift from chance-based medieval thought to probability-based modern thought. They have not, however, focused on the technology that makes the implementation of such thought possible. At the same time, historians of computing have emphasized the rise of mechanical calculators—predecessors of modern computers—in this same period, but only in reference to solving practical problems arising from increasingly complex societies. This paper will draw on the two different streams of historical thought to show how the rise of probability and statistics and the rise of mechanical calculating devices were inextricably linked in complex ways.},
  keywords={Computers;Probability;Meteorology;Probabilistic logic;Computer crime;History;history;computing;probability},
  doi={10.1109/HISTELCON47851.2019.9039963},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{4127430,
  author={Majumder, D. Dutta and Ulrichs, Christian and Majumder, Debosmita and Mewis, Inga and Thakur, Ashoke Ranjan and Brahmachary, R.L. and Banerjee, Rajat and Rahman, Ayesha and Debnath, Nitai and Seth, Dipankar and Das, Sumistha and Roy, Indrani and Ghosh, Amrita and Sagar, Prity and Schulz, Carsten and Linh, Nguyen Quang and Goswami, Arunava},
  booktitle={2007 International Conference on Computing: Theory and Applications (ICCTA'07)}, 
  title={Current Status and Future Trends of Nanoscale Technology and Its Impact on Modern Computing, Biology, Medicine and Agricultural Biotechnology}, 
  year={2007},
  volume={},
  number={},
  pages={563-573},
  abstract={Nanoscale technologies have gone from being just an ambitious concept to being a rapidly advancing area of interdisciplinary science with immense practical importance. Feynman's vision on nanoscience provided great impetus to the development of nanophysics, nanochemistry, nanoelectronics and nanotechnology in general. High resolution microscopic devices such as scanning tunneling microscope, transmission electron microscope and atomic force microscope etc. in mid 1980s allowed researchers to see individual atoms on surfaces and arrange them. The authors (nanobiologists, computer scientists, biotechnologists and material scientists) attempt to provide a review of the state of the art in the field of nanoscale technologies and its impact on various fields of research like computation, basic biology, medicine and agricultural biotechnology. Imprints of memory mechanisms in living systems operating at different levels (e.g. biochemical, immunological and neuronal) have provided inputs to design and fabricate 'bio-inspired' nanoelectronic devices suitable for various applications. Several examples of such nanoscale technology based frameworks and devices are presented in the scenario of their potential role in the development of future nanoscale technologies. Nanoscale technologies might finally revolutionize computational intelligence and thinking. The power and limits of computing processes govern the intelligence, knowledge acquisition and thinking process of human and machine. Present computational methods and models provide us courage to study the problem, but these tools are not yet sufficient to answer the following riddles of machine intelligence - what can computers do better than humans? What can humans do better than computers? And the most important one - what is computable? The authors try to present evidences that show bio-inspired nanoscale technologies might gain the power in helping us to go deeper into these challenges of research in future},
  keywords={Biology computing;Nanobioscience;Biotechnology;Atomic force microscopy;Scanning electron microscopy;Transmission electron microscopy;Humans;Nanoelectronics;Nanoscale devices;Computational intelligence;Agriculture;Alzheimer's disease;biotechnology;cancer;computational biology;consciousness;cybernetics;genomics;HIV;hydrophobic nanosilica;lipophilic nanosilica;machine learning;malaria;metabolomics;Nanoscience;nanosilica;neuronal network;pervasive computing;quantum mechanics;reversible computing.},
  doi={10.1109/ICCTA.2007.46},
  ISSN={},
  month={March},}@INPROCEEDINGS{7509810,
  author={Chen, Jinhua and Jiang, Qin and Wang, Yuxin and Tang, Jing},
  booktitle={2016 IEEE International Conference on Big Data Analysis (ICBDA)}, 
  title={Study of data analysis model based on big data technology}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={The traditional data analysis are based on the cause and effect relationship, formed a sample microscopic analysis, qualitative and quantitative analysis, the thinking mode of trend extrapolation analysis. Big data has a fundamental impact on the traditional data analysis. Big data analysis based on correlation, formed global macro analysis, data and technical analysis, correlation analysis and new thinking mode of correlation analysis. Namely, from causal analysis to correlation analysis and knowledge discovery, from model fitting to data mining, from logical reasoning to association rules. Data analysis in the era of big data have taken great changes, Namely, Big data analysis, from the analysis of objects, the mode of data processing, analytical methods and tools, analytical thinking.},
  keywords={Data analysis;Big data;Statistical analysis;Data models;Correlation;Analytical models;Computational modeling;big data;data analysis;qualitative and quantitative analysis},
  doi={10.1109/ICBDA.2016.7509810},
  ISSN={},
  month={March},}@INPROCEEDINGS{10825858,
  author={Osti, Giulia and Roke, Elizabeth Russey},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Collaborating for Change? Assessing Metadata Inclusivity in Digital Collections with Large Language Models (LLMs)}, 
  year={2024},
  volume={},
  number={},
  pages={2479-2488},
  abstract={This research explores how Large Language Models (LLMs) can be contribute to human expertise and ethical judgment to support reparative archival description practices. We assess the interpretive abilities of three LLMs (Command R+, GPT-3.5 Turbo, and GPT-4o Mini) in assisting humans with metadata inclusivity evaluations. Our testbed comprises a small metadata subset (369 records) from the Robert Langmuir African-American Photograph Collection at Emory University. Despite limited task-specific training and no access to the digital objects associated with the metadata, the LLMs demonstrated notable capacity in identifying gaps, harmful language, and latent contextual elements. By integrating computational methods into descriptive workflows, this research advances Computational Archival Science (CAS), demonstrating how LLMs can enable connecting computational techniques with archival practices in tackling complex, human values-driven challenges.},
  keywords={Training;Ethics;Large language models;Collaboration;Oral communication;Metadata;Big Data;Object recognition;Cultural differences;Testing;Reparative description;metadata inclusivity;Large Language Models (LLMs);Artificial Intelligence (AI);Computational Archival Science (CAS)},
  doi={10.1109/BigData62323.2024.10825858},
  ISSN={2573-2978},
  month={Dec},}@ARTICLE{9328751,
  author={Altin, Mahsun and Gürsoy, Furkan and Xu, Lina},
  journal={IEEE Access}, 
  title={Machine-Generated Hierarchical Structure of Human Activities to Reveal How Machines Think}, 
  year={2021},
  volume={9},
  number={},
  pages={18307-18317},
  abstract={Deep-learning based computer vision models have proved themselves to be ground-breaking approaches to human activity recognition (HAR). However, most existing works are dedicated to improve the prediction accuracy through either creating new model architectures, increasing model complexity, or refining model parameters by training on larger datasets. Here, we propose an alternative idea, differing from existing work, to increase model accuracy and also to shape model predictions to align with human understandings through automatically creating higher-level summarizing labels for similar groups of human activities. First, we argue the importance and feasibility of constructing a hierarchical labeling system for human activity recognition. Then, we utilize the predictions of a black box HAR model to identify similarities between different activities. Finally, we tailor hierarchical clustering methods to automatically generate hierarchical trees of activities and conduct experiments. In this system, the activity labels on the same level will have a designed magnitude of accuracy and reflect a specific amount of activity details. This strategy enables a trade-off between the extent of the details in the recognized activity and the user privacy by masking some sensitive predictions; and also provides possibilities for the use of formerly prohibited invasive models in privacy-concerned scenarios. Since the hierarchy is generated from the machine's perspective, the predictions at the upper levels provide better accuracy, which is especially useful when there are too detailed labels in the training set that are rather trivial to the final prediction goal. Moreover, the analysis of the structure of these trees can reveal the biases in the prediction model and guide future data collection strategies.},
  keywords={Predictive models;Privacy;Taxonomy;Computational modeling;Labeling;Data models;Activity recognition;Hierarchical labeling;human activity recognition;machine learning;privacy preservation;video processing},
  doi={10.1109/ACCESS.2021.3053084},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{6681102,
  author={Yamashita, Satoshi and Usui, Hisashi and Kitahara, Kiyoshi and Takato, Setsuo},
  booktitle={2013 13th International Conference on Computational Science and Its Applications}, 
  title={The Elements of Programming Style for Making Class Materials with Figures}, 
  year={2013},
  volume={},
  number={},
  pages={72-80},
  abstract={Mathematics teachers want to enable students to understand mathematical objects clearly and want to use their original class materials with accurate and impressive figures. To do so, it is suitable to use both TeX and Computer Algebra System (CAS). Nevertheless, the graphic output of CAS is not suited to the TeX document of the material. To improve it, since 2006, the authors have been developing KETpic as a plug-in based on CAS. The use of both TeX and KETpic based on CAS enables teachers to produce their original class materials with accurate and impressive figures. They wish not only to produce their original class materials with figures but also to use the class materials with figures produced by the others. To realize that objective, a good KETpic programming style is needed. For example, when educators produce a figure along with their material by KETpic, they wish to perform symbolic thinking, i.e. they create a KETpic program in a mathematical drawing procedure and concentrate their energy on qualitative improvement of the figures while they recognize the global image of the figure. Symbolic thinking is a factor in good elements of KETpic programming style. The authors investigated other good elements of KETpic programming style using a documentation approach, which is the method of checking teachers' records in detail for their improvement. In this paper, the authors present four good elements of the KETpic programming style.},
  keywords={Materials;Equations;Programming profession;Graphics;Software;CAS;TeX;KETpic;programming style;symbolic thinking;documentation approach},
  doi={10.1109/ICCSA.2013.20},
  ISSN={},
  month={June},}@INPROCEEDINGS{6030380,
  author={Wang, Xiaoxia and Zhou, Zhurong},
  booktitle={2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference}, 
  title={The research of situational teaching mode of programming in high school with Scratch}, 
  year={2011},
  volume={2},
  number={},
  pages={488-492},
  abstract={Since the new Curriculum Reform was carried off, there has been a lot of research on teaching mode of programming in high school. On the basis of the exploration of the potentials if designing a teaching mode with the Scratch Graphical Programming Language, this paper builds a situational teaching mode of programming in high school with Scratch. This teaching mode first design a programming learning situation which is familiar by students because of its close connection to the students' daily life with Scratch for student through the analysis of the common elements between the situation and the concept of programming. The n guide students learning in the situation, and transfer back to the traditional programming environmental after he understand the content of concept. This teaching mode can arouse the students' interests of learning; promote the students' learning transfer ability. Ultimately this teaching mode can help students better understand algorithm programming and established their Computational thinking. Both of them play a significant positive role in developing students' logical thinking ability and their ability in solving practical problem.},
  keywords={Educational institutions;Algorithm design and analysis;Programming profession;Computers;Programming environments;Programming teaching in high school;Scratch;Situational teaching mode},
  doi={10.1109/ITAIC.2011.6030380},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10739152,
  author={C, Adharsh and Benitta, D. Angeline and Eliyas, Sherin and Balamurugan},
  booktitle={2024 International Conference on Electrical Electronics and Computing Technologies (ICEECT)}, 
  title={Gamification: The Effective way for better learning}, 
  year={2024},
  volume={1},
  number={},
  pages={1-5},
  abstract={Gamification is a blooming technology that transforms stereotypical academics into interesting game-like elements. Through gamification, educators motivate the students to involve themselves in the game design for entertainment and adopt the features of the game design in an educational setting for enhanced learning. This work focuses on an educational digital game for learning sorting algorithms and concepts from data structures. The game is designed based on constructivism learning theory and the MDA framework, aiming to promote active and student-centered learning. The game challenges players to rearrange a sequence of unsorted aliens by using a set of commands, such as comparing, swapping, and moving. The game also records players’ actions and performance through log data, which can be analyzed for learning behavior, and outcomes. It describes the game design and development process, as well as the potential benefits and limitations of using the game in computer science education, and also discusses how the game can facilitate the development of computational thinking skills such as problem formulation, abstraction, algorithmic thinking, and generalization.},
  keywords={Three-dimensional displays;Data analysis;Operating systems;Education;Personal digital devices;Entertainment industry;Games;Transforms;Data structures;Sorting;gamification;e-learning;student engagement},
  doi={10.1109/ICEECT61758.2024.10739152},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8601215,
  author={Betchoo, Nirmal Kumar},
  booktitle={2018 International Conference on Intelligent and Innovative Computing Applications (ICONIC)}, 
  title={Resource Leveraging and Teaching Computing in the New Lower Secondary Mauritian Curriculum}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={The Ministry of Information Technology, Information and Communication, under the aegis of the Mauritian government aims at developing digital learning to improve the potential of Mauritian students for the future. As the country posits itself as a cyber-island with a fully developed information technology hub, it has become imperative to think about leveraging the teaching of computer science in lower secondary schools (Grades 7-9). So far, this has been limited to basic courses in computing that are essentially theory focused. This paper states that students at this stated level need to develop `computational thinking' so that they are ready for the workplace and will effectively enter the digital world. It limits itself to two key variables resource leveraging and teaching computing. In the first case, it raises arguments on programming languages, hardware and software that might apply to students in the new curriculum. In the teaching area, the paper suggests that a combination of teaching programming, inclusion and informal learning will be the possibilities to accompany students overcome the digital divide and get the opportunity to become effective as learners and trained ICT students to serve their nation.},
  keywords={Education;Programming profession;Software;Computer languages;Information technology;resource leveraging;teaching;programming;software;digital divide;lower secondary;Mauritius},
  doi={10.1109/ICONIC.2018.8601215},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10908001,
  author={Zhang, Xiuxiu and Guan, Xiaowei and Wang, Ying and Guan, Hao},
  booktitle={2024 International Symposium on Digital Home (ISDH)}, 
  title={Design and Implementation of a Programmable Dynamic Geometry System with Support for Reverse Debugging}, 
  year={2024},
  volume={},
  number={},
  pages={278-283},
  abstract={Dynamic geometry systems (DGS) are widely used in mathematics education to enhance students' thinking skills through geometric exploration. Integrating programming into DGS fosters both mathematical and computational thinking. However, research on reverse debugging design for programmable dynamic geometry systems is limited, and existing systems fail to meet the needs for operation reversal. To address this, this paper proposes a programming environment that supports reverse debugging, aiming to overcome the limitations of current programmable dynamic geometry systems in debugging. We abstracted dynamic geometry operations and defined three types of drawing instructions. To ensure sequential execution and debugging, we designed a debuggable sequential execution algorithm, followed by a reverse debugging control algorithm. The effectiveness of the system is verified by experiments.},
  keywords={Geometry;Heuristic algorithms;Education;Debugging;Dynamic programming;Programming profession;Programming environments;programmable dynamic geometry system;debugging;reverse debugging},
  doi={10.1109/ISDH64927.2024.00053},
  ISSN={2769-8823},
  month={Nov},}@INPROCEEDINGS{6934152,
  author={Leanna Prater, M. A. and Mazur, Joan M.},
  booktitle={2014 Computer Games: AI, Animation, Mobile, Multimedia, Educational and Serious Games (CGAMES)}, 
  title={Embedded standards-based digital gaming assessments: Pilot study with teachers}, 
  year={2014},
  volume={},
  number={},
  pages={1-5},
  abstract={Although the research on digital gaming has recently shown that collaboration, problem solving and critical thinking are in evidence with K-12 students who design games; researchers still need to make the case that digital game design content meets rigorous new Common Core standards for Language Arts and mathematics. No class time will be devoted to game design unless proponents of digital gaming can develop and demonstrate this argument. This preliminary data focus on a feasibility implementation of an assessment designed to embed these standards. Three elementary level classroom teachers and their students used the process and demonstrated that (1) teachers can learn to design and use this process and (2) their students demonstrate elements of computational thinking that not only includes the Common Core standards but extends them.},
  keywords={Games;Educational institutions;Standards;Software;Programming;digital games;Common Core;assessment},
  doi={10.1109/CGames.2014.6934152},
  ISSN={},
  month={July},}@ARTICLE{9969919,
  author={Gomez, Manuel J. and Ruipérez-Valiente, José A. and Clemente, Félix J. García},
  journal={IEEE Transactions on Learning Technologies}, 
  title={A Systematic Literature Review of Game-Based Assessment Studies: Trends and Challenges}, 
  year={2023},
  volume={16},
  number={4},
  pages={500-515},
  abstract={Technology has become an essential part of our everyday life, and its use in educational environments keeps growing. In addition, games are one of the most popular activities across cultures and ages, and there is ample evidence that supports the benefits of using games for assessment. This field is commonly known as game-based assessment (GBA), which refers to the use of games to assess learners' competencies, skills, or knowledge. In this article, we analyze the current status of the GBA field by performing the first systematic literature review on empirical GBA studies. It is based on 65 research papers that used digital GBAs to determine: the context where the study has been applied, the primary purpose, the domain of the game used, game/tool availability, the size of the data sample, the computational methods and algorithms applied, the targeted stakeholders of the study, and what limitations and challenges are reported by authors. Based on the categories established and our analysis, the findings suggest that GBAs are mainly used in K-16 education and for assessment purposes, and that most GBAs focus on assessing STEM content, and cognitive and soft skills. Furthermore, the current limitations indicate that future GBA research would benefit from the use of bigger data samples and more specialized algorithms. Based on our results, we discuss current trends in the field and open challenges (including replication and validation problems), providing recommendations for the future research agenda of the GBA field.},
  keywords={Games;Systematics;Education;Databases;Bibliographies;Video games;Market research;Educational technology;game-based assessment (GBA);game-based learning (GBL)},
  doi={10.1109/TLT.2022.3226661},
  ISSN={1939-1382},
  month={Aug},}@INPROCEEDINGS{9620625,
  author={Shaw, Mia S. and Ji, GaYeon and Zhang, Yi and Kafai, Yasmin B.},
  booktitle={2021 Conference on Research in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT)}, 
  title={Promoting socio-political identification with computer science: How high school youth restory their identities through electronic textile quilts}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={While many initiatives have broadened participation of minoritized youth in K-12 computing education, far fewer efforts have focused on expanding the social, political and cultural contexts of CS identity development. In this study, we propose a “restorying” pedagogy which engaged high school youth in interrogating dominant narratives about computer science through collaborative, electronic textile quilt-making. In our social design experiment approach, we designed and implemented a workshop where 14 racially- and ethnically-diverse youth crafted and coded interactive quilt patches that were digitally “stitched” into a collaborative artifact, with each patch reimagining CS from youths' perspectives (particularly regarding what CS is, who can participate in CS, and how CS is done). By analyzing post-workshop interviews and participant artifacts, we observed that counterstorytelling through electronic quilting can act as accessible and authentic tools to support youth's political identity work, electronic counternarrative expression, and community building in computing education. In the discussion, we address how restorying can contribute towards developing self-authored identities and critical computational literacies among youth and educators, as well as political solidarity within CS learning environments.},
  keywords={Computer science;Smart textiles;Ethics;Education;Collaboration;Tools;Logic gates;Identity;electronic textiles;counternarratives},
  doi={10.1109/RESPECT51740.2021.9620625},
  ISSN={},
  month={May},}@INPROCEEDINGS{8744115,
  author={Soriano, Arturo and Ponce, Pedro and Molina, Arturo},
  booktitle={2019 20th International Conference on Research and Education in Mechatronics (REM)}, 
  title={A Novel Design of Virtual Laboratory}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid growth of the manufacturing, automotive, robotics, and smart-grid industries will require engineers that posses attributes related to multidisciplinary formation and strong tools to design solutions to complex problems. The engineer's formation requires to include the development of multidisciplinary abilities into their programs and backing the theory with real-world practice. In this sense, specialized laboratories are necessary in order to carry out this kind of formation and training. However, the lack of specialized laboratories is one of the main obstacles preventing us from reaching this objective. The specialized laboratories require specialized installation, maintenance and cost management as well as a design that can accommodate a large number of students. In contrast, the virtual laboratories are one tool that can be used to deal with both issues which are the lack of specialized engineers and the absence of specialized laboratories. This work proposes a new design of a virtual laboratory in order to specialize engineers in several fields such as power electronics, electric machines, automatic control, and information and computational technologies. The laboratory proposed includes tools such as co-simulation, co-modeling, and co-design in order to face complex problems within the industry.},
  keywords={Mathematical model;Industries;Tools;Service robots;Power electronics;Virtual laboratory;co-simulation;co-design;co-modelling},
  doi={10.1109/REM.2019.8744115},
  ISSN={},
  month={May},}@INBOOK{9388156,
  author={Sengupta, Pratim and Dickes, Amanda and Farris, Amy Voss},
  booktitle={Voicing Code in STEM: A Dialogical Imagination}, 
  title={8 Computational Heterogeneity: A Radical Reflection}, 
  year={2021},
  volume={},
  number={},
  pages={191-209},
  abstract={In Experience and Education, Dewey argued that humankind is “given to formulating its beliefs in terms of Either-Ors, between which it recognizes no intermediate possibilities.” Not surprisingly, educational computing is no exception. One such Either-Or binary that is relevant to our project so far is computing vs. computational thinking.2 A keynote address delivered recently at a computing education conference by the computer scientist and educator Judy Robertson is quite illuminating in this respect.3 Robertson argued against a blind emphasis on computational “thinking” as the centerpiece of computational literacy. Focusing only on creating SCRATCH programs may lead especially young learners away from understanding how the computer actually works as a “machine.” Children's drawings of what is inside a computer show that learning to use computational abstractions that we typically introduce in the K-12 levels—such as variables and loops—does not necessarily help us understand how these abstractions are processed and represented inside the computer. What gets lost in our push to teach children how to code is the physicality of computing as a machine, which involves a deeper understanding of the relationship between the hardware and software—and many other forms of computational abstractions that are not even presented to children as part of their experience of coding or computing.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262363075},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/9388156},}
